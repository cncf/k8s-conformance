I0418 08:25:52.766281      18 e2e.go:116] Starting e2e run "c5fadca4-7a0b-4c11-b8d1-508daf2cfdb2" on Ginkgo node 1
Apr 18 08:25:52.778: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1681806352 - will randomize all specs

Will run 362 of 7067 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Apr 18 08:25:52.856: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:25:52.857: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 18 08:25:52.873: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 18 08:25:52.893: INFO: 10 / 10 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 18 08:25:52.893: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Apr 18 08:25:52.893: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 18 08:25:52.898: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'everest-csi-driver' (0 seconds elapsed)
Apr 18 08:25:52.898: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'icagent' (0 seconds elapsed)
Apr 18 08:25:52.898: INFO: e2e test version: v1.25.0
Apr 18 08:25:52.900: INFO: kube-apiserver version: v1.25.2-r0-CCE22.12.1
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Apr 18 08:25:52.900: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:25:52.904: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.050 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Apr 18 08:25:52.856: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:25:52.857: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Apr 18 08:25:52.873: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Apr 18 08:25:52.893: INFO: 10 / 10 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Apr 18 08:25:52.893: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
    Apr 18 08:25:52.893: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Apr 18 08:25:52.898: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'everest-csi-driver' (0 seconds elapsed)
    Apr 18 08:25:52.898: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'icagent' (0 seconds elapsed)
    Apr 18 08:25:52.898: INFO: e2e test version: v1.25.0
    Apr 18 08:25:52.900: INFO: kube-apiserver version: v1.25.2-r0-CCE22.12.1
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Apr 18 08:25:52.900: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:25:52.904: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:25:52.921
Apr 18 08:25:52.921: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename gc 04/18/23 08:25:52.922
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:25:52.937
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:25:52.943
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 04/18/23 08:25:52.954
STEP: create the rc2 04/18/23 08:25:52.959
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 04/18/23 08:25:57.969
STEP: delete the rc simpletest-rc-to-be-deleted 04/18/23 08:25:58.072
STEP: wait for the rc to be deleted 04/18/23 08:25:58.077
STEP: Gathering metrics 04/18/23 08:26:03.086
W0418 08:26:03.095394      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 18 08:26:03.095: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr 18 08:26:03.095: INFO: Deleting pod "simpletest-rc-to-be-deleted-24sx8" in namespace "gc-7356"
Apr 18 08:26:03.106: INFO: Deleting pod "simpletest-rc-to-be-deleted-4j6tt" in namespace "gc-7356"
Apr 18 08:26:03.117: INFO: Deleting pod "simpletest-rc-to-be-deleted-55p8v" in namespace "gc-7356"
Apr 18 08:26:03.134: INFO: Deleting pod "simpletest-rc-to-be-deleted-6jksf" in namespace "gc-7356"
Apr 18 08:26:03.150: INFO: Deleting pod "simpletest-rc-to-be-deleted-79mtt" in namespace "gc-7356"
Apr 18 08:26:03.165: INFO: Deleting pod "simpletest-rc-to-be-deleted-9ct8s" in namespace "gc-7356"
Apr 18 08:26:03.181: INFO: Deleting pod "simpletest-rc-to-be-deleted-9mnp8" in namespace "gc-7356"
Apr 18 08:26:03.193: INFO: Deleting pod "simpletest-rc-to-be-deleted-cmvvq" in namespace "gc-7356"
Apr 18 08:26:03.199: INFO: Deleting pod "simpletest-rc-to-be-deleted-cw826" in namespace "gc-7356"
Apr 18 08:26:03.207: INFO: Deleting pod "simpletest-rc-to-be-deleted-fbx2k" in namespace "gc-7356"
Apr 18 08:26:03.215: INFO: Deleting pod "simpletest-rc-to-be-deleted-fmq2b" in namespace "gc-7356"
Apr 18 08:26:03.225: INFO: Deleting pod "simpletest-rc-to-be-deleted-gqslm" in namespace "gc-7356"
Apr 18 08:26:03.233: INFO: Deleting pod "simpletest-rc-to-be-deleted-hc6cl" in namespace "gc-7356"
Apr 18 08:26:03.245: INFO: Deleting pod "simpletest-rc-to-be-deleted-hkjqf" in namespace "gc-7356"
Apr 18 08:26:03.261: INFO: Deleting pod "simpletest-rc-to-be-deleted-j58xc" in namespace "gc-7356"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 18 08:26:03.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7356" for this suite. 04/18/23 08:26:03.273
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":1,"skipped":16,"failed":0}
------------------------------
• [SLOW TEST] [10.356 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:25:52.921
    Apr 18 08:25:52.921: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename gc 04/18/23 08:25:52.922
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:25:52.937
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:25:52.943
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 04/18/23 08:25:52.954
    STEP: create the rc2 04/18/23 08:25:52.959
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 04/18/23 08:25:57.969
    STEP: delete the rc simpletest-rc-to-be-deleted 04/18/23 08:25:58.072
    STEP: wait for the rc to be deleted 04/18/23 08:25:58.077
    STEP: Gathering metrics 04/18/23 08:26:03.086
    W0418 08:26:03.095394      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 18 08:26:03.095: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Apr 18 08:26:03.095: INFO: Deleting pod "simpletest-rc-to-be-deleted-24sx8" in namespace "gc-7356"
    Apr 18 08:26:03.106: INFO: Deleting pod "simpletest-rc-to-be-deleted-4j6tt" in namespace "gc-7356"
    Apr 18 08:26:03.117: INFO: Deleting pod "simpletest-rc-to-be-deleted-55p8v" in namespace "gc-7356"
    Apr 18 08:26:03.134: INFO: Deleting pod "simpletest-rc-to-be-deleted-6jksf" in namespace "gc-7356"
    Apr 18 08:26:03.150: INFO: Deleting pod "simpletest-rc-to-be-deleted-79mtt" in namespace "gc-7356"
    Apr 18 08:26:03.165: INFO: Deleting pod "simpletest-rc-to-be-deleted-9ct8s" in namespace "gc-7356"
    Apr 18 08:26:03.181: INFO: Deleting pod "simpletest-rc-to-be-deleted-9mnp8" in namespace "gc-7356"
    Apr 18 08:26:03.193: INFO: Deleting pod "simpletest-rc-to-be-deleted-cmvvq" in namespace "gc-7356"
    Apr 18 08:26:03.199: INFO: Deleting pod "simpletest-rc-to-be-deleted-cw826" in namespace "gc-7356"
    Apr 18 08:26:03.207: INFO: Deleting pod "simpletest-rc-to-be-deleted-fbx2k" in namespace "gc-7356"
    Apr 18 08:26:03.215: INFO: Deleting pod "simpletest-rc-to-be-deleted-fmq2b" in namespace "gc-7356"
    Apr 18 08:26:03.225: INFO: Deleting pod "simpletest-rc-to-be-deleted-gqslm" in namespace "gc-7356"
    Apr 18 08:26:03.233: INFO: Deleting pod "simpletest-rc-to-be-deleted-hc6cl" in namespace "gc-7356"
    Apr 18 08:26:03.245: INFO: Deleting pod "simpletest-rc-to-be-deleted-hkjqf" in namespace "gc-7356"
    Apr 18 08:26:03.261: INFO: Deleting pod "simpletest-rc-to-be-deleted-j58xc" in namespace "gc-7356"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 18 08:26:03.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7356" for this suite. 04/18/23 08:26:03.273
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:26:03.277
Apr 18 08:26:03.277: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubelet-test 04/18/23 08:26:03.278
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:26:03.288
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:26:03.292
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Apr 18 08:26:03.301: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1" in namespace "kubelet-test-2361" to be "running and ready"
Apr 18 08:26:03.304: INFO: Pod "busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.411023ms
Apr 18 08:26:03.304: INFO: The phase of Pod busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:26:05.309: INFO: Pod "busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007561966s
Apr 18 08:26:05.309: INFO: The phase of Pod busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:26:07.309: INFO: Pod "busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007610733s
Apr 18 08:26:07.309: INFO: The phase of Pod busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:26:09.308: INFO: Pod "busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006581395s
Apr 18 08:26:09.308: INFO: The phase of Pod busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:26:11.308: INFO: Pod "busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1": Phase="Running", Reason="", readiness=true. Elapsed: 8.006650635s
Apr 18 08:26:11.308: INFO: The phase of Pod busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1 is Running (Ready = true)
Apr 18 08:26:11.308: INFO: Pod "busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 18 08:26:11.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2361" for this suite. 04/18/23 08:26:11.327
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":2,"skipped":19,"failed":0}
------------------------------
• [SLOW TEST] [8.054 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:26:03.277
    Apr 18 08:26:03.277: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubelet-test 04/18/23 08:26:03.278
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:26:03.288
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:26:03.292
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Apr 18 08:26:03.301: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1" in namespace "kubelet-test-2361" to be "running and ready"
    Apr 18 08:26:03.304: INFO: Pod "busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.411023ms
    Apr 18 08:26:03.304: INFO: The phase of Pod busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:26:05.309: INFO: Pod "busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007561966s
    Apr 18 08:26:05.309: INFO: The phase of Pod busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:26:07.309: INFO: Pod "busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007610733s
    Apr 18 08:26:07.309: INFO: The phase of Pod busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:26:09.308: INFO: Pod "busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006581395s
    Apr 18 08:26:09.308: INFO: The phase of Pod busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:26:11.308: INFO: Pod "busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1": Phase="Running", Reason="", readiness=true. Elapsed: 8.006650635s
    Apr 18 08:26:11.308: INFO: The phase of Pod busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1 is Running (Ready = true)
    Apr 18 08:26:11.308: INFO: Pod "busybox-readonly-fsf1936a8d-e1a1-4cd3-b20e-bae6dede97d1" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 18 08:26:11.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-2361" for this suite. 04/18/23 08:26:11.327
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:26:11.332
Apr 18 08:26:11.333: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename secrets 04/18/23 08:26:11.333
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:26:11.345
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:26:11.348
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-f13b0e73-e648-4584-b7ea-88b7c46a99b7 04/18/23 08:26:11.352
STEP: Creating a pod to test consume secrets 04/18/23 08:26:11.355
Apr 18 08:26:11.362: INFO: Waiting up to 5m0s for pod "pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db" in namespace "secrets-2712" to be "Succeeded or Failed"
Apr 18 08:26:11.365: INFO: Pod "pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db": Phase="Pending", Reason="", readiness=false. Elapsed: 3.196448ms
Apr 18 08:26:13.369: INFO: Pod "pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007063415s
Apr 18 08:26:15.369: INFO: Pod "pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006393844s
Apr 18 08:26:17.369: INFO: Pod "pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007221275s
STEP: Saw pod success 04/18/23 08:26:17.369
Apr 18 08:26:17.370: INFO: Pod "pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db" satisfied condition "Succeeded or Failed"
Apr 18 08:26:17.372: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 08:26:17.378
Apr 18 08:26:17.387: INFO: Waiting for pod pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db to disappear
Apr 18 08:26:17.389: INFO: Pod pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 08:26:17.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2712" for this suite. 04/18/23 08:26:17.393
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":3,"skipped":68,"failed":0}
------------------------------
• [SLOW TEST] [6.066 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:26:11.332
    Apr 18 08:26:11.333: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename secrets 04/18/23 08:26:11.333
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:26:11.345
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:26:11.348
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-f13b0e73-e648-4584-b7ea-88b7c46a99b7 04/18/23 08:26:11.352
    STEP: Creating a pod to test consume secrets 04/18/23 08:26:11.355
    Apr 18 08:26:11.362: INFO: Waiting up to 5m0s for pod "pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db" in namespace "secrets-2712" to be "Succeeded or Failed"
    Apr 18 08:26:11.365: INFO: Pod "pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db": Phase="Pending", Reason="", readiness=false. Elapsed: 3.196448ms
    Apr 18 08:26:13.369: INFO: Pod "pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007063415s
    Apr 18 08:26:15.369: INFO: Pod "pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006393844s
    Apr 18 08:26:17.369: INFO: Pod "pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007221275s
    STEP: Saw pod success 04/18/23 08:26:17.369
    Apr 18 08:26:17.370: INFO: Pod "pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db" satisfied condition "Succeeded or Failed"
    Apr 18 08:26:17.372: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 08:26:17.378
    Apr 18 08:26:17.387: INFO: Waiting for pod pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db to disappear
    Apr 18 08:26:17.389: INFO: Pod pod-secrets-33de176d-11fc-4c76-ae9b-e80682b545db no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 08:26:17.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2712" for this suite. 04/18/23 08:26:17.393
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:26:17.399
Apr 18 08:26:17.399: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename var-expansion 04/18/23 08:26:17.4
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:26:17.408
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:26:17.412
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 04/18/23 08:26:17.416
STEP: waiting for pod running 04/18/23 08:26:17.423
Apr 18 08:26:17.423: INFO: Waiting up to 2m0s for pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29" in namespace "var-expansion-2315" to be "running"
Apr 18 08:26:17.425: INFO: Pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.443388ms
Apr 18 08:26:19.429: INFO: Pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29": Phase="Running", Reason="", readiness=true. Elapsed: 2.005814845s
Apr 18 08:26:19.429: INFO: Pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29" satisfied condition "running"
STEP: creating a file in subpath 04/18/23 08:26:19.429
Apr 18 08:26:19.432: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-2315 PodName:var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:26:19.432: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:26:19.432: INFO: ExecWithOptions: Clientset creation
Apr 18 08:26:19.432: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/var-expansion-2315/pods/var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 04/18/23 08:26:19.525
Apr 18 08:26:19.528: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-2315 PodName:var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:26:19.528: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:26:19.528: INFO: ExecWithOptions: Clientset creation
Apr 18 08:26:19.528: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/var-expansion-2315/pods/var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 04/18/23 08:26:19.575
Apr 18 08:26:20.085: INFO: Successfully updated pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29"
STEP: waiting for annotated pod running 04/18/23 08:26:20.085
Apr 18 08:26:20.085: INFO: Waiting up to 2m0s for pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29" in namespace "var-expansion-2315" to be "running"
Apr 18 08:26:20.088: INFO: Pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29": Phase="Running", Reason="", readiness=true. Elapsed: 2.546139ms
Apr 18 08:26:20.088: INFO: Pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29" satisfied condition "running"
STEP: deleting the pod gracefully 04/18/23 08:26:20.088
Apr 18 08:26:20.088: INFO: Deleting pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29" in namespace "var-expansion-2315"
Apr 18 08:26:20.093: INFO: Wait up to 5m0s for pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 08:26:54.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2315" for this suite. 04/18/23 08:26:54.106
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":4,"skipped":69,"failed":0}
------------------------------
• [SLOW TEST] [36.715 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:26:17.399
    Apr 18 08:26:17.399: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename var-expansion 04/18/23 08:26:17.4
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:26:17.408
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:26:17.412
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 04/18/23 08:26:17.416
    STEP: waiting for pod running 04/18/23 08:26:17.423
    Apr 18 08:26:17.423: INFO: Waiting up to 2m0s for pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29" in namespace "var-expansion-2315" to be "running"
    Apr 18 08:26:17.425: INFO: Pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.443388ms
    Apr 18 08:26:19.429: INFO: Pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29": Phase="Running", Reason="", readiness=true. Elapsed: 2.005814845s
    Apr 18 08:26:19.429: INFO: Pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29" satisfied condition "running"
    STEP: creating a file in subpath 04/18/23 08:26:19.429
    Apr 18 08:26:19.432: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-2315 PodName:var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:26:19.432: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:26:19.432: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:26:19.432: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/var-expansion-2315/pods/var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 04/18/23 08:26:19.525
    Apr 18 08:26:19.528: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-2315 PodName:var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:26:19.528: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:26:19.528: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:26:19.528: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/var-expansion-2315/pods/var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 04/18/23 08:26:19.575
    Apr 18 08:26:20.085: INFO: Successfully updated pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29"
    STEP: waiting for annotated pod running 04/18/23 08:26:20.085
    Apr 18 08:26:20.085: INFO: Waiting up to 2m0s for pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29" in namespace "var-expansion-2315" to be "running"
    Apr 18 08:26:20.088: INFO: Pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29": Phase="Running", Reason="", readiness=true. Elapsed: 2.546139ms
    Apr 18 08:26:20.088: INFO: Pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29" satisfied condition "running"
    STEP: deleting the pod gracefully 04/18/23 08:26:20.088
    Apr 18 08:26:20.088: INFO: Deleting pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29" in namespace "var-expansion-2315"
    Apr 18 08:26:20.093: INFO: Wait up to 5m0s for pod "var-expansion-cc38afbb-24e3-4a97-863d-cfb8decbcc29" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 08:26:54.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2315" for this suite. 04/18/23 08:26:54.106
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:26:54.115
Apr 18 08:26:54.115: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 08:26:54.116
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:26:54.129
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:26:54.132
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 08:26:54.156
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:26:54.646
STEP: Deploying the webhook pod 04/18/23 08:26:54.653
STEP: Wait for the deployment to be ready 04/18/23 08:26:54.663
Apr 18 08:26:54.668: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 04/18/23 08:26:56.677
STEP: Verifying the service has paired with the endpoint 04/18/23 08:26:56.685
Apr 18 08:26:57.685: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 04/18/23 08:26:57.689
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 04/18/23 08:26:57.691
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 04/18/23 08:26:57.691
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 04/18/23 08:26:57.691
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 04/18/23 08:26:57.693
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 04/18/23 08:26:57.693
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 04/18/23 08:26:57.695
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 08:26:57.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4080" for this suite. 04/18/23 08:26:57.699
STEP: Destroying namespace "webhook-4080-markers" for this suite. 04/18/23 08:26:57.704
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":5,"skipped":94,"failed":0}
------------------------------
• [3.623 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:26:54.115
    Apr 18 08:26:54.115: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 08:26:54.116
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:26:54.129
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:26:54.132
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 08:26:54.156
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:26:54.646
    STEP: Deploying the webhook pod 04/18/23 08:26:54.653
    STEP: Wait for the deployment to be ready 04/18/23 08:26:54.663
    Apr 18 08:26:54.668: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 04/18/23 08:26:56.677
    STEP: Verifying the service has paired with the endpoint 04/18/23 08:26:56.685
    Apr 18 08:26:57.685: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 04/18/23 08:26:57.689
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 04/18/23 08:26:57.691
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 04/18/23 08:26:57.691
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 04/18/23 08:26:57.691
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 04/18/23 08:26:57.693
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 04/18/23 08:26:57.693
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 04/18/23 08:26:57.695
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 08:26:57.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4080" for this suite. 04/18/23 08:26:57.699
    STEP: Destroying namespace "webhook-4080-markers" for this suite. 04/18/23 08:26:57.704
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:26:57.738
Apr 18 08:26:57.739: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename configmap 04/18/23 08:26:57.739
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:26:57.754
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:26:57.76
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-c86742a0-219e-42ec-8104-ff78012ad7d5 04/18/23 08:26:57.768
STEP: Creating the pod 04/18/23 08:26:57.772
Apr 18 08:26:57.780: INFO: Waiting up to 5m0s for pod "pod-configmaps-c24a9241-6d3c-4738-bd85-6ceace7a8123" in namespace "configmap-3780" to be "running"
Apr 18 08:26:57.783: INFO: Pod "pod-configmaps-c24a9241-6d3c-4738-bd85-6ceace7a8123": Phase="Pending", Reason="", readiness=false. Elapsed: 2.837489ms
Apr 18 08:26:59.788: INFO: Pod "pod-configmaps-c24a9241-6d3c-4738-bd85-6ceace7a8123": Phase="Running", Reason="", readiness=false. Elapsed: 2.007351606s
Apr 18 08:26:59.788: INFO: Pod "pod-configmaps-c24a9241-6d3c-4738-bd85-6ceace7a8123" satisfied condition "running"
STEP: Waiting for pod with text data 04/18/23 08:26:59.788
STEP: Waiting for pod with binary data 04/18/23 08:26:59.793
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 08:26:59.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3780" for this suite. 04/18/23 08:26:59.803
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":6,"skipped":97,"failed":0}
------------------------------
• [2.068 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:26:57.738
    Apr 18 08:26:57.739: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename configmap 04/18/23 08:26:57.739
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:26:57.754
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:26:57.76
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-c86742a0-219e-42ec-8104-ff78012ad7d5 04/18/23 08:26:57.768
    STEP: Creating the pod 04/18/23 08:26:57.772
    Apr 18 08:26:57.780: INFO: Waiting up to 5m0s for pod "pod-configmaps-c24a9241-6d3c-4738-bd85-6ceace7a8123" in namespace "configmap-3780" to be "running"
    Apr 18 08:26:57.783: INFO: Pod "pod-configmaps-c24a9241-6d3c-4738-bd85-6ceace7a8123": Phase="Pending", Reason="", readiness=false. Elapsed: 2.837489ms
    Apr 18 08:26:59.788: INFO: Pod "pod-configmaps-c24a9241-6d3c-4738-bd85-6ceace7a8123": Phase="Running", Reason="", readiness=false. Elapsed: 2.007351606s
    Apr 18 08:26:59.788: INFO: Pod "pod-configmaps-c24a9241-6d3c-4738-bd85-6ceace7a8123" satisfied condition "running"
    STEP: Waiting for pod with text data 04/18/23 08:26:59.788
    STEP: Waiting for pod with binary data 04/18/23 08:26:59.793
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 08:26:59.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3780" for this suite. 04/18/23 08:26:59.803
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:26:59.809
Apr 18 08:26:59.809: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename watch 04/18/23 08:26:59.81
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:26:59.825
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:26:59.829
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 04/18/23 08:26:59.832
STEP: creating a watch on configmaps with label B 04/18/23 08:26:59.834
STEP: creating a watch on configmaps with label A or B 04/18/23 08:26:59.836
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 04/18/23 08:26:59.837
Apr 18 08:26:59.841: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168460 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 08:26:59.841: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168460 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 04/18/23 08:26:59.841
Apr 18 08:26:59.851: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168461 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 08:26:59.851: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168461 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 04/18/23 08:26:59.851
Apr 18 08:26:59.859: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168462 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 08:26:59.859: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168462 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 04/18/23 08:26:59.859
Apr 18 08:26:59.863: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168463 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 08:26:59.863: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168463 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 04/18/23 08:26:59.863
Apr 18 08:26:59.869: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5303  010fde6e-8597-49b5-bea1-ecc3ae96ff3c 4168464 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 08:26:59.869: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5303  010fde6e-8597-49b5-bea1-ecc3ae96ff3c 4168464 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 04/18/23 08:27:09.869
Apr 18 08:27:09.874: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5303  010fde6e-8597-49b5-bea1-ecc3ae96ff3c 4168525 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 08:27:09.874: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5303  010fde6e-8597-49b5-bea1-ecc3ae96ff3c 4168525 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 18 08:27:19.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5303" for this suite. 04/18/23 08:27:19.881
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":7,"skipped":129,"failed":0}
------------------------------
• [SLOW TEST] [20.076 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:26:59.809
    Apr 18 08:26:59.809: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename watch 04/18/23 08:26:59.81
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:26:59.825
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:26:59.829
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 04/18/23 08:26:59.832
    STEP: creating a watch on configmaps with label B 04/18/23 08:26:59.834
    STEP: creating a watch on configmaps with label A or B 04/18/23 08:26:59.836
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 04/18/23 08:26:59.837
    Apr 18 08:26:59.841: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168460 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 08:26:59.841: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168460 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 04/18/23 08:26:59.841
    Apr 18 08:26:59.851: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168461 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 08:26:59.851: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168461 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 04/18/23 08:26:59.851
    Apr 18 08:26:59.859: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168462 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 08:26:59.859: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168462 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 04/18/23 08:26:59.859
    Apr 18 08:26:59.863: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168463 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 08:26:59.863: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5303  7a2008bc-76d4-4db1-8501-5d6df824b91c 4168463 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 04/18/23 08:26:59.863
    Apr 18 08:26:59.869: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5303  010fde6e-8597-49b5-bea1-ecc3ae96ff3c 4168464 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 08:26:59.869: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5303  010fde6e-8597-49b5-bea1-ecc3ae96ff3c 4168464 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 04/18/23 08:27:09.869
    Apr 18 08:27:09.874: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5303  010fde6e-8597-49b5-bea1-ecc3ae96ff3c 4168525 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 08:27:09.874: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5303  010fde6e-8597-49b5-bea1-ecc3ae96ff3c 4168525 0 2023-04-18 08:26:59 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 08:26:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 18 08:27:19.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-5303" for this suite. 04/18/23 08:27:19.881
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:27:19.886
Apr 18 08:27:19.886: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 08:27:19.887
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:27:19.898
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:27:19.901
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-769db0e1-5d3c-46ee-baae-6d717d53d0c3 04/18/23 08:27:19.91
STEP: Creating the pod 04/18/23 08:27:19.914
Apr 18 08:27:19.920: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d7efb6e8-884c-4e90-8a55-468c15831adb" in namespace "projected-4" to be "running and ready"
Apr 18 08:27:19.923: INFO: Pod "pod-projected-configmaps-d7efb6e8-884c-4e90-8a55-468c15831adb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.589505ms
Apr 18 08:27:19.923: INFO: The phase of Pod pod-projected-configmaps-d7efb6e8-884c-4e90-8a55-468c15831adb is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:27:21.926: INFO: Pod "pod-projected-configmaps-d7efb6e8-884c-4e90-8a55-468c15831adb": Phase="Running", Reason="", readiness=true. Elapsed: 2.005788388s
Apr 18 08:27:21.926: INFO: The phase of Pod pod-projected-configmaps-d7efb6e8-884c-4e90-8a55-468c15831adb is Running (Ready = true)
Apr 18 08:27:21.926: INFO: Pod "pod-projected-configmaps-d7efb6e8-884c-4e90-8a55-468c15831adb" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-769db0e1-5d3c-46ee-baae-6d717d53d0c3 04/18/23 08:27:21.934
STEP: waiting to observe update in volume 04/18/23 08:27:21.938
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 08:28:34.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4" for this suite. 04/18/23 08:28:34.193
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":8,"skipped":138,"failed":0}
------------------------------
• [SLOW TEST] [74.312 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:27:19.886
    Apr 18 08:27:19.886: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 08:27:19.887
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:27:19.898
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:27:19.901
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-769db0e1-5d3c-46ee-baae-6d717d53d0c3 04/18/23 08:27:19.91
    STEP: Creating the pod 04/18/23 08:27:19.914
    Apr 18 08:27:19.920: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d7efb6e8-884c-4e90-8a55-468c15831adb" in namespace "projected-4" to be "running and ready"
    Apr 18 08:27:19.923: INFO: Pod "pod-projected-configmaps-d7efb6e8-884c-4e90-8a55-468c15831adb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.589505ms
    Apr 18 08:27:19.923: INFO: The phase of Pod pod-projected-configmaps-d7efb6e8-884c-4e90-8a55-468c15831adb is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:27:21.926: INFO: Pod "pod-projected-configmaps-d7efb6e8-884c-4e90-8a55-468c15831adb": Phase="Running", Reason="", readiness=true. Elapsed: 2.005788388s
    Apr 18 08:27:21.926: INFO: The phase of Pod pod-projected-configmaps-d7efb6e8-884c-4e90-8a55-468c15831adb is Running (Ready = true)
    Apr 18 08:27:21.926: INFO: Pod "pod-projected-configmaps-d7efb6e8-884c-4e90-8a55-468c15831adb" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-769db0e1-5d3c-46ee-baae-6d717d53d0c3 04/18/23 08:27:21.934
    STEP: waiting to observe update in volume 04/18/23 08:27:21.938
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 08:28:34.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4" for this suite. 04/18/23 08:28:34.193
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:28:34.199
Apr 18 08:28:34.199: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename svc-latency 04/18/23 08:28:34.199
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:28:34.212
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:28:34.218
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Apr 18 08:28:34.222: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6580 04/18/23 08:28:34.223
I0418 08:28:34.229372      18 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6580, replica count: 1
I0418 08:28:35.280765      18 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 08:28:36.282722      18 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 08:28:37.283061      18 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 08:28:38.283214      18 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 08:28:39.284141      18 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 08:28:39.391: INFO: Created: latency-svc-6qcjz
Apr 18 08:28:39.397: INFO: Got endpoints: latency-svc-6qcjz [12.856313ms]
Apr 18 08:28:39.405: INFO: Created: latency-svc-lpp5b
Apr 18 08:28:39.410: INFO: Got endpoints: latency-svc-lpp5b [13.017649ms]
Apr 18 08:28:39.414: INFO: Created: latency-svc-97dmd
Apr 18 08:28:39.418: INFO: Got endpoints: latency-svc-97dmd [20.98199ms]
Apr 18 08:28:39.423: INFO: Created: latency-svc-sp9pz
Apr 18 08:28:39.441: INFO: Got endpoints: latency-svc-sp9pz [44.364393ms]
Apr 18 08:28:39.449: INFO: Created: latency-svc-wfjww
Apr 18 08:28:39.457: INFO: Got endpoints: latency-svc-wfjww [60.033806ms]
Apr 18 08:28:39.458: INFO: Created: latency-svc-gmmpx
Apr 18 08:28:39.462: INFO: Got endpoints: latency-svc-gmmpx [64.73021ms]
Apr 18 08:28:39.465: INFO: Created: latency-svc-l85rb
Apr 18 08:28:39.471: INFO: Got endpoints: latency-svc-l85rb [73.412246ms]
Apr 18 08:28:39.471: INFO: Created: latency-svc-pj4w2
Apr 18 08:28:39.475: INFO: Got endpoints: latency-svc-pj4w2 [78.009791ms]
Apr 18 08:28:39.478: INFO: Created: latency-svc-j6db2
Apr 18 08:28:39.484: INFO: Got endpoints: latency-svc-j6db2 [86.402872ms]
Apr 18 08:28:39.486: INFO: Created: latency-svc-jblqg
Apr 18 08:28:39.489: INFO: Got endpoints: latency-svc-jblqg [91.336297ms]
Apr 18 08:28:39.491: INFO: Created: latency-svc-h4wbp
Apr 18 08:28:39.495: INFO: Got endpoints: latency-svc-h4wbp [97.88194ms]
Apr 18 08:28:39.499: INFO: Created: latency-svc-lcj6k
Apr 18 08:28:39.507: INFO: Got endpoints: latency-svc-lcj6k [109.596016ms]
Apr 18 08:28:39.508: INFO: Created: latency-svc-zx8c6
Apr 18 08:28:39.512: INFO: Got endpoints: latency-svc-zx8c6 [115.031155ms]
Apr 18 08:28:39.514: INFO: Created: latency-svc-vlvm4
Apr 18 08:28:39.520: INFO: Got endpoints: latency-svc-vlvm4 [122.856831ms]
Apr 18 08:28:39.520: INFO: Created: latency-svc-q98ts
Apr 18 08:28:39.523: INFO: Created: latency-svc-6wnh9
Apr 18 08:28:39.527: INFO: Got endpoints: latency-svc-q98ts [116.955371ms]
Apr 18 08:28:39.528: INFO: Got endpoints: latency-svc-6wnh9 [109.732315ms]
Apr 18 08:28:39.530: INFO: Created: latency-svc-lq28t
Apr 18 08:28:39.534: INFO: Got endpoints: latency-svc-lq28t [137.004732ms]
Apr 18 08:28:39.535: INFO: Created: latency-svc-xk5fr
Apr 18 08:28:39.539: INFO: Got endpoints: latency-svc-xk5fr [97.692298ms]
Apr 18 08:28:39.544: INFO: Created: latency-svc-7m5xj
Apr 18 08:28:39.551: INFO: Got endpoints: latency-svc-7m5xj [93.844475ms]
Apr 18 08:28:39.552: INFO: Created: latency-svc-q72kq
Apr 18 08:28:39.555: INFO: Got endpoints: latency-svc-q72kq [93.65743ms]
Apr 18 08:28:39.558: INFO: Created: latency-svc-8rwr5
Apr 18 08:28:39.561: INFO: Got endpoints: latency-svc-8rwr5 [89.926166ms]
Apr 18 08:28:39.561: INFO: Created: latency-svc-4rlwr
Apr 18 08:28:39.566: INFO: Got endpoints: latency-svc-4rlwr [168.800271ms]
Apr 18 08:28:39.567: INFO: Created: latency-svc-lm8dq
Apr 18 08:28:39.571: INFO: Got endpoints: latency-svc-lm8dq [95.645768ms]
Apr 18 08:28:39.571: INFO: Created: latency-svc-q5xl2
Apr 18 08:28:39.575: INFO: Got endpoints: latency-svc-q5xl2 [91.722005ms]
Apr 18 08:28:39.576: INFO: Created: latency-svc-gxlkk
Apr 18 08:28:39.580: INFO: Got endpoints: latency-svc-gxlkk [91.304261ms]
Apr 18 08:28:39.582: INFO: Created: latency-svc-xrmlk
Apr 18 08:28:39.586: INFO: Got endpoints: latency-svc-xrmlk [90.835337ms]
Apr 18 08:28:39.587: INFO: Created: latency-svc-mn6c7
Apr 18 08:28:39.592: INFO: Got endpoints: latency-svc-mn6c7 [85.399943ms]
Apr 18 08:28:39.593: INFO: Created: latency-svc-vnnvp
Apr 18 08:28:39.597: INFO: Got endpoints: latency-svc-vnnvp [84.458457ms]
Apr 18 08:28:39.599: INFO: Created: latency-svc-dmbhl
Apr 18 08:28:39.601: INFO: Got endpoints: latency-svc-dmbhl [81.322019ms]
Apr 18 08:28:39.604: INFO: Created: latency-svc-pvbcw
Apr 18 08:28:39.607: INFO: Got endpoints: latency-svc-pvbcw [80.419732ms]
Apr 18 08:28:39.610: INFO: Created: latency-svc-xgtck
Apr 18 08:28:39.614: INFO: Got endpoints: latency-svc-xgtck [85.849278ms]
Apr 18 08:28:39.616: INFO: Created: latency-svc-pxwcn
Apr 18 08:28:39.620: INFO: Got endpoints: latency-svc-pxwcn [85.681458ms]
Apr 18 08:28:39.621: INFO: Created: latency-svc-fl5gp
Apr 18 08:28:39.625: INFO: Got endpoints: latency-svc-fl5gp [85.794435ms]
Apr 18 08:28:39.626: INFO: Created: latency-svc-fpmcb
Apr 18 08:28:39.630: INFO: Got endpoints: latency-svc-fpmcb [78.998627ms]
Apr 18 08:28:39.631: INFO: Created: latency-svc-tb5rb
Apr 18 08:28:39.636: INFO: Got endpoints: latency-svc-tb5rb [80.301699ms]
Apr 18 08:28:39.637: INFO: Created: latency-svc-jgpqs
Apr 18 08:28:39.650: INFO: Got endpoints: latency-svc-jgpqs [89.475488ms]
Apr 18 08:28:39.651: INFO: Created: latency-svc-wkn4b
Apr 18 08:28:39.655: INFO: Got endpoints: latency-svc-wkn4b [88.957427ms]
Apr 18 08:28:39.657: INFO: Created: latency-svc-bkcwj
Apr 18 08:28:39.661: INFO: Got endpoints: latency-svc-bkcwj [90.275447ms]
Apr 18 08:28:39.663: INFO: Created: latency-svc-wt7pv
Apr 18 08:28:39.668: INFO: Got endpoints: latency-svc-wt7pv [92.245912ms]
Apr 18 08:28:39.669: INFO: Created: latency-svc-qfktq
Apr 18 08:28:39.674: INFO: Got endpoints: latency-svc-qfktq [94.079159ms]
Apr 18 08:28:39.675: INFO: Created: latency-svc-hjptj
Apr 18 08:28:39.680: INFO: Got endpoints: latency-svc-hjptj [94.205609ms]
Apr 18 08:28:39.681: INFO: Created: latency-svc-sfklm
Apr 18 08:28:39.685: INFO: Got endpoints: latency-svc-sfklm [92.475442ms]
Apr 18 08:28:39.687: INFO: Created: latency-svc-xrkd6
Apr 18 08:28:39.691: INFO: Got endpoints: latency-svc-xrkd6 [93.798123ms]
Apr 18 08:28:39.692: INFO: Created: latency-svc-z7dj7
Apr 18 08:28:39.700: INFO: Got endpoints: latency-svc-z7dj7 [98.225852ms]
Apr 18 08:28:39.701: INFO: Created: latency-svc-jn6l5
Apr 18 08:28:39.704: INFO: Got endpoints: latency-svc-jn6l5 [96.584828ms]
Apr 18 08:28:39.707: INFO: Created: latency-svc-sf4v9
Apr 18 08:28:39.710: INFO: Got endpoints: latency-svc-sf4v9 [95.949729ms]
Apr 18 08:28:39.713: INFO: Created: latency-svc-qhszd
Apr 18 08:28:39.716: INFO: Got endpoints: latency-svc-qhszd [96.178057ms]
Apr 18 08:28:39.719: INFO: Created: latency-svc-7bwvr
Apr 18 08:28:39.722: INFO: Got endpoints: latency-svc-7bwvr [97.434774ms]
Apr 18 08:28:39.725: INFO: Created: latency-svc-sls26
Apr 18 08:28:39.731: INFO: Created: latency-svc-6fb4b
Apr 18 08:28:39.731: INFO: Got endpoints: latency-svc-sls26 [100.895343ms]
Apr 18 08:28:39.736: INFO: Got endpoints: latency-svc-6fb4b [100.222482ms]
Apr 18 08:28:39.737: INFO: Created: latency-svc-kqdzw
Apr 18 08:28:39.741: INFO: Got endpoints: latency-svc-kqdzw [90.333852ms]
Apr 18 08:28:39.744: INFO: Created: latency-svc-mbx6m
Apr 18 08:28:39.749: INFO: Got endpoints: latency-svc-mbx6m [93.710107ms]
Apr 18 08:28:39.751: INFO: Created: latency-svc-4blxb
Apr 18 08:28:39.755: INFO: Got endpoints: latency-svc-4blxb [93.795125ms]
Apr 18 08:28:39.757: INFO: Created: latency-svc-hp8q5
Apr 18 08:28:39.761: INFO: Got endpoints: latency-svc-hp8q5 [92.453821ms]
Apr 18 08:28:39.763: INFO: Created: latency-svc-458bg
Apr 18 08:28:39.768: INFO: Got endpoints: latency-svc-458bg [93.459005ms]
Apr 18 08:28:39.768: INFO: Created: latency-svc-tt8rk
Apr 18 08:28:39.772: INFO: Got endpoints: latency-svc-tt8rk [91.568689ms]
Apr 18 08:28:39.774: INFO: Created: latency-svc-v78h7
Apr 18 08:28:39.777: INFO: Got endpoints: latency-svc-v78h7 [91.621504ms]
Apr 18 08:28:39.778: INFO: Created: latency-svc-5rzcf
Apr 18 08:28:39.782: INFO: Got endpoints: latency-svc-5rzcf [91.1482ms]
Apr 18 08:28:39.783: INFO: Created: latency-svc-5spxr
Apr 18 08:28:39.787: INFO: Got endpoints: latency-svc-5spxr [87.939275ms]
Apr 18 08:28:39.789: INFO: Created: latency-svc-pm6pg
Apr 18 08:28:39.792: INFO: Got endpoints: latency-svc-pm6pg [87.906563ms]
Apr 18 08:28:39.794: INFO: Created: latency-svc-8mqt6
Apr 18 08:28:39.798: INFO: Got endpoints: latency-svc-8mqt6 [88.031752ms]
Apr 18 08:28:39.800: INFO: Created: latency-svc-8lbm7
Apr 18 08:28:39.803: INFO: Got endpoints: latency-svc-8lbm7 [86.909783ms]
Apr 18 08:28:39.805: INFO: Created: latency-svc-l9rd4
Apr 18 08:28:39.810: INFO: Got endpoints: latency-svc-l9rd4 [87.233673ms]
Apr 18 08:28:39.811: INFO: Created: latency-svc-nvsnc
Apr 18 08:28:39.815: INFO: Got endpoints: latency-svc-nvsnc [84.556599ms]
Apr 18 08:28:39.818: INFO: Created: latency-svc-ghzjw
Apr 18 08:28:39.824: INFO: Got endpoints: latency-svc-ghzjw [87.545124ms]
Apr 18 08:28:39.825: INFO: Created: latency-svc-mjl9s
Apr 18 08:28:39.827: INFO: Created: latency-svc-8nhzh
Apr 18 08:28:39.831: INFO: Got endpoints: latency-svc-mjl9s [90.630416ms]
Apr 18 08:28:39.832: INFO: Got endpoints: latency-svc-8nhzh [83.20405ms]
Apr 18 08:28:39.836: INFO: Created: latency-svc-ztd6c
Apr 18 08:28:39.839: INFO: Got endpoints: latency-svc-ztd6c [83.942839ms]
Apr 18 08:28:39.841: INFO: Created: latency-svc-75bj5
Apr 18 08:28:39.852: INFO: Got endpoints: latency-svc-75bj5 [91.27683ms]
Apr 18 08:28:39.854: INFO: Created: latency-svc-qf8tz
Apr 18 08:28:39.859: INFO: Got endpoints: latency-svc-qf8tz [91.355932ms]
Apr 18 08:28:39.860: INFO: Created: latency-svc-xzhg6
Apr 18 08:28:39.864: INFO: Got endpoints: latency-svc-xzhg6 [91.936951ms]
Apr 18 08:28:39.866: INFO: Created: latency-svc-hzn9v
Apr 18 08:28:39.875: INFO: Got endpoints: latency-svc-hzn9v [98.467775ms]
Apr 18 08:28:39.879: INFO: Created: latency-svc-wdgsk
Apr 18 08:28:39.882: INFO: Got endpoints: latency-svc-wdgsk [99.758083ms]
Apr 18 08:28:39.883: INFO: Created: latency-svc-278kh
Apr 18 08:28:39.887: INFO: Got endpoints: latency-svc-278kh [98.82675ms]
Apr 18 08:28:39.888: INFO: Created: latency-svc-4szqn
Apr 18 08:28:39.892: INFO: Got endpoints: latency-svc-4szqn [100.108316ms]
Apr 18 08:28:39.893: INFO: Created: latency-svc-rd6j8
Apr 18 08:28:39.898: INFO: Got endpoints: latency-svc-rd6j8 [100.082828ms]
Apr 18 08:28:39.898: INFO: Created: latency-svc-4d4vv
Apr 18 08:28:39.902: INFO: Got endpoints: latency-svc-4d4vv [99.01947ms]
Apr 18 08:28:39.905: INFO: Created: latency-svc-chzqc
Apr 18 08:28:39.909: INFO: Got endpoints: latency-svc-chzqc [99.054076ms]
Apr 18 08:28:39.910: INFO: Created: latency-svc-ksw46
Apr 18 08:28:39.913: INFO: Got endpoints: latency-svc-ksw46 [97.207723ms]
Apr 18 08:28:39.914: INFO: Created: latency-svc-hnv47
Apr 18 08:28:39.919: INFO: Got endpoints: latency-svc-hnv47 [95.386486ms]
Apr 18 08:28:39.922: INFO: Created: latency-svc-6sm2f
Apr 18 08:28:39.925: INFO: Got endpoints: latency-svc-6sm2f [93.437945ms]
Apr 18 08:28:39.926: INFO: Created: latency-svc-ndkqz
Apr 18 08:28:39.930: INFO: Got endpoints: latency-svc-ndkqz [98.558275ms]
Apr 18 08:28:39.931: INFO: Created: latency-svc-5h26g
Apr 18 08:28:39.935: INFO: Got endpoints: latency-svc-5h26g [96.116393ms]
Apr 18 08:28:39.936: INFO: Created: latency-svc-j7vg4
Apr 18 08:28:39.944: INFO: Got endpoints: latency-svc-j7vg4 [91.992436ms]
Apr 18 08:28:39.945: INFO: Created: latency-svc-77lbw
Apr 18 08:28:39.955: INFO: Got endpoints: latency-svc-77lbw [96.183585ms]
Apr 18 08:28:39.956: INFO: Created: latency-svc-2cqlq
Apr 18 08:28:39.961: INFO: Got endpoints: latency-svc-2cqlq [96.886777ms]
Apr 18 08:28:39.961: INFO: Created: latency-svc-jdk8t
Apr 18 08:28:39.965: INFO: Got endpoints: latency-svc-jdk8t [89.491855ms]
Apr 18 08:28:39.967: INFO: Created: latency-svc-lhdvk
Apr 18 08:28:39.971: INFO: Got endpoints: latency-svc-lhdvk [89.140832ms]
Apr 18 08:28:39.972: INFO: Created: latency-svc-r69lc
Apr 18 08:28:39.977: INFO: Got endpoints: latency-svc-r69lc [90.433503ms]
Apr 18 08:28:39.978: INFO: Created: latency-svc-8fkns
Apr 18 08:28:39.983: INFO: Got endpoints: latency-svc-8fkns [90.822116ms]
Apr 18 08:28:39.984: INFO: Created: latency-svc-xtf6c
Apr 18 08:28:39.988: INFO: Got endpoints: latency-svc-xtf6c [90.453056ms]
Apr 18 08:28:39.989: INFO: Created: latency-svc-ctprx
Apr 18 08:28:39.992: INFO: Got endpoints: latency-svc-ctprx [90.315492ms]
Apr 18 08:28:39.995: INFO: Created: latency-svc-mchbt
Apr 18 08:28:39.998: INFO: Got endpoints: latency-svc-mchbt [88.884ms]
Apr 18 08:28:40.000: INFO: Created: latency-svc-n9q4c
Apr 18 08:28:40.003: INFO: Got endpoints: latency-svc-n9q4c [90.577207ms]
Apr 18 08:28:40.005: INFO: Created: latency-svc-2gr8k
Apr 18 08:28:40.011: INFO: Got endpoints: latency-svc-2gr8k [91.781812ms]
Apr 18 08:28:40.011: INFO: Created: latency-svc-qhf47
Apr 18 08:28:40.016: INFO: Created: latency-svc-vxdp5
Apr 18 08:28:40.017: INFO: Got endpoints: latency-svc-qhf47 [92.086186ms]
Apr 18 08:28:40.020: INFO: Got endpoints: latency-svc-vxdp5 [90.124189ms]
Apr 18 08:28:40.023: INFO: Created: latency-svc-h29ss
Apr 18 08:28:40.025: INFO: Got endpoints: latency-svc-h29ss [90.107245ms]
Apr 18 08:28:40.027: INFO: Created: latency-svc-9gxgf
Apr 18 08:28:40.031: INFO: Got endpoints: latency-svc-9gxgf [86.683884ms]
Apr 18 08:28:40.032: INFO: Created: latency-svc-5vks5
Apr 18 08:28:40.036: INFO: Got endpoints: latency-svc-5vks5 [80.594736ms]
Apr 18 08:28:40.037: INFO: Created: latency-svc-wtjbm
Apr 18 08:28:40.045: INFO: Got endpoints: latency-svc-wtjbm [83.898403ms]
Apr 18 08:28:40.046: INFO: Created: latency-svc-cjs5n
Apr 18 08:28:40.050: INFO: Created: latency-svc-28lbb
Apr 18 08:28:40.053: INFO: Got endpoints: latency-svc-cjs5n [87.762594ms]
Apr 18 08:28:40.058: INFO: Got endpoints: latency-svc-28lbb [87.517153ms]
Apr 18 08:28:40.061: INFO: Created: latency-svc-ktcgv
Apr 18 08:28:40.065: INFO: Got endpoints: latency-svc-ktcgv [88.185847ms]
Apr 18 08:28:40.066: INFO: Created: latency-svc-hbhgq
Apr 18 08:28:40.069: INFO: Got endpoints: latency-svc-hbhgq [86.372996ms]
Apr 18 08:28:40.072: INFO: Created: latency-svc-cwxf2
Apr 18 08:28:40.077: INFO: Got endpoints: latency-svc-cwxf2 [88.943571ms]
Apr 18 08:28:40.078: INFO: Created: latency-svc-9l2qq
Apr 18 08:28:40.082: INFO: Got endpoints: latency-svc-9l2qq [89.297701ms]
Apr 18 08:28:40.084: INFO: Created: latency-svc-5g7mz
Apr 18 08:28:40.088: INFO: Got endpoints: latency-svc-5g7mz [90.173386ms]
Apr 18 08:28:40.089: INFO: Created: latency-svc-mx8qr
Apr 18 08:28:40.094: INFO: Got endpoints: latency-svc-mx8qr [90.907109ms]
Apr 18 08:28:40.095: INFO: Created: latency-svc-7bwll
Apr 18 08:28:40.100: INFO: Got endpoints: latency-svc-7bwll [88.696455ms]
Apr 18 08:28:40.100: INFO: Created: latency-svc-mg6t6
Apr 18 08:28:40.105: INFO: Got endpoints: latency-svc-mg6t6 [88.120852ms]
Apr 18 08:28:40.106: INFO: Created: latency-svc-xmqhl
Apr 18 08:28:40.110: INFO: Got endpoints: latency-svc-xmqhl [89.28312ms]
Apr 18 08:28:40.112: INFO: Created: latency-svc-frtqr
Apr 18 08:28:40.117: INFO: Created: latency-svc-s7v8q
Apr 18 08:28:40.117: INFO: Got endpoints: latency-svc-frtqr [91.999147ms]
Apr 18 08:28:40.122: INFO: Got endpoints: latency-svc-s7v8q [90.739581ms]
Apr 18 08:28:40.122: INFO: Created: latency-svc-hr746
Apr 18 08:28:40.127: INFO: Got endpoints: latency-svc-hr746 [91.01464ms]
Apr 18 08:28:40.127: INFO: Created: latency-svc-tcwrr
Apr 18 08:28:40.132: INFO: Got endpoints: latency-svc-tcwrr [87.267818ms]
Apr 18 08:28:40.133: INFO: Created: latency-svc-qg7px
Apr 18 08:28:40.137: INFO: Got endpoints: latency-svc-qg7px [84.215484ms]
Apr 18 08:28:40.140: INFO: Created: latency-svc-nx4gk
Apr 18 08:28:40.148: INFO: Got endpoints: latency-svc-nx4gk [89.372591ms]
Apr 18 08:28:40.151: INFO: Created: latency-svc-bbkvv
Apr 18 08:28:40.156: INFO: Got endpoints: latency-svc-bbkvv [90.310419ms]
Apr 18 08:28:40.157: INFO: Created: latency-svc-5rthv
Apr 18 08:28:40.162: INFO: Got endpoints: latency-svc-5rthv [92.978437ms]
Apr 18 08:28:40.164: INFO: Created: latency-svc-gb8fs
Apr 18 08:28:40.168: INFO: Got endpoints: latency-svc-gb8fs [90.674205ms]
Apr 18 08:28:40.169: INFO: Created: latency-svc-95v2q
Apr 18 08:28:40.172: INFO: Got endpoints: latency-svc-95v2q [90.44492ms]
Apr 18 08:28:40.175: INFO: Created: latency-svc-hg4dm
Apr 18 08:28:40.178: INFO: Got endpoints: latency-svc-hg4dm [90.161469ms]
Apr 18 08:28:40.181: INFO: Created: latency-svc-42t2n
Apr 18 08:28:40.192: INFO: Got endpoints: latency-svc-42t2n [97.368022ms]
Apr 18 08:28:40.193: INFO: Created: latency-svc-2kmj5
Apr 18 08:28:40.198: INFO: Got endpoints: latency-svc-2kmj5 [98.734095ms]
Apr 18 08:28:40.199: INFO: Created: latency-svc-h56kd
Apr 18 08:28:40.203: INFO: Got endpoints: latency-svc-h56kd [98.005843ms]
Apr 18 08:28:40.205: INFO: Created: latency-svc-kx8r6
Apr 18 08:28:40.210: INFO: Got endpoints: latency-svc-kx8r6 [99.655123ms]
Apr 18 08:28:40.210: INFO: Created: latency-svc-mzlfp
Apr 18 08:28:40.214: INFO: Got endpoints: latency-svc-mzlfp [96.904055ms]
Apr 18 08:28:40.216: INFO: Created: latency-svc-bp8xs
Apr 18 08:28:40.220: INFO: Got endpoints: latency-svc-bp8xs [98.066124ms]
Apr 18 08:28:40.221: INFO: Created: latency-svc-vq8lb
Apr 18 08:28:40.225: INFO: Got endpoints: latency-svc-vq8lb [98.288184ms]
Apr 18 08:28:40.227: INFO: Created: latency-svc-nc9m5
Apr 18 08:28:40.230: INFO: Got endpoints: latency-svc-nc9m5 [98.337191ms]
Apr 18 08:28:40.233: INFO: Created: latency-svc-bgl74
Apr 18 08:28:40.235: INFO: Created: latency-svc-x4xm6
Apr 18 08:28:40.239: INFO: Got endpoints: latency-svc-bgl74 [101.839694ms]
Apr 18 08:28:40.241: INFO: Got endpoints: latency-svc-x4xm6 [93.328662ms]
Apr 18 08:28:40.245: INFO: Created: latency-svc-5j9j6
Apr 18 08:28:40.254: INFO: Created: latency-svc-kl6mc
Apr 18 08:28:40.255: INFO: Got endpoints: latency-svc-5j9j6 [99.597052ms]
Apr 18 08:28:40.260: INFO: Got endpoints: latency-svc-kl6mc [98.163396ms]
Apr 18 08:28:40.261: INFO: Created: latency-svc-28gz5
Apr 18 08:28:40.265: INFO: Got endpoints: latency-svc-28gz5 [97.226683ms]
Apr 18 08:28:40.268: INFO: Created: latency-svc-qs5t7
Apr 18 08:28:40.271: INFO: Got endpoints: latency-svc-qs5t7 [98.322757ms]
Apr 18 08:28:40.272: INFO: Created: latency-svc-j5mql
Apr 18 08:28:40.275: INFO: Got endpoints: latency-svc-j5mql [97.371605ms]
Apr 18 08:28:40.277: INFO: Created: latency-svc-5dv9p
Apr 18 08:28:40.281: INFO: Created: latency-svc-9s8f2
Apr 18 08:28:40.284: INFO: Got endpoints: latency-svc-5dv9p [92.132343ms]
Apr 18 08:28:40.287: INFO: Got endpoints: latency-svc-9s8f2 [88.730934ms]
Apr 18 08:28:40.288: INFO: Created: latency-svc-mx62x
Apr 18 08:28:40.293: INFO: Got endpoints: latency-svc-mx62x [89.510462ms]
Apr 18 08:28:40.296: INFO: Created: latency-svc-7l4t9
Apr 18 08:28:40.300: INFO: Got endpoints: latency-svc-7l4t9 [90.108329ms]
Apr 18 08:28:40.301: INFO: Created: latency-svc-4n9lf
Apr 18 08:28:40.306: INFO: Got endpoints: latency-svc-4n9lf [91.38921ms]
Apr 18 08:28:40.307: INFO: Created: latency-svc-7gblf
Apr 18 08:28:40.312: INFO: Got endpoints: latency-svc-7gblf [91.986809ms]
Apr 18 08:28:40.313: INFO: Created: latency-svc-f8fl9
Apr 18 08:28:40.317: INFO: Got endpoints: latency-svc-f8fl9 [92.010741ms]
Apr 18 08:28:40.318: INFO: Created: latency-svc-4tfc7
Apr 18 08:28:40.322: INFO: Got endpoints: latency-svc-4tfc7 [92.239601ms]
Apr 18 08:28:40.325: INFO: Created: latency-svc-dr4sn
Apr 18 08:28:40.328: INFO: Got endpoints: latency-svc-dr4sn [89.24017ms]
Apr 18 08:28:40.331: INFO: Created: latency-svc-2jxlw
Apr 18 08:28:40.335: INFO: Got endpoints: latency-svc-2jxlw [93.414633ms]
Apr 18 08:28:40.336: INFO: Created: latency-svc-fzxg7
Apr 18 08:28:40.343: INFO: Got endpoints: latency-svc-fzxg7 [87.914951ms]
Apr 18 08:28:40.345: INFO: Created: latency-svc-2tpts
Apr 18 08:28:40.355: INFO: Got endpoints: latency-svc-2tpts [94.339266ms]
Apr 18 08:28:40.356: INFO: Created: latency-svc-xjtsh
Apr 18 08:28:40.360: INFO: Got endpoints: latency-svc-xjtsh [94.658256ms]
Apr 18 08:28:40.363: INFO: Created: latency-svc-l7vfl
Apr 18 08:28:40.367: INFO: Got endpoints: latency-svc-l7vfl [96.811673ms]
Apr 18 08:28:40.370: INFO: Created: latency-svc-c5vnw
Apr 18 08:28:40.374: INFO: Got endpoints: latency-svc-c5vnw [98.300203ms]
Apr 18 08:28:40.374: INFO: Created: latency-svc-8hdz8
Apr 18 08:28:40.379: INFO: Got endpoints: latency-svc-8hdz8 [95.292553ms]
Apr 18 08:28:40.380: INFO: Created: latency-svc-8nb69
Apr 18 08:28:40.386: INFO: Got endpoints: latency-svc-8nb69 [99.076586ms]
Apr 18 08:28:40.389: INFO: Created: latency-svc-mrr9k
Apr 18 08:28:40.393: INFO: Got endpoints: latency-svc-mrr9k [100.278747ms]
Apr 18 08:28:40.397: INFO: Created: latency-svc-rncjh
Apr 18 08:28:40.401: INFO: Created: latency-svc-9hmdn
Apr 18 08:28:40.402: INFO: Got endpoints: latency-svc-rncjh [102.202653ms]
Apr 18 08:28:40.407: INFO: Got endpoints: latency-svc-9hmdn [101.623936ms]
Apr 18 08:28:40.409: INFO: Created: latency-svc-sxfkx
Apr 18 08:28:40.415: INFO: Got endpoints: latency-svc-sxfkx [103.032421ms]
Apr 18 08:28:40.417: INFO: Created: latency-svc-n2r7l
Apr 18 08:28:40.423: INFO: Got endpoints: latency-svc-n2r7l [105.704612ms]
Apr 18 08:28:40.424: INFO: Created: latency-svc-m78kd
Apr 18 08:28:40.429: INFO: Got endpoints: latency-svc-m78kd [106.56197ms]
Apr 18 08:28:40.431: INFO: Created: latency-svc-b2drg
Apr 18 08:28:40.435: INFO: Got endpoints: latency-svc-b2drg [106.650153ms]
Apr 18 08:28:40.438: INFO: Created: latency-svc-24flq
Apr 18 08:28:40.451: INFO: Got endpoints: latency-svc-24flq [116.749571ms]
Apr 18 08:28:40.454: INFO: Created: latency-svc-2g468
Apr 18 08:28:40.461: INFO: Got endpoints: latency-svc-2g468 [117.429974ms]
Apr 18 08:28:40.462: INFO: Created: latency-svc-hf2xz
Apr 18 08:28:40.466: INFO: Got endpoints: latency-svc-hf2xz [111.35342ms]
Apr 18 08:28:40.470: INFO: Created: latency-svc-b9bbt
Apr 18 08:28:40.476: INFO: Got endpoints: latency-svc-b9bbt [115.852972ms]
Apr 18 08:28:40.476: INFO: Created: latency-svc-nzn5f
Apr 18 08:28:40.481: INFO: Got endpoints: latency-svc-nzn5f [113.936624ms]
Apr 18 08:28:40.482: INFO: Created: latency-svc-7k8q8
Apr 18 08:28:40.488: INFO: Created: latency-svc-2s7x2
Apr 18 08:28:40.488: INFO: Got endpoints: latency-svc-7k8q8 [114.414028ms]
Apr 18 08:28:40.492: INFO: Got endpoints: latency-svc-2s7x2 [113.059372ms]
Apr 18 08:28:40.493: INFO: Created: latency-svc-sht4t
Apr 18 08:28:40.496: INFO: Got endpoints: latency-svc-sht4t [109.821266ms]
Apr 18 08:28:40.499: INFO: Created: latency-svc-rl8cr
Apr 18 08:28:40.503: INFO: Got endpoints: latency-svc-rl8cr [110.213037ms]
Apr 18 08:28:40.505: INFO: Created: latency-svc-7ntjb
Apr 18 08:28:40.512: INFO: Got endpoints: latency-svc-7ntjb [109.561218ms]
Apr 18 08:28:40.515: INFO: Created: latency-svc-9rbz4
Apr 18 08:28:40.520: INFO: Got endpoints: latency-svc-9rbz4 [112.531783ms]
Apr 18 08:28:40.521: INFO: Created: latency-svc-z55nt
Apr 18 08:28:40.525: INFO: Got endpoints: latency-svc-z55nt [110.281158ms]
Apr 18 08:28:40.529: INFO: Created: latency-svc-45gdw
Apr 18 08:28:40.532: INFO: Created: latency-svc-754l2
Apr 18 08:28:40.534: INFO: Got endpoints: latency-svc-45gdw [111.254893ms]
Apr 18 08:28:40.536: INFO: Got endpoints: latency-svc-754l2 [107.102935ms]
Apr 18 08:28:40.547: INFO: Created: latency-svc-dsp6v
Apr 18 08:28:40.557: INFO: Got endpoints: latency-svc-dsp6v [122.220304ms]
Apr 18 08:28:40.558: INFO: Created: latency-svc-2xtjx
Apr 18 08:28:40.563: INFO: Got endpoints: latency-svc-2xtjx [111.823432ms]
Apr 18 08:28:40.565: INFO: Created: latency-svc-p7cd7
Apr 18 08:28:40.569: INFO: Created: latency-svc-d95rd
Apr 18 08:28:40.573: INFO: Got endpoints: latency-svc-p7cd7 [111.667765ms]
Apr 18 08:28:40.575: INFO: Got endpoints: latency-svc-d95rd [108.414365ms]
Apr 18 08:28:40.579: INFO: Created: latency-svc-lnl5k
Apr 18 08:28:40.583: INFO: Got endpoints: latency-svc-lnl5k [107.607053ms]
Apr 18 08:28:40.588: INFO: Created: latency-svc-2cvbd
Apr 18 08:28:40.593: INFO: Got endpoints: latency-svc-2cvbd [111.393517ms]
Apr 18 08:28:40.594: INFO: Created: latency-svc-5n4sc
Apr 18 08:28:40.598: INFO: Got endpoints: latency-svc-5n4sc [110.053015ms]
Apr 18 08:28:40.601: INFO: Created: latency-svc-zdkrg
Apr 18 08:28:40.606: INFO: Got endpoints: latency-svc-zdkrg [113.966003ms]
Apr 18 08:28:40.608: INFO: Created: latency-svc-fnjh4
Apr 18 08:28:40.614: INFO: Got endpoints: latency-svc-fnjh4 [118.009932ms]
Apr 18 08:28:40.654: INFO: Created: latency-svc-z6vmf
Apr 18 08:28:40.690: INFO: Got endpoints: latency-svc-z6vmf [186.709617ms]
Apr 18 08:28:40.693: INFO: Created: latency-svc-q24bj
Apr 18 08:28:40.728: INFO: Got endpoints: latency-svc-q24bj [216.62654ms]
Apr 18 08:28:40.730: INFO: Created: latency-svc-vjxlq
Apr 18 08:28:40.747: INFO: Got endpoints: latency-svc-vjxlq [227.205638ms]
Apr 18 08:28:40.751: INFO: Created: latency-svc-dkpln
Apr 18 08:28:40.762: INFO: Got endpoints: latency-svc-dkpln [236.8182ms]
Apr 18 08:28:40.763: INFO: Created: latency-svc-q272d
Apr 18 08:28:40.781: INFO: Got endpoints: latency-svc-q272d [246.420449ms]
Apr 18 08:28:40.788: INFO: Created: latency-svc-9w49f
Apr 18 08:28:40.800: INFO: Got endpoints: latency-svc-9w49f [263.730896ms]
Apr 18 08:28:40.805: INFO: Created: latency-svc-tmdgp
Apr 18 08:28:40.827: INFO: Got endpoints: latency-svc-tmdgp [269.516914ms]
Apr 18 08:28:40.830: INFO: Created: latency-svc-hsbsb
Apr 18 08:28:40.838: INFO: Got endpoints: latency-svc-hsbsb [275.124197ms]
Apr 18 08:28:40.852: INFO: Created: latency-svc-bwbhc
Apr 18 08:28:40.875: INFO: Got endpoints: latency-svc-bwbhc [302.487775ms]
Apr 18 08:28:40.882: INFO: Created: latency-svc-rpv2g
Apr 18 08:28:40.901: INFO: Got endpoints: latency-svc-rpv2g [325.80352ms]
Apr 18 08:28:40.906: INFO: Created: latency-svc-jqpw9
Apr 18 08:28:40.912: INFO: Got endpoints: latency-svc-jqpw9 [328.636609ms]
Apr 18 08:28:40.915: INFO: Created: latency-svc-dj6kn
Apr 18 08:28:40.925: INFO: Got endpoints: latency-svc-dj6kn [332.463291ms]
Apr 18 08:28:40.927: INFO: Created: latency-svc-7fvq7
Apr 18 08:28:40.940: INFO: Got endpoints: latency-svc-7fvq7 [341.705274ms]
Apr 18 08:28:40.957: INFO: Created: latency-svc-7h5lv
Apr 18 08:28:40.964: INFO: Got endpoints: latency-svc-7h5lv [357.864238ms]
Apr 18 08:28:40.971: INFO: Created: latency-svc-9wtjp
Apr 18 08:28:40.977: INFO: Got endpoints: latency-svc-9wtjp [362.69366ms]
Apr 18 08:28:40.980: INFO: Created: latency-svc-qgdf8
Apr 18 08:28:40.988: INFO: Got endpoints: latency-svc-qgdf8 [298.036627ms]
Apr 18 08:28:40.988: INFO: Latencies: [13.017649ms 20.98199ms 44.364393ms 60.033806ms 64.73021ms 73.412246ms 78.009791ms 78.998627ms 80.301699ms 80.419732ms 80.594736ms 81.322019ms 83.20405ms 83.898403ms 83.942839ms 84.215484ms 84.458457ms 84.556599ms 85.399943ms 85.681458ms 85.794435ms 85.849278ms 86.372996ms 86.402872ms 86.683884ms 86.909783ms 87.233673ms 87.267818ms 87.517153ms 87.545124ms 87.762594ms 87.906563ms 87.914951ms 87.939275ms 88.031752ms 88.120852ms 88.185847ms 88.696455ms 88.730934ms 88.884ms 88.943571ms 88.957427ms 89.140832ms 89.24017ms 89.28312ms 89.297701ms 89.372591ms 89.475488ms 89.491855ms 89.510462ms 89.926166ms 90.107245ms 90.108329ms 90.124189ms 90.161469ms 90.173386ms 90.275447ms 90.310419ms 90.315492ms 90.333852ms 90.433503ms 90.44492ms 90.453056ms 90.577207ms 90.630416ms 90.674205ms 90.739581ms 90.822116ms 90.835337ms 90.907109ms 91.01464ms 91.1482ms 91.27683ms 91.304261ms 91.336297ms 91.355932ms 91.38921ms 91.568689ms 91.621504ms 91.722005ms 91.781812ms 91.936951ms 91.986809ms 91.992436ms 91.999147ms 92.010741ms 92.086186ms 92.132343ms 92.239601ms 92.245912ms 92.453821ms 92.475442ms 92.978437ms 93.328662ms 93.414633ms 93.437945ms 93.459005ms 93.65743ms 93.710107ms 93.795125ms 93.798123ms 93.844475ms 94.079159ms 94.205609ms 94.339266ms 94.658256ms 95.292553ms 95.386486ms 95.645768ms 95.949729ms 96.116393ms 96.178057ms 96.183585ms 96.584828ms 96.811673ms 96.886777ms 96.904055ms 97.207723ms 97.226683ms 97.368022ms 97.371605ms 97.434774ms 97.692298ms 97.88194ms 98.005843ms 98.066124ms 98.163396ms 98.225852ms 98.288184ms 98.300203ms 98.322757ms 98.337191ms 98.467775ms 98.558275ms 98.734095ms 98.82675ms 99.01947ms 99.054076ms 99.076586ms 99.597052ms 99.655123ms 99.758083ms 100.082828ms 100.108316ms 100.222482ms 100.278747ms 100.895343ms 101.623936ms 101.839694ms 102.202653ms 103.032421ms 105.704612ms 106.56197ms 106.650153ms 107.102935ms 107.607053ms 108.414365ms 109.561218ms 109.596016ms 109.732315ms 109.821266ms 110.053015ms 110.213037ms 110.281158ms 111.254893ms 111.35342ms 111.393517ms 111.667765ms 111.823432ms 112.531783ms 113.059372ms 113.936624ms 113.966003ms 114.414028ms 115.031155ms 115.852972ms 116.749571ms 116.955371ms 117.429974ms 118.009932ms 122.220304ms 122.856831ms 137.004732ms 168.800271ms 186.709617ms 216.62654ms 227.205638ms 236.8182ms 246.420449ms 263.730896ms 269.516914ms 275.124197ms 298.036627ms 302.487775ms 325.80352ms 328.636609ms 332.463291ms 341.705274ms 357.864238ms 362.69366ms]
Apr 18 08:28:40.988: INFO: 50 %ile: 93.798123ms
Apr 18 08:28:40.988: INFO: 90 %ile: 122.220304ms
Apr 18 08:28:40.988: INFO: 99 %ile: 357.864238ms
Apr 18 08:28:40.988: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Apr 18 08:28:40.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6580" for this suite. 04/18/23 08:28:40.994
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":9,"skipped":162,"failed":0}
------------------------------
• [SLOW TEST] [6.804 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:28:34.199
    Apr 18 08:28:34.199: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename svc-latency 04/18/23 08:28:34.199
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:28:34.212
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:28:34.218
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Apr 18 08:28:34.222: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-6580 04/18/23 08:28:34.223
    I0418 08:28:34.229372      18 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6580, replica count: 1
    I0418 08:28:35.280765      18 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 08:28:36.282722      18 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 08:28:37.283061      18 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 08:28:38.283214      18 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 08:28:39.284141      18 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 08:28:39.391: INFO: Created: latency-svc-6qcjz
    Apr 18 08:28:39.397: INFO: Got endpoints: latency-svc-6qcjz [12.856313ms]
    Apr 18 08:28:39.405: INFO: Created: latency-svc-lpp5b
    Apr 18 08:28:39.410: INFO: Got endpoints: latency-svc-lpp5b [13.017649ms]
    Apr 18 08:28:39.414: INFO: Created: latency-svc-97dmd
    Apr 18 08:28:39.418: INFO: Got endpoints: latency-svc-97dmd [20.98199ms]
    Apr 18 08:28:39.423: INFO: Created: latency-svc-sp9pz
    Apr 18 08:28:39.441: INFO: Got endpoints: latency-svc-sp9pz [44.364393ms]
    Apr 18 08:28:39.449: INFO: Created: latency-svc-wfjww
    Apr 18 08:28:39.457: INFO: Got endpoints: latency-svc-wfjww [60.033806ms]
    Apr 18 08:28:39.458: INFO: Created: latency-svc-gmmpx
    Apr 18 08:28:39.462: INFO: Got endpoints: latency-svc-gmmpx [64.73021ms]
    Apr 18 08:28:39.465: INFO: Created: latency-svc-l85rb
    Apr 18 08:28:39.471: INFO: Got endpoints: latency-svc-l85rb [73.412246ms]
    Apr 18 08:28:39.471: INFO: Created: latency-svc-pj4w2
    Apr 18 08:28:39.475: INFO: Got endpoints: latency-svc-pj4w2 [78.009791ms]
    Apr 18 08:28:39.478: INFO: Created: latency-svc-j6db2
    Apr 18 08:28:39.484: INFO: Got endpoints: latency-svc-j6db2 [86.402872ms]
    Apr 18 08:28:39.486: INFO: Created: latency-svc-jblqg
    Apr 18 08:28:39.489: INFO: Got endpoints: latency-svc-jblqg [91.336297ms]
    Apr 18 08:28:39.491: INFO: Created: latency-svc-h4wbp
    Apr 18 08:28:39.495: INFO: Got endpoints: latency-svc-h4wbp [97.88194ms]
    Apr 18 08:28:39.499: INFO: Created: latency-svc-lcj6k
    Apr 18 08:28:39.507: INFO: Got endpoints: latency-svc-lcj6k [109.596016ms]
    Apr 18 08:28:39.508: INFO: Created: latency-svc-zx8c6
    Apr 18 08:28:39.512: INFO: Got endpoints: latency-svc-zx8c6 [115.031155ms]
    Apr 18 08:28:39.514: INFO: Created: latency-svc-vlvm4
    Apr 18 08:28:39.520: INFO: Got endpoints: latency-svc-vlvm4 [122.856831ms]
    Apr 18 08:28:39.520: INFO: Created: latency-svc-q98ts
    Apr 18 08:28:39.523: INFO: Created: latency-svc-6wnh9
    Apr 18 08:28:39.527: INFO: Got endpoints: latency-svc-q98ts [116.955371ms]
    Apr 18 08:28:39.528: INFO: Got endpoints: latency-svc-6wnh9 [109.732315ms]
    Apr 18 08:28:39.530: INFO: Created: latency-svc-lq28t
    Apr 18 08:28:39.534: INFO: Got endpoints: latency-svc-lq28t [137.004732ms]
    Apr 18 08:28:39.535: INFO: Created: latency-svc-xk5fr
    Apr 18 08:28:39.539: INFO: Got endpoints: latency-svc-xk5fr [97.692298ms]
    Apr 18 08:28:39.544: INFO: Created: latency-svc-7m5xj
    Apr 18 08:28:39.551: INFO: Got endpoints: latency-svc-7m5xj [93.844475ms]
    Apr 18 08:28:39.552: INFO: Created: latency-svc-q72kq
    Apr 18 08:28:39.555: INFO: Got endpoints: latency-svc-q72kq [93.65743ms]
    Apr 18 08:28:39.558: INFO: Created: latency-svc-8rwr5
    Apr 18 08:28:39.561: INFO: Got endpoints: latency-svc-8rwr5 [89.926166ms]
    Apr 18 08:28:39.561: INFO: Created: latency-svc-4rlwr
    Apr 18 08:28:39.566: INFO: Got endpoints: latency-svc-4rlwr [168.800271ms]
    Apr 18 08:28:39.567: INFO: Created: latency-svc-lm8dq
    Apr 18 08:28:39.571: INFO: Got endpoints: latency-svc-lm8dq [95.645768ms]
    Apr 18 08:28:39.571: INFO: Created: latency-svc-q5xl2
    Apr 18 08:28:39.575: INFO: Got endpoints: latency-svc-q5xl2 [91.722005ms]
    Apr 18 08:28:39.576: INFO: Created: latency-svc-gxlkk
    Apr 18 08:28:39.580: INFO: Got endpoints: latency-svc-gxlkk [91.304261ms]
    Apr 18 08:28:39.582: INFO: Created: latency-svc-xrmlk
    Apr 18 08:28:39.586: INFO: Got endpoints: latency-svc-xrmlk [90.835337ms]
    Apr 18 08:28:39.587: INFO: Created: latency-svc-mn6c7
    Apr 18 08:28:39.592: INFO: Got endpoints: latency-svc-mn6c7 [85.399943ms]
    Apr 18 08:28:39.593: INFO: Created: latency-svc-vnnvp
    Apr 18 08:28:39.597: INFO: Got endpoints: latency-svc-vnnvp [84.458457ms]
    Apr 18 08:28:39.599: INFO: Created: latency-svc-dmbhl
    Apr 18 08:28:39.601: INFO: Got endpoints: latency-svc-dmbhl [81.322019ms]
    Apr 18 08:28:39.604: INFO: Created: latency-svc-pvbcw
    Apr 18 08:28:39.607: INFO: Got endpoints: latency-svc-pvbcw [80.419732ms]
    Apr 18 08:28:39.610: INFO: Created: latency-svc-xgtck
    Apr 18 08:28:39.614: INFO: Got endpoints: latency-svc-xgtck [85.849278ms]
    Apr 18 08:28:39.616: INFO: Created: latency-svc-pxwcn
    Apr 18 08:28:39.620: INFO: Got endpoints: latency-svc-pxwcn [85.681458ms]
    Apr 18 08:28:39.621: INFO: Created: latency-svc-fl5gp
    Apr 18 08:28:39.625: INFO: Got endpoints: latency-svc-fl5gp [85.794435ms]
    Apr 18 08:28:39.626: INFO: Created: latency-svc-fpmcb
    Apr 18 08:28:39.630: INFO: Got endpoints: latency-svc-fpmcb [78.998627ms]
    Apr 18 08:28:39.631: INFO: Created: latency-svc-tb5rb
    Apr 18 08:28:39.636: INFO: Got endpoints: latency-svc-tb5rb [80.301699ms]
    Apr 18 08:28:39.637: INFO: Created: latency-svc-jgpqs
    Apr 18 08:28:39.650: INFO: Got endpoints: latency-svc-jgpqs [89.475488ms]
    Apr 18 08:28:39.651: INFO: Created: latency-svc-wkn4b
    Apr 18 08:28:39.655: INFO: Got endpoints: latency-svc-wkn4b [88.957427ms]
    Apr 18 08:28:39.657: INFO: Created: latency-svc-bkcwj
    Apr 18 08:28:39.661: INFO: Got endpoints: latency-svc-bkcwj [90.275447ms]
    Apr 18 08:28:39.663: INFO: Created: latency-svc-wt7pv
    Apr 18 08:28:39.668: INFO: Got endpoints: latency-svc-wt7pv [92.245912ms]
    Apr 18 08:28:39.669: INFO: Created: latency-svc-qfktq
    Apr 18 08:28:39.674: INFO: Got endpoints: latency-svc-qfktq [94.079159ms]
    Apr 18 08:28:39.675: INFO: Created: latency-svc-hjptj
    Apr 18 08:28:39.680: INFO: Got endpoints: latency-svc-hjptj [94.205609ms]
    Apr 18 08:28:39.681: INFO: Created: latency-svc-sfklm
    Apr 18 08:28:39.685: INFO: Got endpoints: latency-svc-sfklm [92.475442ms]
    Apr 18 08:28:39.687: INFO: Created: latency-svc-xrkd6
    Apr 18 08:28:39.691: INFO: Got endpoints: latency-svc-xrkd6 [93.798123ms]
    Apr 18 08:28:39.692: INFO: Created: latency-svc-z7dj7
    Apr 18 08:28:39.700: INFO: Got endpoints: latency-svc-z7dj7 [98.225852ms]
    Apr 18 08:28:39.701: INFO: Created: latency-svc-jn6l5
    Apr 18 08:28:39.704: INFO: Got endpoints: latency-svc-jn6l5 [96.584828ms]
    Apr 18 08:28:39.707: INFO: Created: latency-svc-sf4v9
    Apr 18 08:28:39.710: INFO: Got endpoints: latency-svc-sf4v9 [95.949729ms]
    Apr 18 08:28:39.713: INFO: Created: latency-svc-qhszd
    Apr 18 08:28:39.716: INFO: Got endpoints: latency-svc-qhszd [96.178057ms]
    Apr 18 08:28:39.719: INFO: Created: latency-svc-7bwvr
    Apr 18 08:28:39.722: INFO: Got endpoints: latency-svc-7bwvr [97.434774ms]
    Apr 18 08:28:39.725: INFO: Created: latency-svc-sls26
    Apr 18 08:28:39.731: INFO: Created: latency-svc-6fb4b
    Apr 18 08:28:39.731: INFO: Got endpoints: latency-svc-sls26 [100.895343ms]
    Apr 18 08:28:39.736: INFO: Got endpoints: latency-svc-6fb4b [100.222482ms]
    Apr 18 08:28:39.737: INFO: Created: latency-svc-kqdzw
    Apr 18 08:28:39.741: INFO: Got endpoints: latency-svc-kqdzw [90.333852ms]
    Apr 18 08:28:39.744: INFO: Created: latency-svc-mbx6m
    Apr 18 08:28:39.749: INFO: Got endpoints: latency-svc-mbx6m [93.710107ms]
    Apr 18 08:28:39.751: INFO: Created: latency-svc-4blxb
    Apr 18 08:28:39.755: INFO: Got endpoints: latency-svc-4blxb [93.795125ms]
    Apr 18 08:28:39.757: INFO: Created: latency-svc-hp8q5
    Apr 18 08:28:39.761: INFO: Got endpoints: latency-svc-hp8q5 [92.453821ms]
    Apr 18 08:28:39.763: INFO: Created: latency-svc-458bg
    Apr 18 08:28:39.768: INFO: Got endpoints: latency-svc-458bg [93.459005ms]
    Apr 18 08:28:39.768: INFO: Created: latency-svc-tt8rk
    Apr 18 08:28:39.772: INFO: Got endpoints: latency-svc-tt8rk [91.568689ms]
    Apr 18 08:28:39.774: INFO: Created: latency-svc-v78h7
    Apr 18 08:28:39.777: INFO: Got endpoints: latency-svc-v78h7 [91.621504ms]
    Apr 18 08:28:39.778: INFO: Created: latency-svc-5rzcf
    Apr 18 08:28:39.782: INFO: Got endpoints: latency-svc-5rzcf [91.1482ms]
    Apr 18 08:28:39.783: INFO: Created: latency-svc-5spxr
    Apr 18 08:28:39.787: INFO: Got endpoints: latency-svc-5spxr [87.939275ms]
    Apr 18 08:28:39.789: INFO: Created: latency-svc-pm6pg
    Apr 18 08:28:39.792: INFO: Got endpoints: latency-svc-pm6pg [87.906563ms]
    Apr 18 08:28:39.794: INFO: Created: latency-svc-8mqt6
    Apr 18 08:28:39.798: INFO: Got endpoints: latency-svc-8mqt6 [88.031752ms]
    Apr 18 08:28:39.800: INFO: Created: latency-svc-8lbm7
    Apr 18 08:28:39.803: INFO: Got endpoints: latency-svc-8lbm7 [86.909783ms]
    Apr 18 08:28:39.805: INFO: Created: latency-svc-l9rd4
    Apr 18 08:28:39.810: INFO: Got endpoints: latency-svc-l9rd4 [87.233673ms]
    Apr 18 08:28:39.811: INFO: Created: latency-svc-nvsnc
    Apr 18 08:28:39.815: INFO: Got endpoints: latency-svc-nvsnc [84.556599ms]
    Apr 18 08:28:39.818: INFO: Created: latency-svc-ghzjw
    Apr 18 08:28:39.824: INFO: Got endpoints: latency-svc-ghzjw [87.545124ms]
    Apr 18 08:28:39.825: INFO: Created: latency-svc-mjl9s
    Apr 18 08:28:39.827: INFO: Created: latency-svc-8nhzh
    Apr 18 08:28:39.831: INFO: Got endpoints: latency-svc-mjl9s [90.630416ms]
    Apr 18 08:28:39.832: INFO: Got endpoints: latency-svc-8nhzh [83.20405ms]
    Apr 18 08:28:39.836: INFO: Created: latency-svc-ztd6c
    Apr 18 08:28:39.839: INFO: Got endpoints: latency-svc-ztd6c [83.942839ms]
    Apr 18 08:28:39.841: INFO: Created: latency-svc-75bj5
    Apr 18 08:28:39.852: INFO: Got endpoints: latency-svc-75bj5 [91.27683ms]
    Apr 18 08:28:39.854: INFO: Created: latency-svc-qf8tz
    Apr 18 08:28:39.859: INFO: Got endpoints: latency-svc-qf8tz [91.355932ms]
    Apr 18 08:28:39.860: INFO: Created: latency-svc-xzhg6
    Apr 18 08:28:39.864: INFO: Got endpoints: latency-svc-xzhg6 [91.936951ms]
    Apr 18 08:28:39.866: INFO: Created: latency-svc-hzn9v
    Apr 18 08:28:39.875: INFO: Got endpoints: latency-svc-hzn9v [98.467775ms]
    Apr 18 08:28:39.879: INFO: Created: latency-svc-wdgsk
    Apr 18 08:28:39.882: INFO: Got endpoints: latency-svc-wdgsk [99.758083ms]
    Apr 18 08:28:39.883: INFO: Created: latency-svc-278kh
    Apr 18 08:28:39.887: INFO: Got endpoints: latency-svc-278kh [98.82675ms]
    Apr 18 08:28:39.888: INFO: Created: latency-svc-4szqn
    Apr 18 08:28:39.892: INFO: Got endpoints: latency-svc-4szqn [100.108316ms]
    Apr 18 08:28:39.893: INFO: Created: latency-svc-rd6j8
    Apr 18 08:28:39.898: INFO: Got endpoints: latency-svc-rd6j8 [100.082828ms]
    Apr 18 08:28:39.898: INFO: Created: latency-svc-4d4vv
    Apr 18 08:28:39.902: INFO: Got endpoints: latency-svc-4d4vv [99.01947ms]
    Apr 18 08:28:39.905: INFO: Created: latency-svc-chzqc
    Apr 18 08:28:39.909: INFO: Got endpoints: latency-svc-chzqc [99.054076ms]
    Apr 18 08:28:39.910: INFO: Created: latency-svc-ksw46
    Apr 18 08:28:39.913: INFO: Got endpoints: latency-svc-ksw46 [97.207723ms]
    Apr 18 08:28:39.914: INFO: Created: latency-svc-hnv47
    Apr 18 08:28:39.919: INFO: Got endpoints: latency-svc-hnv47 [95.386486ms]
    Apr 18 08:28:39.922: INFO: Created: latency-svc-6sm2f
    Apr 18 08:28:39.925: INFO: Got endpoints: latency-svc-6sm2f [93.437945ms]
    Apr 18 08:28:39.926: INFO: Created: latency-svc-ndkqz
    Apr 18 08:28:39.930: INFO: Got endpoints: latency-svc-ndkqz [98.558275ms]
    Apr 18 08:28:39.931: INFO: Created: latency-svc-5h26g
    Apr 18 08:28:39.935: INFO: Got endpoints: latency-svc-5h26g [96.116393ms]
    Apr 18 08:28:39.936: INFO: Created: latency-svc-j7vg4
    Apr 18 08:28:39.944: INFO: Got endpoints: latency-svc-j7vg4 [91.992436ms]
    Apr 18 08:28:39.945: INFO: Created: latency-svc-77lbw
    Apr 18 08:28:39.955: INFO: Got endpoints: latency-svc-77lbw [96.183585ms]
    Apr 18 08:28:39.956: INFO: Created: latency-svc-2cqlq
    Apr 18 08:28:39.961: INFO: Got endpoints: latency-svc-2cqlq [96.886777ms]
    Apr 18 08:28:39.961: INFO: Created: latency-svc-jdk8t
    Apr 18 08:28:39.965: INFO: Got endpoints: latency-svc-jdk8t [89.491855ms]
    Apr 18 08:28:39.967: INFO: Created: latency-svc-lhdvk
    Apr 18 08:28:39.971: INFO: Got endpoints: latency-svc-lhdvk [89.140832ms]
    Apr 18 08:28:39.972: INFO: Created: latency-svc-r69lc
    Apr 18 08:28:39.977: INFO: Got endpoints: latency-svc-r69lc [90.433503ms]
    Apr 18 08:28:39.978: INFO: Created: latency-svc-8fkns
    Apr 18 08:28:39.983: INFO: Got endpoints: latency-svc-8fkns [90.822116ms]
    Apr 18 08:28:39.984: INFO: Created: latency-svc-xtf6c
    Apr 18 08:28:39.988: INFO: Got endpoints: latency-svc-xtf6c [90.453056ms]
    Apr 18 08:28:39.989: INFO: Created: latency-svc-ctprx
    Apr 18 08:28:39.992: INFO: Got endpoints: latency-svc-ctprx [90.315492ms]
    Apr 18 08:28:39.995: INFO: Created: latency-svc-mchbt
    Apr 18 08:28:39.998: INFO: Got endpoints: latency-svc-mchbt [88.884ms]
    Apr 18 08:28:40.000: INFO: Created: latency-svc-n9q4c
    Apr 18 08:28:40.003: INFO: Got endpoints: latency-svc-n9q4c [90.577207ms]
    Apr 18 08:28:40.005: INFO: Created: latency-svc-2gr8k
    Apr 18 08:28:40.011: INFO: Got endpoints: latency-svc-2gr8k [91.781812ms]
    Apr 18 08:28:40.011: INFO: Created: latency-svc-qhf47
    Apr 18 08:28:40.016: INFO: Created: latency-svc-vxdp5
    Apr 18 08:28:40.017: INFO: Got endpoints: latency-svc-qhf47 [92.086186ms]
    Apr 18 08:28:40.020: INFO: Got endpoints: latency-svc-vxdp5 [90.124189ms]
    Apr 18 08:28:40.023: INFO: Created: latency-svc-h29ss
    Apr 18 08:28:40.025: INFO: Got endpoints: latency-svc-h29ss [90.107245ms]
    Apr 18 08:28:40.027: INFO: Created: latency-svc-9gxgf
    Apr 18 08:28:40.031: INFO: Got endpoints: latency-svc-9gxgf [86.683884ms]
    Apr 18 08:28:40.032: INFO: Created: latency-svc-5vks5
    Apr 18 08:28:40.036: INFO: Got endpoints: latency-svc-5vks5 [80.594736ms]
    Apr 18 08:28:40.037: INFO: Created: latency-svc-wtjbm
    Apr 18 08:28:40.045: INFO: Got endpoints: latency-svc-wtjbm [83.898403ms]
    Apr 18 08:28:40.046: INFO: Created: latency-svc-cjs5n
    Apr 18 08:28:40.050: INFO: Created: latency-svc-28lbb
    Apr 18 08:28:40.053: INFO: Got endpoints: latency-svc-cjs5n [87.762594ms]
    Apr 18 08:28:40.058: INFO: Got endpoints: latency-svc-28lbb [87.517153ms]
    Apr 18 08:28:40.061: INFO: Created: latency-svc-ktcgv
    Apr 18 08:28:40.065: INFO: Got endpoints: latency-svc-ktcgv [88.185847ms]
    Apr 18 08:28:40.066: INFO: Created: latency-svc-hbhgq
    Apr 18 08:28:40.069: INFO: Got endpoints: latency-svc-hbhgq [86.372996ms]
    Apr 18 08:28:40.072: INFO: Created: latency-svc-cwxf2
    Apr 18 08:28:40.077: INFO: Got endpoints: latency-svc-cwxf2 [88.943571ms]
    Apr 18 08:28:40.078: INFO: Created: latency-svc-9l2qq
    Apr 18 08:28:40.082: INFO: Got endpoints: latency-svc-9l2qq [89.297701ms]
    Apr 18 08:28:40.084: INFO: Created: latency-svc-5g7mz
    Apr 18 08:28:40.088: INFO: Got endpoints: latency-svc-5g7mz [90.173386ms]
    Apr 18 08:28:40.089: INFO: Created: latency-svc-mx8qr
    Apr 18 08:28:40.094: INFO: Got endpoints: latency-svc-mx8qr [90.907109ms]
    Apr 18 08:28:40.095: INFO: Created: latency-svc-7bwll
    Apr 18 08:28:40.100: INFO: Got endpoints: latency-svc-7bwll [88.696455ms]
    Apr 18 08:28:40.100: INFO: Created: latency-svc-mg6t6
    Apr 18 08:28:40.105: INFO: Got endpoints: latency-svc-mg6t6 [88.120852ms]
    Apr 18 08:28:40.106: INFO: Created: latency-svc-xmqhl
    Apr 18 08:28:40.110: INFO: Got endpoints: latency-svc-xmqhl [89.28312ms]
    Apr 18 08:28:40.112: INFO: Created: latency-svc-frtqr
    Apr 18 08:28:40.117: INFO: Created: latency-svc-s7v8q
    Apr 18 08:28:40.117: INFO: Got endpoints: latency-svc-frtqr [91.999147ms]
    Apr 18 08:28:40.122: INFO: Got endpoints: latency-svc-s7v8q [90.739581ms]
    Apr 18 08:28:40.122: INFO: Created: latency-svc-hr746
    Apr 18 08:28:40.127: INFO: Got endpoints: latency-svc-hr746 [91.01464ms]
    Apr 18 08:28:40.127: INFO: Created: latency-svc-tcwrr
    Apr 18 08:28:40.132: INFO: Got endpoints: latency-svc-tcwrr [87.267818ms]
    Apr 18 08:28:40.133: INFO: Created: latency-svc-qg7px
    Apr 18 08:28:40.137: INFO: Got endpoints: latency-svc-qg7px [84.215484ms]
    Apr 18 08:28:40.140: INFO: Created: latency-svc-nx4gk
    Apr 18 08:28:40.148: INFO: Got endpoints: latency-svc-nx4gk [89.372591ms]
    Apr 18 08:28:40.151: INFO: Created: latency-svc-bbkvv
    Apr 18 08:28:40.156: INFO: Got endpoints: latency-svc-bbkvv [90.310419ms]
    Apr 18 08:28:40.157: INFO: Created: latency-svc-5rthv
    Apr 18 08:28:40.162: INFO: Got endpoints: latency-svc-5rthv [92.978437ms]
    Apr 18 08:28:40.164: INFO: Created: latency-svc-gb8fs
    Apr 18 08:28:40.168: INFO: Got endpoints: latency-svc-gb8fs [90.674205ms]
    Apr 18 08:28:40.169: INFO: Created: latency-svc-95v2q
    Apr 18 08:28:40.172: INFO: Got endpoints: latency-svc-95v2q [90.44492ms]
    Apr 18 08:28:40.175: INFO: Created: latency-svc-hg4dm
    Apr 18 08:28:40.178: INFO: Got endpoints: latency-svc-hg4dm [90.161469ms]
    Apr 18 08:28:40.181: INFO: Created: latency-svc-42t2n
    Apr 18 08:28:40.192: INFO: Got endpoints: latency-svc-42t2n [97.368022ms]
    Apr 18 08:28:40.193: INFO: Created: latency-svc-2kmj5
    Apr 18 08:28:40.198: INFO: Got endpoints: latency-svc-2kmj5 [98.734095ms]
    Apr 18 08:28:40.199: INFO: Created: latency-svc-h56kd
    Apr 18 08:28:40.203: INFO: Got endpoints: latency-svc-h56kd [98.005843ms]
    Apr 18 08:28:40.205: INFO: Created: latency-svc-kx8r6
    Apr 18 08:28:40.210: INFO: Got endpoints: latency-svc-kx8r6 [99.655123ms]
    Apr 18 08:28:40.210: INFO: Created: latency-svc-mzlfp
    Apr 18 08:28:40.214: INFO: Got endpoints: latency-svc-mzlfp [96.904055ms]
    Apr 18 08:28:40.216: INFO: Created: latency-svc-bp8xs
    Apr 18 08:28:40.220: INFO: Got endpoints: latency-svc-bp8xs [98.066124ms]
    Apr 18 08:28:40.221: INFO: Created: latency-svc-vq8lb
    Apr 18 08:28:40.225: INFO: Got endpoints: latency-svc-vq8lb [98.288184ms]
    Apr 18 08:28:40.227: INFO: Created: latency-svc-nc9m5
    Apr 18 08:28:40.230: INFO: Got endpoints: latency-svc-nc9m5 [98.337191ms]
    Apr 18 08:28:40.233: INFO: Created: latency-svc-bgl74
    Apr 18 08:28:40.235: INFO: Created: latency-svc-x4xm6
    Apr 18 08:28:40.239: INFO: Got endpoints: latency-svc-bgl74 [101.839694ms]
    Apr 18 08:28:40.241: INFO: Got endpoints: latency-svc-x4xm6 [93.328662ms]
    Apr 18 08:28:40.245: INFO: Created: latency-svc-5j9j6
    Apr 18 08:28:40.254: INFO: Created: latency-svc-kl6mc
    Apr 18 08:28:40.255: INFO: Got endpoints: latency-svc-5j9j6 [99.597052ms]
    Apr 18 08:28:40.260: INFO: Got endpoints: latency-svc-kl6mc [98.163396ms]
    Apr 18 08:28:40.261: INFO: Created: latency-svc-28gz5
    Apr 18 08:28:40.265: INFO: Got endpoints: latency-svc-28gz5 [97.226683ms]
    Apr 18 08:28:40.268: INFO: Created: latency-svc-qs5t7
    Apr 18 08:28:40.271: INFO: Got endpoints: latency-svc-qs5t7 [98.322757ms]
    Apr 18 08:28:40.272: INFO: Created: latency-svc-j5mql
    Apr 18 08:28:40.275: INFO: Got endpoints: latency-svc-j5mql [97.371605ms]
    Apr 18 08:28:40.277: INFO: Created: latency-svc-5dv9p
    Apr 18 08:28:40.281: INFO: Created: latency-svc-9s8f2
    Apr 18 08:28:40.284: INFO: Got endpoints: latency-svc-5dv9p [92.132343ms]
    Apr 18 08:28:40.287: INFO: Got endpoints: latency-svc-9s8f2 [88.730934ms]
    Apr 18 08:28:40.288: INFO: Created: latency-svc-mx62x
    Apr 18 08:28:40.293: INFO: Got endpoints: latency-svc-mx62x [89.510462ms]
    Apr 18 08:28:40.296: INFO: Created: latency-svc-7l4t9
    Apr 18 08:28:40.300: INFO: Got endpoints: latency-svc-7l4t9 [90.108329ms]
    Apr 18 08:28:40.301: INFO: Created: latency-svc-4n9lf
    Apr 18 08:28:40.306: INFO: Got endpoints: latency-svc-4n9lf [91.38921ms]
    Apr 18 08:28:40.307: INFO: Created: latency-svc-7gblf
    Apr 18 08:28:40.312: INFO: Got endpoints: latency-svc-7gblf [91.986809ms]
    Apr 18 08:28:40.313: INFO: Created: latency-svc-f8fl9
    Apr 18 08:28:40.317: INFO: Got endpoints: latency-svc-f8fl9 [92.010741ms]
    Apr 18 08:28:40.318: INFO: Created: latency-svc-4tfc7
    Apr 18 08:28:40.322: INFO: Got endpoints: latency-svc-4tfc7 [92.239601ms]
    Apr 18 08:28:40.325: INFO: Created: latency-svc-dr4sn
    Apr 18 08:28:40.328: INFO: Got endpoints: latency-svc-dr4sn [89.24017ms]
    Apr 18 08:28:40.331: INFO: Created: latency-svc-2jxlw
    Apr 18 08:28:40.335: INFO: Got endpoints: latency-svc-2jxlw [93.414633ms]
    Apr 18 08:28:40.336: INFO: Created: latency-svc-fzxg7
    Apr 18 08:28:40.343: INFO: Got endpoints: latency-svc-fzxg7 [87.914951ms]
    Apr 18 08:28:40.345: INFO: Created: latency-svc-2tpts
    Apr 18 08:28:40.355: INFO: Got endpoints: latency-svc-2tpts [94.339266ms]
    Apr 18 08:28:40.356: INFO: Created: latency-svc-xjtsh
    Apr 18 08:28:40.360: INFO: Got endpoints: latency-svc-xjtsh [94.658256ms]
    Apr 18 08:28:40.363: INFO: Created: latency-svc-l7vfl
    Apr 18 08:28:40.367: INFO: Got endpoints: latency-svc-l7vfl [96.811673ms]
    Apr 18 08:28:40.370: INFO: Created: latency-svc-c5vnw
    Apr 18 08:28:40.374: INFO: Got endpoints: latency-svc-c5vnw [98.300203ms]
    Apr 18 08:28:40.374: INFO: Created: latency-svc-8hdz8
    Apr 18 08:28:40.379: INFO: Got endpoints: latency-svc-8hdz8 [95.292553ms]
    Apr 18 08:28:40.380: INFO: Created: latency-svc-8nb69
    Apr 18 08:28:40.386: INFO: Got endpoints: latency-svc-8nb69 [99.076586ms]
    Apr 18 08:28:40.389: INFO: Created: latency-svc-mrr9k
    Apr 18 08:28:40.393: INFO: Got endpoints: latency-svc-mrr9k [100.278747ms]
    Apr 18 08:28:40.397: INFO: Created: latency-svc-rncjh
    Apr 18 08:28:40.401: INFO: Created: latency-svc-9hmdn
    Apr 18 08:28:40.402: INFO: Got endpoints: latency-svc-rncjh [102.202653ms]
    Apr 18 08:28:40.407: INFO: Got endpoints: latency-svc-9hmdn [101.623936ms]
    Apr 18 08:28:40.409: INFO: Created: latency-svc-sxfkx
    Apr 18 08:28:40.415: INFO: Got endpoints: latency-svc-sxfkx [103.032421ms]
    Apr 18 08:28:40.417: INFO: Created: latency-svc-n2r7l
    Apr 18 08:28:40.423: INFO: Got endpoints: latency-svc-n2r7l [105.704612ms]
    Apr 18 08:28:40.424: INFO: Created: latency-svc-m78kd
    Apr 18 08:28:40.429: INFO: Got endpoints: latency-svc-m78kd [106.56197ms]
    Apr 18 08:28:40.431: INFO: Created: latency-svc-b2drg
    Apr 18 08:28:40.435: INFO: Got endpoints: latency-svc-b2drg [106.650153ms]
    Apr 18 08:28:40.438: INFO: Created: latency-svc-24flq
    Apr 18 08:28:40.451: INFO: Got endpoints: latency-svc-24flq [116.749571ms]
    Apr 18 08:28:40.454: INFO: Created: latency-svc-2g468
    Apr 18 08:28:40.461: INFO: Got endpoints: latency-svc-2g468 [117.429974ms]
    Apr 18 08:28:40.462: INFO: Created: latency-svc-hf2xz
    Apr 18 08:28:40.466: INFO: Got endpoints: latency-svc-hf2xz [111.35342ms]
    Apr 18 08:28:40.470: INFO: Created: latency-svc-b9bbt
    Apr 18 08:28:40.476: INFO: Got endpoints: latency-svc-b9bbt [115.852972ms]
    Apr 18 08:28:40.476: INFO: Created: latency-svc-nzn5f
    Apr 18 08:28:40.481: INFO: Got endpoints: latency-svc-nzn5f [113.936624ms]
    Apr 18 08:28:40.482: INFO: Created: latency-svc-7k8q8
    Apr 18 08:28:40.488: INFO: Created: latency-svc-2s7x2
    Apr 18 08:28:40.488: INFO: Got endpoints: latency-svc-7k8q8 [114.414028ms]
    Apr 18 08:28:40.492: INFO: Got endpoints: latency-svc-2s7x2 [113.059372ms]
    Apr 18 08:28:40.493: INFO: Created: latency-svc-sht4t
    Apr 18 08:28:40.496: INFO: Got endpoints: latency-svc-sht4t [109.821266ms]
    Apr 18 08:28:40.499: INFO: Created: latency-svc-rl8cr
    Apr 18 08:28:40.503: INFO: Got endpoints: latency-svc-rl8cr [110.213037ms]
    Apr 18 08:28:40.505: INFO: Created: latency-svc-7ntjb
    Apr 18 08:28:40.512: INFO: Got endpoints: latency-svc-7ntjb [109.561218ms]
    Apr 18 08:28:40.515: INFO: Created: latency-svc-9rbz4
    Apr 18 08:28:40.520: INFO: Got endpoints: latency-svc-9rbz4 [112.531783ms]
    Apr 18 08:28:40.521: INFO: Created: latency-svc-z55nt
    Apr 18 08:28:40.525: INFO: Got endpoints: latency-svc-z55nt [110.281158ms]
    Apr 18 08:28:40.529: INFO: Created: latency-svc-45gdw
    Apr 18 08:28:40.532: INFO: Created: latency-svc-754l2
    Apr 18 08:28:40.534: INFO: Got endpoints: latency-svc-45gdw [111.254893ms]
    Apr 18 08:28:40.536: INFO: Got endpoints: latency-svc-754l2 [107.102935ms]
    Apr 18 08:28:40.547: INFO: Created: latency-svc-dsp6v
    Apr 18 08:28:40.557: INFO: Got endpoints: latency-svc-dsp6v [122.220304ms]
    Apr 18 08:28:40.558: INFO: Created: latency-svc-2xtjx
    Apr 18 08:28:40.563: INFO: Got endpoints: latency-svc-2xtjx [111.823432ms]
    Apr 18 08:28:40.565: INFO: Created: latency-svc-p7cd7
    Apr 18 08:28:40.569: INFO: Created: latency-svc-d95rd
    Apr 18 08:28:40.573: INFO: Got endpoints: latency-svc-p7cd7 [111.667765ms]
    Apr 18 08:28:40.575: INFO: Got endpoints: latency-svc-d95rd [108.414365ms]
    Apr 18 08:28:40.579: INFO: Created: latency-svc-lnl5k
    Apr 18 08:28:40.583: INFO: Got endpoints: latency-svc-lnl5k [107.607053ms]
    Apr 18 08:28:40.588: INFO: Created: latency-svc-2cvbd
    Apr 18 08:28:40.593: INFO: Got endpoints: latency-svc-2cvbd [111.393517ms]
    Apr 18 08:28:40.594: INFO: Created: latency-svc-5n4sc
    Apr 18 08:28:40.598: INFO: Got endpoints: latency-svc-5n4sc [110.053015ms]
    Apr 18 08:28:40.601: INFO: Created: latency-svc-zdkrg
    Apr 18 08:28:40.606: INFO: Got endpoints: latency-svc-zdkrg [113.966003ms]
    Apr 18 08:28:40.608: INFO: Created: latency-svc-fnjh4
    Apr 18 08:28:40.614: INFO: Got endpoints: latency-svc-fnjh4 [118.009932ms]
    Apr 18 08:28:40.654: INFO: Created: latency-svc-z6vmf
    Apr 18 08:28:40.690: INFO: Got endpoints: latency-svc-z6vmf [186.709617ms]
    Apr 18 08:28:40.693: INFO: Created: latency-svc-q24bj
    Apr 18 08:28:40.728: INFO: Got endpoints: latency-svc-q24bj [216.62654ms]
    Apr 18 08:28:40.730: INFO: Created: latency-svc-vjxlq
    Apr 18 08:28:40.747: INFO: Got endpoints: latency-svc-vjxlq [227.205638ms]
    Apr 18 08:28:40.751: INFO: Created: latency-svc-dkpln
    Apr 18 08:28:40.762: INFO: Got endpoints: latency-svc-dkpln [236.8182ms]
    Apr 18 08:28:40.763: INFO: Created: latency-svc-q272d
    Apr 18 08:28:40.781: INFO: Got endpoints: latency-svc-q272d [246.420449ms]
    Apr 18 08:28:40.788: INFO: Created: latency-svc-9w49f
    Apr 18 08:28:40.800: INFO: Got endpoints: latency-svc-9w49f [263.730896ms]
    Apr 18 08:28:40.805: INFO: Created: latency-svc-tmdgp
    Apr 18 08:28:40.827: INFO: Got endpoints: latency-svc-tmdgp [269.516914ms]
    Apr 18 08:28:40.830: INFO: Created: latency-svc-hsbsb
    Apr 18 08:28:40.838: INFO: Got endpoints: latency-svc-hsbsb [275.124197ms]
    Apr 18 08:28:40.852: INFO: Created: latency-svc-bwbhc
    Apr 18 08:28:40.875: INFO: Got endpoints: latency-svc-bwbhc [302.487775ms]
    Apr 18 08:28:40.882: INFO: Created: latency-svc-rpv2g
    Apr 18 08:28:40.901: INFO: Got endpoints: latency-svc-rpv2g [325.80352ms]
    Apr 18 08:28:40.906: INFO: Created: latency-svc-jqpw9
    Apr 18 08:28:40.912: INFO: Got endpoints: latency-svc-jqpw9 [328.636609ms]
    Apr 18 08:28:40.915: INFO: Created: latency-svc-dj6kn
    Apr 18 08:28:40.925: INFO: Got endpoints: latency-svc-dj6kn [332.463291ms]
    Apr 18 08:28:40.927: INFO: Created: latency-svc-7fvq7
    Apr 18 08:28:40.940: INFO: Got endpoints: latency-svc-7fvq7 [341.705274ms]
    Apr 18 08:28:40.957: INFO: Created: latency-svc-7h5lv
    Apr 18 08:28:40.964: INFO: Got endpoints: latency-svc-7h5lv [357.864238ms]
    Apr 18 08:28:40.971: INFO: Created: latency-svc-9wtjp
    Apr 18 08:28:40.977: INFO: Got endpoints: latency-svc-9wtjp [362.69366ms]
    Apr 18 08:28:40.980: INFO: Created: latency-svc-qgdf8
    Apr 18 08:28:40.988: INFO: Got endpoints: latency-svc-qgdf8 [298.036627ms]
    Apr 18 08:28:40.988: INFO: Latencies: [13.017649ms 20.98199ms 44.364393ms 60.033806ms 64.73021ms 73.412246ms 78.009791ms 78.998627ms 80.301699ms 80.419732ms 80.594736ms 81.322019ms 83.20405ms 83.898403ms 83.942839ms 84.215484ms 84.458457ms 84.556599ms 85.399943ms 85.681458ms 85.794435ms 85.849278ms 86.372996ms 86.402872ms 86.683884ms 86.909783ms 87.233673ms 87.267818ms 87.517153ms 87.545124ms 87.762594ms 87.906563ms 87.914951ms 87.939275ms 88.031752ms 88.120852ms 88.185847ms 88.696455ms 88.730934ms 88.884ms 88.943571ms 88.957427ms 89.140832ms 89.24017ms 89.28312ms 89.297701ms 89.372591ms 89.475488ms 89.491855ms 89.510462ms 89.926166ms 90.107245ms 90.108329ms 90.124189ms 90.161469ms 90.173386ms 90.275447ms 90.310419ms 90.315492ms 90.333852ms 90.433503ms 90.44492ms 90.453056ms 90.577207ms 90.630416ms 90.674205ms 90.739581ms 90.822116ms 90.835337ms 90.907109ms 91.01464ms 91.1482ms 91.27683ms 91.304261ms 91.336297ms 91.355932ms 91.38921ms 91.568689ms 91.621504ms 91.722005ms 91.781812ms 91.936951ms 91.986809ms 91.992436ms 91.999147ms 92.010741ms 92.086186ms 92.132343ms 92.239601ms 92.245912ms 92.453821ms 92.475442ms 92.978437ms 93.328662ms 93.414633ms 93.437945ms 93.459005ms 93.65743ms 93.710107ms 93.795125ms 93.798123ms 93.844475ms 94.079159ms 94.205609ms 94.339266ms 94.658256ms 95.292553ms 95.386486ms 95.645768ms 95.949729ms 96.116393ms 96.178057ms 96.183585ms 96.584828ms 96.811673ms 96.886777ms 96.904055ms 97.207723ms 97.226683ms 97.368022ms 97.371605ms 97.434774ms 97.692298ms 97.88194ms 98.005843ms 98.066124ms 98.163396ms 98.225852ms 98.288184ms 98.300203ms 98.322757ms 98.337191ms 98.467775ms 98.558275ms 98.734095ms 98.82675ms 99.01947ms 99.054076ms 99.076586ms 99.597052ms 99.655123ms 99.758083ms 100.082828ms 100.108316ms 100.222482ms 100.278747ms 100.895343ms 101.623936ms 101.839694ms 102.202653ms 103.032421ms 105.704612ms 106.56197ms 106.650153ms 107.102935ms 107.607053ms 108.414365ms 109.561218ms 109.596016ms 109.732315ms 109.821266ms 110.053015ms 110.213037ms 110.281158ms 111.254893ms 111.35342ms 111.393517ms 111.667765ms 111.823432ms 112.531783ms 113.059372ms 113.936624ms 113.966003ms 114.414028ms 115.031155ms 115.852972ms 116.749571ms 116.955371ms 117.429974ms 118.009932ms 122.220304ms 122.856831ms 137.004732ms 168.800271ms 186.709617ms 216.62654ms 227.205638ms 236.8182ms 246.420449ms 263.730896ms 269.516914ms 275.124197ms 298.036627ms 302.487775ms 325.80352ms 328.636609ms 332.463291ms 341.705274ms 357.864238ms 362.69366ms]
    Apr 18 08:28:40.988: INFO: 50 %ile: 93.798123ms
    Apr 18 08:28:40.988: INFO: 90 %ile: 122.220304ms
    Apr 18 08:28:40.988: INFO: 99 %ile: 357.864238ms
    Apr 18 08:28:40.988: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Apr 18 08:28:40.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-6580" for this suite. 04/18/23 08:28:40.994
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:28:41.003
Apr 18 08:28:41.004: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 08:28:41.006
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:28:41.016
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:28:41.02
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 04/18/23 08:28:41.023
Apr 18 08:28:41.024: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: rename a version 04/18/23 08:28:47.414
STEP: check the new version name is served 04/18/23 08:28:47.478
STEP: check the old version name is removed 04/18/23 08:28:50.282
STEP: check the other version is not changed 04/18/23 08:28:51.68
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 08:28:56.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7995" for this suite. 04/18/23 08:28:56.684
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":10,"skipped":181,"failed":0}
------------------------------
• [SLOW TEST] [15.685 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:28:41.003
    Apr 18 08:28:41.004: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 08:28:41.006
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:28:41.016
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:28:41.02
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 04/18/23 08:28:41.023
    Apr 18 08:28:41.024: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: rename a version 04/18/23 08:28:47.414
    STEP: check the new version name is served 04/18/23 08:28:47.478
    STEP: check the old version name is removed 04/18/23 08:28:50.282
    STEP: check the other version is not changed 04/18/23 08:28:51.68
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 08:28:56.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7995" for this suite. 04/18/23 08:28:56.684
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:28:56.689
Apr 18 08:28:56.690: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename gc 04/18/23 08:28:56.69
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:28:56.701
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:28:56.704
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 04/18/23 08:28:56.708
STEP: Wait for the Deployment to create new ReplicaSet 04/18/23 08:28:56.713
STEP: delete the deployment 04/18/23 08:28:57.222
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 04/18/23 08:28:57.227
STEP: Gathering metrics 04/18/23 08:28:57.744
W0418 08:28:57.753230      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 18 08:28:57.753: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 18 08:28:57.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5501" for this suite. 04/18/23 08:28:57.756
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":11,"skipped":183,"failed":0}
------------------------------
• [1.071 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:28:56.689
    Apr 18 08:28:56.690: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename gc 04/18/23 08:28:56.69
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:28:56.701
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:28:56.704
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 04/18/23 08:28:56.708
    STEP: Wait for the Deployment to create new ReplicaSet 04/18/23 08:28:56.713
    STEP: delete the deployment 04/18/23 08:28:57.222
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 04/18/23 08:28:57.227
    STEP: Gathering metrics 04/18/23 08:28:57.744
    W0418 08:28:57.753230      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 18 08:28:57.753: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 18 08:28:57.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5501" for this suite. 04/18/23 08:28:57.756
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:28:57.761
Apr 18 08:28:57.761: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename podtemplate 04/18/23 08:28:57.762
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:28:57.772
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:28:57.775
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Apr 18 08:28:57.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-6295" for this suite. 04/18/23 08:28:57.805
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":12,"skipped":211,"failed":0}
------------------------------
• [0.048 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:28:57.761
    Apr 18 08:28:57.761: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename podtemplate 04/18/23 08:28:57.762
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:28:57.772
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:28:57.775
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Apr 18 08:28:57.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-6295" for this suite. 04/18/23 08:28:57.805
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:28:57.811
Apr 18 08:28:57.811: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 08:28:57.811
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:28:57.82
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:28:57.824
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Apr 18 08:28:57.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-8356 create -f -'
Apr 18 08:28:58.466: INFO: stderr: ""
Apr 18 08:28:58.466: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Apr 18 08:28:58.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-8356 create -f -'
Apr 18 08:28:58.640: INFO: stderr: ""
Apr 18 08:28:58.640: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/18/23 08:28:58.64
Apr 18 08:28:59.644: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 08:28:59.644: INFO: Found 0 / 1
Apr 18 08:29:00.644: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 08:29:00.644: INFO: Found 1 / 1
Apr 18 08:29:00.644: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 18 08:29:00.648: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 08:29:00.648: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 18 08:29:00.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-8356 describe pod agnhost-primary-7mc5k'
Apr 18 08:29:00.720: INFO: stderr: ""
Apr 18 08:29:00.720: INFO: stdout: "Name:             agnhost-primary-7mc5k\nNamespace:        kubectl-8356\nPriority:         0\nService Account:  default\nNode:             192.168.1.152/192.168.1.152\nStart Time:       Tue, 18 Apr 2023 08:28:58 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               172.16.1.29\nIPs:\n  IP:           172.16.1.29\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://5f47f774c14d57aaa6becaecd17793e3dd6fe361073f332dde31b373cfbb533b\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 18 Apr 2023 08:28:59 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-bfzsh (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-bfzsh:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason                 Age              From               Message\n  ----    ------                 ----             ----               -------\n  Normal  Scheduled              2s               default-scheduler  Successfully assigned kubectl-8356/agnhost-primary-7mc5k to 192.168.1.152\n  Normal  Pulled                 2s               kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  SuccessfulCreate       2s               kubelet            Created container agnhost-primary\n  Normal  SuccessfulMountVolume  1s (x2 over 2s)  kubelet            Successfully mounted volumes for pod \"agnhost-primary-7mc5k_kubectl-8356(216ef70c-bbc6-4b30-b889-986c7671bee8)\"\n  Normal  Started                1s               kubelet            Started container agnhost-primary\n"
Apr 18 08:29:00.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-8356 describe rc agnhost-primary'
Apr 18 08:29:00.783: INFO: stderr: ""
Apr 18 08:29:00.783: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-8356\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-7mc5k\n"
Apr 18 08:29:00.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-8356 describe service agnhost-primary'
Apr 18 08:29:00.868: INFO: stderr: ""
Apr 18 08:29:00.868: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-8356\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.247.152.64\nIPs:               10.247.152.64\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.16.1.29:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 18 08:29:00.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-8356 describe node 192.168.1.152'
Apr 18 08:29:00.956: INFO: stderr: ""
Apr 18 08:29:00.956: INFO: stdout: "Name:               192.168.1.152\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=c4.large.2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-de\n                    failure-domain.beta.kubernetes.io/zone=eu-de-01\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=192.168.1.152\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/baremetal=false\n                    node.kubernetes.io/container-engine=containerd\n                    node.kubernetes.io/instance-type=c4.large.2\n                    node.kubernetes.io/subnetid=ac304843-127a-41af-ba4e-5ce0cd1b0e4d\n                    os.architecture=amd64\n                    os.name=EulerOS_2.0_SP9x86_64\n                    os.version=4.18.0-147.5.1.6.h766.eulerosv2r9.x86_64\n                    topology.kubernetes.io/region=eu-de\n                    topology.kubernetes.io/zone=eu-de-01\nAnnotations:        alpha.kubernetes.io/provided-node-ip: 192.168.1.152\n                    csi.volume.kubernetes.io/nodeid:\n                      {\"disk.csi.everest.io\":\"a3487761-ac45-434d-a1d0-fdaf66d5b706\",\"local.csi.everest.io\":\"a3487761-ac45-434d-a1d0-fdaf66d5b706\",\"nas.csi.evere...\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 17 Apr 2023 15:47:22 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  192.168.1.152\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 18 Apr 2023 08:28:58 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 18 Apr 2023 08:28:57 +0000   Mon, 17 Apr 2023 15:47:19 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 18 Apr 2023 08:28:57 +0000   Mon, 17 Apr 2023 15:47:19 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 18 Apr 2023 08:28:57 +0000   Mon, 17 Apr 2023 15:47:19 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 18 Apr 2023 08:28:57 +0000   Mon, 17 Apr 2023 15:47:32 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.1.152\n  ExternalIP:  80.158.52.47\n  Hostname:    192.168.1.152\nCapacity:\n  cpu:                2\n  ephemeral-storage:  10251540Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  localssd:           0\n  localvolume:        0\n  memory:             3772888Ki\n  pods:               20\nAllocatable:\n  cpu:                1930m\n  ephemeral-storage:  9447819249\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  localssd:           0\n  localvolume:        0\n  memory:             2544088Ki\n  pods:               20\nSystem Info:\n  Machine ID:                 a3487761-ac45-434d-a1d0-fdaf66d5b706\n  System UUID:                2e15fc7f-1c9a-40ef-9e04-5b2cb79b0997\n  Boot ID:                    4a9820c5-d51a-46cd-8ae7-bd1a40e516bc\n  Kernel Version:             4.18.0-147.5.1.6.h766.eulerosv2r9.x86_64\n  OS Image:                   EulerOS 2.0 (SP9x86_64)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.4.1-112-g855254a92\n  Kubelet Version:            v1.25.2-r0-CCE22.12.1\n  Kube-Proxy Version:         v1.25.2-r0-CCE22.12.1\nProviderID:                   d56800ad-dd36-11ed-8983-02550a100049\nNon-terminated Pods:          (7 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  gc-5501                     simpletest.deployment-59dbb66569-92kjh                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\n  kube-system                 everest-csi-driver-2sbdm                                   100m (5%)     500m (25%)  300Mi (12%)      300Mi (12%)    16h\n  kube-system                 icagent-blm9c                                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         16h\n  kubectl-8356                agnhost-primary-7mc5k                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         3m38s\n  sonobuoy                    sonobuoy-e2e-job-98a0ff59191d4d9f                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         3m30s\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-brt2v    0 (0%)        0 (0%)      0 (0%)           0 (0%)         3m30s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                100m (5%)    500m (25%)\n  memory             300Mi (12%)  300Mi (12%)\n  ephemeral-storage  0 (0%)       0 (0%)\n  hugepages-1Gi      0 (0%)       0 (0%)\n  hugepages-2Mi      0 (0%)       0 (0%)\n  localssd           0            0\n  localvolume        0            0\nEvents:              <none>\n"
Apr 18 08:29:00.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-8356 describe namespace kubectl-8356'
Apr 18 08:29:01.019: INFO: stderr: ""
Apr 18 08:29:01.019: INFO: stdout: "Name:         kubectl-8356\nLabels:       e2e-framework=kubectl\n              e2e-run=c5fadca4-7a0b-4c11-b8d1-508daf2cfdb2\n              kubernetes.io/metadata.name=kubectl-8356\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 08:29:01.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8356" for this suite. 04/18/23 08:29:01.023
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":13,"skipped":243,"failed":0}
------------------------------
• [3.217 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:28:57.811
    Apr 18 08:28:57.811: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 08:28:57.811
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:28:57.82
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:28:57.824
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Apr 18 08:28:57.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-8356 create -f -'
    Apr 18 08:28:58.466: INFO: stderr: ""
    Apr 18 08:28:58.466: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Apr 18 08:28:58.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-8356 create -f -'
    Apr 18 08:28:58.640: INFO: stderr: ""
    Apr 18 08:28:58.640: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/18/23 08:28:58.64
    Apr 18 08:28:59.644: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 08:28:59.644: INFO: Found 0 / 1
    Apr 18 08:29:00.644: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 08:29:00.644: INFO: Found 1 / 1
    Apr 18 08:29:00.644: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Apr 18 08:29:00.648: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 08:29:00.648: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 18 08:29:00.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-8356 describe pod agnhost-primary-7mc5k'
    Apr 18 08:29:00.720: INFO: stderr: ""
    Apr 18 08:29:00.720: INFO: stdout: "Name:             agnhost-primary-7mc5k\nNamespace:        kubectl-8356\nPriority:         0\nService Account:  default\nNode:             192.168.1.152/192.168.1.152\nStart Time:       Tue, 18 Apr 2023 08:28:58 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               172.16.1.29\nIPs:\n  IP:           172.16.1.29\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://5f47f774c14d57aaa6becaecd17793e3dd6fe361073f332dde31b373cfbb533b\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 18 Apr 2023 08:28:59 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-bfzsh (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-bfzsh:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason                 Age              From               Message\n  ----    ------                 ----             ----               -------\n  Normal  Scheduled              2s               default-scheduler  Successfully assigned kubectl-8356/agnhost-primary-7mc5k to 192.168.1.152\n  Normal  Pulled                 2s               kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  SuccessfulCreate       2s               kubelet            Created container agnhost-primary\n  Normal  SuccessfulMountVolume  1s (x2 over 2s)  kubelet            Successfully mounted volumes for pod \"agnhost-primary-7mc5k_kubectl-8356(216ef70c-bbc6-4b30-b889-986c7671bee8)\"\n  Normal  Started                1s               kubelet            Started container agnhost-primary\n"
    Apr 18 08:29:00.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-8356 describe rc agnhost-primary'
    Apr 18 08:29:00.783: INFO: stderr: ""
    Apr 18 08:29:00.783: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-8356\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-7mc5k\n"
    Apr 18 08:29:00.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-8356 describe service agnhost-primary'
    Apr 18 08:29:00.868: INFO: stderr: ""
    Apr 18 08:29:00.868: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-8356\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.247.152.64\nIPs:               10.247.152.64\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.16.1.29:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Apr 18 08:29:00.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-8356 describe node 192.168.1.152'
    Apr 18 08:29:00.956: INFO: stderr: ""
    Apr 18 08:29:00.956: INFO: stdout: "Name:               192.168.1.152\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=c4.large.2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-de\n                    failure-domain.beta.kubernetes.io/zone=eu-de-01\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=192.168.1.152\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/baremetal=false\n                    node.kubernetes.io/container-engine=containerd\n                    node.kubernetes.io/instance-type=c4.large.2\n                    node.kubernetes.io/subnetid=ac304843-127a-41af-ba4e-5ce0cd1b0e4d\n                    os.architecture=amd64\n                    os.name=EulerOS_2.0_SP9x86_64\n                    os.version=4.18.0-147.5.1.6.h766.eulerosv2r9.x86_64\n                    topology.kubernetes.io/region=eu-de\n                    topology.kubernetes.io/zone=eu-de-01\nAnnotations:        alpha.kubernetes.io/provided-node-ip: 192.168.1.152\n                    csi.volume.kubernetes.io/nodeid:\n                      {\"disk.csi.everest.io\":\"a3487761-ac45-434d-a1d0-fdaf66d5b706\",\"local.csi.everest.io\":\"a3487761-ac45-434d-a1d0-fdaf66d5b706\",\"nas.csi.evere...\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 17 Apr 2023 15:47:22 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  192.168.1.152\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 18 Apr 2023 08:28:58 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 18 Apr 2023 08:28:57 +0000   Mon, 17 Apr 2023 15:47:19 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 18 Apr 2023 08:28:57 +0000   Mon, 17 Apr 2023 15:47:19 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 18 Apr 2023 08:28:57 +0000   Mon, 17 Apr 2023 15:47:19 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 18 Apr 2023 08:28:57 +0000   Mon, 17 Apr 2023 15:47:32 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.1.152\n  ExternalIP:  80.158.52.47\n  Hostname:    192.168.1.152\nCapacity:\n  cpu:                2\n  ephemeral-storage:  10251540Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  localssd:           0\n  localvolume:        0\n  memory:             3772888Ki\n  pods:               20\nAllocatable:\n  cpu:                1930m\n  ephemeral-storage:  9447819249\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  localssd:           0\n  localvolume:        0\n  memory:             2544088Ki\n  pods:               20\nSystem Info:\n  Machine ID:                 a3487761-ac45-434d-a1d0-fdaf66d5b706\n  System UUID:                2e15fc7f-1c9a-40ef-9e04-5b2cb79b0997\n  Boot ID:                    4a9820c5-d51a-46cd-8ae7-bd1a40e516bc\n  Kernel Version:             4.18.0-147.5.1.6.h766.eulerosv2r9.x86_64\n  OS Image:                   EulerOS 2.0 (SP9x86_64)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.4.1-112-g855254a92\n  Kubelet Version:            v1.25.2-r0-CCE22.12.1\n  Kube-Proxy Version:         v1.25.2-r0-CCE22.12.1\nProviderID:                   d56800ad-dd36-11ed-8983-02550a100049\nNon-terminated Pods:          (7 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  gc-5501                     simpletest.deployment-59dbb66569-92kjh                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\n  kube-system                 everest-csi-driver-2sbdm                                   100m (5%)     500m (25%)  300Mi (12%)      300Mi (12%)    16h\n  kube-system                 icagent-blm9c                                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         16h\n  kubectl-8356                agnhost-primary-7mc5k                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         3m38s\n  sonobuoy                    sonobuoy-e2e-job-98a0ff59191d4d9f                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         3m30s\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-brt2v    0 (0%)        0 (0%)      0 (0%)           0 (0%)         3m30s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                100m (5%)    500m (25%)\n  memory             300Mi (12%)  300Mi (12%)\n  ephemeral-storage  0 (0%)       0 (0%)\n  hugepages-1Gi      0 (0%)       0 (0%)\n  hugepages-2Mi      0 (0%)       0 (0%)\n  localssd           0            0\n  localvolume        0            0\nEvents:              <none>\n"
    Apr 18 08:29:00.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-8356 describe namespace kubectl-8356'
    Apr 18 08:29:01.019: INFO: stderr: ""
    Apr 18 08:29:01.019: INFO: stdout: "Name:         kubectl-8356\nLabels:       e2e-framework=kubectl\n              e2e-run=c5fadca4-7a0b-4c11-b8d1-508daf2cfdb2\n              kubernetes.io/metadata.name=kubectl-8356\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 08:29:01.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8356" for this suite. 04/18/23 08:29:01.023
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:29:01.03
Apr 18 08:29:01.030: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename pods 04/18/23 08:29:01.031
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:01.039
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:01.043
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 04/18/23 08:29:01.046
STEP: submitting the pod to kubernetes 04/18/23 08:29:01.046
STEP: verifying QOS class is set on the pod 04/18/23 08:29:01.052
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Apr 18 08:29:01.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8720" for this suite. 04/18/23 08:29:01.061
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":14,"skipped":255,"failed":0}
------------------------------
• [0.036 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:29:01.03
    Apr 18 08:29:01.030: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename pods 04/18/23 08:29:01.031
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:01.039
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:01.043
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 04/18/23 08:29:01.046
    STEP: submitting the pod to kubernetes 04/18/23 08:29:01.046
    STEP: verifying QOS class is set on the pod 04/18/23 08:29:01.052
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Apr 18 08:29:01.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8720" for this suite. 04/18/23 08:29:01.061
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:29:01.072
Apr 18 08:29:01.072: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 08:29:01.074
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:01.085
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:01.089
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 08:29:01.104
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:29:01.378
STEP: Deploying the webhook pod 04/18/23 08:29:01.384
STEP: Wait for the deployment to be ready 04/18/23 08:29:01.394
Apr 18 08:29:01.399: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 08:29:03.408
STEP: Verifying the service has paired with the endpoint 04/18/23 08:29:03.416
Apr 18 08:29:04.417: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 04/18/23 08:29:04.42
STEP: create a pod 04/18/23 08:29:04.491
Apr 18 08:29:04.495: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-532" to be "running"
Apr 18 08:29:04.498: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.653917ms
Apr 18 08:29:06.502: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.006808318s
Apr 18 08:29:06.502: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 04/18/23 08:29:06.502
Apr 18 08:29:06.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=webhook-532 attach --namespace=webhook-532 to-be-attached-pod -i -c=container1'
Apr 18 08:29:06.588: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 08:29:06.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-532" for this suite. 04/18/23 08:29:06.596
STEP: Destroying namespace "webhook-532-markers" for this suite. 04/18/23 08:29:06.6
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":15,"skipped":282,"failed":0}
------------------------------
• [SLOW TEST] [5.554 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:29:01.072
    Apr 18 08:29:01.072: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 08:29:01.074
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:01.085
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:01.089
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 08:29:01.104
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:29:01.378
    STEP: Deploying the webhook pod 04/18/23 08:29:01.384
    STEP: Wait for the deployment to be ready 04/18/23 08:29:01.394
    Apr 18 08:29:01.399: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 08:29:03.408
    STEP: Verifying the service has paired with the endpoint 04/18/23 08:29:03.416
    Apr 18 08:29:04.417: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 04/18/23 08:29:04.42
    STEP: create a pod 04/18/23 08:29:04.491
    Apr 18 08:29:04.495: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-532" to be "running"
    Apr 18 08:29:04.498: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.653917ms
    Apr 18 08:29:06.502: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.006808318s
    Apr 18 08:29:06.502: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 04/18/23 08:29:06.502
    Apr 18 08:29:06.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=webhook-532 attach --namespace=webhook-532 to-be-attached-pod -i -c=container1'
    Apr 18 08:29:06.588: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 08:29:06.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-532" for this suite. 04/18/23 08:29:06.596
    STEP: Destroying namespace "webhook-532-markers" for this suite. 04/18/23 08:29:06.6
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:29:06.627
Apr 18 08:29:06.627: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 04/18/23 08:29:06.627
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:06.639
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:06.642
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 04/18/23 08:29:06.646
STEP: Creating hostNetwork=false pod 04/18/23 08:29:06.646
Apr 18 08:29:06.654: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-2983" to be "running and ready"
Apr 18 08:29:06.657: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.785338ms
Apr 18 08:29:06.657: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:29:08.660: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.005920627s
Apr 18 08:29:08.660: INFO: The phase of Pod test-pod is Running (Ready = true)
Apr 18 08:29:08.660: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 04/18/23 08:29:08.663
Apr 18 08:29:08.671: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-2983" to be "running and ready"
Apr 18 08:29:08.677: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.968086ms
Apr 18 08:29:08.677: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:29:10.680: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009557354s
Apr 18 08:29:10.680: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Apr 18 08:29:10.680: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 04/18/23 08:29:10.683
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 04/18/23 08:29:10.683
Apr 18 08:29:10.683: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:29:10.683: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:29:10.683: INFO: ExecWithOptions: Clientset creation
Apr 18 08:29:10.683: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 18 08:29:10.738: INFO: Exec stderr: ""
Apr 18 08:29:10.738: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:29:10.738: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:29:10.739: INFO: ExecWithOptions: Clientset creation
Apr 18 08:29:10.739: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 18 08:29:10.789: INFO: Exec stderr: ""
Apr 18 08:29:10.789: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:29:10.789: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:29:10.790: INFO: ExecWithOptions: Clientset creation
Apr 18 08:29:10.790: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 18 08:29:10.839: INFO: Exec stderr: ""
Apr 18 08:29:10.839: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:29:10.839: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:29:10.840: INFO: ExecWithOptions: Clientset creation
Apr 18 08:29:10.840: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 18 08:29:10.900: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 04/18/23 08:29:10.9
Apr 18 08:29:10.901: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:29:10.901: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:29:10.901: INFO: ExecWithOptions: Clientset creation
Apr 18 08:29:10.901: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Apr 18 08:29:10.941: INFO: Exec stderr: ""
Apr 18 08:29:10.941: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:29:10.941: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:29:10.941: INFO: ExecWithOptions: Clientset creation
Apr 18 08:29:10.941: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Apr 18 08:29:10.982: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 04/18/23 08:29:10.982
Apr 18 08:29:10.982: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:29:10.982: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:29:10.982: INFO: ExecWithOptions: Clientset creation
Apr 18 08:29:10.982: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 18 08:29:11.037: INFO: Exec stderr: ""
Apr 18 08:29:11.037: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:29:11.037: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:29:11.037: INFO: ExecWithOptions: Clientset creation
Apr 18 08:29:11.037: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 18 08:29:11.097: INFO: Exec stderr: ""
Apr 18 08:29:11.097: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:29:11.097: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:29:11.098: INFO: ExecWithOptions: Clientset creation
Apr 18 08:29:11.098: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 18 08:29:11.137: INFO: Exec stderr: ""
Apr 18 08:29:11.137: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:29:11.137: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:29:11.138: INFO: ExecWithOptions: Clientset creation
Apr 18 08:29:11.138: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 18 08:29:11.198: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Apr 18 08:29:11.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2983" for this suite. 04/18/23 08:29:11.202
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":16,"skipped":296,"failed":0}
------------------------------
• [4.581 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:29:06.627
    Apr 18 08:29:06.627: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 04/18/23 08:29:06.627
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:06.639
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:06.642
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 04/18/23 08:29:06.646
    STEP: Creating hostNetwork=false pod 04/18/23 08:29:06.646
    Apr 18 08:29:06.654: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-2983" to be "running and ready"
    Apr 18 08:29:06.657: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.785338ms
    Apr 18 08:29:06.657: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:29:08.660: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.005920627s
    Apr 18 08:29:08.660: INFO: The phase of Pod test-pod is Running (Ready = true)
    Apr 18 08:29:08.660: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 04/18/23 08:29:08.663
    Apr 18 08:29:08.671: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-2983" to be "running and ready"
    Apr 18 08:29:08.677: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.968086ms
    Apr 18 08:29:08.677: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:29:10.680: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009557354s
    Apr 18 08:29:10.680: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Apr 18 08:29:10.680: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 04/18/23 08:29:10.683
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 04/18/23 08:29:10.683
    Apr 18 08:29:10.683: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:29:10.683: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:29:10.683: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:29:10.683: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 18 08:29:10.738: INFO: Exec stderr: ""
    Apr 18 08:29:10.738: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:29:10.738: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:29:10.739: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:29:10.739: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 18 08:29:10.789: INFO: Exec stderr: ""
    Apr 18 08:29:10.789: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:29:10.789: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:29:10.790: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:29:10.790: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 18 08:29:10.839: INFO: Exec stderr: ""
    Apr 18 08:29:10.839: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:29:10.839: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:29:10.840: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:29:10.840: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 18 08:29:10.900: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 04/18/23 08:29:10.9
    Apr 18 08:29:10.901: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:29:10.901: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:29:10.901: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:29:10.901: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Apr 18 08:29:10.941: INFO: Exec stderr: ""
    Apr 18 08:29:10.941: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:29:10.941: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:29:10.941: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:29:10.941: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Apr 18 08:29:10.982: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 04/18/23 08:29:10.982
    Apr 18 08:29:10.982: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:29:10.982: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:29:10.982: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:29:10.982: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 18 08:29:11.037: INFO: Exec stderr: ""
    Apr 18 08:29:11.037: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:29:11.037: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:29:11.037: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:29:11.037: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 18 08:29:11.097: INFO: Exec stderr: ""
    Apr 18 08:29:11.097: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:29:11.097: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:29:11.098: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:29:11.098: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 18 08:29:11.137: INFO: Exec stderr: ""
    Apr 18 08:29:11.137: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2983 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:29:11.137: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:29:11.138: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:29:11.138: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2983/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 18 08:29:11.198: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Apr 18 08:29:11.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-2983" for this suite. 04/18/23 08:29:11.202
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:29:11.209
Apr 18 08:29:11.209: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename events 04/18/23 08:29:11.209
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:11.219
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:11.223
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 04/18/23 08:29:11.226
STEP: listing all events in all namespaces 04/18/23 08:29:11.23
STEP: patching the test event 04/18/23 08:29:11.234
STEP: fetching the test event 04/18/23 08:29:11.238
STEP: updating the test event 04/18/23 08:29:11.242
STEP: getting the test event 04/18/23 08:29:11.252
STEP: deleting the test event 04/18/23 08:29:11.254
STEP: listing all events in all namespaces 04/18/23 08:29:11.261
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Apr 18 08:29:11.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6062" for this suite. 04/18/23 08:29:11.271
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":17,"skipped":306,"failed":0}
------------------------------
• [0.071 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:29:11.209
    Apr 18 08:29:11.209: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename events 04/18/23 08:29:11.209
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:11.219
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:11.223
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 04/18/23 08:29:11.226
    STEP: listing all events in all namespaces 04/18/23 08:29:11.23
    STEP: patching the test event 04/18/23 08:29:11.234
    STEP: fetching the test event 04/18/23 08:29:11.238
    STEP: updating the test event 04/18/23 08:29:11.242
    STEP: getting the test event 04/18/23 08:29:11.252
    STEP: deleting the test event 04/18/23 08:29:11.254
    STEP: listing all events in all namespaces 04/18/23 08:29:11.261
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Apr 18 08:29:11.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-6062" for this suite. 04/18/23 08:29:11.271
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:29:11.28
Apr 18 08:29:11.280: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename deployment 04/18/23 08:29:11.281
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:11.29
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:11.293
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Apr 18 08:29:11.297: INFO: Creating deployment "test-recreate-deployment"
Apr 18 08:29:11.301: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 18 08:29:11.308: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr 18 08:29:13.315: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 18 08:29:13.317: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 08:29:15.322: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 08:29:17.321: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 08:29:19.321: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 08:29:21.322: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 08:29:23.321: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 18 08:29:23.329: INFO: Updating deployment test-recreate-deployment
Apr 18 08:29:23.329: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 08:29:23.397: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-5420  94bfa1d8-db33-491e-bc7d-01f730a2664f 4171531 2 2023-04-18 08:29:11 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002930048 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-18 08:29:23 +0000 UTC,LastTransitionTime:2023-04-18 08:29:23 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-04-18 08:29:23 +0000 UTC,LastTransitionTime:2023-04-18 08:29:11 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Apr 18 08:29:23.399: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-5420  6d52cebf-1673-418f-875e-e32dae6a8e47 4171528 1 2023-04-18 08:29:23 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 94bfa1d8-db33-491e-bc7d-01f730a2664f 0xc002930530 0xc002930531}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"94bfa1d8-db33-491e-bc7d-01f730a2664f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0029305c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 18 08:29:23.399: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 18 08:29:23.399: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-5420  e92f9693-e0b7-4462-9a98-3f8b20de2577 4171522 2 2023-04-18 08:29:11 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 94bfa1d8-db33-491e-bc7d-01f730a2664f 0xc002930407 0xc002930408}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"94bfa1d8-db33-491e-bc7d-01f730a2664f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0029304b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 18 08:29:23.402: INFO: Pod "test-recreate-deployment-9d58999df-tlthk" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-tlthk test-recreate-deployment-9d58999df- deployment-5420  d9d373f1-c6b6-47d0-80d9-443c7ecd152b 4171530 0 2023-04-18 08:29:23 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 6d52cebf-1673-418f-875e-e32dae6a8e47 0xc0051fd6d0 0xc0051fd6d1}] [] [{kube-controller-manager Update v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6d52cebf-1673-418f-875e-e32dae6a8e47\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8mc4f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8mc4f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:29:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:29:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:29:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:29:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:,StartTime:2023-04-18 08:29:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 08:29:23.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5420" for this suite. 04/18/23 08:29:23.406
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":18,"skipped":311,"failed":0}
------------------------------
• [SLOW TEST] [12.130 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:29:11.28
    Apr 18 08:29:11.280: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename deployment 04/18/23 08:29:11.281
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:11.29
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:11.293
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Apr 18 08:29:11.297: INFO: Creating deployment "test-recreate-deployment"
    Apr 18 08:29:11.301: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Apr 18 08:29:11.308: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Apr 18 08:29:13.315: INFO: Waiting deployment "test-recreate-deployment" to complete
    Apr 18 08:29:13.317: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 08:29:15.322: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 08:29:17.321: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 08:29:19.321: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 08:29:21.322: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 29, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 08:29:23.321: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Apr 18 08:29:23.329: INFO: Updating deployment test-recreate-deployment
    Apr 18 08:29:23.329: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 08:29:23.397: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-5420  94bfa1d8-db33-491e-bc7d-01f730a2664f 4171531 2 2023-04-18 08:29:11 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002930048 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-18 08:29:23 +0000 UTC,LastTransitionTime:2023-04-18 08:29:23 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-04-18 08:29:23 +0000 UTC,LastTransitionTime:2023-04-18 08:29:11 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Apr 18 08:29:23.399: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-5420  6d52cebf-1673-418f-875e-e32dae6a8e47 4171528 1 2023-04-18 08:29:23 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 94bfa1d8-db33-491e-bc7d-01f730a2664f 0xc002930530 0xc002930531}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"94bfa1d8-db33-491e-bc7d-01f730a2664f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0029305c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 08:29:23.399: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Apr 18 08:29:23.399: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-5420  e92f9693-e0b7-4462-9a98-3f8b20de2577 4171522 2 2023-04-18 08:29:11 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 94bfa1d8-db33-491e-bc7d-01f730a2664f 0xc002930407 0xc002930408}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"94bfa1d8-db33-491e-bc7d-01f730a2664f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0029304b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 08:29:23.402: INFO: Pod "test-recreate-deployment-9d58999df-tlthk" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-tlthk test-recreate-deployment-9d58999df- deployment-5420  d9d373f1-c6b6-47d0-80d9-443c7ecd152b 4171530 0 2023-04-18 08:29:23 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 6d52cebf-1673-418f-875e-e32dae6a8e47 0xc0051fd6d0 0xc0051fd6d1}] [] [{kube-controller-manager Update v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6d52cebf-1673-418f-875e-e32dae6a8e47\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:29:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8mc4f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8mc4f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:29:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:29:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:29:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:29:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:,StartTime:2023-04-18 08:29:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 08:29:23.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-5420" for this suite. 04/18/23 08:29:23.406
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:29:23.415
Apr 18 08:29:23.415: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 08:29:23.416
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:23.426
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:23.43
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 04/18/23 08:29:23.433
Apr 18 08:29:23.441: INFO: Waiting up to 5m0s for pod "downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d" in namespace "projected-7185" to be "Succeeded or Failed"
Apr 18 08:29:23.444: INFO: Pod "downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.827582ms
Apr 18 08:29:25.448: INFO: Pod "downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007016147s
Apr 18 08:29:27.447: INFO: Pod "downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005602182s
STEP: Saw pod success 04/18/23 08:29:27.447
Apr 18 08:29:27.447: INFO: Pod "downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d" satisfied condition "Succeeded or Failed"
Apr 18 08:29:27.450: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d container client-container: <nil>
STEP: delete the pod 04/18/23 08:29:27.455
Apr 18 08:29:27.464: INFO: Waiting for pod downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d to disappear
Apr 18 08:29:27.466: INFO: Pod downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 08:29:27.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7185" for this suite. 04/18/23 08:29:27.47
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":19,"skipped":383,"failed":0}
------------------------------
• [4.058 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:29:23.415
    Apr 18 08:29:23.415: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 08:29:23.416
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:23.426
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:23.43
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 04/18/23 08:29:23.433
    Apr 18 08:29:23.441: INFO: Waiting up to 5m0s for pod "downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d" in namespace "projected-7185" to be "Succeeded or Failed"
    Apr 18 08:29:23.444: INFO: Pod "downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.827582ms
    Apr 18 08:29:25.448: INFO: Pod "downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007016147s
    Apr 18 08:29:27.447: INFO: Pod "downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005602182s
    STEP: Saw pod success 04/18/23 08:29:27.447
    Apr 18 08:29:27.447: INFO: Pod "downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d" satisfied condition "Succeeded or Failed"
    Apr 18 08:29:27.450: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d container client-container: <nil>
    STEP: delete the pod 04/18/23 08:29:27.455
    Apr 18 08:29:27.464: INFO: Waiting for pod downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d to disappear
    Apr 18 08:29:27.466: INFO: Pod downwardapi-volume-05001e14-0728-42f9-a292-1efb5e25301d no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 08:29:27.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7185" for this suite. 04/18/23 08:29:27.47
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:29:27.474
Apr 18 08:29:27.474: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir 04/18/23 08:29:27.475
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:27.484
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:27.487
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 04/18/23 08:29:27.49
Apr 18 08:29:27.498: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-27bbb560-d360-45e0-8058-d85d4cd78ed8" in namespace "emptydir-7957" to be "running"
Apr 18 08:29:27.503: INFO: Pod "pod-sharedvolume-27bbb560-d360-45e0-8058-d85d4cd78ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.126621ms
Apr 18 08:29:29.506: INFO: Pod "pod-sharedvolume-27bbb560-d360-45e0-8058-d85d4cd78ed8": Phase="Running", Reason="", readiness=false. Elapsed: 2.008658877s
Apr 18 08:29:29.506: INFO: Pod "pod-sharedvolume-27bbb560-d360-45e0-8058-d85d4cd78ed8" satisfied condition "running"
STEP: Reading file content from the nginx-container 04/18/23 08:29:29.506
Apr 18 08:29:29.506: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-7957 PodName:pod-sharedvolume-27bbb560-d360-45e0-8058-d85d4cd78ed8 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:29:29.506: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:29:29.507: INFO: ExecWithOptions: Clientset creation
Apr 18 08:29:29.507: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/emptydir-7957/pods/pod-sharedvolume-27bbb560-d360-45e0-8058-d85d4cd78ed8/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Apr 18 08:29:29.562: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 08:29:29.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7957" for this suite. 04/18/23 08:29:29.566
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":20,"skipped":388,"failed":0}
------------------------------
• [2.097 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:29:27.474
    Apr 18 08:29:27.474: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir 04/18/23 08:29:27.475
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:27.484
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:27.487
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 04/18/23 08:29:27.49
    Apr 18 08:29:27.498: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-27bbb560-d360-45e0-8058-d85d4cd78ed8" in namespace "emptydir-7957" to be "running"
    Apr 18 08:29:27.503: INFO: Pod "pod-sharedvolume-27bbb560-d360-45e0-8058-d85d4cd78ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.126621ms
    Apr 18 08:29:29.506: INFO: Pod "pod-sharedvolume-27bbb560-d360-45e0-8058-d85d4cd78ed8": Phase="Running", Reason="", readiness=false. Elapsed: 2.008658877s
    Apr 18 08:29:29.506: INFO: Pod "pod-sharedvolume-27bbb560-d360-45e0-8058-d85d4cd78ed8" satisfied condition "running"
    STEP: Reading file content from the nginx-container 04/18/23 08:29:29.506
    Apr 18 08:29:29.506: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-7957 PodName:pod-sharedvolume-27bbb560-d360-45e0-8058-d85d4cd78ed8 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:29:29.506: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:29:29.507: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:29:29.507: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/emptydir-7957/pods/pod-sharedvolume-27bbb560-d360-45e0-8058-d85d4cd78ed8/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Apr 18 08:29:29.562: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 08:29:29.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7957" for this suite. 04/18/23 08:29:29.566
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:29:29.572
Apr 18 08:29:29.572: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename security-context 04/18/23 08:29:29.572
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:29.582
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:29.586
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/18/23 08:29:29.589
Apr 18 08:29:29.595: INFO: Waiting up to 5m0s for pod "security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025" in namespace "security-context-5075" to be "Succeeded or Failed"
Apr 18 08:29:29.598: INFO: Pod "security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025": Phase="Pending", Reason="", readiness=false. Elapsed: 2.92705ms
Apr 18 08:29:31.602: INFO: Pod "security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006929942s
Apr 18 08:29:33.601: INFO: Pod "security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006281816s
STEP: Saw pod success 04/18/23 08:29:33.601
Apr 18 08:29:33.601: INFO: Pod "security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025" satisfied condition "Succeeded or Failed"
Apr 18 08:29:33.604: INFO: Trying to get logs from node 192.168.1.152 pod security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025 container test-container: <nil>
STEP: delete the pod 04/18/23 08:29:33.609
Apr 18 08:29:33.619: INFO: Waiting for pod security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025 to disappear
Apr 18 08:29:33.621: INFO: Pod security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 18 08:29:33.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-5075" for this suite. 04/18/23 08:29:33.625
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":21,"skipped":419,"failed":0}
------------------------------
• [4.059 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:29:29.572
    Apr 18 08:29:29.572: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename security-context 04/18/23 08:29:29.572
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:29.582
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:29.586
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/18/23 08:29:29.589
    Apr 18 08:29:29.595: INFO: Waiting up to 5m0s for pod "security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025" in namespace "security-context-5075" to be "Succeeded or Failed"
    Apr 18 08:29:29.598: INFO: Pod "security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025": Phase="Pending", Reason="", readiness=false. Elapsed: 2.92705ms
    Apr 18 08:29:31.602: INFO: Pod "security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006929942s
    Apr 18 08:29:33.601: INFO: Pod "security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006281816s
    STEP: Saw pod success 04/18/23 08:29:33.601
    Apr 18 08:29:33.601: INFO: Pod "security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025" satisfied condition "Succeeded or Failed"
    Apr 18 08:29:33.604: INFO: Trying to get logs from node 192.168.1.152 pod security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025 container test-container: <nil>
    STEP: delete the pod 04/18/23 08:29:33.609
    Apr 18 08:29:33.619: INFO: Waiting for pod security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025 to disappear
    Apr 18 08:29:33.621: INFO: Pod security-context-bdc01b39-f5c0-44be-bd6a-982b7f7b7025 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 18 08:29:33.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-5075" for this suite. 04/18/23 08:29:33.625
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:29:33.634
Apr 18 08:29:33.634: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename endpointslice 04/18/23 08:29:33.635
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:33.649
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:33.652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 04/18/23 08:29:33.656
STEP: getting /apis/discovery.k8s.io 04/18/23 08:29:33.659
STEP: getting /apis/discovery.k8s.iov1 04/18/23 08:29:33.661
STEP: creating 04/18/23 08:29:33.662
STEP: getting 04/18/23 08:29:33.674
STEP: listing 04/18/23 08:29:33.677
STEP: watching 04/18/23 08:29:33.679
Apr 18 08:29:33.679: INFO: starting watch
STEP: cluster-wide listing 04/18/23 08:29:33.681
STEP: cluster-wide watching 04/18/23 08:29:33.684
Apr 18 08:29:33.684: INFO: starting watch
STEP: patching 04/18/23 08:29:33.685
STEP: updating 04/18/23 08:29:33.752
Apr 18 08:29:33.759: INFO: waiting for watch events with expected annotations
Apr 18 08:29:33.759: INFO: saw patched and updated annotations
STEP: deleting 04/18/23 08:29:33.759
STEP: deleting a collection 04/18/23 08:29:33.769
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 18 08:29:33.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9692" for this suite. 04/18/23 08:29:33.782
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":22,"skipped":450,"failed":0}
------------------------------
• [0.154 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:29:33.634
    Apr 18 08:29:33.634: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename endpointslice 04/18/23 08:29:33.635
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:33.649
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:33.652
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 04/18/23 08:29:33.656
    STEP: getting /apis/discovery.k8s.io 04/18/23 08:29:33.659
    STEP: getting /apis/discovery.k8s.iov1 04/18/23 08:29:33.661
    STEP: creating 04/18/23 08:29:33.662
    STEP: getting 04/18/23 08:29:33.674
    STEP: listing 04/18/23 08:29:33.677
    STEP: watching 04/18/23 08:29:33.679
    Apr 18 08:29:33.679: INFO: starting watch
    STEP: cluster-wide listing 04/18/23 08:29:33.681
    STEP: cluster-wide watching 04/18/23 08:29:33.684
    Apr 18 08:29:33.684: INFO: starting watch
    STEP: patching 04/18/23 08:29:33.685
    STEP: updating 04/18/23 08:29:33.752
    Apr 18 08:29:33.759: INFO: waiting for watch events with expected annotations
    Apr 18 08:29:33.759: INFO: saw patched and updated annotations
    STEP: deleting 04/18/23 08:29:33.759
    STEP: deleting a collection 04/18/23 08:29:33.769
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 18 08:29:33.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-9692" for this suite. 04/18/23 08:29:33.782
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:29:33.788
Apr 18 08:29:33.788: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename dns 04/18/23 08:29:33.788
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:33.8
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:33.804
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-565.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-565.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 04/18/23 08:29:33.807
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-565.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-565.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 04/18/23 08:29:33.807
STEP: creating a pod to probe /etc/hosts 04/18/23 08:29:33.807
STEP: submitting the pod to kubernetes 04/18/23 08:29:33.807
Apr 18 08:29:33.814: INFO: Waiting up to 15m0s for pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de" in namespace "dns-565" to be "running"
Apr 18 08:29:33.819: INFO: Pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de": Phase="Pending", Reason="", readiness=false. Elapsed: 4.728519ms
Apr 18 08:29:35.823: INFO: Pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008791502s
Apr 18 08:29:37.823: INFO: Pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008811159s
Apr 18 08:29:39.823: INFO: Pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008851241s
Apr 18 08:29:41.823: INFO: Pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008624711s
Apr 18 08:29:43.823: INFO: Pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de": Phase="Running", Reason="", readiness=true. Elapsed: 10.008971748s
Apr 18 08:29:43.823: INFO: Pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de" satisfied condition "running"
STEP: retrieving the pod 04/18/23 08:29:43.823
STEP: looking for the results for each expected name from probers 04/18/23 08:29:43.826
Apr 18 08:29:43.841: INFO: DNS probes using dns-565/dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de succeeded

STEP: deleting the pod 04/18/23 08:29:43.841
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 08:29:43.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-565" for this suite. 04/18/23 08:29:43.859
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":23,"skipped":458,"failed":0}
------------------------------
• [SLOW TEST] [10.076 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:29:33.788
    Apr 18 08:29:33.788: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename dns 04/18/23 08:29:33.788
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:33.8
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:33.804
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-565.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-565.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     04/18/23 08:29:33.807
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-565.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-565.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     04/18/23 08:29:33.807
    STEP: creating a pod to probe /etc/hosts 04/18/23 08:29:33.807
    STEP: submitting the pod to kubernetes 04/18/23 08:29:33.807
    Apr 18 08:29:33.814: INFO: Waiting up to 15m0s for pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de" in namespace "dns-565" to be "running"
    Apr 18 08:29:33.819: INFO: Pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de": Phase="Pending", Reason="", readiness=false. Elapsed: 4.728519ms
    Apr 18 08:29:35.823: INFO: Pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008791502s
    Apr 18 08:29:37.823: INFO: Pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008811159s
    Apr 18 08:29:39.823: INFO: Pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008851241s
    Apr 18 08:29:41.823: INFO: Pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008624711s
    Apr 18 08:29:43.823: INFO: Pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de": Phase="Running", Reason="", readiness=true. Elapsed: 10.008971748s
    Apr 18 08:29:43.823: INFO: Pod "dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 08:29:43.823
    STEP: looking for the results for each expected name from probers 04/18/23 08:29:43.826
    Apr 18 08:29:43.841: INFO: DNS probes using dns-565/dns-test-75e5d78c-fad1-44bc-bd0b-eba457d142de succeeded

    STEP: deleting the pod 04/18/23 08:29:43.841
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 08:29:43.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-565" for this suite. 04/18/23 08:29:43.859
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:29:43.864
Apr 18 08:29:43.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename subpath 04/18/23 08:29:43.865
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:43.875
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:43.879
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/18/23 08:29:43.882
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-h72c 04/18/23 08:29:43.89
STEP: Creating a pod to test atomic-volume-subpath 04/18/23 08:29:43.89
Apr 18 08:29:43.897: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-h72c" in namespace "subpath-7376" to be "Succeeded or Failed"
Apr 18 08:29:43.903: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.238856ms
Apr 18 08:29:45.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 2.009482157s
Apr 18 08:29:47.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 4.009676106s
Apr 18 08:29:49.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 6.009609654s
Apr 18 08:29:51.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 8.01028482s
Apr 18 08:29:53.908: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 10.010641327s
Apr 18 08:29:55.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 12.010041623s
Apr 18 08:29:57.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 14.009718272s
Apr 18 08:29:59.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 16.009745373s
Apr 18 08:30:01.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 18.009839815s
Apr 18 08:30:03.908: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 20.010577117s
Apr 18 08:30:05.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=false. Elapsed: 22.010242091s
Apr 18 08:30:07.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.010105755s
STEP: Saw pod success 04/18/23 08:30:07.907
Apr 18 08:30:07.907: INFO: Pod "pod-subpath-test-configmap-h72c" satisfied condition "Succeeded or Failed"
Apr 18 08:30:07.911: INFO: Trying to get logs from node 192.168.1.152 pod pod-subpath-test-configmap-h72c container test-container-subpath-configmap-h72c: <nil>
STEP: delete the pod 04/18/23 08:30:07.917
Apr 18 08:30:07.927: INFO: Waiting for pod pod-subpath-test-configmap-h72c to disappear
Apr 18 08:30:07.929: INFO: Pod pod-subpath-test-configmap-h72c no longer exists
STEP: Deleting pod pod-subpath-test-configmap-h72c 04/18/23 08:30:07.929
Apr 18 08:30:07.930: INFO: Deleting pod "pod-subpath-test-configmap-h72c" in namespace "subpath-7376"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 18 08:30:07.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7376" for this suite. 04/18/23 08:30:07.937
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":24,"skipped":475,"failed":0}
------------------------------
• [SLOW TEST] [24.078 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:29:43.864
    Apr 18 08:29:43.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename subpath 04/18/23 08:29:43.865
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:29:43.875
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:29:43.879
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/18/23 08:29:43.882
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-h72c 04/18/23 08:29:43.89
    STEP: Creating a pod to test atomic-volume-subpath 04/18/23 08:29:43.89
    Apr 18 08:29:43.897: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-h72c" in namespace "subpath-7376" to be "Succeeded or Failed"
    Apr 18 08:29:43.903: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.238856ms
    Apr 18 08:29:45.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 2.009482157s
    Apr 18 08:29:47.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 4.009676106s
    Apr 18 08:29:49.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 6.009609654s
    Apr 18 08:29:51.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 8.01028482s
    Apr 18 08:29:53.908: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 10.010641327s
    Apr 18 08:29:55.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 12.010041623s
    Apr 18 08:29:57.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 14.009718272s
    Apr 18 08:29:59.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 16.009745373s
    Apr 18 08:30:01.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 18.009839815s
    Apr 18 08:30:03.908: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=true. Elapsed: 20.010577117s
    Apr 18 08:30:05.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Running", Reason="", readiness=false. Elapsed: 22.010242091s
    Apr 18 08:30:07.907: INFO: Pod "pod-subpath-test-configmap-h72c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.010105755s
    STEP: Saw pod success 04/18/23 08:30:07.907
    Apr 18 08:30:07.907: INFO: Pod "pod-subpath-test-configmap-h72c" satisfied condition "Succeeded or Failed"
    Apr 18 08:30:07.911: INFO: Trying to get logs from node 192.168.1.152 pod pod-subpath-test-configmap-h72c container test-container-subpath-configmap-h72c: <nil>
    STEP: delete the pod 04/18/23 08:30:07.917
    Apr 18 08:30:07.927: INFO: Waiting for pod pod-subpath-test-configmap-h72c to disappear
    Apr 18 08:30:07.929: INFO: Pod pod-subpath-test-configmap-h72c no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-h72c 04/18/23 08:30:07.929
    Apr 18 08:30:07.930: INFO: Deleting pod "pod-subpath-test-configmap-h72c" in namespace "subpath-7376"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 18 08:30:07.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-7376" for this suite. 04/18/23 08:30:07.937
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:30:07.942
Apr 18 08:30:07.942: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 08:30:07.943
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:30:07.954
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:30:07.958
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 04/18/23 08:30:07.962
Apr 18 08:30:07.967: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7" in namespace "projected-4188" to be "Succeeded or Failed"
Apr 18 08:30:07.970: INFO: Pod "downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.961817ms
Apr 18 08:30:09.974: INFO: Pod "downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006790973s
Apr 18 08:30:11.974: INFO: Pod "downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006850716s
STEP: Saw pod success 04/18/23 08:30:11.974
Apr 18 08:30:11.974: INFO: Pod "downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7" satisfied condition "Succeeded or Failed"
Apr 18 08:30:11.977: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7 container client-container: <nil>
STEP: delete the pod 04/18/23 08:30:11.982
Apr 18 08:30:11.992: INFO: Waiting for pod downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7 to disappear
Apr 18 08:30:11.995: INFO: Pod downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 08:30:11.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4188" for this suite. 04/18/23 08:30:11.999
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":25,"skipped":475,"failed":0}
------------------------------
• [4.061 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:30:07.942
    Apr 18 08:30:07.942: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 08:30:07.943
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:30:07.954
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:30:07.958
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 04/18/23 08:30:07.962
    Apr 18 08:30:07.967: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7" in namespace "projected-4188" to be "Succeeded or Failed"
    Apr 18 08:30:07.970: INFO: Pod "downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.961817ms
    Apr 18 08:30:09.974: INFO: Pod "downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006790973s
    Apr 18 08:30:11.974: INFO: Pod "downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006850716s
    STEP: Saw pod success 04/18/23 08:30:11.974
    Apr 18 08:30:11.974: INFO: Pod "downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7" satisfied condition "Succeeded or Failed"
    Apr 18 08:30:11.977: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7 container client-container: <nil>
    STEP: delete the pod 04/18/23 08:30:11.982
    Apr 18 08:30:11.992: INFO: Waiting for pod downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7 to disappear
    Apr 18 08:30:11.995: INFO: Pod downwardapi-volume-eca21c87-1392-46ed-8a4f-0369b0bbe0d7 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 08:30:11.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4188" for this suite. 04/18/23 08:30:11.999
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:30:12.004
Apr 18 08:30:12.004: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename configmap 04/18/23 08:30:12.005
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:30:12.015
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:30:12.019
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-7188/configmap-test-15120d75-fd3f-440b-a21f-1536a0f0dd8e 04/18/23 08:30:12.022
STEP: Creating a pod to test consume configMaps 04/18/23 08:30:12.026
Apr 18 08:30:12.032: INFO: Waiting up to 5m0s for pod "pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d" in namespace "configmap-7188" to be "Succeeded or Failed"
Apr 18 08:30:12.034: INFO: Pod "pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.503657ms
Apr 18 08:30:14.038: INFO: Pod "pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006059558s
Apr 18 08:30:16.038: INFO: Pod "pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005722347s
STEP: Saw pod success 04/18/23 08:30:16.038
Apr 18 08:30:16.038: INFO: Pod "pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d" satisfied condition "Succeeded or Failed"
Apr 18 08:30:16.040: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d container env-test: <nil>
STEP: delete the pod 04/18/23 08:30:16.048
Apr 18 08:30:16.060: INFO: Waiting for pod pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d to disappear
Apr 18 08:30:16.062: INFO: Pod pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 08:30:16.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7188" for this suite. 04/18/23 08:30:16.066
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":26,"skipped":509,"failed":0}
------------------------------
• [4.066 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:30:12.004
    Apr 18 08:30:12.004: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename configmap 04/18/23 08:30:12.005
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:30:12.015
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:30:12.019
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-7188/configmap-test-15120d75-fd3f-440b-a21f-1536a0f0dd8e 04/18/23 08:30:12.022
    STEP: Creating a pod to test consume configMaps 04/18/23 08:30:12.026
    Apr 18 08:30:12.032: INFO: Waiting up to 5m0s for pod "pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d" in namespace "configmap-7188" to be "Succeeded or Failed"
    Apr 18 08:30:12.034: INFO: Pod "pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.503657ms
    Apr 18 08:30:14.038: INFO: Pod "pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006059558s
    Apr 18 08:30:16.038: INFO: Pod "pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005722347s
    STEP: Saw pod success 04/18/23 08:30:16.038
    Apr 18 08:30:16.038: INFO: Pod "pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d" satisfied condition "Succeeded or Failed"
    Apr 18 08:30:16.040: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d container env-test: <nil>
    STEP: delete the pod 04/18/23 08:30:16.048
    Apr 18 08:30:16.060: INFO: Waiting for pod pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d to disappear
    Apr 18 08:30:16.062: INFO: Pod pod-configmaps-a158e48e-1ce1-4c43-9125-9dbd4a87ed5d no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 08:30:16.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7188" for this suite. 04/18/23 08:30:16.066
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:30:16.071
Apr 18 08:30:16.071: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 08:30:16.072
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:30:16.082
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:30:16.085
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 04/18/23 08:30:16.09
Apr 18 08:30:16.090: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Apr 18 08:30:16.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 create -f -'
Apr 18 08:30:16.279: INFO: stderr: ""
Apr 18 08:30:16.279: INFO: stdout: "service/agnhost-replica created\n"
Apr 18 08:30:16.279: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Apr 18 08:30:16.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 create -f -'
Apr 18 08:30:16.450: INFO: stderr: ""
Apr 18 08:30:16.450: INFO: stdout: "service/agnhost-primary created\n"
Apr 18 08:30:16.450: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 18 08:30:16.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 create -f -'
Apr 18 08:30:16.605: INFO: stderr: ""
Apr 18 08:30:16.605: INFO: stdout: "service/frontend created\n"
Apr 18 08:30:16.606: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Apr 18 08:30:16.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 create -f -'
Apr 18 08:30:16.765: INFO: stderr: ""
Apr 18 08:30:16.765: INFO: stdout: "deployment.apps/frontend created\n"
Apr 18 08:30:16.765: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 18 08:30:16.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 create -f -'
Apr 18 08:30:16.945: INFO: stderr: ""
Apr 18 08:30:16.945: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Apr 18 08:30:16.945: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 18 08:30:16.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 create -f -'
Apr 18 08:30:17.101: INFO: stderr: ""
Apr 18 08:30:17.101: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 04/18/23 08:30:17.101
Apr 18 08:30:17.101: INFO: Waiting for all frontend pods to be Running.
Apr 18 08:30:27.153: INFO: Waiting for frontend to serve content.
Apr 18 08:30:27.163: INFO: Trying to add a new entry to the guestbook.
Apr 18 08:30:27.173: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 04/18/23 08:30:27.179
Apr 18 08:30:27.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 delete --grace-period=0 --force -f -'
Apr 18 08:30:27.257: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 08:30:27.257: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 04/18/23 08:30:27.257
Apr 18 08:30:27.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 delete --grace-period=0 --force -f -'
Apr 18 08:30:27.332: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 08:30:27.332: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 04/18/23 08:30:27.332
Apr 18 08:30:27.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 delete --grace-period=0 --force -f -'
Apr 18 08:30:27.408: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 08:30:27.408: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 04/18/23 08:30:27.408
Apr 18 08:30:27.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 delete --grace-period=0 --force -f -'
Apr 18 08:30:27.503: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 08:30:27.503: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 04/18/23 08:30:27.503
Apr 18 08:30:27.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 delete --grace-period=0 --force -f -'
Apr 18 08:30:27.566: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 08:30:27.566: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 04/18/23 08:30:27.566
Apr 18 08:30:27.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 delete --grace-period=0 --force -f -'
Apr 18 08:30:27.655: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 08:30:27.655: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 08:30:27.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-417" for this suite. 04/18/23 08:30:27.659
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":27,"skipped":517,"failed":0}
------------------------------
• [SLOW TEST] [11.604 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:30:16.071
    Apr 18 08:30:16.071: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 08:30:16.072
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:30:16.082
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:30:16.085
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 04/18/23 08:30:16.09
    Apr 18 08:30:16.090: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Apr 18 08:30:16.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 create -f -'
    Apr 18 08:30:16.279: INFO: stderr: ""
    Apr 18 08:30:16.279: INFO: stdout: "service/agnhost-replica created\n"
    Apr 18 08:30:16.279: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Apr 18 08:30:16.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 create -f -'
    Apr 18 08:30:16.450: INFO: stderr: ""
    Apr 18 08:30:16.450: INFO: stdout: "service/agnhost-primary created\n"
    Apr 18 08:30:16.450: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Apr 18 08:30:16.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 create -f -'
    Apr 18 08:30:16.605: INFO: stderr: ""
    Apr 18 08:30:16.605: INFO: stdout: "service/frontend created\n"
    Apr 18 08:30:16.606: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Apr 18 08:30:16.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 create -f -'
    Apr 18 08:30:16.765: INFO: stderr: ""
    Apr 18 08:30:16.765: INFO: stdout: "deployment.apps/frontend created\n"
    Apr 18 08:30:16.765: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Apr 18 08:30:16.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 create -f -'
    Apr 18 08:30:16.945: INFO: stderr: ""
    Apr 18 08:30:16.945: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Apr 18 08:30:16.945: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Apr 18 08:30:16.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 create -f -'
    Apr 18 08:30:17.101: INFO: stderr: ""
    Apr 18 08:30:17.101: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 04/18/23 08:30:17.101
    Apr 18 08:30:17.101: INFO: Waiting for all frontend pods to be Running.
    Apr 18 08:30:27.153: INFO: Waiting for frontend to serve content.
    Apr 18 08:30:27.163: INFO: Trying to add a new entry to the guestbook.
    Apr 18 08:30:27.173: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 04/18/23 08:30:27.179
    Apr 18 08:30:27.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 delete --grace-period=0 --force -f -'
    Apr 18 08:30:27.257: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 08:30:27.257: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 04/18/23 08:30:27.257
    Apr 18 08:30:27.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 delete --grace-period=0 --force -f -'
    Apr 18 08:30:27.332: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 08:30:27.332: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 04/18/23 08:30:27.332
    Apr 18 08:30:27.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 delete --grace-period=0 --force -f -'
    Apr 18 08:30:27.408: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 08:30:27.408: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 04/18/23 08:30:27.408
    Apr 18 08:30:27.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 delete --grace-period=0 --force -f -'
    Apr 18 08:30:27.503: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 08:30:27.503: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 04/18/23 08:30:27.503
    Apr 18 08:30:27.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 delete --grace-period=0 --force -f -'
    Apr 18 08:30:27.566: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 08:30:27.566: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 04/18/23 08:30:27.566
    Apr 18 08:30:27.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-417 delete --grace-period=0 --force -f -'
    Apr 18 08:30:27.655: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 08:30:27.655: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 08:30:27.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-417" for this suite. 04/18/23 08:30:27.659
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:30:27.675
Apr 18 08:30:27.675: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename gc 04/18/23 08:30:27.676
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:30:27.692
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:30:27.695
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 04/18/23 08:30:27.702
STEP: delete the rc 04/18/23 08:30:32.715
STEP: wait for the rc to be deleted 04/18/23 08:30:32.72
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 04/18/23 08:30:37.725
STEP: Gathering metrics 04/18/23 08:31:07.731
W0418 08:31:07.738093      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 18 08:31:07.738: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr 18 08:31:07.738: INFO: Deleting pod "simpletest.rc-2fgfr" in namespace "gc-9814"
Apr 18 08:31:07.752: INFO: Deleting pod "simpletest.rc-2htnm" in namespace "gc-9814"
Apr 18 08:31:07.761: INFO: Deleting pod "simpletest.rc-2rksn" in namespace "gc-9814"
Apr 18 08:31:07.770: INFO: Deleting pod "simpletest.rc-4gf2z" in namespace "gc-9814"
Apr 18 08:31:07.779: INFO: Deleting pod "simpletest.rc-5jn28" in namespace "gc-9814"
Apr 18 08:31:07.787: INFO: Deleting pod "simpletest.rc-5qpl9" in namespace "gc-9814"
Apr 18 08:31:07.796: INFO: Deleting pod "simpletest.rc-5zjt9" in namespace "gc-9814"
Apr 18 08:31:07.806: INFO: Deleting pod "simpletest.rc-7jjws" in namespace "gc-9814"
Apr 18 08:31:07.816: INFO: Deleting pod "simpletest.rc-7psrg" in namespace "gc-9814"
Apr 18 08:31:07.825: INFO: Deleting pod "simpletest.rc-8lkln" in namespace "gc-9814"
Apr 18 08:31:07.832: INFO: Deleting pod "simpletest.rc-9qp8p" in namespace "gc-9814"
Apr 18 08:31:07.841: INFO: Deleting pod "simpletest.rc-c428r" in namespace "gc-9814"
Apr 18 08:31:07.851: INFO: Deleting pod "simpletest.rc-fglqr" in namespace "gc-9814"
Apr 18 08:31:07.860: INFO: Deleting pod "simpletest.rc-gcttd" in namespace "gc-9814"
Apr 18 08:31:07.869: INFO: Deleting pod "simpletest.rc-ghvbm" in namespace "gc-9814"
Apr 18 08:31:07.879: INFO: Deleting pod "simpletest.rc-gq5r8" in namespace "gc-9814"
Apr 18 08:31:07.887: INFO: Deleting pod "simpletest.rc-gtq9r" in namespace "gc-9814"
Apr 18 08:31:07.896: INFO: Deleting pod "simpletest.rc-gxv74" in namespace "gc-9814"
Apr 18 08:31:07.903: INFO: Deleting pod "simpletest.rc-m4kft" in namespace "gc-9814"
Apr 18 08:31:07.912: INFO: Deleting pod "simpletest.rc-nrsbp" in namespace "gc-9814"
Apr 18 08:31:07.921: INFO: Deleting pod "simpletest.rc-qdp5n" in namespace "gc-9814"
Apr 18 08:31:07.931: INFO: Deleting pod "simpletest.rc-qkvrf" in namespace "gc-9814"
Apr 18 08:31:07.939: INFO: Deleting pod "simpletest.rc-qq7qq" in namespace "gc-9814"
Apr 18 08:31:07.953: INFO: Deleting pod "simpletest.rc-sbw26" in namespace "gc-9814"
Apr 18 08:31:07.964: INFO: Deleting pod "simpletest.rc-sqk5t" in namespace "gc-9814"
Apr 18 08:31:07.971: INFO: Deleting pod "simpletest.rc-tjq22" in namespace "gc-9814"
Apr 18 08:31:07.979: INFO: Deleting pod "simpletest.rc-vwppf" in namespace "gc-9814"
Apr 18 08:31:07.990: INFO: Deleting pod "simpletest.rc-xgnqq" in namespace "gc-9814"
Apr 18 08:31:07.997: INFO: Deleting pod "simpletest.rc-xwsjk" in namespace "gc-9814"
Apr 18 08:31:08.006: INFO: Deleting pod "simpletest.rc-z2bw2" in namespace "gc-9814"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 18 08:31:08.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9814" for this suite. 04/18/23 08:31:08.018
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":28,"skipped":518,"failed":0}
------------------------------
• [SLOW TEST] [40.350 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:30:27.675
    Apr 18 08:30:27.675: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename gc 04/18/23 08:30:27.676
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:30:27.692
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:30:27.695
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 04/18/23 08:30:27.702
    STEP: delete the rc 04/18/23 08:30:32.715
    STEP: wait for the rc to be deleted 04/18/23 08:30:32.72
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 04/18/23 08:30:37.725
    STEP: Gathering metrics 04/18/23 08:31:07.731
    W0418 08:31:07.738093      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 18 08:31:07.738: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Apr 18 08:31:07.738: INFO: Deleting pod "simpletest.rc-2fgfr" in namespace "gc-9814"
    Apr 18 08:31:07.752: INFO: Deleting pod "simpletest.rc-2htnm" in namespace "gc-9814"
    Apr 18 08:31:07.761: INFO: Deleting pod "simpletest.rc-2rksn" in namespace "gc-9814"
    Apr 18 08:31:07.770: INFO: Deleting pod "simpletest.rc-4gf2z" in namespace "gc-9814"
    Apr 18 08:31:07.779: INFO: Deleting pod "simpletest.rc-5jn28" in namespace "gc-9814"
    Apr 18 08:31:07.787: INFO: Deleting pod "simpletest.rc-5qpl9" in namespace "gc-9814"
    Apr 18 08:31:07.796: INFO: Deleting pod "simpletest.rc-5zjt9" in namespace "gc-9814"
    Apr 18 08:31:07.806: INFO: Deleting pod "simpletest.rc-7jjws" in namespace "gc-9814"
    Apr 18 08:31:07.816: INFO: Deleting pod "simpletest.rc-7psrg" in namespace "gc-9814"
    Apr 18 08:31:07.825: INFO: Deleting pod "simpletest.rc-8lkln" in namespace "gc-9814"
    Apr 18 08:31:07.832: INFO: Deleting pod "simpletest.rc-9qp8p" in namespace "gc-9814"
    Apr 18 08:31:07.841: INFO: Deleting pod "simpletest.rc-c428r" in namespace "gc-9814"
    Apr 18 08:31:07.851: INFO: Deleting pod "simpletest.rc-fglqr" in namespace "gc-9814"
    Apr 18 08:31:07.860: INFO: Deleting pod "simpletest.rc-gcttd" in namespace "gc-9814"
    Apr 18 08:31:07.869: INFO: Deleting pod "simpletest.rc-ghvbm" in namespace "gc-9814"
    Apr 18 08:31:07.879: INFO: Deleting pod "simpletest.rc-gq5r8" in namespace "gc-9814"
    Apr 18 08:31:07.887: INFO: Deleting pod "simpletest.rc-gtq9r" in namespace "gc-9814"
    Apr 18 08:31:07.896: INFO: Deleting pod "simpletest.rc-gxv74" in namespace "gc-9814"
    Apr 18 08:31:07.903: INFO: Deleting pod "simpletest.rc-m4kft" in namespace "gc-9814"
    Apr 18 08:31:07.912: INFO: Deleting pod "simpletest.rc-nrsbp" in namespace "gc-9814"
    Apr 18 08:31:07.921: INFO: Deleting pod "simpletest.rc-qdp5n" in namespace "gc-9814"
    Apr 18 08:31:07.931: INFO: Deleting pod "simpletest.rc-qkvrf" in namespace "gc-9814"
    Apr 18 08:31:07.939: INFO: Deleting pod "simpletest.rc-qq7qq" in namespace "gc-9814"
    Apr 18 08:31:07.953: INFO: Deleting pod "simpletest.rc-sbw26" in namespace "gc-9814"
    Apr 18 08:31:07.964: INFO: Deleting pod "simpletest.rc-sqk5t" in namespace "gc-9814"
    Apr 18 08:31:07.971: INFO: Deleting pod "simpletest.rc-tjq22" in namespace "gc-9814"
    Apr 18 08:31:07.979: INFO: Deleting pod "simpletest.rc-vwppf" in namespace "gc-9814"
    Apr 18 08:31:07.990: INFO: Deleting pod "simpletest.rc-xgnqq" in namespace "gc-9814"
    Apr 18 08:31:07.997: INFO: Deleting pod "simpletest.rc-xwsjk" in namespace "gc-9814"
    Apr 18 08:31:08.006: INFO: Deleting pod "simpletest.rc-z2bw2" in namespace "gc-9814"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 18 08:31:08.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-9814" for this suite. 04/18/23 08:31:08.018
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:31:08.025
Apr 18 08:31:08.025: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename replication-controller 04/18/23 08:31:08.026
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:31:08.04
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:31:08.043
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f 04/18/23 08:31:08.05
Apr 18 08:31:08.059: INFO: Pod name my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f: Found 0 pods out of 1
Apr 18 08:31:13.064: INFO: Pod name my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f: Found 1 pods out of 1
Apr 18 08:31:13.064: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f" are running
Apr 18 08:31:13.064: INFO: Waiting up to 5m0s for pod "my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f-jpgb7" in namespace "replication-controller-3864" to be "running"
Apr 18 08:31:13.067: INFO: Pod "my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f-jpgb7": Phase="Running", Reason="", readiness=true. Elapsed: 2.810795ms
Apr 18 08:31:13.067: INFO: Pod "my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f-jpgb7" satisfied condition "running"
Apr 18 08:31:13.067: INFO: Pod "my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f-jpgb7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 08:31:08 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 08:31:09 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 08:31:09 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 08:31:08 +0000 UTC Reason: Message:}])
Apr 18 08:31:13.067: INFO: Trying to dial the pod
Apr 18 08:31:18.078: INFO: Controller my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f: Got expected result from replica 1 [my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f-jpgb7]: "my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f-jpgb7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 18 08:31:18.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3864" for this suite. 04/18/23 08:31:18.082
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":29,"skipped":526,"failed":0}
------------------------------
• [SLOW TEST] [10.062 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:31:08.025
    Apr 18 08:31:08.025: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename replication-controller 04/18/23 08:31:08.026
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:31:08.04
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:31:08.043
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f 04/18/23 08:31:08.05
    Apr 18 08:31:08.059: INFO: Pod name my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f: Found 0 pods out of 1
    Apr 18 08:31:13.064: INFO: Pod name my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f: Found 1 pods out of 1
    Apr 18 08:31:13.064: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f" are running
    Apr 18 08:31:13.064: INFO: Waiting up to 5m0s for pod "my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f-jpgb7" in namespace "replication-controller-3864" to be "running"
    Apr 18 08:31:13.067: INFO: Pod "my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f-jpgb7": Phase="Running", Reason="", readiness=true. Elapsed: 2.810795ms
    Apr 18 08:31:13.067: INFO: Pod "my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f-jpgb7" satisfied condition "running"
    Apr 18 08:31:13.067: INFO: Pod "my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f-jpgb7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 08:31:08 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 08:31:09 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 08:31:09 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 08:31:08 +0000 UTC Reason: Message:}])
    Apr 18 08:31:13.067: INFO: Trying to dial the pod
    Apr 18 08:31:18.078: INFO: Controller my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f: Got expected result from replica 1 [my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f-jpgb7]: "my-hostname-basic-9b15fe7f-5443-4ea5-99df-e66281e1d47f-jpgb7", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 18 08:31:18.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-3864" for this suite. 04/18/23 08:31:18.082
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:31:18.089
Apr 18 08:31:18.089: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename crd-watch 04/18/23 08:31:18.09
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:31:18.1
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:31:18.104
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Apr 18 08:31:18.107: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Creating first CR  04/18/23 08:31:20.686
Apr 18 08:31:20.690: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T08:31:20Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T08:31:20Z]] name:name1 resourceVersion:4172621 uid:23b3db57-dfb8-42d1-bf68-9d73efd51000] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 04/18/23 08:31:30.691
Apr 18 08:31:30.696: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T08:31:30Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T08:31:30Z]] name:name2 resourceVersion:4172674 uid:009f27fc-a62e-449d-8476-6c16005fff20] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 04/18/23 08:31:40.697
Apr 18 08:31:40.703: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T08:31:20Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T08:31:40Z]] name:name1 resourceVersion:4172721 uid:23b3db57-dfb8-42d1-bf68-9d73efd51000] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 04/18/23 08:31:50.703
Apr 18 08:31:50.711: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T08:31:30Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T08:31:50Z]] name:name2 resourceVersion:4172766 uid:009f27fc-a62e-449d-8476-6c16005fff20] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 04/18/23 08:32:00.712
Apr 18 08:32:00.718: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T08:31:20Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T08:31:40Z]] name:name1 resourceVersion:4172809 uid:23b3db57-dfb8-42d1-bf68-9d73efd51000] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 04/18/23 08:32:10.719
Apr 18 08:32:10.725: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T08:31:30Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T08:31:50Z]] name:name2 resourceVersion:4172854 uid:009f27fc-a62e-449d-8476-6c16005fff20] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 08:32:21.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-9875" for this suite. 04/18/23 08:32:21.253
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":30,"skipped":560,"failed":0}
------------------------------
• [SLOW TEST] [63.170 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:31:18.089
    Apr 18 08:31:18.089: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename crd-watch 04/18/23 08:31:18.09
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:31:18.1
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:31:18.104
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Apr 18 08:31:18.107: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Creating first CR  04/18/23 08:31:20.686
    Apr 18 08:31:20.690: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T08:31:20Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T08:31:20Z]] name:name1 resourceVersion:4172621 uid:23b3db57-dfb8-42d1-bf68-9d73efd51000] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 04/18/23 08:31:30.691
    Apr 18 08:31:30.696: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T08:31:30Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T08:31:30Z]] name:name2 resourceVersion:4172674 uid:009f27fc-a62e-449d-8476-6c16005fff20] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 04/18/23 08:31:40.697
    Apr 18 08:31:40.703: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T08:31:20Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T08:31:40Z]] name:name1 resourceVersion:4172721 uid:23b3db57-dfb8-42d1-bf68-9d73efd51000] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 04/18/23 08:31:50.703
    Apr 18 08:31:50.711: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T08:31:30Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T08:31:50Z]] name:name2 resourceVersion:4172766 uid:009f27fc-a62e-449d-8476-6c16005fff20] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 04/18/23 08:32:00.712
    Apr 18 08:32:00.718: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T08:31:20Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T08:31:40Z]] name:name1 resourceVersion:4172809 uid:23b3db57-dfb8-42d1-bf68-9d73efd51000] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 04/18/23 08:32:10.719
    Apr 18 08:32:10.725: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T08:31:30Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T08:31:50Z]] name:name2 resourceVersion:4172854 uid:009f27fc-a62e-449d-8476-6c16005fff20] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 08:32:21.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-9875" for this suite. 04/18/23 08:32:21.253
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:32:21.259
Apr 18 08:32:21.259: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 08:32:21.259
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:32:21.27
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:32:21.275
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/18/23 08:32:21.282
Apr 18 08:32:21.289: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-6123" to be "running and ready"
Apr 18 08:32:21.292: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.974823ms
Apr 18 08:32:21.292: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:32:23.295: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.006128396s
Apr 18 08:32:23.295: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 18 08:32:23.295: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 04/18/23 08:32:23.297
Apr 18 08:32:23.303: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-6123" to be "running and ready"
Apr 18 08:32:23.307: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 3.445618ms
Apr 18 08:32:23.307: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:32:25.310: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006735483s
Apr 18 08:32:25.310: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:32:27.310: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006906465s
Apr 18 08:32:27.310: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:32:29.312: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 6.008341859s
Apr 18 08:32:29.312: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Apr 18 08:32:29.312: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 04/18/23 08:32:29.315
STEP: delete the pod with lifecycle hook 04/18/23 08:32:29.328
Apr 18 08:32:29.335: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 18 08:32:29.338: INFO: Pod pod-with-poststart-http-hook still exists
Apr 18 08:32:31.339: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 18 08:32:31.342: INFO: Pod pod-with-poststart-http-hook still exists
Apr 18 08:32:33.339: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 18 08:32:33.342: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 18 08:32:33.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6123" for this suite. 04/18/23 08:32:33.346
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":31,"skipped":580,"failed":0}
------------------------------
• [SLOW TEST] [12.091 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:32:21.259
    Apr 18 08:32:21.259: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 08:32:21.259
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:32:21.27
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:32:21.275
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/18/23 08:32:21.282
    Apr 18 08:32:21.289: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-6123" to be "running and ready"
    Apr 18 08:32:21.292: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.974823ms
    Apr 18 08:32:21.292: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:32:23.295: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.006128396s
    Apr 18 08:32:23.295: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 18 08:32:23.295: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 04/18/23 08:32:23.297
    Apr 18 08:32:23.303: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-6123" to be "running and ready"
    Apr 18 08:32:23.307: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 3.445618ms
    Apr 18 08:32:23.307: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:32:25.310: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006735483s
    Apr 18 08:32:25.310: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:32:27.310: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006906465s
    Apr 18 08:32:27.310: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:32:29.312: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 6.008341859s
    Apr 18 08:32:29.312: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Apr 18 08:32:29.312: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 04/18/23 08:32:29.315
    STEP: delete the pod with lifecycle hook 04/18/23 08:32:29.328
    Apr 18 08:32:29.335: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Apr 18 08:32:29.338: INFO: Pod pod-with-poststart-http-hook still exists
    Apr 18 08:32:31.339: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Apr 18 08:32:31.342: INFO: Pod pod-with-poststart-http-hook still exists
    Apr 18 08:32:33.339: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Apr 18 08:32:33.342: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 18 08:32:33.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-6123" for this suite. 04/18/23 08:32:33.346
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:32:33.351
Apr 18 08:32:33.351: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 08:32:33.352
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:32:33.363
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:32:33.366
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 04/18/23 08:32:33.37
Apr 18 08:32:33.375: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef" in namespace "projected-2028" to be "Succeeded or Failed"
Apr 18 08:32:33.378: INFO: Pod "downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.460646ms
Apr 18 08:32:35.382: INFO: Pod "downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006840712s
Apr 18 08:32:37.381: INFO: Pod "downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005745585s
STEP: Saw pod success 04/18/23 08:32:37.381
Apr 18 08:32:37.381: INFO: Pod "downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef" satisfied condition "Succeeded or Failed"
Apr 18 08:32:37.384: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef container client-container: <nil>
STEP: delete the pod 04/18/23 08:32:37.397
Apr 18 08:32:37.407: INFO: Waiting for pod downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef to disappear
Apr 18 08:32:37.409: INFO: Pod downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 08:32:37.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2028" for this suite. 04/18/23 08:32:37.413
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":32,"skipped":602,"failed":0}
------------------------------
• [4.066 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:32:33.351
    Apr 18 08:32:33.351: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 08:32:33.352
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:32:33.363
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:32:33.366
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 04/18/23 08:32:33.37
    Apr 18 08:32:33.375: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef" in namespace "projected-2028" to be "Succeeded or Failed"
    Apr 18 08:32:33.378: INFO: Pod "downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.460646ms
    Apr 18 08:32:35.382: INFO: Pod "downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006840712s
    Apr 18 08:32:37.381: INFO: Pod "downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005745585s
    STEP: Saw pod success 04/18/23 08:32:37.381
    Apr 18 08:32:37.381: INFO: Pod "downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef" satisfied condition "Succeeded or Failed"
    Apr 18 08:32:37.384: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef container client-container: <nil>
    STEP: delete the pod 04/18/23 08:32:37.397
    Apr 18 08:32:37.407: INFO: Waiting for pod downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef to disappear
    Apr 18 08:32:37.409: INFO: Pod downwardapi-volume-0dc2784f-4dc7-4fce-abd5-6a8b9907bcef no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 08:32:37.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2028" for this suite. 04/18/23 08:32:37.413
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:32:37.418
Apr 18 08:32:37.418: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir 04/18/23 08:32:37.418
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:32:37.428
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:32:37.432
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 04/18/23 08:32:37.435
Apr 18 08:32:37.443: INFO: Waiting up to 5m0s for pod "pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6" in namespace "emptydir-9545" to be "Succeeded or Failed"
Apr 18 08:32:37.445: INFO: Pod "pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.268631ms
Apr 18 08:32:39.450: INFO: Pod "pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00630919s
Apr 18 08:32:41.449: INFO: Pod "pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005583683s
STEP: Saw pod success 04/18/23 08:32:41.449
Apr 18 08:32:41.449: INFO: Pod "pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6" satisfied condition "Succeeded or Failed"
Apr 18 08:32:41.452: INFO: Trying to get logs from node 192.168.1.152 pod pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6 container test-container: <nil>
STEP: delete the pod 04/18/23 08:32:41.457
Apr 18 08:32:41.466: INFO: Waiting for pod pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6 to disappear
Apr 18 08:32:41.468: INFO: Pod pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 08:32:41.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9545" for this suite. 04/18/23 08:32:41.473
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":33,"skipped":618,"failed":0}
------------------------------
• [4.060 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:32:37.418
    Apr 18 08:32:37.418: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir 04/18/23 08:32:37.418
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:32:37.428
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:32:37.432
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 04/18/23 08:32:37.435
    Apr 18 08:32:37.443: INFO: Waiting up to 5m0s for pod "pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6" in namespace "emptydir-9545" to be "Succeeded or Failed"
    Apr 18 08:32:37.445: INFO: Pod "pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.268631ms
    Apr 18 08:32:39.450: INFO: Pod "pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00630919s
    Apr 18 08:32:41.449: INFO: Pod "pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005583683s
    STEP: Saw pod success 04/18/23 08:32:41.449
    Apr 18 08:32:41.449: INFO: Pod "pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6" satisfied condition "Succeeded or Failed"
    Apr 18 08:32:41.452: INFO: Trying to get logs from node 192.168.1.152 pod pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6 container test-container: <nil>
    STEP: delete the pod 04/18/23 08:32:41.457
    Apr 18 08:32:41.466: INFO: Waiting for pod pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6 to disappear
    Apr 18 08:32:41.468: INFO: Pod pod-e9a2e265-072a-492f-81a9-3597ab7ff5d6 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 08:32:41.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9545" for this suite. 04/18/23 08:32:41.473
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:32:41.483
Apr 18 08:32:41.483: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename resourcequota 04/18/23 08:32:41.484
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:32:41.497
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:32:41.503
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 04/18/23 08:32:41.507
STEP: Ensuring ResourceQuota status is calculated 04/18/23 08:32:41.51
STEP: Creating a ResourceQuota with not terminating scope 04/18/23 08:32:43.515
STEP: Ensuring ResourceQuota status is calculated 04/18/23 08:32:43.54
STEP: Creating a long running pod 04/18/23 08:32:45.543
STEP: Ensuring resource quota with not terminating scope captures the pod usage 04/18/23 08:32:45.639
STEP: Ensuring resource quota with terminating scope ignored the pod usage 04/18/23 08:32:47.644
STEP: Deleting the pod 04/18/23 08:32:49.647
STEP: Ensuring resource quota status released the pod usage 04/18/23 08:32:49.662
STEP: Creating a terminating pod 04/18/23 08:32:51.667
STEP: Ensuring resource quota with terminating scope captures the pod usage 04/18/23 08:32:51.676
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 04/18/23 08:32:53.681
STEP: Deleting the pod 04/18/23 08:32:55.685
STEP: Ensuring resource quota status released the pod usage 04/18/23 08:32:55.694
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 08:32:57.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-488" for this suite. 04/18/23 08:32:57.701
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":34,"skipped":664,"failed":0}
------------------------------
• [SLOW TEST] [16.223 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:32:41.483
    Apr 18 08:32:41.483: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename resourcequota 04/18/23 08:32:41.484
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:32:41.497
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:32:41.503
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 04/18/23 08:32:41.507
    STEP: Ensuring ResourceQuota status is calculated 04/18/23 08:32:41.51
    STEP: Creating a ResourceQuota with not terminating scope 04/18/23 08:32:43.515
    STEP: Ensuring ResourceQuota status is calculated 04/18/23 08:32:43.54
    STEP: Creating a long running pod 04/18/23 08:32:45.543
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 04/18/23 08:32:45.639
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 04/18/23 08:32:47.644
    STEP: Deleting the pod 04/18/23 08:32:49.647
    STEP: Ensuring resource quota status released the pod usage 04/18/23 08:32:49.662
    STEP: Creating a terminating pod 04/18/23 08:32:51.667
    STEP: Ensuring resource quota with terminating scope captures the pod usage 04/18/23 08:32:51.676
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 04/18/23 08:32:53.681
    STEP: Deleting the pod 04/18/23 08:32:55.685
    STEP: Ensuring resource quota status released the pod usage 04/18/23 08:32:55.694
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 08:32:57.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-488" for this suite. 04/18/23 08:32:57.701
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:32:57.708
Apr 18 08:32:57.709: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 08:32:57.71
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:32:57.72
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:32:57.723
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 08:32:57.735
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:32:58.128
STEP: Deploying the webhook pod 04/18/23 08:32:58.134
STEP: Wait for the deployment to be ready 04/18/23 08:32:58.144
Apr 18 08:32:58.152: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 08:33:00.161
STEP: Verifying the service has paired with the endpoint 04/18/23 08:33:00.171
Apr 18 08:33:01.171: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Apr 18 08:33:01.174: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1652-crds.webhook.example.com via the AdmissionRegistration API 04/18/23 08:33:01.687
STEP: Creating a custom resource that should be mutated by the webhook 04/18/23 08:33:01.705
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 08:33:04.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-974" for this suite. 04/18/23 08:33:04.337
STEP: Destroying namespace "webhook-974-markers" for this suite. 04/18/23 08:33:04.347
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":35,"skipped":675,"failed":0}
------------------------------
• [SLOW TEST] [6.689 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:32:57.708
    Apr 18 08:32:57.709: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 08:32:57.71
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:32:57.72
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:32:57.723
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 08:32:57.735
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:32:58.128
    STEP: Deploying the webhook pod 04/18/23 08:32:58.134
    STEP: Wait for the deployment to be ready 04/18/23 08:32:58.144
    Apr 18 08:32:58.152: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 08:33:00.161
    STEP: Verifying the service has paired with the endpoint 04/18/23 08:33:00.171
    Apr 18 08:33:01.171: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Apr 18 08:33:01.174: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1652-crds.webhook.example.com via the AdmissionRegistration API 04/18/23 08:33:01.687
    STEP: Creating a custom resource that should be mutated by the webhook 04/18/23 08:33:01.705
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 08:33:04.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-974" for this suite. 04/18/23 08:33:04.337
    STEP: Destroying namespace "webhook-974-markers" for this suite. 04/18/23 08:33:04.347
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:33:04.398
Apr 18 08:33:04.398: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename disruption 04/18/23 08:33:04.398
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:33:04.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:33:04.419
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 04/18/23 08:33:04.425
STEP: Waiting for the pdb to be processed 04/18/23 08:33:04.432
STEP: updating the pdb 04/18/23 08:33:06.438
STEP: Waiting for the pdb to be processed 04/18/23 08:33:06.446
STEP: patching the pdb 04/18/23 08:33:08.452
STEP: Waiting for the pdb to be processed 04/18/23 08:33:08.459
STEP: Waiting for the pdb to be deleted 04/18/23 08:33:10.472
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 18 08:33:10.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-5219" for this suite. 04/18/23 08:33:10.479
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":36,"skipped":680,"failed":0}
------------------------------
• [SLOW TEST] [6.085 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:33:04.398
    Apr 18 08:33:04.398: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename disruption 04/18/23 08:33:04.398
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:33:04.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:33:04.419
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 04/18/23 08:33:04.425
    STEP: Waiting for the pdb to be processed 04/18/23 08:33:04.432
    STEP: updating the pdb 04/18/23 08:33:06.438
    STEP: Waiting for the pdb to be processed 04/18/23 08:33:06.446
    STEP: patching the pdb 04/18/23 08:33:08.452
    STEP: Waiting for the pdb to be processed 04/18/23 08:33:08.459
    STEP: Waiting for the pdb to be deleted 04/18/23 08:33:10.472
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 18 08:33:10.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-5219" for this suite. 04/18/23 08:33:10.479
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:33:10.483
Apr 18 08:33:10.483: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename secrets 04/18/23 08:33:10.484
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:33:10.494
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:33:10.497
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-41768eb8-0cad-40a0-85f2-218934f650c5 04/18/23 08:33:10.5
STEP: Creating a pod to test consume secrets 04/18/23 08:33:10.504
Apr 18 08:33:10.510: INFO: Waiting up to 5m0s for pod "pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1" in namespace "secrets-4743" to be "Succeeded or Failed"
Apr 18 08:33:10.514: INFO: Pod "pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.524142ms
Apr 18 08:33:12.518: INFO: Pod "pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007950989s
Apr 18 08:33:14.518: INFO: Pod "pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007385173s
STEP: Saw pod success 04/18/23 08:33:14.518
Apr 18 08:33:14.518: INFO: Pod "pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1" satisfied condition "Succeeded or Failed"
Apr 18 08:33:14.520: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1 container secret-env-test: <nil>
STEP: delete the pod 04/18/23 08:33:14.526
Apr 18 08:33:14.535: INFO: Waiting for pod pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1 to disappear
Apr 18 08:33:14.538: INFO: Pod pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 18 08:33:14.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4743" for this suite. 04/18/23 08:33:14.541
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":37,"skipped":683,"failed":0}
------------------------------
• [4.065 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:33:10.483
    Apr 18 08:33:10.483: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename secrets 04/18/23 08:33:10.484
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:33:10.494
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:33:10.497
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-41768eb8-0cad-40a0-85f2-218934f650c5 04/18/23 08:33:10.5
    STEP: Creating a pod to test consume secrets 04/18/23 08:33:10.504
    Apr 18 08:33:10.510: INFO: Waiting up to 5m0s for pod "pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1" in namespace "secrets-4743" to be "Succeeded or Failed"
    Apr 18 08:33:10.514: INFO: Pod "pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.524142ms
    Apr 18 08:33:12.518: INFO: Pod "pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007950989s
    Apr 18 08:33:14.518: INFO: Pod "pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007385173s
    STEP: Saw pod success 04/18/23 08:33:14.518
    Apr 18 08:33:14.518: INFO: Pod "pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1" satisfied condition "Succeeded or Failed"
    Apr 18 08:33:14.520: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1 container secret-env-test: <nil>
    STEP: delete the pod 04/18/23 08:33:14.526
    Apr 18 08:33:14.535: INFO: Waiting for pod pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1 to disappear
    Apr 18 08:33:14.538: INFO: Pod pod-secrets-7eda709c-d82f-4a0c-b3da-caaa0144c7f1 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 08:33:14.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4743" for this suite. 04/18/23 08:33:14.541
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:33:14.548
Apr 18 08:33:14.549: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename deployment 04/18/23 08:33:14.549
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:33:14.56
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:33:14.564
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Apr 18 08:33:14.574: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 18 08:33:19.579: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/18/23 08:33:19.579
Apr 18 08:33:19.579: INFO: Waiting up to 5m0s for pod "test-rollover-controller-wfl5l" in namespace "deployment-7496" to be "running"
Apr 18 08:33:19.581: INFO: Pod "test-rollover-controller-wfl5l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.505821ms
Apr 18 08:33:21.585: INFO: Pod "test-rollover-controller-wfl5l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006424442s
Apr 18 08:33:23.585: INFO: Pod "test-rollover-controller-wfl5l": Phase="Running", Reason="", readiness=true. Elapsed: 4.006231208s
Apr 18 08:33:23.585: INFO: Pod "test-rollover-controller-wfl5l" satisfied condition "running"
Apr 18 08:33:23.585: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 18 08:33:25.589: INFO: Creating deployment "test-rollover-deployment"
Apr 18 08:33:25.596: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 18 08:33:27.603: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 18 08:33:27.608: INFO: Ensure that both replica sets have 1 created replica
Apr 18 08:33:27.613: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 18 08:33:27.624: INFO: Updating deployment test-rollover-deployment
Apr 18 08:33:27.624: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 18 08:33:29.632: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 18 08:33:29.637: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 18 08:33:29.648: INFO: all replica sets need to contain the pod-template-hash label
Apr 18 08:33:29.648: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 08:33:31.654: INFO: all replica sets need to contain the pod-template-hash label
Apr 18 08:33:31.654: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 08:33:33.655: INFO: all replica sets need to contain the pod-template-hash label
Apr 18 08:33:33.655: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 08:33:35.658: INFO: all replica sets need to contain the pod-template-hash label
Apr 18 08:33:35.658: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 08:33:37.654: INFO: all replica sets need to contain the pod-template-hash label
Apr 18 08:33:37.654: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 08:33:39.657: INFO: 
Apr 18 08:33:39.657: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 08:33:39.666: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-7496  2c28d9d8-caba-43fc-b56e-2350a527869b 4173495 2 2023-04-18 08:33:25 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-18 08:33:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:33:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f20298 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-18 08:33:25 +0000 UTC,LastTransitionTime:2023-04-18 08:33:25 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-04-18 08:33:38 +0000 UTC,LastTransitionTime:2023-04-18 08:33:25 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 18 08:33:39.668: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-7496  5737b8ed-aac6-4307-8b67-08a2e50ba361 4173488 2 2023-04-18 08:33:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 2c28d9d8-caba-43fc-b56e-2350a527869b 0xc004f20987 0xc004f20988}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:33:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2c28d9d8-caba-43fc-b56e-2350a527869b\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:33:38 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f20a38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 18 08:33:39.668: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 18 08:33:39.669: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7496  70f9ad24-6fde-4ebb-b5ac-f90bdafe4cf3 4173494 2 2023-04-18 08:33:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 2c28d9d8-caba-43fc-b56e-2350a527869b 0xc004f2072f 0xc004f20740}] [] [{e2e.test Update apps/v1 2023-04-18 08:33:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:33:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2c28d9d8-caba-43fc-b56e-2350a527869b\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:33:38 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004f207f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 18 08:33:39.669: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-7496  8a60525d-0609-4838-96b5-39ae3b49573d 4173433 2 2023-04-18 08:33:25 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 2c28d9d8-caba-43fc-b56e-2350a527869b 0xc004f20867 0xc004f20868}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:33:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2c28d9d8-caba-43fc-b56e-2350a527869b\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:33:27 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f20918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 18 08:33:39.672: INFO: Pod "test-rollover-deployment-6d45fd857b-htm5v" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-htm5v test-rollover-deployment-6d45fd857b- deployment-7496  f26c24c8-a20c-4fea-986f-efb113581ab2 4173441 0 2023-04-18 08:33:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 5737b8ed-aac6-4307-8b67-08a2e50ba361 0xc005cdc577 0xc005cdc578}] [] [{kube-controller-manager Update v1 2023-04-18 08:33:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5737b8ed-aac6-4307-8b67-08a2e50ba361\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:33:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.60\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mj67d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mj67d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:33:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:33:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:33:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:33:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.60,StartTime:2023-04-18 08:33:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:33:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://1ea50a55ef053c16807d3868521bc135033e7c743c40e1bf9cfb609543fe55cf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.60,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 08:33:39.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7496" for this suite. 04/18/23 08:33:39.676
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":38,"skipped":701,"failed":0}
------------------------------
• [SLOW TEST] [25.131 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:33:14.548
    Apr 18 08:33:14.549: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename deployment 04/18/23 08:33:14.549
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:33:14.56
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:33:14.564
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Apr 18 08:33:14.574: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Apr 18 08:33:19.579: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/18/23 08:33:19.579
    Apr 18 08:33:19.579: INFO: Waiting up to 5m0s for pod "test-rollover-controller-wfl5l" in namespace "deployment-7496" to be "running"
    Apr 18 08:33:19.581: INFO: Pod "test-rollover-controller-wfl5l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.505821ms
    Apr 18 08:33:21.585: INFO: Pod "test-rollover-controller-wfl5l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006424442s
    Apr 18 08:33:23.585: INFO: Pod "test-rollover-controller-wfl5l": Phase="Running", Reason="", readiness=true. Elapsed: 4.006231208s
    Apr 18 08:33:23.585: INFO: Pod "test-rollover-controller-wfl5l" satisfied condition "running"
    Apr 18 08:33:23.585: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Apr 18 08:33:25.589: INFO: Creating deployment "test-rollover-deployment"
    Apr 18 08:33:25.596: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Apr 18 08:33:27.603: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Apr 18 08:33:27.608: INFO: Ensure that both replica sets have 1 created replica
    Apr 18 08:33:27.613: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Apr 18 08:33:27.624: INFO: Updating deployment test-rollover-deployment
    Apr 18 08:33:27.624: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Apr 18 08:33:29.632: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Apr 18 08:33:29.637: INFO: Make sure deployment "test-rollover-deployment" is complete
    Apr 18 08:33:29.648: INFO: all replica sets need to contain the pod-template-hash label
    Apr 18 08:33:29.648: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 08:33:31.654: INFO: all replica sets need to contain the pod-template-hash label
    Apr 18 08:33:31.654: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 08:33:33.655: INFO: all replica sets need to contain the pod-template-hash label
    Apr 18 08:33:33.655: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 08:33:35.658: INFO: all replica sets need to contain the pod-template-hash label
    Apr 18 08:33:35.658: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 08:33:37.654: INFO: all replica sets need to contain the pod-template-hash label
    Apr 18 08:33:37.654: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 33, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 33, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 08:33:39.657: INFO: 
    Apr 18 08:33:39.657: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 08:33:39.666: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-7496  2c28d9d8-caba-43fc-b56e-2350a527869b 4173495 2 2023-04-18 08:33:25 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-18 08:33:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:33:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f20298 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-18 08:33:25 +0000 UTC,LastTransitionTime:2023-04-18 08:33:25 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-04-18 08:33:38 +0000 UTC,LastTransitionTime:2023-04-18 08:33:25 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 18 08:33:39.668: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-7496  5737b8ed-aac6-4307-8b67-08a2e50ba361 4173488 2 2023-04-18 08:33:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 2c28d9d8-caba-43fc-b56e-2350a527869b 0xc004f20987 0xc004f20988}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:33:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2c28d9d8-caba-43fc-b56e-2350a527869b\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:33:38 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f20a38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 08:33:39.668: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Apr 18 08:33:39.669: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7496  70f9ad24-6fde-4ebb-b5ac-f90bdafe4cf3 4173494 2 2023-04-18 08:33:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 2c28d9d8-caba-43fc-b56e-2350a527869b 0xc004f2072f 0xc004f20740}] [] [{e2e.test Update apps/v1 2023-04-18 08:33:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:33:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2c28d9d8-caba-43fc-b56e-2350a527869b\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:33:38 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004f207f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 08:33:39.669: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-7496  8a60525d-0609-4838-96b5-39ae3b49573d 4173433 2 2023-04-18 08:33:25 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 2c28d9d8-caba-43fc-b56e-2350a527869b 0xc004f20867 0xc004f20868}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:33:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2c28d9d8-caba-43fc-b56e-2350a527869b\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:33:27 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f20918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 08:33:39.672: INFO: Pod "test-rollover-deployment-6d45fd857b-htm5v" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-htm5v test-rollover-deployment-6d45fd857b- deployment-7496  f26c24c8-a20c-4fea-986f-efb113581ab2 4173441 0 2023-04-18 08:33:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 5737b8ed-aac6-4307-8b67-08a2e50ba361 0xc005cdc577 0xc005cdc578}] [] [{kube-controller-manager Update v1 2023-04-18 08:33:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5737b8ed-aac6-4307-8b67-08a2e50ba361\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:33:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.60\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mj67d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mj67d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:33:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:33:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:33:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:33:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.60,StartTime:2023-04-18 08:33:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:33:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://1ea50a55ef053c16807d3868521bc135033e7c743c40e1bf9cfb609543fe55cf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.60,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 08:33:39.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7496" for this suite. 04/18/23 08:33:39.676
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:33:39.681
Apr 18 08:33:39.681: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename dns 04/18/23 08:33:39.682
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:33:39.697
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:33:39.701
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 04/18/23 08:33:39.705
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3871.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3871.svc.cluster.local; sleep 1; done
 04/18/23 08:33:39.709
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3871.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3871.svc.cluster.local; sleep 1; done
 04/18/23 08:33:39.709
STEP: creating a pod to probe DNS 04/18/23 08:33:39.709
STEP: submitting the pod to kubernetes 04/18/23 08:33:39.709
Apr 18 08:33:39.715: INFO: Waiting up to 15m0s for pod "dns-test-f715559f-2b4f-4872-84e0-f64fa1eb7dbe" in namespace "dns-3871" to be "running"
Apr 18 08:33:39.718: INFO: Pod "dns-test-f715559f-2b4f-4872-84e0-f64fa1eb7dbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.947016ms
Apr 18 08:33:41.723: INFO: Pod "dns-test-f715559f-2b4f-4872-84e0-f64fa1eb7dbe": Phase="Running", Reason="", readiness=true. Elapsed: 2.007524865s
Apr 18 08:33:41.723: INFO: Pod "dns-test-f715559f-2b4f-4872-84e0-f64fa1eb7dbe" satisfied condition "running"
STEP: retrieving the pod 04/18/23 08:33:41.723
STEP: looking for the results for each expected name from probers 04/18/23 08:33:41.725
Apr 18 08:33:41.734: INFO: DNS probes using dns-test-f715559f-2b4f-4872-84e0-f64fa1eb7dbe succeeded

STEP: deleting the pod 04/18/23 08:33:41.734
STEP: changing the externalName to bar.example.com 04/18/23 08:33:41.758
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3871.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3871.svc.cluster.local; sleep 1; done
 04/18/23 08:33:41.776
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3871.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3871.svc.cluster.local; sleep 1; done
 04/18/23 08:33:41.776
STEP: creating a second pod to probe DNS 04/18/23 08:33:41.776
STEP: submitting the pod to kubernetes 04/18/23 08:33:41.776
Apr 18 08:33:41.781: INFO: Waiting up to 15m0s for pod "dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c" in namespace "dns-3871" to be "running"
Apr 18 08:33:41.788: INFO: Pod "dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.267883ms
Apr 18 08:33:43.793: INFO: Pod "dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c": Phase="Running", Reason="", readiness=true. Elapsed: 2.011754748s
Apr 18 08:33:43.793: INFO: Pod "dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c" satisfied condition "running"
STEP: retrieving the pod 04/18/23 08:33:43.793
STEP: looking for the results for each expected name from probers 04/18/23 08:33:43.796
Apr 18 08:33:43.801: INFO: File wheezy_udp@dns-test-service-3.dns-3871.svc.cluster.local from pod  dns-3871/dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 18 08:33:43.805: INFO: File jessie_udp@dns-test-service-3.dns-3871.svc.cluster.local from pod  dns-3871/dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 18 08:33:43.805: INFO: Lookups using dns-3871/dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c failed for: [wheezy_udp@dns-test-service-3.dns-3871.svc.cluster.local jessie_udp@dns-test-service-3.dns-3871.svc.cluster.local]

Apr 18 08:33:48.813: INFO: DNS probes using dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c succeeded

STEP: deleting the pod 04/18/23 08:33:48.813
STEP: changing the service to type=ClusterIP 04/18/23 08:33:48.822
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3871.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3871.svc.cluster.local; sleep 1; done
 04/18/23 08:33:48.832
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3871.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3871.svc.cluster.local; sleep 1; done
 04/18/23 08:33:48.832
STEP: creating a third pod to probe DNS 04/18/23 08:33:48.832
STEP: submitting the pod to kubernetes 04/18/23 08:33:48.836
Apr 18 08:33:48.849: INFO: Waiting up to 15m0s for pod "dns-test-66847766-39fa-47b3-8baa-1d92dd37b3b8" in namespace "dns-3871" to be "running"
Apr 18 08:33:48.853: INFO: Pod "dns-test-66847766-39fa-47b3-8baa-1d92dd37b3b8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.207307ms
Apr 18 08:33:50.856: INFO: Pod "dns-test-66847766-39fa-47b3-8baa-1d92dd37b3b8": Phase="Running", Reason="", readiness=true. Elapsed: 2.006672596s
Apr 18 08:33:50.856: INFO: Pod "dns-test-66847766-39fa-47b3-8baa-1d92dd37b3b8" satisfied condition "running"
STEP: retrieving the pod 04/18/23 08:33:50.856
STEP: looking for the results for each expected name from probers 04/18/23 08:33:50.859
Apr 18 08:33:50.876: INFO: DNS probes using dns-test-66847766-39fa-47b3-8baa-1d92dd37b3b8 succeeded

STEP: deleting the pod 04/18/23 08:33:50.876
STEP: deleting the test externalName service 04/18/23 08:33:50.892
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 08:33:50.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3871" for this suite. 04/18/23 08:33:50.917
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":39,"skipped":738,"failed":0}
------------------------------
• [SLOW TEST] [11.243 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:33:39.681
    Apr 18 08:33:39.681: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename dns 04/18/23 08:33:39.682
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:33:39.697
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:33:39.701
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 04/18/23 08:33:39.705
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3871.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3871.svc.cluster.local; sleep 1; done
     04/18/23 08:33:39.709
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3871.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3871.svc.cluster.local; sleep 1; done
     04/18/23 08:33:39.709
    STEP: creating a pod to probe DNS 04/18/23 08:33:39.709
    STEP: submitting the pod to kubernetes 04/18/23 08:33:39.709
    Apr 18 08:33:39.715: INFO: Waiting up to 15m0s for pod "dns-test-f715559f-2b4f-4872-84e0-f64fa1eb7dbe" in namespace "dns-3871" to be "running"
    Apr 18 08:33:39.718: INFO: Pod "dns-test-f715559f-2b4f-4872-84e0-f64fa1eb7dbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.947016ms
    Apr 18 08:33:41.723: INFO: Pod "dns-test-f715559f-2b4f-4872-84e0-f64fa1eb7dbe": Phase="Running", Reason="", readiness=true. Elapsed: 2.007524865s
    Apr 18 08:33:41.723: INFO: Pod "dns-test-f715559f-2b4f-4872-84e0-f64fa1eb7dbe" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 08:33:41.723
    STEP: looking for the results for each expected name from probers 04/18/23 08:33:41.725
    Apr 18 08:33:41.734: INFO: DNS probes using dns-test-f715559f-2b4f-4872-84e0-f64fa1eb7dbe succeeded

    STEP: deleting the pod 04/18/23 08:33:41.734
    STEP: changing the externalName to bar.example.com 04/18/23 08:33:41.758
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3871.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3871.svc.cluster.local; sleep 1; done
     04/18/23 08:33:41.776
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3871.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3871.svc.cluster.local; sleep 1; done
     04/18/23 08:33:41.776
    STEP: creating a second pod to probe DNS 04/18/23 08:33:41.776
    STEP: submitting the pod to kubernetes 04/18/23 08:33:41.776
    Apr 18 08:33:41.781: INFO: Waiting up to 15m0s for pod "dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c" in namespace "dns-3871" to be "running"
    Apr 18 08:33:41.788: INFO: Pod "dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.267883ms
    Apr 18 08:33:43.793: INFO: Pod "dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c": Phase="Running", Reason="", readiness=true. Elapsed: 2.011754748s
    Apr 18 08:33:43.793: INFO: Pod "dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 08:33:43.793
    STEP: looking for the results for each expected name from probers 04/18/23 08:33:43.796
    Apr 18 08:33:43.801: INFO: File wheezy_udp@dns-test-service-3.dns-3871.svc.cluster.local from pod  dns-3871/dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 18 08:33:43.805: INFO: File jessie_udp@dns-test-service-3.dns-3871.svc.cluster.local from pod  dns-3871/dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 18 08:33:43.805: INFO: Lookups using dns-3871/dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c failed for: [wheezy_udp@dns-test-service-3.dns-3871.svc.cluster.local jessie_udp@dns-test-service-3.dns-3871.svc.cluster.local]

    Apr 18 08:33:48.813: INFO: DNS probes using dns-test-77948373-7875-4eb3-8ca5-d1a4d78e524c succeeded

    STEP: deleting the pod 04/18/23 08:33:48.813
    STEP: changing the service to type=ClusterIP 04/18/23 08:33:48.822
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3871.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3871.svc.cluster.local; sleep 1; done
     04/18/23 08:33:48.832
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3871.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3871.svc.cluster.local; sleep 1; done
     04/18/23 08:33:48.832
    STEP: creating a third pod to probe DNS 04/18/23 08:33:48.832
    STEP: submitting the pod to kubernetes 04/18/23 08:33:48.836
    Apr 18 08:33:48.849: INFO: Waiting up to 15m0s for pod "dns-test-66847766-39fa-47b3-8baa-1d92dd37b3b8" in namespace "dns-3871" to be "running"
    Apr 18 08:33:48.853: INFO: Pod "dns-test-66847766-39fa-47b3-8baa-1d92dd37b3b8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.207307ms
    Apr 18 08:33:50.856: INFO: Pod "dns-test-66847766-39fa-47b3-8baa-1d92dd37b3b8": Phase="Running", Reason="", readiness=true. Elapsed: 2.006672596s
    Apr 18 08:33:50.856: INFO: Pod "dns-test-66847766-39fa-47b3-8baa-1d92dd37b3b8" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 08:33:50.856
    STEP: looking for the results for each expected name from probers 04/18/23 08:33:50.859
    Apr 18 08:33:50.876: INFO: DNS probes using dns-test-66847766-39fa-47b3-8baa-1d92dd37b3b8 succeeded

    STEP: deleting the pod 04/18/23 08:33:50.876
    STEP: deleting the test externalName service 04/18/23 08:33:50.892
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 08:33:50.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3871" for this suite. 04/18/23 08:33:50.917
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:33:50.925
Apr 18 08:33:50.925: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir 04/18/23 08:33:50.926
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:33:50.94
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:33:50.943
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 04/18/23 08:33:50.949
Apr 18 08:33:50.956: INFO: Waiting up to 5m0s for pod "pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2" in namespace "emptydir-3587" to be "Succeeded or Failed"
Apr 18 08:33:50.959: INFO: Pod "pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.937944ms
Apr 18 08:33:52.963: INFO: Pod "pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006872996s
Apr 18 08:33:54.962: INFO: Pod "pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006527773s
STEP: Saw pod success 04/18/23 08:33:54.962
Apr 18 08:33:54.962: INFO: Pod "pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2" satisfied condition "Succeeded or Failed"
Apr 18 08:33:54.965: INFO: Trying to get logs from node 192.168.1.152 pod pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2 container test-container: <nil>
STEP: delete the pod 04/18/23 08:33:54.97
Apr 18 08:33:54.978: INFO: Waiting for pod pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2 to disappear
Apr 18 08:33:54.981: INFO: Pod pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 08:33:54.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3587" for this suite. 04/18/23 08:33:54.985
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":40,"skipped":748,"failed":0}
------------------------------
• [4.064 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:33:50.925
    Apr 18 08:33:50.925: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir 04/18/23 08:33:50.926
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:33:50.94
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:33:50.943
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 04/18/23 08:33:50.949
    Apr 18 08:33:50.956: INFO: Waiting up to 5m0s for pod "pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2" in namespace "emptydir-3587" to be "Succeeded or Failed"
    Apr 18 08:33:50.959: INFO: Pod "pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.937944ms
    Apr 18 08:33:52.963: INFO: Pod "pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006872996s
    Apr 18 08:33:54.962: INFO: Pod "pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006527773s
    STEP: Saw pod success 04/18/23 08:33:54.962
    Apr 18 08:33:54.962: INFO: Pod "pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2" satisfied condition "Succeeded or Failed"
    Apr 18 08:33:54.965: INFO: Trying to get logs from node 192.168.1.152 pod pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2 container test-container: <nil>
    STEP: delete the pod 04/18/23 08:33:54.97
    Apr 18 08:33:54.978: INFO: Waiting for pod pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2 to disappear
    Apr 18 08:33:54.981: INFO: Pod pod-922d5992-d7cd-4e9a-8fad-566c8026d2b2 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 08:33:54.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3587" for this suite. 04/18/23 08:33:54.985
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:33:54.989
Apr 18 08:33:54.989: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename controllerrevisions 04/18/23 08:33:54.99
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:33:54.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:33:55.002
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-m2l7d-daemon-set" 04/18/23 08:33:55.02
STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 08:33:55.024
Apr 18 08:33:55.029: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 0
Apr 18 08:33:55.029: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
Apr 18 08:33:56.037: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 1
Apr 18 08:33:56.037: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
Apr 18 08:33:57.037: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 1
Apr 18 08:33:57.037: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
Apr 18 08:33:58.037: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 1
Apr 18 08:33:58.037: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
Apr 18 08:33:59.038: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 1
Apr 18 08:33:59.038: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
Apr 18 08:34:00.036: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 1
Apr 18 08:34:00.036: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
Apr 18 08:34:01.037: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 2
Apr 18 08:34:01.037: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
Apr 18 08:34:02.038: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 2
Apr 18 08:34:02.038: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
Apr 18 08:34:03.037: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 3
Apr 18 08:34:03.037: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-m2l7d-daemon-set
STEP: Confirm DaemonSet "e2e-m2l7d-daemon-set" successfully created with "daemonset-name=e2e-m2l7d-daemon-set" label 04/18/23 08:34:03.04
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-m2l7d-daemon-set" 04/18/23 08:34:03.052
Apr 18 08:34:03.055: INFO: Located ControllerRevision: "e2e-m2l7d-daemon-set-69b6f479fc"
STEP: Patching ControllerRevision "e2e-m2l7d-daemon-set-69b6f479fc" 04/18/23 08:34:03.058
Apr 18 08:34:03.093: INFO: e2e-m2l7d-daemon-set-69b6f479fc has been patched
STEP: Create a new ControllerRevision 04/18/23 08:34:03.093
Apr 18 08:34:03.097: INFO: Created ControllerRevision: e2e-m2l7d-daemon-set-bf5bf5457
STEP: Confirm that there are two ControllerRevisions 04/18/23 08:34:03.097
Apr 18 08:34:03.097: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 18 08:34:03.099: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-m2l7d-daemon-set-69b6f479fc" 04/18/23 08:34:03.099
STEP: Confirm that there is only one ControllerRevision 04/18/23 08:34:03.106
Apr 18 08:34:03.106: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 18 08:34:03.109: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-m2l7d-daemon-set-bf5bf5457" 04/18/23 08:34:03.111
Apr 18 08:34:03.118: INFO: e2e-m2l7d-daemon-set-bf5bf5457 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 04/18/23 08:34:03.118
W0418 08:34:03.127563      18 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 04/18/23 08:34:03.127
Apr 18 08:34:03.127: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 18 08:34:04.132: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 18 08:34:04.135: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-m2l7d-daemon-set-bf5bf5457=updated" 04/18/23 08:34:04.136
STEP: Confirm that there is only one ControllerRevision 04/18/23 08:34:04.142
Apr 18 08:34:04.142: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 18 08:34:04.150: INFO: Found 1 ControllerRevisions
Apr 18 08:34:04.154: INFO: ControllerRevision "e2e-m2l7d-daemon-set-65bdfd5d4" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-m2l7d-daemon-set" 04/18/23 08:34:04.156
STEP: deleting DaemonSet.extensions e2e-m2l7d-daemon-set in namespace controllerrevisions-6288, will wait for the garbage collector to delete the pods 04/18/23 08:34:04.156
Apr 18 08:34:04.219: INFO: Deleting DaemonSet.extensions e2e-m2l7d-daemon-set took: 7.311359ms
Apr 18 08:34:04.319: INFO: Terminating DaemonSet.extensions e2e-m2l7d-daemon-set pods took: 100.407451ms
Apr 18 08:34:05.723: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 0
Apr 18 08:34:05.723: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-m2l7d-daemon-set
Apr 18 08:34:05.725: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4173727"},"items":null}

Apr 18 08:34:05.728: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4173727"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Apr 18 08:34:05.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-6288" for this suite. 04/18/23 08:34:05.741
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":41,"skipped":749,"failed":0}
------------------------------
• [SLOW TEST] [10.759 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:33:54.989
    Apr 18 08:33:54.989: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename controllerrevisions 04/18/23 08:33:54.99
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:33:54.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:33:55.002
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-m2l7d-daemon-set" 04/18/23 08:33:55.02
    STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 08:33:55.024
    Apr 18 08:33:55.029: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 0
    Apr 18 08:33:55.029: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
    Apr 18 08:33:56.037: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 1
    Apr 18 08:33:56.037: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
    Apr 18 08:33:57.037: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 1
    Apr 18 08:33:57.037: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
    Apr 18 08:33:58.037: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 1
    Apr 18 08:33:58.037: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
    Apr 18 08:33:59.038: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 1
    Apr 18 08:33:59.038: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
    Apr 18 08:34:00.036: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 1
    Apr 18 08:34:00.036: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
    Apr 18 08:34:01.037: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 2
    Apr 18 08:34:01.037: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
    Apr 18 08:34:02.038: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 2
    Apr 18 08:34:02.038: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
    Apr 18 08:34:03.037: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 3
    Apr 18 08:34:03.037: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-m2l7d-daemon-set
    STEP: Confirm DaemonSet "e2e-m2l7d-daemon-set" successfully created with "daemonset-name=e2e-m2l7d-daemon-set" label 04/18/23 08:34:03.04
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-m2l7d-daemon-set" 04/18/23 08:34:03.052
    Apr 18 08:34:03.055: INFO: Located ControllerRevision: "e2e-m2l7d-daemon-set-69b6f479fc"
    STEP: Patching ControllerRevision "e2e-m2l7d-daemon-set-69b6f479fc" 04/18/23 08:34:03.058
    Apr 18 08:34:03.093: INFO: e2e-m2l7d-daemon-set-69b6f479fc has been patched
    STEP: Create a new ControllerRevision 04/18/23 08:34:03.093
    Apr 18 08:34:03.097: INFO: Created ControllerRevision: e2e-m2l7d-daemon-set-bf5bf5457
    STEP: Confirm that there are two ControllerRevisions 04/18/23 08:34:03.097
    Apr 18 08:34:03.097: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 18 08:34:03.099: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-m2l7d-daemon-set-69b6f479fc" 04/18/23 08:34:03.099
    STEP: Confirm that there is only one ControllerRevision 04/18/23 08:34:03.106
    Apr 18 08:34:03.106: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 18 08:34:03.109: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-m2l7d-daemon-set-bf5bf5457" 04/18/23 08:34:03.111
    Apr 18 08:34:03.118: INFO: e2e-m2l7d-daemon-set-bf5bf5457 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 04/18/23 08:34:03.118
    W0418 08:34:03.127563      18 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 04/18/23 08:34:03.127
    Apr 18 08:34:03.127: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 18 08:34:04.132: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 18 08:34:04.135: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-m2l7d-daemon-set-bf5bf5457=updated" 04/18/23 08:34:04.136
    STEP: Confirm that there is only one ControllerRevision 04/18/23 08:34:04.142
    Apr 18 08:34:04.142: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 18 08:34:04.150: INFO: Found 1 ControllerRevisions
    Apr 18 08:34:04.154: INFO: ControllerRevision "e2e-m2l7d-daemon-set-65bdfd5d4" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-m2l7d-daemon-set" 04/18/23 08:34:04.156
    STEP: deleting DaemonSet.extensions e2e-m2l7d-daemon-set in namespace controllerrevisions-6288, will wait for the garbage collector to delete the pods 04/18/23 08:34:04.156
    Apr 18 08:34:04.219: INFO: Deleting DaemonSet.extensions e2e-m2l7d-daemon-set took: 7.311359ms
    Apr 18 08:34:04.319: INFO: Terminating DaemonSet.extensions e2e-m2l7d-daemon-set pods took: 100.407451ms
    Apr 18 08:34:05.723: INFO: Number of nodes with available pods controlled by daemonset e2e-m2l7d-daemon-set: 0
    Apr 18 08:34:05.723: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-m2l7d-daemon-set
    Apr 18 08:34:05.725: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4173727"},"items":null}

    Apr 18 08:34:05.728: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4173727"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 08:34:05.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-6288" for this suite. 04/18/23 08:34:05.741
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:34:05.749
Apr 18 08:34:05.749: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename statefulset 04/18/23 08:34:05.749
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:34:05.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:34:05.761
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4092 04/18/23 08:34:05.765
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 04/18/23 08:34:05.769
STEP: Creating pod with conflicting port in namespace statefulset-4092 04/18/23 08:34:05.773
STEP: Waiting until pod test-pod will start running in namespace statefulset-4092 04/18/23 08:34:05.779
Apr 18 08:34:05.779: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-4092" to be "running"
Apr 18 08:34:05.781: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.4969ms
Apr 18 08:34:07.785: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.006202046s
Apr 18 08:34:07.785: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-4092 04/18/23 08:34:07.785
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4092 04/18/23 08:34:07.836
Apr 18 08:34:07.946: INFO: Observed stateful pod in namespace: statefulset-4092, name: ss-0, uid: 3ccd025f-d33d-4b3c-9a93-290f563d7239, status phase: Pending. Waiting for statefulset controller to delete.
Apr 18 08:34:07.957: INFO: Observed stateful pod in namespace: statefulset-4092, name: ss-0, uid: 3ccd025f-d33d-4b3c-9a93-290f563d7239, status phase: Failed. Waiting for statefulset controller to delete.
Apr 18 08:34:07.966: INFO: Observed stateful pod in namespace: statefulset-4092, name: ss-0, uid: 3ccd025f-d33d-4b3c-9a93-290f563d7239, status phase: Failed. Waiting for statefulset controller to delete.
Apr 18 08:34:07.970: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4092
STEP: Removing pod with conflicting port in namespace statefulset-4092 04/18/23 08:34:07.97
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4092 and will be in running state 04/18/23 08:34:07.977
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 08:34:09.984: INFO: Deleting all statefulset in ns statefulset-4092
Apr 18 08:34:09.986: INFO: Scaling statefulset ss to 0
Apr 18 08:34:20.002: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 08:34:20.005: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 08:34:20.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4092" for this suite. 04/18/23 08:34:20.025
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":42,"skipped":764,"failed":0}
------------------------------
• [SLOW TEST] [14.280 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:34:05.749
    Apr 18 08:34:05.749: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename statefulset 04/18/23 08:34:05.749
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:34:05.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:34:05.761
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4092 04/18/23 08:34:05.765
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 04/18/23 08:34:05.769
    STEP: Creating pod with conflicting port in namespace statefulset-4092 04/18/23 08:34:05.773
    STEP: Waiting until pod test-pod will start running in namespace statefulset-4092 04/18/23 08:34:05.779
    Apr 18 08:34:05.779: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-4092" to be "running"
    Apr 18 08:34:05.781: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.4969ms
    Apr 18 08:34:07.785: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.006202046s
    Apr 18 08:34:07.785: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-4092 04/18/23 08:34:07.785
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4092 04/18/23 08:34:07.836
    Apr 18 08:34:07.946: INFO: Observed stateful pod in namespace: statefulset-4092, name: ss-0, uid: 3ccd025f-d33d-4b3c-9a93-290f563d7239, status phase: Pending. Waiting for statefulset controller to delete.
    Apr 18 08:34:07.957: INFO: Observed stateful pod in namespace: statefulset-4092, name: ss-0, uid: 3ccd025f-d33d-4b3c-9a93-290f563d7239, status phase: Failed. Waiting for statefulset controller to delete.
    Apr 18 08:34:07.966: INFO: Observed stateful pod in namespace: statefulset-4092, name: ss-0, uid: 3ccd025f-d33d-4b3c-9a93-290f563d7239, status phase: Failed. Waiting for statefulset controller to delete.
    Apr 18 08:34:07.970: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4092
    STEP: Removing pod with conflicting port in namespace statefulset-4092 04/18/23 08:34:07.97
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4092 and will be in running state 04/18/23 08:34:07.977
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 08:34:09.984: INFO: Deleting all statefulset in ns statefulset-4092
    Apr 18 08:34:09.986: INFO: Scaling statefulset ss to 0
    Apr 18 08:34:20.002: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 08:34:20.005: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 08:34:20.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4092" for this suite. 04/18/23 08:34:20.025
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:34:20.029
Apr 18 08:34:20.029: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 08:34:20.03
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:34:20.04
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:34:20.044
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-d83420f7-c579-4805-89c8-8a7292ac5c08 04/18/23 08:34:20.052
STEP: Creating configMap with name cm-test-opt-upd-8c4be1cc-89ca-4015-9165-cdb6ec346e07 04/18/23 08:34:20.056
STEP: Creating the pod 04/18/23 08:34:20.06
Apr 18 08:34:20.068: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-509c1cca-d682-44f1-b16f-a0a67c9fc638" in namespace "projected-9177" to be "running and ready"
Apr 18 08:34:20.071: INFO: Pod "pod-projected-configmaps-509c1cca-d682-44f1-b16f-a0a67c9fc638": Phase="Pending", Reason="", readiness=false. Elapsed: 3.203113ms
Apr 18 08:34:20.071: INFO: The phase of Pod pod-projected-configmaps-509c1cca-d682-44f1-b16f-a0a67c9fc638 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:34:22.074: INFO: Pod "pod-projected-configmaps-509c1cca-d682-44f1-b16f-a0a67c9fc638": Phase="Running", Reason="", readiness=true. Elapsed: 2.00680818s
Apr 18 08:34:22.074: INFO: The phase of Pod pod-projected-configmaps-509c1cca-d682-44f1-b16f-a0a67c9fc638 is Running (Ready = true)
Apr 18 08:34:22.074: INFO: Pod "pod-projected-configmaps-509c1cca-d682-44f1-b16f-a0a67c9fc638" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-d83420f7-c579-4805-89c8-8a7292ac5c08 04/18/23 08:34:22.092
STEP: Updating configmap cm-test-opt-upd-8c4be1cc-89ca-4015-9165-cdb6ec346e07 04/18/23 08:34:22.097
STEP: Creating configMap with name cm-test-opt-create-ad5445b6-ae71-4539-92d2-8c5b0a3c8f25 04/18/23 08:34:22.103
STEP: waiting to observe update in volume 04/18/23 08:34:22.109
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 08:34:26.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9177" for this suite. 04/18/23 08:34:26.14
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":43,"skipped":769,"failed":0}
------------------------------
• [SLOW TEST] [6.116 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:34:20.029
    Apr 18 08:34:20.029: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 08:34:20.03
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:34:20.04
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:34:20.044
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-d83420f7-c579-4805-89c8-8a7292ac5c08 04/18/23 08:34:20.052
    STEP: Creating configMap with name cm-test-opt-upd-8c4be1cc-89ca-4015-9165-cdb6ec346e07 04/18/23 08:34:20.056
    STEP: Creating the pod 04/18/23 08:34:20.06
    Apr 18 08:34:20.068: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-509c1cca-d682-44f1-b16f-a0a67c9fc638" in namespace "projected-9177" to be "running and ready"
    Apr 18 08:34:20.071: INFO: Pod "pod-projected-configmaps-509c1cca-d682-44f1-b16f-a0a67c9fc638": Phase="Pending", Reason="", readiness=false. Elapsed: 3.203113ms
    Apr 18 08:34:20.071: INFO: The phase of Pod pod-projected-configmaps-509c1cca-d682-44f1-b16f-a0a67c9fc638 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:34:22.074: INFO: Pod "pod-projected-configmaps-509c1cca-d682-44f1-b16f-a0a67c9fc638": Phase="Running", Reason="", readiness=true. Elapsed: 2.00680818s
    Apr 18 08:34:22.074: INFO: The phase of Pod pod-projected-configmaps-509c1cca-d682-44f1-b16f-a0a67c9fc638 is Running (Ready = true)
    Apr 18 08:34:22.074: INFO: Pod "pod-projected-configmaps-509c1cca-d682-44f1-b16f-a0a67c9fc638" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-d83420f7-c579-4805-89c8-8a7292ac5c08 04/18/23 08:34:22.092
    STEP: Updating configmap cm-test-opt-upd-8c4be1cc-89ca-4015-9165-cdb6ec346e07 04/18/23 08:34:22.097
    STEP: Creating configMap with name cm-test-opt-create-ad5445b6-ae71-4539-92d2-8c5b0a3c8f25 04/18/23 08:34:22.103
    STEP: waiting to observe update in volume 04/18/23 08:34:22.109
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 08:34:26.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9177" for this suite. 04/18/23 08:34:26.14
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:34:26.145
Apr 18 08:34:26.146: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 08:34:26.146
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:34:26.157
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:34:26.161
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 08:34:26.173
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:34:26.625
STEP: Deploying the webhook pod 04/18/23 08:34:26.631
STEP: Wait for the deployment to be ready 04/18/23 08:34:26.642
Apr 18 08:34:26.649: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 08:34:28.658
STEP: Verifying the service has paired with the endpoint 04/18/23 08:34:28.666
Apr 18 08:34:29.667: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 04/18/23 08:34:29.727
STEP: Creating a configMap that should be mutated 04/18/23 08:34:29.751
STEP: Deleting the collection of validation webhooks 04/18/23 08:34:29.778
STEP: Creating a configMap that should not be mutated 04/18/23 08:34:29.826
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 08:34:29.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9615" for this suite. 04/18/23 08:34:29.839
STEP: Destroying namespace "webhook-9615-markers" for this suite. 04/18/23 08:34:29.844
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":44,"skipped":790,"failed":0}
------------------------------
• [3.751 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:34:26.145
    Apr 18 08:34:26.146: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 08:34:26.146
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:34:26.157
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:34:26.161
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 08:34:26.173
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:34:26.625
    STEP: Deploying the webhook pod 04/18/23 08:34:26.631
    STEP: Wait for the deployment to be ready 04/18/23 08:34:26.642
    Apr 18 08:34:26.649: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 08:34:28.658
    STEP: Verifying the service has paired with the endpoint 04/18/23 08:34:28.666
    Apr 18 08:34:29.667: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 04/18/23 08:34:29.727
    STEP: Creating a configMap that should be mutated 04/18/23 08:34:29.751
    STEP: Deleting the collection of validation webhooks 04/18/23 08:34:29.778
    STEP: Creating a configMap that should not be mutated 04/18/23 08:34:29.826
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 08:34:29.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9615" for this suite. 04/18/23 08:34:29.839
    STEP: Destroying namespace "webhook-9615-markers" for this suite. 04/18/23 08:34:29.844
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:34:29.897
Apr 18 08:34:29.897: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-probe 04/18/23 08:34:29.898
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:34:29.914
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:34:29.918
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-b7157e23-32a9-4e28-af1c-27824d886cb2 in namespace container-probe-4718 04/18/23 08:34:29.921
Apr 18 08:34:29.928: INFO: Waiting up to 5m0s for pod "liveness-b7157e23-32a9-4e28-af1c-27824d886cb2" in namespace "container-probe-4718" to be "not pending"
Apr 18 08:34:29.932: INFO: Pod "liveness-b7157e23-32a9-4e28-af1c-27824d886cb2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.825ms
Apr 18 08:34:31.936: INFO: Pod "liveness-b7157e23-32a9-4e28-af1c-27824d886cb2": Phase="Running", Reason="", readiness=true. Elapsed: 2.007803397s
Apr 18 08:34:31.936: INFO: Pod "liveness-b7157e23-32a9-4e28-af1c-27824d886cb2" satisfied condition "not pending"
Apr 18 08:34:31.936: INFO: Started pod liveness-b7157e23-32a9-4e28-af1c-27824d886cb2 in namespace container-probe-4718
STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 08:34:31.936
Apr 18 08:34:31.938: INFO: Initial restart count of pod liveness-b7157e23-32a9-4e28-af1c-27824d886cb2 is 0
STEP: deleting the pod 04/18/23 08:38:32.401
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 08:38:32.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4718" for this suite. 04/18/23 08:38:32.418
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":45,"skipped":795,"failed":0}
------------------------------
• [SLOW TEST] [242.532 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:34:29.897
    Apr 18 08:34:29.897: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-probe 04/18/23 08:34:29.898
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:34:29.914
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:34:29.918
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-b7157e23-32a9-4e28-af1c-27824d886cb2 in namespace container-probe-4718 04/18/23 08:34:29.921
    Apr 18 08:34:29.928: INFO: Waiting up to 5m0s for pod "liveness-b7157e23-32a9-4e28-af1c-27824d886cb2" in namespace "container-probe-4718" to be "not pending"
    Apr 18 08:34:29.932: INFO: Pod "liveness-b7157e23-32a9-4e28-af1c-27824d886cb2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.825ms
    Apr 18 08:34:31.936: INFO: Pod "liveness-b7157e23-32a9-4e28-af1c-27824d886cb2": Phase="Running", Reason="", readiness=true. Elapsed: 2.007803397s
    Apr 18 08:34:31.936: INFO: Pod "liveness-b7157e23-32a9-4e28-af1c-27824d886cb2" satisfied condition "not pending"
    Apr 18 08:34:31.936: INFO: Started pod liveness-b7157e23-32a9-4e28-af1c-27824d886cb2 in namespace container-probe-4718
    STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 08:34:31.936
    Apr 18 08:34:31.938: INFO: Initial restart count of pod liveness-b7157e23-32a9-4e28-af1c-27824d886cb2 is 0
    STEP: deleting the pod 04/18/23 08:38:32.401
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 08:38:32.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4718" for this suite. 04/18/23 08:38:32.418
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:38:32.43
Apr 18 08:38:32.430: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename endpointslice 04/18/23 08:38:32.431
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:38:32.451
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:38:32.459
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 18 08:38:34.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-1144" for this suite. 04/18/23 08:38:34.512
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":46,"skipped":797,"failed":0}
------------------------------
• [2.087 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:38:32.43
    Apr 18 08:38:32.430: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename endpointslice 04/18/23 08:38:32.431
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:38:32.451
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:38:32.459
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 18 08:38:34.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-1144" for this suite. 04/18/23 08:38:34.512
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:38:34.517
Apr 18 08:38:34.517: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir-wrapper 04/18/23 08:38:34.517
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:38:34.526
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:38:34.53
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 04/18/23 08:38:34.533
STEP: Creating RC which spawns configmap-volume pods 04/18/23 08:38:34.773
Apr 18 08:38:34.903: INFO: Pod name wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/18/23 08:38:34.903
Apr 18 08:38:34.903: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-c9xqg" in namespace "emptydir-wrapper-6794" to be "running"
Apr 18 08:38:34.948: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-c9xqg": Phase="Pending", Reason="", readiness=false. Elapsed: 45.487523ms
Apr 18 08:38:36.953: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-c9xqg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049788359s
Apr 18 08:38:38.953: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-c9xqg": Phase="Running", Reason="", readiness=true. Elapsed: 4.050613072s
Apr 18 08:38:38.953: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-c9xqg" satisfied condition "running"
Apr 18 08:38:38.953: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-jjs8x" in namespace "emptydir-wrapper-6794" to be "running"
Apr 18 08:38:38.957: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-jjs8x": Phase="Pending", Reason="", readiness=false. Elapsed: 3.342724ms
Apr 18 08:38:40.962: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-jjs8x": Phase="Running", Reason="", readiness=true. Elapsed: 2.00891652s
Apr 18 08:38:40.962: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-jjs8x" satisfied condition "running"
Apr 18 08:38:40.962: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-jv54s" in namespace "emptydir-wrapper-6794" to be "running"
Apr 18 08:38:40.965: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-jv54s": Phase="Running", Reason="", readiness=true. Elapsed: 2.861882ms
Apr 18 08:38:40.965: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-jv54s" satisfied condition "running"
Apr 18 08:38:40.965: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-m2v69" in namespace "emptydir-wrapper-6794" to be "running"
Apr 18 08:38:40.968: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-m2v69": Phase="Running", Reason="", readiness=true. Elapsed: 2.907782ms
Apr 18 08:38:40.968: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-m2v69" satisfied condition "running"
Apr 18 08:38:40.968: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-zc4c7" in namespace "emptydir-wrapper-6794" to be "running"
Apr 18 08:38:40.973: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-zc4c7": Phase="Running", Reason="", readiness=true. Elapsed: 4.626999ms
Apr 18 08:38:40.973: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-zc4c7" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90 in namespace emptydir-wrapper-6794, will wait for the garbage collector to delete the pods 04/18/23 08:38:40.973
Apr 18 08:38:41.031: INFO: Deleting ReplicationController wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90 took: 4.82975ms
Apr 18 08:38:41.131: INFO: Terminating ReplicationController wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90 pods took: 100.603906ms
STEP: Creating RC which spawns configmap-volume pods 04/18/23 08:38:43.136
Apr 18 08:38:43.151: INFO: Pod name wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2: Found 0 pods out of 5
Apr 18 08:38:48.160: INFO: Pod name wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/18/23 08:38:48.16
Apr 18 08:38:48.160: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-2wt8w" in namespace "emptydir-wrapper-6794" to be "running"
Apr 18 08:38:48.163: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-2wt8w": Phase="Running", Reason="", readiness=true. Elapsed: 3.144915ms
Apr 18 08:38:48.163: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-2wt8w" satisfied condition "running"
Apr 18 08:38:48.163: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-f2vvp" in namespace "emptydir-wrapper-6794" to be "running"
Apr 18 08:38:48.166: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-f2vvp": Phase="Running", Reason="", readiness=true. Elapsed: 2.988115ms
Apr 18 08:38:48.166: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-f2vvp" satisfied condition "running"
Apr 18 08:38:48.166: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-jhlk8" in namespace "emptydir-wrapper-6794" to be "running"
Apr 18 08:38:48.169: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-jhlk8": Phase="Running", Reason="", readiness=true. Elapsed: 3.165501ms
Apr 18 08:38:48.169: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-jhlk8" satisfied condition "running"
Apr 18 08:38:48.169: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-jn78g" in namespace "emptydir-wrapper-6794" to be "running"
Apr 18 08:38:48.173: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-jn78g": Phase="Running", Reason="", readiness=true. Elapsed: 3.313351ms
Apr 18 08:38:48.173: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-jn78g" satisfied condition "running"
Apr 18 08:38:48.173: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-mqwdf" in namespace "emptydir-wrapper-6794" to be "running"
Apr 18 08:38:48.175: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-mqwdf": Phase="Running", Reason="", readiness=true. Elapsed: 2.808691ms
Apr 18 08:38:48.175: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-mqwdf" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2 in namespace emptydir-wrapper-6794, will wait for the garbage collector to delete the pods 04/18/23 08:38:48.175
Apr 18 08:38:48.234: INFO: Deleting ReplicationController wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2 took: 5.378962ms
Apr 18 08:38:48.334: INFO: Terminating ReplicationController wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2 pods took: 100.328787ms
STEP: Creating RC which spawns configmap-volume pods 04/18/23 08:38:49.838
Apr 18 08:38:49.853: INFO: Pod name wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04: Found 0 pods out of 5
Apr 18 08:38:54.862: INFO: Pod name wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/18/23 08:38:54.862
Apr 18 08:38:54.862: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-2pm5n" in namespace "emptydir-wrapper-6794" to be "running"
Apr 18 08:38:54.865: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-2pm5n": Phase="Running", Reason="", readiness=true. Elapsed: 3.174886ms
Apr 18 08:38:54.865: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-2pm5n" satisfied condition "running"
Apr 18 08:38:54.865: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-7pkgz" in namespace "emptydir-wrapper-6794" to be "running"
Apr 18 08:38:54.868: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-7pkgz": Phase="Running", Reason="", readiness=true. Elapsed: 2.951922ms
Apr 18 08:38:54.868: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-7pkgz" satisfied condition "running"
Apr 18 08:38:54.868: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-8hzwl" in namespace "emptydir-wrapper-6794" to be "running"
Apr 18 08:38:54.871: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-8hzwl": Phase="Running", Reason="", readiness=true. Elapsed: 2.734399ms
Apr 18 08:38:54.871: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-8hzwl" satisfied condition "running"
Apr 18 08:38:54.871: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-f9vq4" in namespace "emptydir-wrapper-6794" to be "running"
Apr 18 08:38:54.874: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-f9vq4": Phase="Running", Reason="", readiness=true. Elapsed: 2.79649ms
Apr 18 08:38:54.874: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-f9vq4" satisfied condition "running"
Apr 18 08:38:54.874: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-hsn79" in namespace "emptydir-wrapper-6794" to be "running"
Apr 18 08:38:54.876: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-hsn79": Phase="Running", Reason="", readiness=true. Elapsed: 2.794288ms
Apr 18 08:38:54.876: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-hsn79" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04 in namespace emptydir-wrapper-6794, will wait for the garbage collector to delete the pods 04/18/23 08:38:54.876
Apr 18 08:38:54.935: INFO: Deleting ReplicationController wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04 took: 5.210096ms
Apr 18 08:38:55.035: INFO: Terminating ReplicationController wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04 pods took: 100.154119ms
STEP: Cleaning up the configMaps 04/18/23 08:38:56.436
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Apr 18 08:38:56.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6794" for this suite. 04/18/23 08:38:56.635
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":47,"skipped":797,"failed":0}
------------------------------
• [SLOW TEST] [22.122 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:38:34.517
    Apr 18 08:38:34.517: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir-wrapper 04/18/23 08:38:34.517
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:38:34.526
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:38:34.53
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 04/18/23 08:38:34.533
    STEP: Creating RC which spawns configmap-volume pods 04/18/23 08:38:34.773
    Apr 18 08:38:34.903: INFO: Pod name wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/18/23 08:38:34.903
    Apr 18 08:38:34.903: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-c9xqg" in namespace "emptydir-wrapper-6794" to be "running"
    Apr 18 08:38:34.948: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-c9xqg": Phase="Pending", Reason="", readiness=false. Elapsed: 45.487523ms
    Apr 18 08:38:36.953: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-c9xqg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049788359s
    Apr 18 08:38:38.953: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-c9xqg": Phase="Running", Reason="", readiness=true. Elapsed: 4.050613072s
    Apr 18 08:38:38.953: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-c9xqg" satisfied condition "running"
    Apr 18 08:38:38.953: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-jjs8x" in namespace "emptydir-wrapper-6794" to be "running"
    Apr 18 08:38:38.957: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-jjs8x": Phase="Pending", Reason="", readiness=false. Elapsed: 3.342724ms
    Apr 18 08:38:40.962: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-jjs8x": Phase="Running", Reason="", readiness=true. Elapsed: 2.00891652s
    Apr 18 08:38:40.962: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-jjs8x" satisfied condition "running"
    Apr 18 08:38:40.962: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-jv54s" in namespace "emptydir-wrapper-6794" to be "running"
    Apr 18 08:38:40.965: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-jv54s": Phase="Running", Reason="", readiness=true. Elapsed: 2.861882ms
    Apr 18 08:38:40.965: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-jv54s" satisfied condition "running"
    Apr 18 08:38:40.965: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-m2v69" in namespace "emptydir-wrapper-6794" to be "running"
    Apr 18 08:38:40.968: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-m2v69": Phase="Running", Reason="", readiness=true. Elapsed: 2.907782ms
    Apr 18 08:38:40.968: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-m2v69" satisfied condition "running"
    Apr 18 08:38:40.968: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-zc4c7" in namespace "emptydir-wrapper-6794" to be "running"
    Apr 18 08:38:40.973: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-zc4c7": Phase="Running", Reason="", readiness=true. Elapsed: 4.626999ms
    Apr 18 08:38:40.973: INFO: Pod "wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90-zc4c7" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90 in namespace emptydir-wrapper-6794, will wait for the garbage collector to delete the pods 04/18/23 08:38:40.973
    Apr 18 08:38:41.031: INFO: Deleting ReplicationController wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90 took: 4.82975ms
    Apr 18 08:38:41.131: INFO: Terminating ReplicationController wrapped-volume-race-d3726a77-ebe1-45af-95d3-2107db25fb90 pods took: 100.603906ms
    STEP: Creating RC which spawns configmap-volume pods 04/18/23 08:38:43.136
    Apr 18 08:38:43.151: INFO: Pod name wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2: Found 0 pods out of 5
    Apr 18 08:38:48.160: INFO: Pod name wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/18/23 08:38:48.16
    Apr 18 08:38:48.160: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-2wt8w" in namespace "emptydir-wrapper-6794" to be "running"
    Apr 18 08:38:48.163: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-2wt8w": Phase="Running", Reason="", readiness=true. Elapsed: 3.144915ms
    Apr 18 08:38:48.163: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-2wt8w" satisfied condition "running"
    Apr 18 08:38:48.163: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-f2vvp" in namespace "emptydir-wrapper-6794" to be "running"
    Apr 18 08:38:48.166: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-f2vvp": Phase="Running", Reason="", readiness=true. Elapsed: 2.988115ms
    Apr 18 08:38:48.166: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-f2vvp" satisfied condition "running"
    Apr 18 08:38:48.166: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-jhlk8" in namespace "emptydir-wrapper-6794" to be "running"
    Apr 18 08:38:48.169: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-jhlk8": Phase="Running", Reason="", readiness=true. Elapsed: 3.165501ms
    Apr 18 08:38:48.169: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-jhlk8" satisfied condition "running"
    Apr 18 08:38:48.169: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-jn78g" in namespace "emptydir-wrapper-6794" to be "running"
    Apr 18 08:38:48.173: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-jn78g": Phase="Running", Reason="", readiness=true. Elapsed: 3.313351ms
    Apr 18 08:38:48.173: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-jn78g" satisfied condition "running"
    Apr 18 08:38:48.173: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-mqwdf" in namespace "emptydir-wrapper-6794" to be "running"
    Apr 18 08:38:48.175: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-mqwdf": Phase="Running", Reason="", readiness=true. Elapsed: 2.808691ms
    Apr 18 08:38:48.175: INFO: Pod "wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2-mqwdf" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2 in namespace emptydir-wrapper-6794, will wait for the garbage collector to delete the pods 04/18/23 08:38:48.175
    Apr 18 08:38:48.234: INFO: Deleting ReplicationController wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2 took: 5.378962ms
    Apr 18 08:38:48.334: INFO: Terminating ReplicationController wrapped-volume-race-85b68cb8-271f-43c6-890b-da7179bb93a2 pods took: 100.328787ms
    STEP: Creating RC which spawns configmap-volume pods 04/18/23 08:38:49.838
    Apr 18 08:38:49.853: INFO: Pod name wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04: Found 0 pods out of 5
    Apr 18 08:38:54.862: INFO: Pod name wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/18/23 08:38:54.862
    Apr 18 08:38:54.862: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-2pm5n" in namespace "emptydir-wrapper-6794" to be "running"
    Apr 18 08:38:54.865: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-2pm5n": Phase="Running", Reason="", readiness=true. Elapsed: 3.174886ms
    Apr 18 08:38:54.865: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-2pm5n" satisfied condition "running"
    Apr 18 08:38:54.865: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-7pkgz" in namespace "emptydir-wrapper-6794" to be "running"
    Apr 18 08:38:54.868: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-7pkgz": Phase="Running", Reason="", readiness=true. Elapsed: 2.951922ms
    Apr 18 08:38:54.868: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-7pkgz" satisfied condition "running"
    Apr 18 08:38:54.868: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-8hzwl" in namespace "emptydir-wrapper-6794" to be "running"
    Apr 18 08:38:54.871: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-8hzwl": Phase="Running", Reason="", readiness=true. Elapsed: 2.734399ms
    Apr 18 08:38:54.871: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-8hzwl" satisfied condition "running"
    Apr 18 08:38:54.871: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-f9vq4" in namespace "emptydir-wrapper-6794" to be "running"
    Apr 18 08:38:54.874: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-f9vq4": Phase="Running", Reason="", readiness=true. Elapsed: 2.79649ms
    Apr 18 08:38:54.874: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-f9vq4" satisfied condition "running"
    Apr 18 08:38:54.874: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-hsn79" in namespace "emptydir-wrapper-6794" to be "running"
    Apr 18 08:38:54.876: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-hsn79": Phase="Running", Reason="", readiness=true. Elapsed: 2.794288ms
    Apr 18 08:38:54.876: INFO: Pod "wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04-hsn79" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04 in namespace emptydir-wrapper-6794, will wait for the garbage collector to delete the pods 04/18/23 08:38:54.876
    Apr 18 08:38:54.935: INFO: Deleting ReplicationController wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04 took: 5.210096ms
    Apr 18 08:38:55.035: INFO: Terminating ReplicationController wrapped-volume-race-ce17f6e4-f62b-499c-8db6-b3336a9ffc04 pods took: 100.154119ms
    STEP: Cleaning up the configMaps 04/18/23 08:38:56.436
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Apr 18 08:38:56.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-6794" for this suite. 04/18/23 08:38:56.635
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:38:56.639
Apr 18 08:38:56.639: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 08:38:56.641
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:38:56.654
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:38:56.657
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 04/18/23 08:38:56.661
Apr 18 08:38:56.667: INFO: Waiting up to 5m0s for pod "downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9" in namespace "downward-api-9563" to be "Succeeded or Failed"
Apr 18 08:38:56.674: INFO: Pod "downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.819765ms
Apr 18 08:38:58.679: INFO: Pod "downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011513654s
Apr 18 08:39:00.679: INFO: Pod "downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011841749s
STEP: Saw pod success 04/18/23 08:39:00.679
Apr 18 08:39:00.679: INFO: Pod "downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9" satisfied condition "Succeeded or Failed"
Apr 18 08:39:00.682: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9 container client-container: <nil>
STEP: delete the pod 04/18/23 08:39:00.696
Apr 18 08:39:00.706: INFO: Waiting for pod downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9 to disappear
Apr 18 08:39:00.709: INFO: Pod downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 08:39:00.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9563" for this suite. 04/18/23 08:39:00.713
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":48,"skipped":798,"failed":0}
------------------------------
• [4.080 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:38:56.639
    Apr 18 08:38:56.639: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 08:38:56.641
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:38:56.654
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:38:56.657
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 04/18/23 08:38:56.661
    Apr 18 08:38:56.667: INFO: Waiting up to 5m0s for pod "downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9" in namespace "downward-api-9563" to be "Succeeded or Failed"
    Apr 18 08:38:56.674: INFO: Pod "downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.819765ms
    Apr 18 08:38:58.679: INFO: Pod "downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011513654s
    Apr 18 08:39:00.679: INFO: Pod "downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011841749s
    STEP: Saw pod success 04/18/23 08:39:00.679
    Apr 18 08:39:00.679: INFO: Pod "downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9" satisfied condition "Succeeded or Failed"
    Apr 18 08:39:00.682: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9 container client-container: <nil>
    STEP: delete the pod 04/18/23 08:39:00.696
    Apr 18 08:39:00.706: INFO: Waiting for pod downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9 to disappear
    Apr 18 08:39:00.709: INFO: Pod downwardapi-volume-61a0cc86-589b-449f-a9d2-18e0be6995c9 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 08:39:00.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9563" for this suite. 04/18/23 08:39:00.713
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:39:00.719
Apr 18 08:39:00.719: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename replicaset 04/18/23 08:39:00.72
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:39:00.739
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:39:00.742
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 04/18/23 08:39:00.746
STEP: Verify that the required pods have come up 04/18/23 08:39:00.755
Apr 18 08:39:00.761: INFO: Pod name sample-pod: Found 0 pods out of 3
Apr 18 08:39:05.766: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 04/18/23 08:39:05.766
Apr 18 08:39:05.769: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 04/18/23 08:39:05.769
STEP: DeleteCollection of the ReplicaSets 04/18/23 08:39:05.771
STEP: After DeleteCollection verify that ReplicaSets have been deleted 04/18/23 08:39:05.777
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 18 08:39:05.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9934" for this suite. 04/18/23 08:39:05.784
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":49,"skipped":808,"failed":0}
------------------------------
• [SLOW TEST] [5.090 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:39:00.719
    Apr 18 08:39:00.719: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename replicaset 04/18/23 08:39:00.72
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:39:00.739
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:39:00.742
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 04/18/23 08:39:00.746
    STEP: Verify that the required pods have come up 04/18/23 08:39:00.755
    Apr 18 08:39:00.761: INFO: Pod name sample-pod: Found 0 pods out of 3
    Apr 18 08:39:05.766: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 04/18/23 08:39:05.766
    Apr 18 08:39:05.769: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 04/18/23 08:39:05.769
    STEP: DeleteCollection of the ReplicaSets 04/18/23 08:39:05.771
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 04/18/23 08:39:05.777
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 18 08:39:05.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9934" for this suite. 04/18/23 08:39:05.784
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:39:05.81
Apr 18 08:39:05.810: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename job 04/18/23 08:39:05.81
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:39:05.827
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:39:05.83
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 04/18/23 08:39:05.836
STEP: Patching the Job 04/18/23 08:39:05.858
STEP: Watching for Job to be patched 04/18/23 08:39:05.875
Apr 18 08:39:05.877: INFO: Event ADDED observed for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking:]
Apr 18 08:39:05.877: INFO: Event MODIFIED found for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 04/18/23 08:39:05.877
STEP: Watching for Job to be updated 04/18/23 08:39:05.903
Apr 18 08:39:05.905: INFO: Event MODIFIED found for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 08:39:05.905: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 04/18/23 08:39:05.905
Apr 18 08:39:05.908: INFO: Job: e2e-4ch45 as labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45]
STEP: Waiting for job to complete 04/18/23 08:39:05.908
STEP: Delete a job collection with a labelselector 04/18/23 08:39:15.912
STEP: Watching for Job to be deleted 04/18/23 08:39:15.917
Apr 18 08:39:15.919: INFO: Event MODIFIED observed for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 08:39:15.919: INFO: Event MODIFIED observed for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 08:39:15.919: INFO: Event MODIFIED observed for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 08:39:15.919: INFO: Event MODIFIED observed for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 08:39:15.919: INFO: Event MODIFIED observed for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 08:39:15.919: INFO: Event DELETED found for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 04/18/23 08:39:15.919
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 18 08:39:15.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2545" for this suite. 04/18/23 08:39:15.932
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":50,"skipped":811,"failed":0}
------------------------------
• [SLOW TEST] [10.129 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:39:05.81
    Apr 18 08:39:05.810: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename job 04/18/23 08:39:05.81
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:39:05.827
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:39:05.83
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 04/18/23 08:39:05.836
    STEP: Patching the Job 04/18/23 08:39:05.858
    STEP: Watching for Job to be patched 04/18/23 08:39:05.875
    Apr 18 08:39:05.877: INFO: Event ADDED observed for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking:]
    Apr 18 08:39:05.877: INFO: Event MODIFIED found for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 04/18/23 08:39:05.877
    STEP: Watching for Job to be updated 04/18/23 08:39:05.903
    Apr 18 08:39:05.905: INFO: Event MODIFIED found for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 08:39:05.905: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 04/18/23 08:39:05.905
    Apr 18 08:39:05.908: INFO: Job: e2e-4ch45 as labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45]
    STEP: Waiting for job to complete 04/18/23 08:39:05.908
    STEP: Delete a job collection with a labelselector 04/18/23 08:39:15.912
    STEP: Watching for Job to be deleted 04/18/23 08:39:15.917
    Apr 18 08:39:15.919: INFO: Event MODIFIED observed for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 08:39:15.919: INFO: Event MODIFIED observed for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 08:39:15.919: INFO: Event MODIFIED observed for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 08:39:15.919: INFO: Event MODIFIED observed for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 08:39:15.919: INFO: Event MODIFIED observed for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 08:39:15.919: INFO: Event DELETED found for Job e2e-4ch45 in namespace job-2545 with labels: map[e2e-4ch45:patched e2e-job-label:e2e-4ch45] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 04/18/23 08:39:15.919
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 18 08:39:15.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-2545" for this suite. 04/18/23 08:39:15.932
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:39:15.941
Apr 18 08:39:15.941: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename statefulset 04/18/23 08:39:15.942
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:39:15.958
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:39:15.962
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-216 04/18/23 08:39:15.965
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 04/18/23 08:39:15.97
Apr 18 08:39:15.977: INFO: Found 0 stateful pods, waiting for 3
Apr 18 08:39:25.981: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 08:39:25.981: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 08:39:25.981: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 08:39:25.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-216 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 08:39:26.116: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 08:39:26.116: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 08:39:26.116: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/18/23 08:39:36.129
Apr 18 08:39:36.150: INFO: Updating stateful set ss2
STEP: Creating a new revision 04/18/23 08:39:36.15
STEP: Updating Pods in reverse ordinal order 04/18/23 08:39:46.167
Apr 18 08:39:46.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-216 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 08:39:46.286: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 18 08:39:46.286: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 08:39:46.286: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 18 08:40:06.304: INFO: Waiting for StatefulSet statefulset-216/ss2 to complete update
STEP: Rolling back to a previous revision 04/18/23 08:40:16.311
Apr 18 08:40:16.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-216 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 08:40:16.422: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 08:40:16.422: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 08:40:16.422: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 08:40:26.452: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 04/18/23 08:40:36.465
Apr 18 08:40:36.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-216 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 08:40:36.566: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 18 08:40:36.566: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 08:40:36.566: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 08:40:46.584: INFO: Deleting all statefulset in ns statefulset-216
Apr 18 08:40:46.586: INFO: Scaling statefulset ss2 to 0
Apr 18 08:40:56.601: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 08:40:56.604: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 08:40:56.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-216" for this suite. 04/18/23 08:40:56.62
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":51,"skipped":843,"failed":0}
------------------------------
• [SLOW TEST] [100.684 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:39:15.941
    Apr 18 08:39:15.941: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename statefulset 04/18/23 08:39:15.942
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:39:15.958
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:39:15.962
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-216 04/18/23 08:39:15.965
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 04/18/23 08:39:15.97
    Apr 18 08:39:15.977: INFO: Found 0 stateful pods, waiting for 3
    Apr 18 08:39:25.981: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 08:39:25.981: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 08:39:25.981: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 08:39:25.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-216 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 08:39:26.116: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 08:39:26.116: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 08:39:26.116: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/18/23 08:39:36.129
    Apr 18 08:39:36.150: INFO: Updating stateful set ss2
    STEP: Creating a new revision 04/18/23 08:39:36.15
    STEP: Updating Pods in reverse ordinal order 04/18/23 08:39:46.167
    Apr 18 08:39:46.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-216 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 08:39:46.286: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 18 08:39:46.286: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 08:39:46.286: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 18 08:40:06.304: INFO: Waiting for StatefulSet statefulset-216/ss2 to complete update
    STEP: Rolling back to a previous revision 04/18/23 08:40:16.311
    Apr 18 08:40:16.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-216 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 08:40:16.422: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 08:40:16.422: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 08:40:16.422: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 08:40:26.452: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 04/18/23 08:40:36.465
    Apr 18 08:40:36.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-216 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 08:40:36.566: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 18 08:40:36.566: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 08:40:36.566: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 08:40:46.584: INFO: Deleting all statefulset in ns statefulset-216
    Apr 18 08:40:46.586: INFO: Scaling statefulset ss2 to 0
    Apr 18 08:40:56.601: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 08:40:56.604: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 08:40:56.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-216" for this suite. 04/18/23 08:40:56.62
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:40:56.625
Apr 18 08:40:56.625: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename pods 04/18/23 08:40:56.626
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:40:56.636
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:40:56.64
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 04/18/23 08:40:56.644
Apr 18 08:40:56.652: INFO: created test-pod-1
Apr 18 08:40:56.661: INFO: created test-pod-2
Apr 18 08:40:56.670: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 04/18/23 08:40:56.67
Apr 18 08:40:56.671: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-775' to be running and ready
Apr 18 08:40:56.686: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 18 08:40:56.687: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 18 08:40:56.687: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 18 08:40:56.687: INFO: 0 / 3 pods in namespace 'pods-775' are running and ready (0 seconds elapsed)
Apr 18 08:40:56.687: INFO: expected 0 pod replicas in namespace 'pods-775', 0 are Running and Ready.
Apr 18 08:40:56.687: INFO: POD         NODE           PHASE    GRACE  CONDITIONS
Apr 18 08:40:56.687: INFO: test-pod-1  192.168.1.152  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:40:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:40:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:40:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:40:56 +0000 UTC  }]
Apr 18 08:40:56.687: INFO: test-pod-2  192.168.1.152  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:40:56 +0000 UTC  }]
Apr 18 08:40:56.687: INFO: test-pod-3  192.168.1.152  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:40:56 +0000 UTC  }]
Apr 18 08:40:56.687: INFO: 
Apr 18 08:40:58.696: INFO: 3 / 3 pods in namespace 'pods-775' are running and ready (2 seconds elapsed)
Apr 18 08:40:58.696: INFO: expected 0 pod replicas in namespace 'pods-775', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 04/18/23 08:40:58.712
Apr 18 08:40:58.714: INFO: Pod quantity 3 is different from expected quantity 0
Apr 18 08:40:59.718: INFO: Pod quantity 3 is different from expected quantity 0
Apr 18 08:41:00.718: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 08:41:01.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-775" for this suite. 04/18/23 08:41:01.721
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":52,"skipped":843,"failed":0}
------------------------------
• [SLOW TEST] [5.101 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:40:56.625
    Apr 18 08:40:56.625: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename pods 04/18/23 08:40:56.626
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:40:56.636
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:40:56.64
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 04/18/23 08:40:56.644
    Apr 18 08:40:56.652: INFO: created test-pod-1
    Apr 18 08:40:56.661: INFO: created test-pod-2
    Apr 18 08:40:56.670: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 04/18/23 08:40:56.67
    Apr 18 08:40:56.671: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-775' to be running and ready
    Apr 18 08:40:56.686: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 18 08:40:56.687: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 18 08:40:56.687: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 18 08:40:56.687: INFO: 0 / 3 pods in namespace 'pods-775' are running and ready (0 seconds elapsed)
    Apr 18 08:40:56.687: INFO: expected 0 pod replicas in namespace 'pods-775', 0 are Running and Ready.
    Apr 18 08:40:56.687: INFO: POD         NODE           PHASE    GRACE  CONDITIONS
    Apr 18 08:40:56.687: INFO: test-pod-1  192.168.1.152  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:40:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:40:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:40:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:40:56 +0000 UTC  }]
    Apr 18 08:40:56.687: INFO: test-pod-2  192.168.1.152  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:40:56 +0000 UTC  }]
    Apr 18 08:40:56.687: INFO: test-pod-3  192.168.1.152  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:40:56 +0000 UTC  }]
    Apr 18 08:40:56.687: INFO: 
    Apr 18 08:40:58.696: INFO: 3 / 3 pods in namespace 'pods-775' are running and ready (2 seconds elapsed)
    Apr 18 08:40:58.696: INFO: expected 0 pod replicas in namespace 'pods-775', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 04/18/23 08:40:58.712
    Apr 18 08:40:58.714: INFO: Pod quantity 3 is different from expected quantity 0
    Apr 18 08:40:59.718: INFO: Pod quantity 3 is different from expected quantity 0
    Apr 18 08:41:00.718: INFO: Pod quantity 3 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 08:41:01.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-775" for this suite. 04/18/23 08:41:01.721
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:41:01.727
Apr 18 08:41:01.727: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename statefulset 04/18/23 08:41:01.728
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:01.737
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:01.742
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1777 04/18/23 08:41:01.745
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-1777 04/18/23 08:41:01.753
Apr 18 08:41:01.760: INFO: Found 0 stateful pods, waiting for 1
Apr 18 08:41:11.764: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 04/18/23 08:41:11.769
STEP: updating a scale subresource 04/18/23 08:41:11.782
STEP: verifying the statefulset Spec.Replicas was modified 04/18/23 08:41:11.788
STEP: Patch a scale subresource 04/18/23 08:41:11.79
STEP: verifying the statefulset Spec.Replicas was modified 04/18/23 08:41:11.797
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 08:41:11.802: INFO: Deleting all statefulset in ns statefulset-1777
Apr 18 08:41:11.809: INFO: Scaling statefulset ss to 0
Apr 18 08:41:21.913: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 08:41:21.917: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 08:41:21.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1777" for this suite. 04/18/23 08:41:21.93
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":53,"skipped":858,"failed":0}
------------------------------
• [SLOW TEST] [20.208 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:41:01.727
    Apr 18 08:41:01.727: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename statefulset 04/18/23 08:41:01.728
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:01.737
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:01.742
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1777 04/18/23 08:41:01.745
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-1777 04/18/23 08:41:01.753
    Apr 18 08:41:01.760: INFO: Found 0 stateful pods, waiting for 1
    Apr 18 08:41:11.764: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 04/18/23 08:41:11.769
    STEP: updating a scale subresource 04/18/23 08:41:11.782
    STEP: verifying the statefulset Spec.Replicas was modified 04/18/23 08:41:11.788
    STEP: Patch a scale subresource 04/18/23 08:41:11.79
    STEP: verifying the statefulset Spec.Replicas was modified 04/18/23 08:41:11.797
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 08:41:11.802: INFO: Deleting all statefulset in ns statefulset-1777
    Apr 18 08:41:11.809: INFO: Scaling statefulset ss to 0
    Apr 18 08:41:21.913: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 08:41:21.917: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 08:41:21.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1777" for this suite. 04/18/23 08:41:21.93
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:41:21.936
Apr 18 08:41:21.936: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename gc 04/18/23 08:41:21.936
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:21.951
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:21.955
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Apr 18 08:41:21.983: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"570e8dcf-222e-4754-82f6-28d75fcfea61", Controller:(*bool)(0xc005cdc71a), BlockOwnerDeletion:(*bool)(0xc005cdc71b)}}
Apr 18 08:41:21.991: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"6f5dd272-4f40-42cd-84c3-3ab38d1737b4", Controller:(*bool)(0xc005cdc98a), BlockOwnerDeletion:(*bool)(0xc005cdc98b)}}
Apr 18 08:41:21.995: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"d656410f-936d-4e97-a734-bf414783956d", Controller:(*bool)(0xc005cdcbea), BlockOwnerDeletion:(*bool)(0xc005cdcbeb)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 18 08:41:27.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9363" for this suite. 04/18/23 08:41:27.011
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":54,"skipped":868,"failed":0}
------------------------------
• [SLOW TEST] [5.080 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:41:21.936
    Apr 18 08:41:21.936: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename gc 04/18/23 08:41:21.936
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:21.951
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:21.955
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Apr 18 08:41:21.983: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"570e8dcf-222e-4754-82f6-28d75fcfea61", Controller:(*bool)(0xc005cdc71a), BlockOwnerDeletion:(*bool)(0xc005cdc71b)}}
    Apr 18 08:41:21.991: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"6f5dd272-4f40-42cd-84c3-3ab38d1737b4", Controller:(*bool)(0xc005cdc98a), BlockOwnerDeletion:(*bool)(0xc005cdc98b)}}
    Apr 18 08:41:21.995: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"d656410f-936d-4e97-a734-bf414783956d", Controller:(*bool)(0xc005cdcbea), BlockOwnerDeletion:(*bool)(0xc005cdcbeb)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 18 08:41:27.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-9363" for this suite. 04/18/23 08:41:27.011
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:41:27.018
Apr 18 08:41:27.018: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename deployment 04/18/23 08:41:27.019
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:27.029
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:27.033
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Apr 18 08:41:27.036: INFO: Creating simple deployment test-new-deployment
Apr 18 08:41:27.053: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource 04/18/23 08:41:29.064
STEP: updating a scale subresource 04/18/23 08:41:29.067
STEP: verifying the deployment Spec.Replicas was modified 04/18/23 08:41:29.071
STEP: Patch a scale subresource 04/18/23 08:41:29.073
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 08:41:29.085: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-5214  b1751d98-2ab8-4226-86cf-df9f256cf05f 4176609 3 2023-04-18 08:41:27 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-04-18 08:41:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:41:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000953f38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-18 08:41:28 +0000 UTC,LastTransitionTime:2023-04-18 08:41:28 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-04-18 08:41:28 +0000 UTC,LastTransitionTime:2023-04-18 08:41:27 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 18 08:41:29.090: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-5214  c198fdc3-c18e-4567-b91b-2743e5e6634c 4176612 2 2023-04-18 08:41:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment b1751d98-2ab8-4226-86cf-df9f256cf05f 0xc005e107a7 0xc005e107a8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:41:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b1751d98-2ab8-4226-86cf-df9f256cf05f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:41:29 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005e10838 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 18 08:41:29.096: INFO: Pod "test-new-deployment-845c8977d9-8fm4p" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-8fm4p test-new-deployment-845c8977d9- deployment-5214  836bd5f4-456e-4b66-b6b1-d84ab542ccd0 4176597 0 2023-04-18 08:41:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 c198fdc3-c18e-4567-b91b-2743e5e6634c 0xc0064163e7 0xc0064163e8}] [] [{kube-controller-manager Update v1 2023-04-18 08:41:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c198fdc3-c18e-4567-b91b-2743e5e6634c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:41:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.82\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tckdc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tckdc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:41:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:41:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:41:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:41:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.82,StartTime:2023-04-18 08:41:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:41:27 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://98a616c5e59ac6f36d57e859e3f7933c383c34e057915403219460e6e2db28cb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.82,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 08:41:29.096: INFO: Pod "test-new-deployment-845c8977d9-rbl2x" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-rbl2x test-new-deployment-845c8977d9- deployment-5214  c6ea61b5-9fcc-4e45-a5a4-1183a49dc7cb 4176611 0 2023-04-18 08:41:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 c198fdc3-c18e-4567-b91b-2743e5e6634c 0xc0064165d7 0xc0064165d8}] [] [{kube-controller-manager Update v1 2023-04-18 08:41:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c198fdc3-c18e-4567-b91b-2743e5e6634c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h9r7z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h9r7z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:41:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 08:41:29.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5214" for this suite. 04/18/23 08:41:29.11
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":55,"skipped":897,"failed":0}
------------------------------
• [2.100 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:41:27.018
    Apr 18 08:41:27.018: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename deployment 04/18/23 08:41:27.019
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:27.029
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:27.033
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Apr 18 08:41:27.036: INFO: Creating simple deployment test-new-deployment
    Apr 18 08:41:27.053: INFO: deployment "test-new-deployment" doesn't have the required revision set
    STEP: getting scale subresource 04/18/23 08:41:29.064
    STEP: updating a scale subresource 04/18/23 08:41:29.067
    STEP: verifying the deployment Spec.Replicas was modified 04/18/23 08:41:29.071
    STEP: Patch a scale subresource 04/18/23 08:41:29.073
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 08:41:29.085: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-5214  b1751d98-2ab8-4226-86cf-df9f256cf05f 4176609 3 2023-04-18 08:41:27 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-04-18 08:41:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:41:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000953f38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-18 08:41:28 +0000 UTC,LastTransitionTime:2023-04-18 08:41:28 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-04-18 08:41:28 +0000 UTC,LastTransitionTime:2023-04-18 08:41:27 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 18 08:41:29.090: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-5214  c198fdc3-c18e-4567-b91b-2743e5e6634c 4176612 2 2023-04-18 08:41:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment b1751d98-2ab8-4226-86cf-df9f256cf05f 0xc005e107a7 0xc005e107a8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:41:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b1751d98-2ab8-4226-86cf-df9f256cf05f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:41:29 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005e10838 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 08:41:29.096: INFO: Pod "test-new-deployment-845c8977d9-8fm4p" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-8fm4p test-new-deployment-845c8977d9- deployment-5214  836bd5f4-456e-4b66-b6b1-d84ab542ccd0 4176597 0 2023-04-18 08:41:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 c198fdc3-c18e-4567-b91b-2743e5e6634c 0xc0064163e7 0xc0064163e8}] [] [{kube-controller-manager Update v1 2023-04-18 08:41:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c198fdc3-c18e-4567-b91b-2743e5e6634c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:41:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.82\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tckdc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tckdc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:41:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:41:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:41:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:41:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.82,StartTime:2023-04-18 08:41:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:41:27 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://98a616c5e59ac6f36d57e859e3f7933c383c34e057915403219460e6e2db28cb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.82,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 08:41:29.096: INFO: Pod "test-new-deployment-845c8977d9-rbl2x" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-rbl2x test-new-deployment-845c8977d9- deployment-5214  c6ea61b5-9fcc-4e45-a5a4-1183a49dc7cb 4176611 0 2023-04-18 08:41:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 c198fdc3-c18e-4567-b91b-2743e5e6634c 0xc0064165d7 0xc0064165d8}] [] [{kube-controller-manager Update v1 2023-04-18 08:41:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c198fdc3-c18e-4567-b91b-2743e5e6634c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h9r7z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h9r7z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:41:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 08:41:29.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-5214" for this suite. 04/18/23 08:41:29.11
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:41:29.118
Apr 18 08:41:29.118: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 08:41:29.119
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:29.129
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:29.132
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/18/23 08:41:29.139
Apr 18 08:41:29.150: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-1259" to be "running and ready"
Apr 18 08:41:29.153: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.362735ms
Apr 18 08:41:29.153: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:41:31.156: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.006245936s
Apr 18 08:41:31.156: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 18 08:41:31.156: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 04/18/23 08:41:31.159
Apr 18 08:41:31.164: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-1259" to be "running and ready"
Apr 18 08:41:31.167: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 3.163675ms
Apr 18 08:41:31.167: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:41:33.171: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.00715737s
Apr 18 08:41:33.171: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Apr 18 08:41:33.171: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 04/18/23 08:41:33.174
Apr 18 08:41:33.180: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 18 08:41:33.182: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 18 08:41:35.183: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 18 08:41:35.186: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 18 08:41:37.183: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 18 08:41:37.186: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 04/18/23 08:41:37.186
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 18 08:41:37.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1259" for this suite. 04/18/23 08:41:37.204
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":56,"skipped":897,"failed":0}
------------------------------
• [SLOW TEST] [8.090 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:41:29.118
    Apr 18 08:41:29.118: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 08:41:29.119
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:29.129
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:29.132
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/18/23 08:41:29.139
    Apr 18 08:41:29.150: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-1259" to be "running and ready"
    Apr 18 08:41:29.153: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.362735ms
    Apr 18 08:41:29.153: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:41:31.156: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.006245936s
    Apr 18 08:41:31.156: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 18 08:41:31.156: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 04/18/23 08:41:31.159
    Apr 18 08:41:31.164: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-1259" to be "running and ready"
    Apr 18 08:41:31.167: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 3.163675ms
    Apr 18 08:41:31.167: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:41:33.171: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.00715737s
    Apr 18 08:41:33.171: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Apr 18 08:41:33.171: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 04/18/23 08:41:33.174
    Apr 18 08:41:33.180: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 18 08:41:33.182: INFO: Pod pod-with-prestop-exec-hook still exists
    Apr 18 08:41:35.183: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 18 08:41:35.186: INFO: Pod pod-with-prestop-exec-hook still exists
    Apr 18 08:41:37.183: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 18 08:41:37.186: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 04/18/23 08:41:37.186
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 18 08:41:37.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-1259" for this suite. 04/18/23 08:41:37.204
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:41:37.21
Apr 18 08:41:37.210: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 08:41:37.211
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:37.223
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:37.227
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 04/18/23 08:41:37.231
Apr 18 08:41:37.231: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: mark a version not serverd 04/18/23 08:41:45.07
STEP: check the unserved version gets removed 04/18/23 08:41:45.087
STEP: check the other version is not changed 04/18/23 08:41:47.725
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 08:41:53.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1647" for this suite. 04/18/23 08:41:53.698
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":57,"skipped":901,"failed":0}
------------------------------
• [SLOW TEST] [16.492 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:41:37.21
    Apr 18 08:41:37.210: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 08:41:37.211
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:37.223
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:37.227
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 04/18/23 08:41:37.231
    Apr 18 08:41:37.231: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: mark a version not serverd 04/18/23 08:41:45.07
    STEP: check the unserved version gets removed 04/18/23 08:41:45.087
    STEP: check the other version is not changed 04/18/23 08:41:47.725
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 08:41:53.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1647" for this suite. 04/18/23 08:41:53.698
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:41:53.702
Apr 18 08:41:53.702: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 08:41:53.702
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:53.713
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:53.717
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 04/18/23 08:41:53.723
STEP: watching for the Service to be added 04/18/23 08:41:53.732
Apr 18 08:41:53.734: INFO: Found Service test-service-22blf in namespace services-5095 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Apr 18 08:41:53.734: INFO: Service test-service-22blf created
STEP: Getting /status 04/18/23 08:41:53.734
Apr 18 08:41:53.739: INFO: Service test-service-22blf has LoadBalancer: {[]}
STEP: patching the ServiceStatus 04/18/23 08:41:53.739
STEP: watching for the Service to be patched 04/18/23 08:41:53.795
Apr 18 08:41:53.799: INFO: observed Service test-service-22blf in namespace services-5095 with annotations: map[] & LoadBalancer: {[]}
Apr 18 08:41:53.799: INFO: Found Service test-service-22blf in namespace services-5095 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Apr 18 08:41:53.799: INFO: Service test-service-22blf has service status patched
STEP: updating the ServiceStatus 04/18/23 08:41:53.799
Apr 18 08:41:53.806: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 04/18/23 08:41:53.806
Apr 18 08:41:53.808: INFO: Observed Service test-service-22blf in namespace services-5095 with annotations: map[] & Conditions: {[]}
Apr 18 08:41:53.808: INFO: Observed event: &Service{ObjectMeta:{test-service-22blf  services-5095  35956367-2171-473d-950e-f6e5f785c961 4176788 0 2023-04-18 08:41:53 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-04-18 08:41:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-04-18 08:41:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.247.120.197,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.247.120.197],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Apr 18 08:41:53.808: INFO: Found Service test-service-22blf in namespace services-5095 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 18 08:41:53.808: INFO: Service test-service-22blf has service status updated
STEP: patching the service 04/18/23 08:41:53.809
STEP: watching for the Service to be patched 04/18/23 08:41:53.819
Apr 18 08:41:53.821: INFO: observed Service test-service-22blf in namespace services-5095 with labels: map[test-service-static:true]
Apr 18 08:41:53.821: INFO: observed Service test-service-22blf in namespace services-5095 with labels: map[test-service-static:true]
Apr 18 08:41:53.821: INFO: observed Service test-service-22blf in namespace services-5095 with labels: map[test-service-static:true]
Apr 18 08:41:53.821: INFO: Found Service test-service-22blf in namespace services-5095 with labels: map[test-service:patched test-service-static:true]
Apr 18 08:41:53.821: INFO: Service test-service-22blf patched
STEP: deleting the service 04/18/23 08:41:53.821
STEP: watching for the Service to be deleted 04/18/23 08:41:53.833
Apr 18 08:41:53.834: INFO: Observed event: ADDED
Apr 18 08:41:53.835: INFO: Observed event: MODIFIED
Apr 18 08:41:53.835: INFO: Observed event: MODIFIED
Apr 18 08:41:53.835: INFO: Observed event: MODIFIED
Apr 18 08:41:53.835: INFO: Found Service test-service-22blf in namespace services-5095 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Apr 18 08:41:53.835: INFO: Service test-service-22blf deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 08:41:53.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5095" for this suite. 04/18/23 08:41:53.839
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":58,"skipped":901,"failed":0}
------------------------------
• [0.148 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:41:53.702
    Apr 18 08:41:53.702: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 08:41:53.702
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:53.713
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:53.717
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 04/18/23 08:41:53.723
    STEP: watching for the Service to be added 04/18/23 08:41:53.732
    Apr 18 08:41:53.734: INFO: Found Service test-service-22blf in namespace services-5095 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Apr 18 08:41:53.734: INFO: Service test-service-22blf created
    STEP: Getting /status 04/18/23 08:41:53.734
    Apr 18 08:41:53.739: INFO: Service test-service-22blf has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 04/18/23 08:41:53.739
    STEP: watching for the Service to be patched 04/18/23 08:41:53.795
    Apr 18 08:41:53.799: INFO: observed Service test-service-22blf in namespace services-5095 with annotations: map[] & LoadBalancer: {[]}
    Apr 18 08:41:53.799: INFO: Found Service test-service-22blf in namespace services-5095 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Apr 18 08:41:53.799: INFO: Service test-service-22blf has service status patched
    STEP: updating the ServiceStatus 04/18/23 08:41:53.799
    Apr 18 08:41:53.806: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 04/18/23 08:41:53.806
    Apr 18 08:41:53.808: INFO: Observed Service test-service-22blf in namespace services-5095 with annotations: map[] & Conditions: {[]}
    Apr 18 08:41:53.808: INFO: Observed event: &Service{ObjectMeta:{test-service-22blf  services-5095  35956367-2171-473d-950e-f6e5f785c961 4176788 0 2023-04-18 08:41:53 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-04-18 08:41:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-04-18 08:41:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.247.120.197,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.247.120.197],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Apr 18 08:41:53.808: INFO: Found Service test-service-22blf in namespace services-5095 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 18 08:41:53.808: INFO: Service test-service-22blf has service status updated
    STEP: patching the service 04/18/23 08:41:53.809
    STEP: watching for the Service to be patched 04/18/23 08:41:53.819
    Apr 18 08:41:53.821: INFO: observed Service test-service-22blf in namespace services-5095 with labels: map[test-service-static:true]
    Apr 18 08:41:53.821: INFO: observed Service test-service-22blf in namespace services-5095 with labels: map[test-service-static:true]
    Apr 18 08:41:53.821: INFO: observed Service test-service-22blf in namespace services-5095 with labels: map[test-service-static:true]
    Apr 18 08:41:53.821: INFO: Found Service test-service-22blf in namespace services-5095 with labels: map[test-service:patched test-service-static:true]
    Apr 18 08:41:53.821: INFO: Service test-service-22blf patched
    STEP: deleting the service 04/18/23 08:41:53.821
    STEP: watching for the Service to be deleted 04/18/23 08:41:53.833
    Apr 18 08:41:53.834: INFO: Observed event: ADDED
    Apr 18 08:41:53.835: INFO: Observed event: MODIFIED
    Apr 18 08:41:53.835: INFO: Observed event: MODIFIED
    Apr 18 08:41:53.835: INFO: Observed event: MODIFIED
    Apr 18 08:41:53.835: INFO: Found Service test-service-22blf in namespace services-5095 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Apr 18 08:41:53.835: INFO: Service test-service-22blf deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 08:41:53.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5095" for this suite. 04/18/23 08:41:53.839
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:41:53.854
Apr 18 08:41:53.854: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 08:41:53.856
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:53.869
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:53.872
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-0de649a9-897a-4107-ace5-015975004113 04/18/23 08:41:53.876
STEP: Creating a pod to test consume configMaps 04/18/23 08:41:53.879
Apr 18 08:41:53.886: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d" in namespace "projected-1917" to be "Succeeded or Failed"
Apr 18 08:41:53.889: INFO: Pod "pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.409921ms
Apr 18 08:41:55.893: INFO: Pod "pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d": Phase="Running", Reason="", readiness=false. Elapsed: 2.006462871s
Apr 18 08:41:57.892: INFO: Pod "pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005956541s
STEP: Saw pod success 04/18/23 08:41:57.892
Apr 18 08:41:57.892: INFO: Pod "pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d" satisfied condition "Succeeded or Failed"
Apr 18 08:41:57.895: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d container projected-configmap-volume-test: <nil>
STEP: delete the pod 04/18/23 08:41:57.906
Apr 18 08:41:57.917: INFO: Waiting for pod pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d to disappear
Apr 18 08:41:57.920: INFO: Pod pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 08:41:57.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1917" for this suite. 04/18/23 08:41:57.924
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":59,"skipped":906,"failed":0}
------------------------------
• [4.074 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:41:53.854
    Apr 18 08:41:53.854: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 08:41:53.856
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:53.869
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:53.872
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-0de649a9-897a-4107-ace5-015975004113 04/18/23 08:41:53.876
    STEP: Creating a pod to test consume configMaps 04/18/23 08:41:53.879
    Apr 18 08:41:53.886: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d" in namespace "projected-1917" to be "Succeeded or Failed"
    Apr 18 08:41:53.889: INFO: Pod "pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.409921ms
    Apr 18 08:41:55.893: INFO: Pod "pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d": Phase="Running", Reason="", readiness=false. Elapsed: 2.006462871s
    Apr 18 08:41:57.892: INFO: Pod "pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005956541s
    STEP: Saw pod success 04/18/23 08:41:57.892
    Apr 18 08:41:57.892: INFO: Pod "pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d" satisfied condition "Succeeded or Failed"
    Apr 18 08:41:57.895: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d container projected-configmap-volume-test: <nil>
    STEP: delete the pod 04/18/23 08:41:57.906
    Apr 18 08:41:57.917: INFO: Waiting for pod pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d to disappear
    Apr 18 08:41:57.920: INFO: Pod pod-projected-configmaps-c61ff53b-e568-4945-a333-851eb525c06d no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 08:41:57.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1917" for this suite. 04/18/23 08:41:57.924
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:41:57.929
Apr 18 08:41:57.929: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir 04/18/23 08:41:57.929
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:57.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:57.941
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 04/18/23 08:41:57.945
Apr 18 08:41:57.952: INFO: Waiting up to 5m0s for pod "pod-9070ca20-aa79-4e93-bd12-21bf209dea9e" in namespace "emptydir-1406" to be "Succeeded or Failed"
Apr 18 08:41:57.957: INFO: Pod "pod-9070ca20-aa79-4e93-bd12-21bf209dea9e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.751123ms
Apr 18 08:41:59.960: INFO: Pod "pod-9070ca20-aa79-4e93-bd12-21bf209dea9e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008044459s
Apr 18 08:42:01.960: INFO: Pod "pod-9070ca20-aa79-4e93-bd12-21bf209dea9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008181349s
STEP: Saw pod success 04/18/23 08:42:01.96
Apr 18 08:42:01.960: INFO: Pod "pod-9070ca20-aa79-4e93-bd12-21bf209dea9e" satisfied condition "Succeeded or Failed"
Apr 18 08:42:01.963: INFO: Trying to get logs from node 192.168.1.152 pod pod-9070ca20-aa79-4e93-bd12-21bf209dea9e container test-container: <nil>
STEP: delete the pod 04/18/23 08:42:01.968
Apr 18 08:42:01.978: INFO: Waiting for pod pod-9070ca20-aa79-4e93-bd12-21bf209dea9e to disappear
Apr 18 08:42:01.980: INFO: Pod pod-9070ca20-aa79-4e93-bd12-21bf209dea9e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 08:42:01.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1406" for this suite. 04/18/23 08:42:01.984
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":60,"skipped":925,"failed":0}
------------------------------
• [4.059 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:41:57.929
    Apr 18 08:41:57.929: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir 04/18/23 08:41:57.929
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:41:57.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:41:57.941
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 04/18/23 08:41:57.945
    Apr 18 08:41:57.952: INFO: Waiting up to 5m0s for pod "pod-9070ca20-aa79-4e93-bd12-21bf209dea9e" in namespace "emptydir-1406" to be "Succeeded or Failed"
    Apr 18 08:41:57.957: INFO: Pod "pod-9070ca20-aa79-4e93-bd12-21bf209dea9e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.751123ms
    Apr 18 08:41:59.960: INFO: Pod "pod-9070ca20-aa79-4e93-bd12-21bf209dea9e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008044459s
    Apr 18 08:42:01.960: INFO: Pod "pod-9070ca20-aa79-4e93-bd12-21bf209dea9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008181349s
    STEP: Saw pod success 04/18/23 08:42:01.96
    Apr 18 08:42:01.960: INFO: Pod "pod-9070ca20-aa79-4e93-bd12-21bf209dea9e" satisfied condition "Succeeded or Failed"
    Apr 18 08:42:01.963: INFO: Trying to get logs from node 192.168.1.152 pod pod-9070ca20-aa79-4e93-bd12-21bf209dea9e container test-container: <nil>
    STEP: delete the pod 04/18/23 08:42:01.968
    Apr 18 08:42:01.978: INFO: Waiting for pod pod-9070ca20-aa79-4e93-bd12-21bf209dea9e to disappear
    Apr 18 08:42:01.980: INFO: Pod pod-9070ca20-aa79-4e93-bd12-21bf209dea9e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 08:42:01.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1406" for this suite. 04/18/23 08:42:01.984
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:42:01.989
Apr 18 08:42:01.990: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 08:42:01.991
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:42:02.001
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:42:02.004
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 08:42:02.017
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:42:02.479
STEP: Deploying the webhook pod 04/18/23 08:42:02.485
STEP: Wait for the deployment to be ready 04/18/23 08:42:02.495
Apr 18 08:42:02.500: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 08:42:04.509
STEP: Verifying the service has paired with the endpoint 04/18/23 08:42:04.519
Apr 18 08:42:05.519: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 04/18/23 08:42:05.523
STEP: create a configmap that should be updated by the webhook 04/18/23 08:42:05.537
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 08:42:05.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1784" for this suite. 04/18/23 08:42:05.561
STEP: Destroying namespace "webhook-1784-markers" for this suite. 04/18/23 08:42:05.567
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":61,"skipped":925,"failed":0}
------------------------------
• [3.615 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:42:01.989
    Apr 18 08:42:01.990: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 08:42:01.991
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:42:02.001
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:42:02.004
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 08:42:02.017
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:42:02.479
    STEP: Deploying the webhook pod 04/18/23 08:42:02.485
    STEP: Wait for the deployment to be ready 04/18/23 08:42:02.495
    Apr 18 08:42:02.500: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 08:42:04.509
    STEP: Verifying the service has paired with the endpoint 04/18/23 08:42:04.519
    Apr 18 08:42:05.519: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 04/18/23 08:42:05.523
    STEP: create a configmap that should be updated by the webhook 04/18/23 08:42:05.537
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 08:42:05.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1784" for this suite. 04/18/23 08:42:05.561
    STEP: Destroying namespace "webhook-1784-markers" for this suite. 04/18/23 08:42:05.567
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:42:05.604
Apr 18 08:42:05.604: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename resourcequota 04/18/23 08:42:05.605
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:42:05.62
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:42:05.624
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 04/18/23 08:42:05.628
STEP: Getting a ResourceQuota 04/18/23 08:42:05.632
STEP: Listing all ResourceQuotas with LabelSelector 04/18/23 08:42:05.635
STEP: Patching the ResourceQuota 04/18/23 08:42:05.637
STEP: Deleting a Collection of ResourceQuotas 04/18/23 08:42:05.649
STEP: Verifying the deleted ResourceQuota 04/18/23 08:42:05.655
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 08:42:05.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8037" for this suite. 04/18/23 08:42:05.661
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":62,"skipped":925,"failed":0}
------------------------------
• [0.062 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:42:05.604
    Apr 18 08:42:05.604: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename resourcequota 04/18/23 08:42:05.605
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:42:05.62
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:42:05.624
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 04/18/23 08:42:05.628
    STEP: Getting a ResourceQuota 04/18/23 08:42:05.632
    STEP: Listing all ResourceQuotas with LabelSelector 04/18/23 08:42:05.635
    STEP: Patching the ResourceQuota 04/18/23 08:42:05.637
    STEP: Deleting a Collection of ResourceQuotas 04/18/23 08:42:05.649
    STEP: Verifying the deleted ResourceQuota 04/18/23 08:42:05.655
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 08:42:05.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8037" for this suite. 04/18/23 08:42:05.661
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:42:05.666
Apr 18 08:42:05.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename secrets 04/18/23 08:42:05.666
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:42:05.685
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:42:05.689
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 08:42:05.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2941" for this suite. 04/18/23 08:42:05.736
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":63,"skipped":925,"failed":0}
------------------------------
• [0.080 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:42:05.666
    Apr 18 08:42:05.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename secrets 04/18/23 08:42:05.666
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:42:05.685
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:42:05.689
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 08:42:05.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2941" for this suite. 04/18/23 08:42:05.736
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:42:05.751
Apr 18 08:42:05.751: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 08:42:05.752
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:42:05.762
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:42:05.765
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-6c32003e-fea7-41e6-8cad-428f01a171bd 04/18/23 08:42:05.769
STEP: Creating a pod to test consume configMaps 04/18/23 08:42:05.772
Apr 18 08:42:05.778: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297" in namespace "projected-8110" to be "Succeeded or Failed"
Apr 18 08:42:05.780: INFO: Pod "pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297": Phase="Pending", Reason="", readiness=false. Elapsed: 2.492799ms
Apr 18 08:42:07.784: INFO: Pod "pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006469003s
Apr 18 08:42:09.784: INFO: Pod "pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005836236s
STEP: Saw pod success 04/18/23 08:42:09.784
Apr 18 08:42:09.784: INFO: Pod "pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297" satisfied condition "Succeeded or Failed"
Apr 18 08:42:09.787: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 08:42:09.792
Apr 18 08:42:09.799: INFO: Waiting for pod pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297 to disappear
Apr 18 08:42:09.803: INFO: Pod pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 08:42:09.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8110" for this suite. 04/18/23 08:42:09.807
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":64,"skipped":953,"failed":0}
------------------------------
• [4.060 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:42:05.751
    Apr 18 08:42:05.751: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 08:42:05.752
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:42:05.762
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:42:05.765
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-6c32003e-fea7-41e6-8cad-428f01a171bd 04/18/23 08:42:05.769
    STEP: Creating a pod to test consume configMaps 04/18/23 08:42:05.772
    Apr 18 08:42:05.778: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297" in namespace "projected-8110" to be "Succeeded or Failed"
    Apr 18 08:42:05.780: INFO: Pod "pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297": Phase="Pending", Reason="", readiness=false. Elapsed: 2.492799ms
    Apr 18 08:42:07.784: INFO: Pod "pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006469003s
    Apr 18 08:42:09.784: INFO: Pod "pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005836236s
    STEP: Saw pod success 04/18/23 08:42:09.784
    Apr 18 08:42:09.784: INFO: Pod "pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297" satisfied condition "Succeeded or Failed"
    Apr 18 08:42:09.787: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 08:42:09.792
    Apr 18 08:42:09.799: INFO: Waiting for pod pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297 to disappear
    Apr 18 08:42:09.803: INFO: Pod pod-projected-configmaps-fd4b76c9-2987-4d36-ad53-04fa190ab297 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 08:42:09.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8110" for this suite. 04/18/23 08:42:09.807
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:42:09.811
Apr 18 08:42:09.812: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename sched-preemption 04/18/23 08:42:09.812
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:42:09.822
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:42:09.826
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 18 08:42:09.839: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 18 08:43:09.866: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 04/18/23 08:43:09.868
Apr 18 08:43:09.888: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr 18 08:43:09.892: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr 18 08:43:09.909: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr 18 08:43:09.914: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Apr 18 08:43:09.938: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Apr 18 08:43:09.943: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 04/18/23 08:43:09.943
Apr 18 08:43:09.943: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8601" to be "running"
Apr 18 08:43:09.948: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 5.241259ms
Apr 18 08:43:11.954: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01090638s
Apr 18 08:43:13.952: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008920009s
Apr 18 08:43:15.951: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008385928s
Apr 18 08:43:17.952: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009616275s
Apr 18 08:43:19.951: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.008664248s
Apr 18 08:43:19.952: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Apr 18 08:43:19.952: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8601" to be "running"
Apr 18 08:43:19.954: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.625935ms
Apr 18 08:43:19.954: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 08:43:19.954: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8601" to be "running"
Apr 18 08:43:19.957: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.882229ms
Apr 18 08:43:19.957: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 08:43:19.957: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8601" to be "running"
Apr 18 08:43:19.960: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.617666ms
Apr 18 08:43:19.960: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 08:43:19.960: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8601" to be "running"
Apr 18 08:43:19.962: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.649354ms
Apr 18 08:43:19.962: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 08:43:19.962: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8601" to be "running"
Apr 18 08:43:19.965: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.483895ms
Apr 18 08:43:19.965: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 04/18/23 08:43:19.965
Apr 18 08:43:19.974: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Apr 18 08:43:19.976: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.214504ms
Apr 18 08:43:21.980: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006132217s
Apr 18 08:43:23.980: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.006188007s
Apr 18 08:43:23.980: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 18 08:43:24.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8601" for this suite. 04/18/23 08:43:24.014
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":65,"skipped":962,"failed":0}
------------------------------
• [SLOW TEST] [74.266 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:42:09.811
    Apr 18 08:42:09.812: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename sched-preemption 04/18/23 08:42:09.812
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:42:09.822
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:42:09.826
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 18 08:42:09.839: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 18 08:43:09.866: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 04/18/23 08:43:09.868
    Apr 18 08:43:09.888: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Apr 18 08:43:09.892: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Apr 18 08:43:09.909: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Apr 18 08:43:09.914: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Apr 18 08:43:09.938: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Apr 18 08:43:09.943: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 04/18/23 08:43:09.943
    Apr 18 08:43:09.943: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8601" to be "running"
    Apr 18 08:43:09.948: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 5.241259ms
    Apr 18 08:43:11.954: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01090638s
    Apr 18 08:43:13.952: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008920009s
    Apr 18 08:43:15.951: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008385928s
    Apr 18 08:43:17.952: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009616275s
    Apr 18 08:43:19.951: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.008664248s
    Apr 18 08:43:19.952: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Apr 18 08:43:19.952: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8601" to be "running"
    Apr 18 08:43:19.954: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.625935ms
    Apr 18 08:43:19.954: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 08:43:19.954: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8601" to be "running"
    Apr 18 08:43:19.957: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.882229ms
    Apr 18 08:43:19.957: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 08:43:19.957: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8601" to be "running"
    Apr 18 08:43:19.960: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.617666ms
    Apr 18 08:43:19.960: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 08:43:19.960: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8601" to be "running"
    Apr 18 08:43:19.962: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.649354ms
    Apr 18 08:43:19.962: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 08:43:19.962: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8601" to be "running"
    Apr 18 08:43:19.965: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.483895ms
    Apr 18 08:43:19.965: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 04/18/23 08:43:19.965
    Apr 18 08:43:19.974: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Apr 18 08:43:19.976: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.214504ms
    Apr 18 08:43:21.980: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006132217s
    Apr 18 08:43:23.980: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.006188007s
    Apr 18 08:43:23.980: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 08:43:24.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8601" for this suite. 04/18/23 08:43:24.014
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:43:24.078
Apr 18 08:43:24.078: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 08:43:24.079
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:43:24.089
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:43:24.093
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 08:43:24.106
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:43:24.375
STEP: Deploying the webhook pod 04/18/23 08:43:24.381
STEP: Wait for the deployment to be ready 04/18/23 08:43:24.395
Apr 18 08:43:24.408: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 08:43:26.417
STEP: Verifying the service has paired with the endpoint 04/18/23 08:43:26.424
Apr 18 08:43:27.424: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Apr 18 08:43:27.428: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Registering the custom resource webhook via the AdmissionRegistration API 04/18/23 08:43:27.938
STEP: Creating a custom resource that should be denied by the webhook 04/18/23 08:43:27.96
STEP: Creating a custom resource whose deletion would be denied by the webhook 04/18/23 08:43:30.011
STEP: Updating the custom resource with disallowed data should be denied 04/18/23 08:43:30.019
STEP: Deleting the custom resource should be denied 04/18/23 08:43:30.027
STEP: Remove the offending key and value from the custom resource data 04/18/23 08:43:30.034
STEP: Deleting the updated custom resource should be successful 04/18/23 08:43:30.047
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 08:43:30.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6509" for this suite. 04/18/23 08:43:30.589
STEP: Destroying namespace "webhook-6509-markers" for this suite. 04/18/23 08:43:30.595
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":66,"skipped":962,"failed":0}
------------------------------
• [SLOW TEST] [6.564 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:43:24.078
    Apr 18 08:43:24.078: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 08:43:24.079
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:43:24.089
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:43:24.093
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 08:43:24.106
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:43:24.375
    STEP: Deploying the webhook pod 04/18/23 08:43:24.381
    STEP: Wait for the deployment to be ready 04/18/23 08:43:24.395
    Apr 18 08:43:24.408: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 08:43:26.417
    STEP: Verifying the service has paired with the endpoint 04/18/23 08:43:26.424
    Apr 18 08:43:27.424: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Apr 18 08:43:27.428: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 04/18/23 08:43:27.938
    STEP: Creating a custom resource that should be denied by the webhook 04/18/23 08:43:27.96
    STEP: Creating a custom resource whose deletion would be denied by the webhook 04/18/23 08:43:30.011
    STEP: Updating the custom resource with disallowed data should be denied 04/18/23 08:43:30.019
    STEP: Deleting the custom resource should be denied 04/18/23 08:43:30.027
    STEP: Remove the offending key and value from the custom resource data 04/18/23 08:43:30.034
    STEP: Deleting the updated custom resource should be successful 04/18/23 08:43:30.047
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 08:43:30.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6509" for this suite. 04/18/23 08:43:30.589
    STEP: Destroying namespace "webhook-6509-markers" for this suite. 04/18/23 08:43:30.595
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:43:30.643
Apr 18 08:43:30.643: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename pod-network-test 04/18/23 08:43:30.644
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:43:30.662
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:43:30.668
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-614 04/18/23 08:43:30.672
STEP: creating a selector 04/18/23 08:43:30.672
STEP: Creating the service pods in kubernetes 04/18/23 08:43:30.672
Apr 18 08:43:30.672: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 18 08:43:30.709: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-614" to be "running and ready"
Apr 18 08:43:30.718: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.111227ms
Apr 18 08:43:30.718: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:43:32.722: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.012383037s
Apr 18 08:43:32.722: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 08:43:34.721: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.011924997s
Apr 18 08:43:34.721: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 08:43:36.721: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.011281004s
Apr 18 08:43:36.721: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 08:43:38.721: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.011722487s
Apr 18 08:43:38.721: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 08:43:40.721: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.011568154s
Apr 18 08:43:40.721: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 08:43:42.721: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.011448653s
Apr 18 08:43:42.721: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 18 08:43:42.721: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 18 08:43:42.724: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-614" to be "running and ready"
Apr 18 08:43:42.726: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.517161ms
Apr 18 08:43:42.726: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 18 08:43:42.726: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 18 08:43:42.729: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-614" to be "running and ready"
Apr 18 08:43:42.731: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.436202ms
Apr 18 08:43:42.731: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 18 08:43:42.731: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/18/23 08:43:42.734
Apr 18 08:43:42.739: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-614" to be "running"
Apr 18 08:43:42.742: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.021446ms
Apr 18 08:43:44.746: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.006870398s
Apr 18 08:43:44.746: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 18 08:43:44.749: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 18 08:43:44.749: INFO: Breadth first check of 172.16.1.92 on host 192.168.1.152...
Apr 18 08:43:44.751: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.1.93:9080/dial?request=hostname&protocol=udp&host=172.16.1.92&port=8081&tries=1'] Namespace:pod-network-test-614 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:43:44.751: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:43:44.752: INFO: ExecWithOptions: Clientset creation
Apr 18 08:43:44.752: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-614/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.1.93%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.1.92%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 18 08:43:44.808: INFO: Waiting for responses: map[]
Apr 18 08:43:44.808: INFO: reached 172.16.1.92 after 0/1 tries
Apr 18 08:43:44.808: INFO: Breadth first check of 172.16.0.45 on host 192.168.1.29...
Apr 18 08:43:44.811: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.1.93:9080/dial?request=hostname&protocol=udp&host=172.16.0.45&port=8081&tries=1'] Namespace:pod-network-test-614 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:43:44.811: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:43:44.811: INFO: ExecWithOptions: Clientset creation
Apr 18 08:43:44.811: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-614/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.1.93%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.0.45%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 18 08:43:44.858: INFO: Waiting for responses: map[]
Apr 18 08:43:44.858: INFO: reached 172.16.0.45 after 0/1 tries
Apr 18 08:43:44.858: INFO: Breadth first check of 172.16.0.202 on host 192.168.1.84...
Apr 18 08:43:44.861: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.1.93:9080/dial?request=hostname&protocol=udp&host=172.16.0.202&port=8081&tries=1'] Namespace:pod-network-test-614 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:43:44.861: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:43:44.861: INFO: ExecWithOptions: Clientset creation
Apr 18 08:43:44.861: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-614/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.1.93%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.0.202%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 18 08:43:44.908: INFO: Waiting for responses: map[]
Apr 18 08:43:44.908: INFO: reached 172.16.0.202 after 0/1 tries
Apr 18 08:43:44.908: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 18 08:43:44.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-614" for this suite. 04/18/23 08:43:44.912
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":67,"skipped":996,"failed":0}
------------------------------
• [SLOW TEST] [14.274 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:43:30.643
    Apr 18 08:43:30.643: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename pod-network-test 04/18/23 08:43:30.644
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:43:30.662
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:43:30.668
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-614 04/18/23 08:43:30.672
    STEP: creating a selector 04/18/23 08:43:30.672
    STEP: Creating the service pods in kubernetes 04/18/23 08:43:30.672
    Apr 18 08:43:30.672: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 18 08:43:30.709: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-614" to be "running and ready"
    Apr 18 08:43:30.718: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.111227ms
    Apr 18 08:43:30.718: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:43:32.722: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.012383037s
    Apr 18 08:43:32.722: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 08:43:34.721: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.011924997s
    Apr 18 08:43:34.721: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 08:43:36.721: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.011281004s
    Apr 18 08:43:36.721: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 08:43:38.721: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.011722487s
    Apr 18 08:43:38.721: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 08:43:40.721: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.011568154s
    Apr 18 08:43:40.721: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 08:43:42.721: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.011448653s
    Apr 18 08:43:42.721: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 18 08:43:42.721: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 18 08:43:42.724: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-614" to be "running and ready"
    Apr 18 08:43:42.726: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.517161ms
    Apr 18 08:43:42.726: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 18 08:43:42.726: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 18 08:43:42.729: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-614" to be "running and ready"
    Apr 18 08:43:42.731: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.436202ms
    Apr 18 08:43:42.731: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 18 08:43:42.731: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/18/23 08:43:42.734
    Apr 18 08:43:42.739: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-614" to be "running"
    Apr 18 08:43:42.742: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.021446ms
    Apr 18 08:43:44.746: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.006870398s
    Apr 18 08:43:44.746: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 18 08:43:44.749: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 18 08:43:44.749: INFO: Breadth first check of 172.16.1.92 on host 192.168.1.152...
    Apr 18 08:43:44.751: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.1.93:9080/dial?request=hostname&protocol=udp&host=172.16.1.92&port=8081&tries=1'] Namespace:pod-network-test-614 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:43:44.751: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:43:44.752: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:43:44.752: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-614/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.1.93%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.1.92%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 18 08:43:44.808: INFO: Waiting for responses: map[]
    Apr 18 08:43:44.808: INFO: reached 172.16.1.92 after 0/1 tries
    Apr 18 08:43:44.808: INFO: Breadth first check of 172.16.0.45 on host 192.168.1.29...
    Apr 18 08:43:44.811: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.1.93:9080/dial?request=hostname&protocol=udp&host=172.16.0.45&port=8081&tries=1'] Namespace:pod-network-test-614 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:43:44.811: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:43:44.811: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:43:44.811: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-614/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.1.93%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.0.45%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 18 08:43:44.858: INFO: Waiting for responses: map[]
    Apr 18 08:43:44.858: INFO: reached 172.16.0.45 after 0/1 tries
    Apr 18 08:43:44.858: INFO: Breadth first check of 172.16.0.202 on host 192.168.1.84...
    Apr 18 08:43:44.861: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.1.93:9080/dial?request=hostname&protocol=udp&host=172.16.0.202&port=8081&tries=1'] Namespace:pod-network-test-614 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:43:44.861: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:43:44.861: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:43:44.861: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-614/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.1.93%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.0.202%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 18 08:43:44.908: INFO: Waiting for responses: map[]
    Apr 18 08:43:44.908: INFO: reached 172.16.0.202 after 0/1 tries
    Apr 18 08:43:44.908: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 18 08:43:44.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-614" for this suite. 04/18/23 08:43:44.912
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:43:44.919
Apr 18 08:43:44.919: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir 04/18/23 08:43:44.921
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:43:44.931
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:43:44.934
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 04/18/23 08:43:44.938
Apr 18 08:43:44.944: INFO: Waiting up to 5m0s for pod "pod-064c7341-f722-4d01-a024-03ba5365c21e" in namespace "emptydir-9199" to be "Succeeded or Failed"
Apr 18 08:43:44.946: INFO: Pod "pod-064c7341-f722-4d01-a024-03ba5365c21e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.244113ms
Apr 18 08:43:46.950: INFO: Pod "pod-064c7341-f722-4d01-a024-03ba5365c21e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006323197s
Apr 18 08:43:48.950: INFO: Pod "pod-064c7341-f722-4d01-a024-03ba5365c21e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00656181s
STEP: Saw pod success 04/18/23 08:43:48.95
Apr 18 08:43:48.950: INFO: Pod "pod-064c7341-f722-4d01-a024-03ba5365c21e" satisfied condition "Succeeded or Failed"
Apr 18 08:43:48.953: INFO: Trying to get logs from node 192.168.1.152 pod pod-064c7341-f722-4d01-a024-03ba5365c21e container test-container: <nil>
STEP: delete the pod 04/18/23 08:43:48.964
Apr 18 08:43:48.973: INFO: Waiting for pod pod-064c7341-f722-4d01-a024-03ba5365c21e to disappear
Apr 18 08:43:48.975: INFO: Pod pod-064c7341-f722-4d01-a024-03ba5365c21e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 08:43:48.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9199" for this suite. 04/18/23 08:43:48.979
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":68,"skipped":1048,"failed":0}
------------------------------
• [4.064 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:43:44.919
    Apr 18 08:43:44.919: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir 04/18/23 08:43:44.921
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:43:44.931
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:43:44.934
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 04/18/23 08:43:44.938
    Apr 18 08:43:44.944: INFO: Waiting up to 5m0s for pod "pod-064c7341-f722-4d01-a024-03ba5365c21e" in namespace "emptydir-9199" to be "Succeeded or Failed"
    Apr 18 08:43:44.946: INFO: Pod "pod-064c7341-f722-4d01-a024-03ba5365c21e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.244113ms
    Apr 18 08:43:46.950: INFO: Pod "pod-064c7341-f722-4d01-a024-03ba5365c21e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006323197s
    Apr 18 08:43:48.950: INFO: Pod "pod-064c7341-f722-4d01-a024-03ba5365c21e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00656181s
    STEP: Saw pod success 04/18/23 08:43:48.95
    Apr 18 08:43:48.950: INFO: Pod "pod-064c7341-f722-4d01-a024-03ba5365c21e" satisfied condition "Succeeded or Failed"
    Apr 18 08:43:48.953: INFO: Trying to get logs from node 192.168.1.152 pod pod-064c7341-f722-4d01-a024-03ba5365c21e container test-container: <nil>
    STEP: delete the pod 04/18/23 08:43:48.964
    Apr 18 08:43:48.973: INFO: Waiting for pod pod-064c7341-f722-4d01-a024-03ba5365c21e to disappear
    Apr 18 08:43:48.975: INFO: Pod pod-064c7341-f722-4d01-a024-03ba5365c21e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 08:43:48.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9199" for this suite. 04/18/23 08:43:48.979
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:43:48.983
Apr 18 08:43:48.983: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename conformance-tests 04/18/23 08:43:48.984
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:43:48.994
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:43:48.998
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 04/18/23 08:43:49.001
Apr 18 08:43:49.001: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Apr 18 08:43:49.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-1920" for this suite. 04/18/23 08:43:49.009
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":69,"skipped":1053,"failed":0}
------------------------------
• [0.030 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:43:48.983
    Apr 18 08:43:48.983: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename conformance-tests 04/18/23 08:43:48.984
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:43:48.994
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:43:48.998
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 04/18/23 08:43:49.001
    Apr 18 08:43:49.001: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Apr 18 08:43:49.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-1920" for this suite. 04/18/23 08:43:49.009
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:43:49.013
Apr 18 08:43:49.013: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename sysctl 04/18/23 08:43:49.014
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:43:49.022
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:43:49.026
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 04/18/23 08:43:49.029
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 18 08:43:49.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-8663" for this suite. 04/18/23 08:43:49.037
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":70,"skipped":1064,"failed":0}
------------------------------
• [0.028 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:43:49.013
    Apr 18 08:43:49.013: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename sysctl 04/18/23 08:43:49.014
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:43:49.022
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:43:49.026
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 04/18/23 08:43:49.029
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 18 08:43:49.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-8663" for this suite. 04/18/23 08:43:49.037
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:43:49.042
Apr 18 08:43:49.042: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename sched-preemption 04/18/23 08:43:49.043
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:43:49.055
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:43:49.059
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 18 08:43:49.072: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 18 08:44:49.098: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 04/18/23 08:44:49.1
Apr 18 08:44:49.114: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr 18 08:44:49.122: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr 18 08:44:49.135: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr 18 08:44:49.148: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Apr 18 08:44:49.232: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Apr 18 08:44:49.237: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 04/18/23 08:44:49.237
Apr 18 08:44:49.237: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-4050" to be "running"
Apr 18 08:44:49.283: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 46.546886ms
Apr 18 08:44:51.287: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.05019466s
Apr 18 08:44:51.287: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Apr 18 08:44:51.287: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-4050" to be "running"
Apr 18 08:44:51.291: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.83388ms
Apr 18 08:44:51.291: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 08:44:51.291: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-4050" to be "running"
Apr 18 08:44:51.293: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.474515ms
Apr 18 08:44:51.293: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 08:44:51.293: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-4050" to be "running"
Apr 18 08:44:51.296: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.595655ms
Apr 18 08:44:51.296: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 08:44:51.296: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-4050" to be "running"
Apr 18 08:44:51.299: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.523738ms
Apr 18 08:44:51.299: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 08:44:51.299: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-4050" to be "running"
Apr 18 08:44:51.301: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.523564ms
Apr 18 08:44:51.301: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 04/18/23 08:44:51.301
Apr 18 08:44:51.306: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-4050" to be "running"
Apr 18 08:44:51.308: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.300044ms
Apr 18 08:44:53.312: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006190163s
Apr 18 08:44:55.312: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005810004s
Apr 18 08:44:57.312: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.006652786s
Apr 18 08:44:57.313: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 18 08:44:57.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4050" for this suite. 04/18/23 08:44:57.333
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":71,"skipped":1078,"failed":0}
------------------------------
• [SLOW TEST] [68.338 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:43:49.042
    Apr 18 08:43:49.042: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename sched-preemption 04/18/23 08:43:49.043
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:43:49.055
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:43:49.059
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 18 08:43:49.072: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 18 08:44:49.098: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 04/18/23 08:44:49.1
    Apr 18 08:44:49.114: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Apr 18 08:44:49.122: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Apr 18 08:44:49.135: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Apr 18 08:44:49.148: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Apr 18 08:44:49.232: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Apr 18 08:44:49.237: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 04/18/23 08:44:49.237
    Apr 18 08:44:49.237: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-4050" to be "running"
    Apr 18 08:44:49.283: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 46.546886ms
    Apr 18 08:44:51.287: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.05019466s
    Apr 18 08:44:51.287: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Apr 18 08:44:51.287: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-4050" to be "running"
    Apr 18 08:44:51.291: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.83388ms
    Apr 18 08:44:51.291: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 08:44:51.291: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-4050" to be "running"
    Apr 18 08:44:51.293: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.474515ms
    Apr 18 08:44:51.293: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 08:44:51.293: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-4050" to be "running"
    Apr 18 08:44:51.296: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.595655ms
    Apr 18 08:44:51.296: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 08:44:51.296: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-4050" to be "running"
    Apr 18 08:44:51.299: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.523738ms
    Apr 18 08:44:51.299: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 08:44:51.299: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-4050" to be "running"
    Apr 18 08:44:51.301: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.523564ms
    Apr 18 08:44:51.301: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 04/18/23 08:44:51.301
    Apr 18 08:44:51.306: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-4050" to be "running"
    Apr 18 08:44:51.308: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.300044ms
    Apr 18 08:44:53.312: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006190163s
    Apr 18 08:44:55.312: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005810004s
    Apr 18 08:44:57.312: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.006652786s
    Apr 18 08:44:57.313: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 08:44:57.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-4050" for this suite. 04/18/23 08:44:57.333
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:44:57.38
Apr 18 08:44:57.380: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename replication-controller 04/18/23 08:44:57.381
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:44:57.392
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:44:57.395
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 04/18/23 08:44:57.401
STEP: waiting for RC to be added 04/18/23 08:44:57.406
STEP: waiting for available Replicas 04/18/23 08:44:57.407
STEP: patching ReplicationController 04/18/23 08:44:58.754
STEP: waiting for RC to be modified 04/18/23 08:44:58.769
STEP: patching ReplicationController status 04/18/23 08:44:58.769
STEP: waiting for RC to be modified 04/18/23 08:44:58.774
STEP: waiting for available Replicas 04/18/23 08:44:58.774
STEP: fetching ReplicationController status 04/18/23 08:44:58.777
STEP: patching ReplicationController scale 04/18/23 08:44:58.78
STEP: waiting for RC to be modified 04/18/23 08:44:58.786
STEP: waiting for ReplicationController's scale to be the max amount 04/18/23 08:44:58.786
STEP: fetching ReplicationController; ensuring that it's patched 04/18/23 08:45:00.179
STEP: updating ReplicationController status 04/18/23 08:45:00.181
STEP: waiting for RC to be modified 04/18/23 08:45:00.189
STEP: listing all ReplicationControllers 04/18/23 08:45:00.189
STEP: checking that ReplicationController has expected values 04/18/23 08:45:00.192
STEP: deleting ReplicationControllers by collection 04/18/23 08:45:00.192
STEP: waiting for ReplicationController to have a DELETED watchEvent 04/18/23 08:45:00.2
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 18 08:45:00.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5771" for this suite. 04/18/23 08:45:00.236
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":72,"skipped":1078,"failed":0}
------------------------------
• [2.860 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:44:57.38
    Apr 18 08:44:57.380: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename replication-controller 04/18/23 08:44:57.381
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:44:57.392
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:44:57.395
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 04/18/23 08:44:57.401
    STEP: waiting for RC to be added 04/18/23 08:44:57.406
    STEP: waiting for available Replicas 04/18/23 08:44:57.407
    STEP: patching ReplicationController 04/18/23 08:44:58.754
    STEP: waiting for RC to be modified 04/18/23 08:44:58.769
    STEP: patching ReplicationController status 04/18/23 08:44:58.769
    STEP: waiting for RC to be modified 04/18/23 08:44:58.774
    STEP: waiting for available Replicas 04/18/23 08:44:58.774
    STEP: fetching ReplicationController status 04/18/23 08:44:58.777
    STEP: patching ReplicationController scale 04/18/23 08:44:58.78
    STEP: waiting for RC to be modified 04/18/23 08:44:58.786
    STEP: waiting for ReplicationController's scale to be the max amount 04/18/23 08:44:58.786
    STEP: fetching ReplicationController; ensuring that it's patched 04/18/23 08:45:00.179
    STEP: updating ReplicationController status 04/18/23 08:45:00.181
    STEP: waiting for RC to be modified 04/18/23 08:45:00.189
    STEP: listing all ReplicationControllers 04/18/23 08:45:00.189
    STEP: checking that ReplicationController has expected values 04/18/23 08:45:00.192
    STEP: deleting ReplicationControllers by collection 04/18/23 08:45:00.192
    STEP: waiting for ReplicationController to have a DELETED watchEvent 04/18/23 08:45:00.2
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 18 08:45:00.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-5771" for this suite. 04/18/23 08:45:00.236
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:00.241
Apr 18 08:45:00.241: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename secrets 04/18/23 08:45:00.242
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:00.257
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:00.26
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 04/18/23 08:45:00.264
STEP: listing secrets in all namespaces to ensure that there are more than zero 04/18/23 08:45:00.268
STEP: patching the secret 04/18/23 08:45:00.273
STEP: deleting the secret using a LabelSelector 04/18/23 08:45:00.281
STEP: listing secrets in all namespaces, searching for label name and value in patch 04/18/23 08:45:00.286
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 18 08:45:00.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3629" for this suite. 04/18/23 08:45:00.293
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":73,"skipped":1086,"failed":0}
------------------------------
• [0.059 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:00.241
    Apr 18 08:45:00.241: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename secrets 04/18/23 08:45:00.242
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:00.257
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:00.26
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 04/18/23 08:45:00.264
    STEP: listing secrets in all namespaces to ensure that there are more than zero 04/18/23 08:45:00.268
    STEP: patching the secret 04/18/23 08:45:00.273
    STEP: deleting the secret using a LabelSelector 04/18/23 08:45:00.281
    STEP: listing secrets in all namespaces, searching for label name and value in patch 04/18/23 08:45:00.286
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 08:45:00.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3629" for this suite. 04/18/23 08:45:00.293
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:00.301
Apr 18 08:45:00.301: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 08:45:00.301
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:00.31
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:00.313
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 08:45:00.326
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:45:00.713
STEP: Deploying the webhook pod 04/18/23 08:45:00.719
STEP: Wait for the deployment to be ready 04/18/23 08:45:00.729
Apr 18 08:45:00.742: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 08:45:02.755
STEP: Verifying the service has paired with the endpoint 04/18/23 08:45:02.765
Apr 18 08:45:03.766: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 04/18/23 08:45:03.831
STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 08:45:03.909
STEP: Deleting the collection of validation webhooks 04/18/23 08:45:03.937
STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 08:45:03.964
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 08:45:03.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7005" for this suite. 04/18/23 08:45:03.976
STEP: Destroying namespace "webhook-7005-markers" for this suite. 04/18/23 08:45:03.982
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":74,"skipped":1111,"failed":0}
------------------------------
• [3.713 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:00.301
    Apr 18 08:45:00.301: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 08:45:00.301
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:00.31
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:00.313
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 08:45:00.326
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:45:00.713
    STEP: Deploying the webhook pod 04/18/23 08:45:00.719
    STEP: Wait for the deployment to be ready 04/18/23 08:45:00.729
    Apr 18 08:45:00.742: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 08:45:02.755
    STEP: Verifying the service has paired with the endpoint 04/18/23 08:45:02.765
    Apr 18 08:45:03.766: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 04/18/23 08:45:03.831
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 08:45:03.909
    STEP: Deleting the collection of validation webhooks 04/18/23 08:45:03.937
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 08:45:03.964
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 08:45:03.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7005" for this suite. 04/18/23 08:45:03.976
    STEP: Destroying namespace "webhook-7005-markers" for this suite. 04/18/23 08:45:03.982
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:04.024
Apr 18 08:45:04.024: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename dns 04/18/23 08:45:04.025
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:04.048
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:04.051
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 04/18/23 08:45:04.055
Apr 18 08:45:04.060: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-4855  0b9bf1a8-8116-4189-85d5-8be7a249f078 4178183 0 2023-04-18 08:45:04 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-04-18 08:45:04 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7zwk2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7zwk2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 08:45:04.061: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-4855" to be "running and ready"
Apr 18 08:45:04.063: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.308874ms
Apr 18 08:45:04.063: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:45:06.067: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.006359371s
Apr 18 08:45:06.067: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Apr 18 08:45:06.067: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 04/18/23 08:45:06.067
Apr 18 08:45:06.067: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-4855 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:45:06.067: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:45:06.068: INFO: ExecWithOptions: Clientset creation
Apr 18 08:45:06.068: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/dns-4855/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 04/18/23 08:45:06.124
Apr 18 08:45:06.124: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-4855 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:45:06.124: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:45:06.125: INFO: ExecWithOptions: Clientset creation
Apr 18 08:45:06.125: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/dns-4855/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 18 08:45:06.187: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 08:45:06.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4855" for this suite. 04/18/23 08:45:06.204
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":75,"skipped":1220,"failed":0}
------------------------------
• [2.183 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:04.024
    Apr 18 08:45:04.024: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename dns 04/18/23 08:45:04.025
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:04.048
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:04.051
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 04/18/23 08:45:04.055
    Apr 18 08:45:04.060: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-4855  0b9bf1a8-8116-4189-85d5-8be7a249f078 4178183 0 2023-04-18 08:45:04 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-04-18 08:45:04 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7zwk2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7zwk2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 08:45:04.061: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-4855" to be "running and ready"
    Apr 18 08:45:04.063: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.308874ms
    Apr 18 08:45:04.063: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:45:06.067: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.006359371s
    Apr 18 08:45:06.067: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Apr 18 08:45:06.067: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 04/18/23 08:45:06.067
    Apr 18 08:45:06.067: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-4855 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:45:06.067: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:45:06.068: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:45:06.068: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/dns-4855/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 04/18/23 08:45:06.124
    Apr 18 08:45:06.124: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-4855 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:45:06.124: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:45:06.125: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:45:06.125: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/dns-4855/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 18 08:45:06.187: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 08:45:06.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-4855" for this suite. 04/18/23 08:45:06.204
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:06.211
Apr 18 08:45:06.211: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubelet-test 04/18/23 08:45:06.212
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:06.221
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:06.224
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 18 08:45:06.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5739" for this suite. 04/18/23 08:45:06.248
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":76,"skipped":1254,"failed":0}
------------------------------
• [0.042 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:06.211
    Apr 18 08:45:06.211: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubelet-test 04/18/23 08:45:06.212
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:06.221
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:06.224
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 18 08:45:06.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-5739" for this suite. 04/18/23 08:45:06.248
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:06.255
Apr 18 08:45:06.255: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename watch 04/18/23 08:45:06.256
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:06.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:06.269
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 04/18/23 08:45:06.272
STEP: modifying the configmap once 04/18/23 08:45:06.277
STEP: modifying the configmap a second time 04/18/23 08:45:06.283
STEP: deleting the configmap 04/18/23 08:45:06.289
STEP: creating a watch on configmaps from the resource version returned by the first update 04/18/23 08:45:06.292
STEP: Expecting to observe notifications for all changes to the configmap after the first update 04/18/23 08:45:06.294
Apr 18 08:45:06.294: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2219  78f5ef69-4f17-47fd-92e6-e2c6ab4a02de 4178228 0 2023-04-18 08:45:06 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-18 08:45:06 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 08:45:06.294: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2219  78f5ef69-4f17-47fd-92e6-e2c6ab4a02de 4178229 0 2023-04-18 08:45:06 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-18 08:45:06 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 18 08:45:06.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2219" for this suite. 04/18/23 08:45:06.297
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":77,"skipped":1302,"failed":0}
------------------------------
• [0.046 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:06.255
    Apr 18 08:45:06.255: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename watch 04/18/23 08:45:06.256
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:06.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:06.269
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 04/18/23 08:45:06.272
    STEP: modifying the configmap once 04/18/23 08:45:06.277
    STEP: modifying the configmap a second time 04/18/23 08:45:06.283
    STEP: deleting the configmap 04/18/23 08:45:06.289
    STEP: creating a watch on configmaps from the resource version returned by the first update 04/18/23 08:45:06.292
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 04/18/23 08:45:06.294
    Apr 18 08:45:06.294: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2219  78f5ef69-4f17-47fd-92e6-e2c6ab4a02de 4178228 0 2023-04-18 08:45:06 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-18 08:45:06 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 08:45:06.294: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2219  78f5ef69-4f17-47fd-92e6-e2c6ab4a02de 4178229 0 2023-04-18 08:45:06 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-18 08:45:06 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 18 08:45:06.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2219" for this suite. 04/18/23 08:45:06.297
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:06.301
Apr 18 08:45:06.301: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 08:45:06.302
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:06.316
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:06.32
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-48dbfb3f-b8d1-4bab-b11d-50123ac857a6 04/18/23 08:45:06.324
STEP: Creating a pod to test consume configMaps 04/18/23 08:45:06.328
Apr 18 08:45:06.334: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639" in namespace "projected-2037" to be "Succeeded or Failed"
Apr 18 08:45:06.338: INFO: Pod "pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639": Phase="Pending", Reason="", readiness=false. Elapsed: 3.525874ms
Apr 18 08:45:08.346: INFO: Pod "pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011790644s
Apr 18 08:45:10.341: INFO: Pod "pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006789516s
STEP: Saw pod success 04/18/23 08:45:10.341
Apr 18 08:45:10.341: INFO: Pod "pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639" satisfied condition "Succeeded or Failed"
Apr 18 08:45:10.346: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 08:45:10.354
Apr 18 08:45:10.363: INFO: Waiting for pod pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639 to disappear
Apr 18 08:45:10.366: INFO: Pod pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 08:45:10.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2037" for this suite. 04/18/23 08:45:10.371
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":78,"skipped":1313,"failed":0}
------------------------------
• [4.074 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:06.301
    Apr 18 08:45:06.301: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 08:45:06.302
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:06.316
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:06.32
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-48dbfb3f-b8d1-4bab-b11d-50123ac857a6 04/18/23 08:45:06.324
    STEP: Creating a pod to test consume configMaps 04/18/23 08:45:06.328
    Apr 18 08:45:06.334: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639" in namespace "projected-2037" to be "Succeeded or Failed"
    Apr 18 08:45:06.338: INFO: Pod "pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639": Phase="Pending", Reason="", readiness=false. Elapsed: 3.525874ms
    Apr 18 08:45:08.346: INFO: Pod "pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011790644s
    Apr 18 08:45:10.341: INFO: Pod "pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006789516s
    STEP: Saw pod success 04/18/23 08:45:10.341
    Apr 18 08:45:10.341: INFO: Pod "pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639" satisfied condition "Succeeded or Failed"
    Apr 18 08:45:10.346: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 08:45:10.354
    Apr 18 08:45:10.363: INFO: Waiting for pod pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639 to disappear
    Apr 18 08:45:10.366: INFO: Pod pod-projected-configmaps-bf8863c9-be1c-487c-9f83-06f6df7e6639 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 08:45:10.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2037" for this suite. 04/18/23 08:45:10.371
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:10.376
Apr 18 08:45:10.376: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 08:45:10.376
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:10.386
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:10.389
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Apr 18 08:45:10.393: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/18/23 08:45:12.645
Apr 18 08:45:12.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-7917 --namespace=crd-publish-openapi-7917 create -f -'
Apr 18 08:45:13.281: INFO: stderr: ""
Apr 18 08:45:13.281: INFO: stdout: "e2e-test-crd-publish-openapi-4487-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 18 08:45:13.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-7917 --namespace=crd-publish-openapi-7917 delete e2e-test-crd-publish-openapi-4487-crds test-cr'
Apr 18 08:45:13.339: INFO: stderr: ""
Apr 18 08:45:13.339: INFO: stdout: "e2e-test-crd-publish-openapi-4487-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Apr 18 08:45:13.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-7917 --namespace=crd-publish-openapi-7917 apply -f -'
Apr 18 08:45:13.529: INFO: stderr: ""
Apr 18 08:45:13.529: INFO: stdout: "e2e-test-crd-publish-openapi-4487-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 18 08:45:13.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-7917 --namespace=crd-publish-openapi-7917 delete e2e-test-crd-publish-openapi-4487-crds test-cr'
Apr 18 08:45:13.589: INFO: stderr: ""
Apr 18 08:45:13.589: INFO: stdout: "e2e-test-crd-publish-openapi-4487-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 04/18/23 08:45:13.589
Apr 18 08:45:13.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-7917 explain e2e-test-crd-publish-openapi-4487-crds'
Apr 18 08:45:13.767: INFO: stderr: ""
Apr 18 08:45:13.767: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4487-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 08:45:15.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7917" for this suite. 04/18/23 08:45:15.918
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":79,"skipped":1326,"failed":0}
------------------------------
• [SLOW TEST] [5.547 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:10.376
    Apr 18 08:45:10.376: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 08:45:10.376
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:10.386
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:10.389
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Apr 18 08:45:10.393: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/18/23 08:45:12.645
    Apr 18 08:45:12.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-7917 --namespace=crd-publish-openapi-7917 create -f -'
    Apr 18 08:45:13.281: INFO: stderr: ""
    Apr 18 08:45:13.281: INFO: stdout: "e2e-test-crd-publish-openapi-4487-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Apr 18 08:45:13.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-7917 --namespace=crd-publish-openapi-7917 delete e2e-test-crd-publish-openapi-4487-crds test-cr'
    Apr 18 08:45:13.339: INFO: stderr: ""
    Apr 18 08:45:13.339: INFO: stdout: "e2e-test-crd-publish-openapi-4487-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Apr 18 08:45:13.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-7917 --namespace=crd-publish-openapi-7917 apply -f -'
    Apr 18 08:45:13.529: INFO: stderr: ""
    Apr 18 08:45:13.529: INFO: stdout: "e2e-test-crd-publish-openapi-4487-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Apr 18 08:45:13.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-7917 --namespace=crd-publish-openapi-7917 delete e2e-test-crd-publish-openapi-4487-crds test-cr'
    Apr 18 08:45:13.589: INFO: stderr: ""
    Apr 18 08:45:13.589: INFO: stdout: "e2e-test-crd-publish-openapi-4487-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 04/18/23 08:45:13.589
    Apr 18 08:45:13.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-7917 explain e2e-test-crd-publish-openapi-4487-crds'
    Apr 18 08:45:13.767: INFO: stderr: ""
    Apr 18 08:45:13.767: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4487-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 08:45:15.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7917" for this suite. 04/18/23 08:45:15.918
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:15.925
Apr 18 08:45:15.925: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename sysctl 04/18/23 08:45:15.926
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:15.935
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:15.938
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 04/18/23 08:45:15.942
STEP: Watching for error events or started pod 04/18/23 08:45:15.948
STEP: Waiting for pod completion 04/18/23 08:45:17.952
Apr 18 08:45:17.952: INFO: Waiting up to 3m0s for pod "sysctl-e3bb122c-d3ac-4957-a59e-71b674e5cd07" in namespace "sysctl-73" to be "completed"
Apr 18 08:45:17.955: INFO: Pod "sysctl-e3bb122c-d3ac-4957-a59e-71b674e5cd07": Phase="Pending", Reason="", readiness=false. Elapsed: 3.142787ms
Apr 18 08:45:19.959: INFO: Pod "sysctl-e3bb122c-d3ac-4957-a59e-71b674e5cd07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006995016s
Apr 18 08:45:19.959: INFO: Pod "sysctl-e3bb122c-d3ac-4957-a59e-71b674e5cd07" satisfied condition "completed"
STEP: Checking that the pod succeeded 04/18/23 08:45:19.962
STEP: Getting logs from the pod 04/18/23 08:45:19.962
STEP: Checking that the sysctl is actually updated 04/18/23 08:45:19.967
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 18 08:45:19.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-73" for this suite. 04/18/23 08:45:19.971
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":80,"skipped":1356,"failed":0}
------------------------------
• [4.051 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:15.925
    Apr 18 08:45:15.925: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename sysctl 04/18/23 08:45:15.926
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:15.935
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:15.938
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 04/18/23 08:45:15.942
    STEP: Watching for error events or started pod 04/18/23 08:45:15.948
    STEP: Waiting for pod completion 04/18/23 08:45:17.952
    Apr 18 08:45:17.952: INFO: Waiting up to 3m0s for pod "sysctl-e3bb122c-d3ac-4957-a59e-71b674e5cd07" in namespace "sysctl-73" to be "completed"
    Apr 18 08:45:17.955: INFO: Pod "sysctl-e3bb122c-d3ac-4957-a59e-71b674e5cd07": Phase="Pending", Reason="", readiness=false. Elapsed: 3.142787ms
    Apr 18 08:45:19.959: INFO: Pod "sysctl-e3bb122c-d3ac-4957-a59e-71b674e5cd07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006995016s
    Apr 18 08:45:19.959: INFO: Pod "sysctl-e3bb122c-d3ac-4957-a59e-71b674e5cd07" satisfied condition "completed"
    STEP: Checking that the pod succeeded 04/18/23 08:45:19.962
    STEP: Getting logs from the pod 04/18/23 08:45:19.962
    STEP: Checking that the sysctl is actually updated 04/18/23 08:45:19.967
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 18 08:45:19.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-73" for this suite. 04/18/23 08:45:19.971
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:19.977
Apr 18 08:45:19.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename gc 04/18/23 08:45:19.977
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:19.986
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:19.989
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 04/18/23 08:45:19.996
STEP: delete the rc 04/18/23 08:45:25.004
STEP: wait for the rc to be deleted 04/18/23 08:45:25.009
STEP: Gathering metrics 04/18/23 08:45:26.016
W0418 08:45:26.025030      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 18 08:45:26.025: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 18 08:45:26.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7299" for this suite. 04/18/23 08:45:26.029
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":81,"skipped":1388,"failed":0}
------------------------------
• [SLOW TEST] [6.056 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:19.977
    Apr 18 08:45:19.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename gc 04/18/23 08:45:19.977
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:19.986
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:19.989
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 04/18/23 08:45:19.996
    STEP: delete the rc 04/18/23 08:45:25.004
    STEP: wait for the rc to be deleted 04/18/23 08:45:25.009
    STEP: Gathering metrics 04/18/23 08:45:26.016
    W0418 08:45:26.025030      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 18 08:45:26.025: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 18 08:45:26.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7299" for this suite. 04/18/23 08:45:26.029
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:26.034
Apr 18 08:45:26.034: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename deployment 04/18/23 08:45:26.035
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:26.05
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:26.054
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Apr 18 08:45:26.064: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 18 08:45:31.068: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/18/23 08:45:31.068
Apr 18 08:45:31.068: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 04/18/23 08:45:31.076
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 08:45:31.083: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-9364  ecd7256d-dd0e-48f8-bd18-2b1fd6bceac8 4178659 1 2023-04-18 08:45:31 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-04-18 08:45:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004214758 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Apr 18 08:45:31.086: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Apr 18 08:45:31.086: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Apr 18 08:45:31.087: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-9364  e29528b5-953b-48b8-9f8c-aca358215591 4178661 1 2023-04-18 08:45:26 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment ecd7256d-dd0e-48f8-bd18-2b1fd6bceac8 0xc0041e96ff 0xc0041e9720}] [] [{e2e.test Update apps/v1 2023-04-18 08:45:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:45:26 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-18 08:45:31 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"ecd7256d-dd0e-48f8-bd18-2b1fd6bceac8\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0041e97e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 18 08:45:31.093: INFO: Pod "test-cleanup-controller-9886k" is available:
&Pod{ObjectMeta:{test-cleanup-controller-9886k test-cleanup-controller- deployment-9364  ba1c4602-31fb-4be2-8488-1623f749119f 4178638 0 2023-04-18 08:45:26 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller e29528b5-953b-48b8-9f8c-aca358215591 0xc0041e9c57 0xc0041e9c58}] [] [{kube-controller-manager Update v1 2023-04-18 08:45:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e29528b5-953b-48b8-9f8c-aca358215591\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:45:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.113\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kq4sx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kq4sx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:45:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:45:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:45:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:45:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.113,StartTime:2023-04-18 08:45:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:45:26 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7c47b3728a4d65bc55c49e010c3fa187946c639f40d516ffae85017b06e8421b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.113,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 08:45:31.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9364" for this suite. 04/18/23 08:45:31.098
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":82,"skipped":1393,"failed":0}
------------------------------
• [SLOW TEST] [5.074 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:26.034
    Apr 18 08:45:26.034: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename deployment 04/18/23 08:45:26.035
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:26.05
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:26.054
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Apr 18 08:45:26.064: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Apr 18 08:45:31.068: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/18/23 08:45:31.068
    Apr 18 08:45:31.068: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 04/18/23 08:45:31.076
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 08:45:31.083: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-9364  ecd7256d-dd0e-48f8-bd18-2b1fd6bceac8 4178659 1 2023-04-18 08:45:31 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-04-18 08:45:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004214758 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

    Apr 18 08:45:31.086: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
    Apr 18 08:45:31.086: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
    Apr 18 08:45:31.087: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-9364  e29528b5-953b-48b8-9f8c-aca358215591 4178661 1 2023-04-18 08:45:26 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment ecd7256d-dd0e-48f8-bd18-2b1fd6bceac8 0xc0041e96ff 0xc0041e9720}] [] [{e2e.test Update apps/v1 2023-04-18 08:45:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:45:26 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-18 08:45:31 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"ecd7256d-dd0e-48f8-bd18-2b1fd6bceac8\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0041e97e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 08:45:31.093: INFO: Pod "test-cleanup-controller-9886k" is available:
    &Pod{ObjectMeta:{test-cleanup-controller-9886k test-cleanup-controller- deployment-9364  ba1c4602-31fb-4be2-8488-1623f749119f 4178638 0 2023-04-18 08:45:26 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller e29528b5-953b-48b8-9f8c-aca358215591 0xc0041e9c57 0xc0041e9c58}] [] [{kube-controller-manager Update v1 2023-04-18 08:45:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e29528b5-953b-48b8-9f8c-aca358215591\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:45:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.113\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kq4sx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kq4sx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:45:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:45:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:45:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:45:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.113,StartTime:2023-04-18 08:45:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:45:26 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7c47b3728a4d65bc55c49e010c3fa187946c639f40d516ffae85017b06e8421b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.113,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 08:45:31.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9364" for this suite. 04/18/23 08:45:31.098
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:31.11
Apr 18 08:45:31.110: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename pods 04/18/23 08:45:31.11
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:31.122
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:31.125
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Apr 18 08:45:31.135: INFO: Waiting up to 5m0s for pod "server-envvars-74446c0a-62ad-45ef-9050-4f59d81badcd" in namespace "pods-130" to be "running and ready"
Apr 18 08:45:31.137: INFO: Pod "server-envvars-74446c0a-62ad-45ef-9050-4f59d81badcd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.878272ms
Apr 18 08:45:31.137: INFO: The phase of Pod server-envvars-74446c0a-62ad-45ef-9050-4f59d81badcd is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:45:33.141: INFO: Pod "server-envvars-74446c0a-62ad-45ef-9050-4f59d81badcd": Phase="Running", Reason="", readiness=true. Elapsed: 2.006085236s
Apr 18 08:45:33.141: INFO: The phase of Pod server-envvars-74446c0a-62ad-45ef-9050-4f59d81badcd is Running (Ready = true)
Apr 18 08:45:33.141: INFO: Pod "server-envvars-74446c0a-62ad-45ef-9050-4f59d81badcd" satisfied condition "running and ready"
Apr 18 08:45:33.159: INFO: Waiting up to 5m0s for pod "client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98" in namespace "pods-130" to be "Succeeded or Failed"
Apr 18 08:45:33.162: INFO: Pod "client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98": Phase="Pending", Reason="", readiness=false. Elapsed: 3.154982ms
Apr 18 08:45:35.167: INFO: Pod "client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007864975s
Apr 18 08:45:37.165: INFO: Pod "client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00644621s
Apr 18 08:45:39.167: INFO: Pod "client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007641228s
STEP: Saw pod success 04/18/23 08:45:39.167
Apr 18 08:45:39.167: INFO: Pod "client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98" satisfied condition "Succeeded or Failed"
Apr 18 08:45:39.169: INFO: Trying to get logs from node 192.168.1.29 pod client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98 container env3cont: <nil>
STEP: delete the pod 04/18/23 08:45:39.184
Apr 18 08:45:39.192: INFO: Waiting for pod client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98 to disappear
Apr 18 08:45:39.195: INFO: Pod client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 08:45:39.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-130" for this suite. 04/18/23 08:45:39.199
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":83,"skipped":1424,"failed":0}
------------------------------
• [SLOW TEST] [8.094 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:31.11
    Apr 18 08:45:31.110: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename pods 04/18/23 08:45:31.11
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:31.122
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:31.125
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Apr 18 08:45:31.135: INFO: Waiting up to 5m0s for pod "server-envvars-74446c0a-62ad-45ef-9050-4f59d81badcd" in namespace "pods-130" to be "running and ready"
    Apr 18 08:45:31.137: INFO: Pod "server-envvars-74446c0a-62ad-45ef-9050-4f59d81badcd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.878272ms
    Apr 18 08:45:31.137: INFO: The phase of Pod server-envvars-74446c0a-62ad-45ef-9050-4f59d81badcd is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:45:33.141: INFO: Pod "server-envvars-74446c0a-62ad-45ef-9050-4f59d81badcd": Phase="Running", Reason="", readiness=true. Elapsed: 2.006085236s
    Apr 18 08:45:33.141: INFO: The phase of Pod server-envvars-74446c0a-62ad-45ef-9050-4f59d81badcd is Running (Ready = true)
    Apr 18 08:45:33.141: INFO: Pod "server-envvars-74446c0a-62ad-45ef-9050-4f59d81badcd" satisfied condition "running and ready"
    Apr 18 08:45:33.159: INFO: Waiting up to 5m0s for pod "client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98" in namespace "pods-130" to be "Succeeded or Failed"
    Apr 18 08:45:33.162: INFO: Pod "client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98": Phase="Pending", Reason="", readiness=false. Elapsed: 3.154982ms
    Apr 18 08:45:35.167: INFO: Pod "client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007864975s
    Apr 18 08:45:37.165: INFO: Pod "client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00644621s
    Apr 18 08:45:39.167: INFO: Pod "client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007641228s
    STEP: Saw pod success 04/18/23 08:45:39.167
    Apr 18 08:45:39.167: INFO: Pod "client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98" satisfied condition "Succeeded or Failed"
    Apr 18 08:45:39.169: INFO: Trying to get logs from node 192.168.1.29 pod client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98 container env3cont: <nil>
    STEP: delete the pod 04/18/23 08:45:39.184
    Apr 18 08:45:39.192: INFO: Waiting for pod client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98 to disappear
    Apr 18 08:45:39.195: INFO: Pod client-envvars-c098f566-2835-4a90-a65f-cc599dd25c98 no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 08:45:39.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-130" for this suite. 04/18/23 08:45:39.199
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:39.206
Apr 18 08:45:39.206: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-runtime 04/18/23 08:45:39.206
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:39.215
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:39.219
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 04/18/23 08:45:39.222
STEP: wait for the container to reach Succeeded 04/18/23 08:45:39.228
STEP: get the container status 04/18/23 08:45:42.242
STEP: the container should be terminated 04/18/23 08:45:42.245
STEP: the termination message should be set 04/18/23 08:45:42.245
Apr 18 08:45:42.245: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 04/18/23 08:45:42.245
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 18 08:45:42.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8191" for this suite. 04/18/23 08:45:42.263
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":84,"skipped":1441,"failed":0}
------------------------------
• [3.062 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:39.206
    Apr 18 08:45:39.206: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-runtime 04/18/23 08:45:39.206
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:39.215
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:39.219
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 04/18/23 08:45:39.222
    STEP: wait for the container to reach Succeeded 04/18/23 08:45:39.228
    STEP: get the container status 04/18/23 08:45:42.242
    STEP: the container should be terminated 04/18/23 08:45:42.245
    STEP: the termination message should be set 04/18/23 08:45:42.245
    Apr 18 08:45:42.245: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 04/18/23 08:45:42.245
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 18 08:45:42.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-8191" for this suite. 04/18/23 08:45:42.263
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:42.27
Apr 18 08:45:42.270: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 08:45:42.27
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:42.279
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:42.283
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 04/18/23 08:45:42.287
Apr 18 08:45:42.294: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7" in namespace "projected-675" to be "Succeeded or Failed"
Apr 18 08:45:42.296: INFO: Pod "downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.39796ms
Apr 18 08:45:44.300: INFO: Pod "downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006319858s
Apr 18 08:45:46.301: INFO: Pod "downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006984034s
STEP: Saw pod success 04/18/23 08:45:46.301
Apr 18 08:45:46.301: INFO: Pod "downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7" satisfied condition "Succeeded or Failed"
Apr 18 08:45:46.303: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7 container client-container: <nil>
STEP: delete the pod 04/18/23 08:45:46.308
Apr 18 08:45:46.317: INFO: Waiting for pod downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7 to disappear
Apr 18 08:45:46.319: INFO: Pod downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 08:45:46.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-675" for this suite. 04/18/23 08:45:46.323
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":85,"skipped":1465,"failed":0}
------------------------------
• [4.057 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:42.27
    Apr 18 08:45:42.270: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 08:45:42.27
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:42.279
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:42.283
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 04/18/23 08:45:42.287
    Apr 18 08:45:42.294: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7" in namespace "projected-675" to be "Succeeded or Failed"
    Apr 18 08:45:42.296: INFO: Pod "downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.39796ms
    Apr 18 08:45:44.300: INFO: Pod "downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006319858s
    Apr 18 08:45:46.301: INFO: Pod "downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006984034s
    STEP: Saw pod success 04/18/23 08:45:46.301
    Apr 18 08:45:46.301: INFO: Pod "downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7" satisfied condition "Succeeded or Failed"
    Apr 18 08:45:46.303: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7 container client-container: <nil>
    STEP: delete the pod 04/18/23 08:45:46.308
    Apr 18 08:45:46.317: INFO: Waiting for pod downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7 to disappear
    Apr 18 08:45:46.319: INFO: Pod downwardapi-volume-a024dc1e-e268-4798-b2a2-d4594873eba7 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 08:45:46.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-675" for this suite. 04/18/23 08:45:46.323
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:46.328
Apr 18 08:45:46.328: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir 04/18/23 08:45:46.329
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:46.337
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:46.341
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 04/18/23 08:45:46.344
Apr 18 08:45:46.352: INFO: Waiting up to 5m0s for pod "pod-59416349-9537-4c88-8a3e-d2a1deff8ac0" in namespace "emptydir-7337" to be "Succeeded or Failed"
Apr 18 08:45:46.355: INFO: Pod "pod-59416349-9537-4c88-8a3e-d2a1deff8ac0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.803745ms
Apr 18 08:45:48.359: INFO: Pod "pod-59416349-9537-4c88-8a3e-d2a1deff8ac0": Phase="Running", Reason="", readiness=false. Elapsed: 2.006329733s
Apr 18 08:45:50.358: INFO: Pod "pod-59416349-9537-4c88-8a3e-d2a1deff8ac0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006136569s
STEP: Saw pod success 04/18/23 08:45:50.358
Apr 18 08:45:50.358: INFO: Pod "pod-59416349-9537-4c88-8a3e-d2a1deff8ac0" satisfied condition "Succeeded or Failed"
Apr 18 08:45:50.361: INFO: Trying to get logs from node 192.168.1.152 pod pod-59416349-9537-4c88-8a3e-d2a1deff8ac0 container test-container: <nil>
STEP: delete the pod 04/18/23 08:45:50.366
Apr 18 08:45:50.376: INFO: Waiting for pod pod-59416349-9537-4c88-8a3e-d2a1deff8ac0 to disappear
Apr 18 08:45:50.378: INFO: Pod pod-59416349-9537-4c88-8a3e-d2a1deff8ac0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 08:45:50.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7337" for this suite. 04/18/23 08:45:50.383
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":86,"skipped":1495,"failed":0}
------------------------------
• [4.059 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:46.328
    Apr 18 08:45:46.328: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir 04/18/23 08:45:46.329
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:46.337
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:46.341
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 04/18/23 08:45:46.344
    Apr 18 08:45:46.352: INFO: Waiting up to 5m0s for pod "pod-59416349-9537-4c88-8a3e-d2a1deff8ac0" in namespace "emptydir-7337" to be "Succeeded or Failed"
    Apr 18 08:45:46.355: INFO: Pod "pod-59416349-9537-4c88-8a3e-d2a1deff8ac0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.803745ms
    Apr 18 08:45:48.359: INFO: Pod "pod-59416349-9537-4c88-8a3e-d2a1deff8ac0": Phase="Running", Reason="", readiness=false. Elapsed: 2.006329733s
    Apr 18 08:45:50.358: INFO: Pod "pod-59416349-9537-4c88-8a3e-d2a1deff8ac0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006136569s
    STEP: Saw pod success 04/18/23 08:45:50.358
    Apr 18 08:45:50.358: INFO: Pod "pod-59416349-9537-4c88-8a3e-d2a1deff8ac0" satisfied condition "Succeeded or Failed"
    Apr 18 08:45:50.361: INFO: Trying to get logs from node 192.168.1.152 pod pod-59416349-9537-4c88-8a3e-d2a1deff8ac0 container test-container: <nil>
    STEP: delete the pod 04/18/23 08:45:50.366
    Apr 18 08:45:50.376: INFO: Waiting for pod pod-59416349-9537-4c88-8a3e-d2a1deff8ac0 to disappear
    Apr 18 08:45:50.378: INFO: Pod pod-59416349-9537-4c88-8a3e-d2a1deff8ac0 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 08:45:50.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7337" for this suite. 04/18/23 08:45:50.383
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:50.387
Apr 18 08:45:50.387: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename proxy 04/18/23 08:45:50.388
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:50.399
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:50.402
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 04/18/23 08:45:50.413
STEP: creating replication controller proxy-service-5mffs in namespace proxy-1952 04/18/23 08:45:50.413
I0418 08:45:50.419872      18 runners.go:193] Created replication controller with name: proxy-service-5mffs, namespace: proxy-1952, replica count: 1
I0418 08:45:51.470389      18 runners.go:193] proxy-service-5mffs Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 08:45:52.470578      18 runners.go:193] proxy-service-5mffs Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 08:45:52.473: INFO: setup took 2.067725229s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 04/18/23 08:45:52.473
Apr 18 08:45:52.480: INFO: (0) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.525244ms)
Apr 18 08:45:52.480: INFO: (0) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.73858ms)
Apr 18 08:45:52.481: INFO: (0) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 8.219512ms)
Apr 18 08:45:52.481: INFO: (0) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 7.975329ms)
Apr 18 08:45:52.481: INFO: (0) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 8.135648ms)
Apr 18 08:45:52.481: INFO: (0) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 7.958034ms)
Apr 18 08:45:52.481: INFO: (0) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 8.312987ms)
Apr 18 08:45:52.482: INFO: (0) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 8.344928ms)
Apr 18 08:45:52.482: INFO: (0) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 8.812102ms)
Apr 18 08:45:52.484: INFO: (0) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 10.29518ms)
Apr 18 08:45:52.497: INFO: (0) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 23.196871ms)
Apr 18 08:45:52.497: INFO: (0) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 23.345514ms)
Apr 18 08:45:52.497: INFO: (0) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 23.690527ms)
Apr 18 08:45:52.497: INFO: (0) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 23.980942ms)
Apr 18 08:45:52.497: INFO: (0) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 23.623317ms)
Apr 18 08:45:52.498: INFO: (0) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 25.01077ms)
Apr 18 08:45:52.505: INFO: (1) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 5.930231ms)
Apr 18 08:45:52.505: INFO: (1) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.110779ms)
Apr 18 08:45:52.506: INFO: (1) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 7.349458ms)
Apr 18 08:45:52.506: INFO: (1) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 7.148205ms)
Apr 18 08:45:52.507: INFO: (1) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 7.941375ms)
Apr 18 08:45:52.507: INFO: (1) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.847263ms)
Apr 18 08:45:52.507: INFO: (1) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 8.686491ms)
Apr 18 08:45:52.507: INFO: (1) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 8.31582ms)
Apr 18 08:45:52.507: INFO: (1) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 8.391358ms)
Apr 18 08:45:52.507: INFO: (1) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 8.665744ms)
Apr 18 08:45:52.525: INFO: (1) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 26.329968ms)
Apr 18 08:45:52.526: INFO: (1) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 27.143041ms)
Apr 18 08:45:52.526: INFO: (1) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 27.381908ms)
Apr 18 08:45:52.527: INFO: (1) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 28.370261ms)
Apr 18 08:45:52.529: INFO: (1) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 30.2666ms)
Apr 18 08:45:52.556: INFO: (1) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 57.571152ms)
Apr 18 08:45:52.596: INFO: (2) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 39.586911ms)
Apr 18 08:45:52.596: INFO: (2) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 39.705604ms)
Apr 18 08:45:52.597: INFO: (2) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 40.570344ms)
Apr 18 08:45:52.597: INFO: (2) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 40.437046ms)
Apr 18 08:45:52.597: INFO: (2) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 40.739847ms)
Apr 18 08:45:52.598: INFO: (2) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 41.21862ms)
Apr 18 08:45:52.598: INFO: (2) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 41.69688ms)
Apr 18 08:45:52.599: INFO: (2) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 42.416521ms)
Apr 18 08:45:52.599: INFO: (2) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 42.767157ms)
Apr 18 08:45:52.599: INFO: (2) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 43.181785ms)
Apr 18 08:45:52.599: INFO: (2) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 42.936772ms)
Apr 18 08:45:52.599: INFO: (2) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 42.892401ms)
Apr 18 08:45:52.599: INFO: (2) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 43.171197ms)
Apr 18 08:45:52.599: INFO: (2) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 42.972622ms)
Apr 18 08:45:52.600: INFO: (2) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 43.812128ms)
Apr 18 08:45:52.600: INFO: (2) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 43.78782ms)
Apr 18 08:45:52.610: INFO: (3) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 9.613165ms)
Apr 18 08:45:52.610: INFO: (3) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 9.931011ms)
Apr 18 08:45:52.610: INFO: (3) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 9.765542ms)
Apr 18 08:45:52.610: INFO: (3) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 9.934171ms)
Apr 18 08:45:52.611: INFO: (3) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 10.728764ms)
Apr 18 08:45:52.611: INFO: (3) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 10.769568ms)
Apr 18 08:45:52.611: INFO: (3) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 10.803257ms)
Apr 18 08:45:52.612: INFO: (3) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 11.819451ms)
Apr 18 08:45:52.612: INFO: (3) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 11.789104ms)
Apr 18 08:45:52.612: INFO: (3) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 11.778918ms)
Apr 18 08:45:52.613: INFO: (3) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 12.595134ms)
Apr 18 08:45:52.613: INFO: (3) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 12.623406ms)
Apr 18 08:45:52.613: INFO: (3) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 12.492619ms)
Apr 18 08:45:52.613: INFO: (3) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 12.916567ms)
Apr 18 08:45:52.614: INFO: (3) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 13.223181ms)
Apr 18 08:45:52.614: INFO: (3) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 13.459635ms)
Apr 18 08:45:52.620: INFO: (4) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 5.763387ms)
Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.598816ms)
Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 7.125505ms)
Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 7.031314ms)
Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.905996ms)
Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 7.006473ms)
Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.0763ms)
Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.707831ms)
Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 7.008543ms)
Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.761534ms)
Apr 18 08:45:52.622: INFO: (4) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 7.557432ms)
Apr 18 08:45:52.622: INFO: (4) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 7.832078ms)
Apr 18 08:45:52.622: INFO: (4) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 8.176334ms)
Apr 18 08:45:52.622: INFO: (4) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 8.46174ms)
Apr 18 08:45:52.622: INFO: (4) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 8.155626ms)
Apr 18 08:45:52.622: INFO: (4) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 8.044739ms)
Apr 18 08:45:52.628: INFO: (5) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 5.633095ms)
Apr 18 08:45:52.629: INFO: (5) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.664482ms)
Apr 18 08:45:52.629: INFO: (5) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 5.930227ms)
Apr 18 08:45:52.629: INFO: (5) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.488405ms)
Apr 18 08:45:52.629: INFO: (5) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 6.684374ms)
Apr 18 08:45:52.630: INFO: (5) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 7.257354ms)
Apr 18 08:45:52.630: INFO: (5) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 7.571187ms)
Apr 18 08:45:52.630: INFO: (5) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 7.142636ms)
Apr 18 08:45:52.630: INFO: (5) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 7.210061ms)
Apr 18 08:45:52.630: INFO: (5) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.674553ms)
Apr 18 08:45:52.631: INFO: (5) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 7.977488ms)
Apr 18 08:45:52.631: INFO: (5) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 8.242403ms)
Apr 18 08:45:52.631: INFO: (5) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 8.326696ms)
Apr 18 08:45:52.631: INFO: (5) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 8.390727ms)
Apr 18 08:45:52.631: INFO: (5) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 8.293332ms)
Apr 18 08:45:52.631: INFO: (5) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 8.39852ms)
Apr 18 08:45:52.636: INFO: (6) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 4.472411ms)
Apr 18 08:45:52.636: INFO: (6) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 4.593969ms)
Apr 18 08:45:52.637: INFO: (6) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.316635ms)
Apr 18 08:45:52.637: INFO: (6) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 5.199098ms)
Apr 18 08:45:52.638: INFO: (6) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 6.438253ms)
Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 7.279777ms)
Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 7.201608ms)
Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.236433ms)
Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 7.365626ms)
Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 7.626323ms)
Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 7.746122ms)
Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 7.685914ms)
Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 8.011667ms)
Apr 18 08:45:52.640: INFO: (6) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 8.432056ms)
Apr 18 08:45:52.640: INFO: (6) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 8.36864ms)
Apr 18 08:45:52.640: INFO: (6) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 8.59354ms)
Apr 18 08:45:52.651: INFO: (7) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 10.011469ms)
Apr 18 08:45:52.651: INFO: (7) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 10.091275ms)
Apr 18 08:45:52.652: INFO: (7) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 11.236287ms)
Apr 18 08:45:52.652: INFO: (7) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 10.980911ms)
Apr 18 08:45:52.652: INFO: (7) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 11.04658ms)
Apr 18 08:45:52.652: INFO: (7) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 11.940118ms)
Apr 18 08:45:52.652: INFO: (7) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 11.832142ms)
Apr 18 08:45:52.652: INFO: (7) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 11.61472ms)
Apr 18 08:45:52.653: INFO: (7) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 11.790575ms)
Apr 18 08:45:52.653: INFO: (7) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 11.928635ms)
Apr 18 08:45:52.653: INFO: (7) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 12.405573ms)
Apr 18 08:45:52.653: INFO: (7) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 12.784197ms)
Apr 18 08:45:52.653: INFO: (7) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 12.923478ms)
Apr 18 08:45:52.654: INFO: (7) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 12.87174ms)
Apr 18 08:45:52.654: INFO: (7) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 13.819532ms)
Apr 18 08:45:52.654: INFO: (7) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 13.537275ms)
Apr 18 08:45:52.660: INFO: (8) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.276734ms)
Apr 18 08:45:52.661: INFO: (8) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 6.186867ms)
Apr 18 08:45:52.661: INFO: (8) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.454781ms)
Apr 18 08:45:52.661: INFO: (8) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.36192ms)
Apr 18 08:45:52.661: INFO: (8) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.73197ms)
Apr 18 08:45:52.660: INFO: (8) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 5.243645ms)
Apr 18 08:45:52.662: INFO: (8) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 6.957253ms)
Apr 18 08:45:52.662: INFO: (8) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 6.957152ms)
Apr 18 08:45:52.683: INFO: (8) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 28.362872ms)
Apr 18 08:45:52.684: INFO: (8) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 28.700878ms)
Apr 18 08:45:52.684: INFO: (8) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 28.816919ms)
Apr 18 08:45:52.684: INFO: (8) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 28.809253ms)
Apr 18 08:45:52.684: INFO: (8) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 28.739034ms)
Apr 18 08:45:52.684: INFO: (8) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 28.800978ms)
Apr 18 08:45:52.685: INFO: (8) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 29.520009ms)
Apr 18 08:45:52.686: INFO: (8) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 30.404976ms)
Apr 18 08:45:52.689: INFO: (9) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 3.474956ms)
Apr 18 08:45:52.690: INFO: (9) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 4.014875ms)
Apr 18 08:45:52.691: INFO: (9) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 4.651631ms)
Apr 18 08:45:52.691: INFO: (9) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 4.80068ms)
Apr 18 08:45:52.691: INFO: (9) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 4.834673ms)
Apr 18 08:45:52.692: INFO: (9) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.226791ms)
Apr 18 08:45:52.692: INFO: (9) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 5.89965ms)
Apr 18 08:45:52.692: INFO: (9) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.035473ms)
Apr 18 08:45:52.693: INFO: (9) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.692301ms)
Apr 18 08:45:52.693: INFO: (9) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.867507ms)
Apr 18 08:45:52.693: INFO: (9) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 7.284315ms)
Apr 18 08:45:52.693: INFO: (9) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 7.257542ms)
Apr 18 08:45:52.694: INFO: (9) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 7.877869ms)
Apr 18 08:45:52.694: INFO: (9) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 8.018834ms)
Apr 18 08:45:52.694: INFO: (9) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 8.059619ms)
Apr 18 08:45:52.695: INFO: (9) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 9.096884ms)
Apr 18 08:45:52.701: INFO: (10) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 5.398573ms)
Apr 18 08:45:52.701: INFO: (10) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 6.100086ms)
Apr 18 08:45:52.701: INFO: (10) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 5.772528ms)
Apr 18 08:45:52.702: INFO: (10) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 6.155146ms)
Apr 18 08:45:52.702: INFO: (10) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.364709ms)
Apr 18 08:45:52.702: INFO: (10) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.665459ms)
Apr 18 08:45:52.702: INFO: (10) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.43581ms)
Apr 18 08:45:52.702: INFO: (10) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 6.537704ms)
Apr 18 08:45:52.702: INFO: (10) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 6.629095ms)
Apr 18 08:45:52.702: INFO: (10) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.69177ms)
Apr 18 08:45:52.703: INFO: (10) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.882341ms)
Apr 18 08:45:52.703: INFO: (10) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 7.143345ms)
Apr 18 08:45:52.703: INFO: (10) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 7.024505ms)
Apr 18 08:45:52.703: INFO: (10) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 7.311758ms)
Apr 18 08:45:52.704: INFO: (10) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 8.016769ms)
Apr 18 08:45:52.704: INFO: (10) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 8.243592ms)
Apr 18 08:45:52.709: INFO: (11) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 5.068365ms)
Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 5.806676ms)
Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 5.954315ms)
Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 6.300545ms)
Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 5.953736ms)
Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.888454ms)
Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 6.182645ms)
Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.394372ms)
Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.950854ms)
Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.236047ms)
Apr 18 08:45:52.712: INFO: (11) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 7.670657ms)
Apr 18 08:45:52.712: INFO: (11) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 7.555379ms)
Apr 18 08:45:52.712: INFO: (11) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 7.726885ms)
Apr 18 08:45:52.712: INFO: (11) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 7.679059ms)
Apr 18 08:45:52.712: INFO: (11) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 7.714019ms)
Apr 18 08:45:52.712: INFO: (11) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 7.851264ms)
Apr 18 08:45:52.720: INFO: (12) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 7.612417ms)
Apr 18 08:45:52.720: INFO: (12) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 7.280988ms)
Apr 18 08:45:52.720: INFO: (12) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 7.514229ms)
Apr 18 08:45:52.720: INFO: (12) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 7.253811ms)
Apr 18 08:45:52.720: INFO: (12) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 7.363641ms)
Apr 18 08:45:52.720: INFO: (12) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 7.545885ms)
Apr 18 08:45:52.721: INFO: (12) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 7.707328ms)
Apr 18 08:45:52.721: INFO: (12) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 7.591413ms)
Apr 18 08:45:52.721: INFO: (12) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 7.693307ms)
Apr 18 08:45:52.721: INFO: (12) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 7.727084ms)
Apr 18 08:45:52.721: INFO: (12) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 7.543392ms)
Apr 18 08:45:52.721: INFO: (12) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.669688ms)
Apr 18 08:45:52.721: INFO: (12) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 7.597133ms)
Apr 18 08:45:52.723: INFO: (12) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 10.342943ms)
Apr 18 08:45:52.723: INFO: (12) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 10.549373ms)
Apr 18 08:45:52.723: INFO: (12) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 10.569751ms)
Apr 18 08:45:52.730: INFO: (13) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 6.268325ms)
Apr 18 08:45:52.730: INFO: (13) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.650844ms)
Apr 18 08:45:52.730: INFO: (13) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.733152ms)
Apr 18 08:45:52.730: INFO: (13) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 6.773865ms)
Apr 18 08:45:52.730: INFO: (13) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 6.590404ms)
Apr 18 08:45:52.730: INFO: (13) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.800192ms)
Apr 18 08:45:52.731: INFO: (13) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 6.818753ms)
Apr 18 08:45:52.731: INFO: (13) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 6.91305ms)
Apr 18 08:45:52.731: INFO: (13) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 7.142079ms)
Apr 18 08:45:52.731: INFO: (13) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.88904ms)
Apr 18 08:45:52.731: INFO: (13) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 6.942293ms)
Apr 18 08:45:52.731: INFO: (13) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.980497ms)
Apr 18 08:45:52.731: INFO: (13) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.046512ms)
Apr 18 08:45:52.734: INFO: (13) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 10.613166ms)
Apr 18 08:45:52.734: INFO: (13) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 10.638984ms)
Apr 18 08:45:52.734: INFO: (13) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 10.56008ms)
Apr 18 08:45:52.739: INFO: (14) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 4.765536ms)
Apr 18 08:45:52.741: INFO: (14) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.819909ms)
Apr 18 08:45:52.741: INFO: (14) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 6.621963ms)
Apr 18 08:45:52.741: INFO: (14) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.530172ms)
Apr 18 08:45:52.741: INFO: (14) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.652699ms)
Apr 18 08:45:52.742: INFO: (14) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 7.98838ms)
Apr 18 08:45:52.742: INFO: (14) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 7.705867ms)
Apr 18 08:45:52.742: INFO: (14) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.911036ms)
Apr 18 08:45:52.742: INFO: (14) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 7.579664ms)
Apr 18 08:45:52.742: INFO: (14) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 7.895561ms)
Apr 18 08:45:52.743: INFO: (14) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 8.127623ms)
Apr 18 08:45:52.743: INFO: (14) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 8.23871ms)
Apr 18 08:45:52.745: INFO: (14) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 10.180507ms)
Apr 18 08:45:52.745: INFO: (14) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 10.150733ms)
Apr 18 08:45:52.745: INFO: (14) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 9.973599ms)
Apr 18 08:45:52.745: INFO: (14) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 10.012486ms)
Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 8.15308ms)
Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 8.270358ms)
Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 8.106939ms)
Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 8.342642ms)
Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 8.507624ms)
Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 8.598622ms)
Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 8.335643ms)
Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 8.125163ms)
Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 8.185459ms)
Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 8.220347ms)
Apr 18 08:45:52.754: INFO: (15) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 9.469171ms)
Apr 18 08:45:52.755: INFO: (15) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 9.530171ms)
Apr 18 08:45:52.755: INFO: (15) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 9.432933ms)
Apr 18 08:45:52.755: INFO: (15) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 9.358443ms)
Apr 18 08:45:52.755: INFO: (15) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 9.699536ms)
Apr 18 08:45:52.755: INFO: (15) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 9.66875ms)
Apr 18 08:45:52.759: INFO: (16) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 4.07884ms)
Apr 18 08:45:52.760: INFO: (16) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 4.942084ms)
Apr 18 08:45:52.760: INFO: (16) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 4.746634ms)
Apr 18 08:45:52.761: INFO: (16) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.507197ms)
Apr 18 08:45:52.762: INFO: (16) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.385262ms)
Apr 18 08:45:52.762: INFO: (16) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 6.760708ms)
Apr 18 08:45:52.762: INFO: (16) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.93938ms)
Apr 18 08:45:52.762: INFO: (16) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.289064ms)
Apr 18 08:45:52.762: INFO: (16) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 6.570054ms)
Apr 18 08:45:52.762: INFO: (16) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 6.84957ms)
Apr 18 08:45:52.762: INFO: (16) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.081085ms)
Apr 18 08:45:52.763: INFO: (16) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 7.253455ms)
Apr 18 08:45:52.763: INFO: (16) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 7.505054ms)
Apr 18 08:45:52.763: INFO: (16) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 7.561716ms)
Apr 18 08:45:52.763: INFO: (16) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 7.61305ms)
Apr 18 08:45:52.763: INFO: (16) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 7.412768ms)
Apr 18 08:45:52.766: INFO: (17) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 3.387311ms)
Apr 18 08:45:52.768: INFO: (17) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 4.617192ms)
Apr 18 08:45:52.769: INFO: (17) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.643168ms)
Apr 18 08:45:52.769: INFO: (17) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 6.122413ms)
Apr 18 08:45:52.769: INFO: (17) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 6.048203ms)
Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.29013ms)
Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 6.459982ms)
Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 6.615786ms)
Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 6.794968ms)
Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.434031ms)
Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.523506ms)
Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 6.639788ms)
Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 6.781655ms)
Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 6.848179ms)
Apr 18 08:45:52.771: INFO: (17) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 7.505144ms)
Apr 18 08:45:52.771: INFO: (17) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 7.81993ms)
Apr 18 08:45:52.776: INFO: (18) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 4.470329ms)
Apr 18 08:45:52.777: INFO: (18) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 5.464888ms)
Apr 18 08:45:52.778: INFO: (18) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.228136ms)
Apr 18 08:45:52.778: INFO: (18) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 6.035909ms)
Apr 18 08:45:52.778: INFO: (18) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 6.642759ms)
Apr 18 08:45:52.778: INFO: (18) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 6.559472ms)
Apr 18 08:45:52.778: INFO: (18) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.625384ms)
Apr 18 08:45:52.779: INFO: (18) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.981265ms)
Apr 18 08:45:52.779: INFO: (18) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 7.275444ms)
Apr 18 08:45:52.780: INFO: (18) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 8.344666ms)
Apr 18 08:45:52.780: INFO: (18) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 7.995142ms)
Apr 18 08:45:52.780: INFO: (18) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 8.432154ms)
Apr 18 08:45:52.780: INFO: (18) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 8.547809ms)
Apr 18 08:45:52.781: INFO: (18) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 8.620072ms)
Apr 18 08:45:52.783: INFO: (18) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 11.268199ms)
Apr 18 08:45:52.783: INFO: (18) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 10.96743ms)
Apr 18 08:45:52.789: INFO: (19) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.970292ms)
Apr 18 08:45:52.790: INFO: (19) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.348465ms)
Apr 18 08:45:52.790: INFO: (19) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 6.417569ms)
Apr 18 08:45:52.790: INFO: (19) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 6.704069ms)
Apr 18 08:45:52.790: INFO: (19) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.907349ms)
Apr 18 08:45:52.791: INFO: (19) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 7.703577ms)
Apr 18 08:45:52.791: INFO: (19) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 8.311158ms)
Apr 18 08:45:52.792: INFO: (19) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 8.331857ms)
Apr 18 08:45:52.792: INFO: (19) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 9.224272ms)
Apr 18 08:45:52.793: INFO: (19) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 9.4ms)
Apr 18 08:45:52.793: INFO: (19) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 9.434066ms)
Apr 18 08:45:52.793: INFO: (19) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 9.83914ms)
Apr 18 08:45:52.793: INFO: (19) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 9.66697ms)
Apr 18 08:45:52.793: INFO: (19) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 9.699841ms)
Apr 18 08:45:52.793: INFO: (19) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 9.861907ms)
Apr 18 08:45:52.793: INFO: (19) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 10.012957ms)
STEP: deleting ReplicationController proxy-service-5mffs in namespace proxy-1952, will wait for the garbage collector to delete the pods 04/18/23 08:45:52.793
Apr 18 08:45:52.853: INFO: Deleting ReplicationController proxy-service-5mffs took: 5.110727ms
Apr 18 08:45:52.953: INFO: Terminating ReplicationController proxy-service-5mffs pods took: 100.14571ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Apr 18 08:45:54.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1952" for this suite. 04/18/23 08:45:54.958
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":87,"skipped":1498,"failed":0}
------------------------------
• [4.575 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:50.387
    Apr 18 08:45:50.387: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename proxy 04/18/23 08:45:50.388
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:50.399
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:50.402
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 04/18/23 08:45:50.413
    STEP: creating replication controller proxy-service-5mffs in namespace proxy-1952 04/18/23 08:45:50.413
    I0418 08:45:50.419872      18 runners.go:193] Created replication controller with name: proxy-service-5mffs, namespace: proxy-1952, replica count: 1
    I0418 08:45:51.470389      18 runners.go:193] proxy-service-5mffs Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 08:45:52.470578      18 runners.go:193] proxy-service-5mffs Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 08:45:52.473: INFO: setup took 2.067725229s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 04/18/23 08:45:52.473
    Apr 18 08:45:52.480: INFO: (0) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.525244ms)
    Apr 18 08:45:52.480: INFO: (0) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.73858ms)
    Apr 18 08:45:52.481: INFO: (0) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 8.219512ms)
    Apr 18 08:45:52.481: INFO: (0) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 7.975329ms)
    Apr 18 08:45:52.481: INFO: (0) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 8.135648ms)
    Apr 18 08:45:52.481: INFO: (0) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 7.958034ms)
    Apr 18 08:45:52.481: INFO: (0) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 8.312987ms)
    Apr 18 08:45:52.482: INFO: (0) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 8.344928ms)
    Apr 18 08:45:52.482: INFO: (0) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 8.812102ms)
    Apr 18 08:45:52.484: INFO: (0) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 10.29518ms)
    Apr 18 08:45:52.497: INFO: (0) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 23.196871ms)
    Apr 18 08:45:52.497: INFO: (0) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 23.345514ms)
    Apr 18 08:45:52.497: INFO: (0) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 23.690527ms)
    Apr 18 08:45:52.497: INFO: (0) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 23.980942ms)
    Apr 18 08:45:52.497: INFO: (0) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 23.623317ms)
    Apr 18 08:45:52.498: INFO: (0) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 25.01077ms)
    Apr 18 08:45:52.505: INFO: (1) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 5.930231ms)
    Apr 18 08:45:52.505: INFO: (1) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.110779ms)
    Apr 18 08:45:52.506: INFO: (1) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 7.349458ms)
    Apr 18 08:45:52.506: INFO: (1) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 7.148205ms)
    Apr 18 08:45:52.507: INFO: (1) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 7.941375ms)
    Apr 18 08:45:52.507: INFO: (1) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.847263ms)
    Apr 18 08:45:52.507: INFO: (1) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 8.686491ms)
    Apr 18 08:45:52.507: INFO: (1) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 8.31582ms)
    Apr 18 08:45:52.507: INFO: (1) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 8.391358ms)
    Apr 18 08:45:52.507: INFO: (1) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 8.665744ms)
    Apr 18 08:45:52.525: INFO: (1) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 26.329968ms)
    Apr 18 08:45:52.526: INFO: (1) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 27.143041ms)
    Apr 18 08:45:52.526: INFO: (1) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 27.381908ms)
    Apr 18 08:45:52.527: INFO: (1) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 28.370261ms)
    Apr 18 08:45:52.529: INFO: (1) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 30.2666ms)
    Apr 18 08:45:52.556: INFO: (1) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 57.571152ms)
    Apr 18 08:45:52.596: INFO: (2) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 39.586911ms)
    Apr 18 08:45:52.596: INFO: (2) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 39.705604ms)
    Apr 18 08:45:52.597: INFO: (2) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 40.570344ms)
    Apr 18 08:45:52.597: INFO: (2) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 40.437046ms)
    Apr 18 08:45:52.597: INFO: (2) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 40.739847ms)
    Apr 18 08:45:52.598: INFO: (2) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 41.21862ms)
    Apr 18 08:45:52.598: INFO: (2) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 41.69688ms)
    Apr 18 08:45:52.599: INFO: (2) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 42.416521ms)
    Apr 18 08:45:52.599: INFO: (2) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 42.767157ms)
    Apr 18 08:45:52.599: INFO: (2) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 43.181785ms)
    Apr 18 08:45:52.599: INFO: (2) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 42.936772ms)
    Apr 18 08:45:52.599: INFO: (2) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 42.892401ms)
    Apr 18 08:45:52.599: INFO: (2) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 43.171197ms)
    Apr 18 08:45:52.599: INFO: (2) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 42.972622ms)
    Apr 18 08:45:52.600: INFO: (2) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 43.812128ms)
    Apr 18 08:45:52.600: INFO: (2) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 43.78782ms)
    Apr 18 08:45:52.610: INFO: (3) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 9.613165ms)
    Apr 18 08:45:52.610: INFO: (3) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 9.931011ms)
    Apr 18 08:45:52.610: INFO: (3) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 9.765542ms)
    Apr 18 08:45:52.610: INFO: (3) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 9.934171ms)
    Apr 18 08:45:52.611: INFO: (3) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 10.728764ms)
    Apr 18 08:45:52.611: INFO: (3) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 10.769568ms)
    Apr 18 08:45:52.611: INFO: (3) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 10.803257ms)
    Apr 18 08:45:52.612: INFO: (3) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 11.819451ms)
    Apr 18 08:45:52.612: INFO: (3) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 11.789104ms)
    Apr 18 08:45:52.612: INFO: (3) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 11.778918ms)
    Apr 18 08:45:52.613: INFO: (3) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 12.595134ms)
    Apr 18 08:45:52.613: INFO: (3) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 12.623406ms)
    Apr 18 08:45:52.613: INFO: (3) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 12.492619ms)
    Apr 18 08:45:52.613: INFO: (3) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 12.916567ms)
    Apr 18 08:45:52.614: INFO: (3) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 13.223181ms)
    Apr 18 08:45:52.614: INFO: (3) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 13.459635ms)
    Apr 18 08:45:52.620: INFO: (4) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 5.763387ms)
    Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.598816ms)
    Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 7.125505ms)
    Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 7.031314ms)
    Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.905996ms)
    Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 7.006473ms)
    Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.0763ms)
    Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.707831ms)
    Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 7.008543ms)
    Apr 18 08:45:52.621: INFO: (4) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.761534ms)
    Apr 18 08:45:52.622: INFO: (4) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 7.557432ms)
    Apr 18 08:45:52.622: INFO: (4) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 7.832078ms)
    Apr 18 08:45:52.622: INFO: (4) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 8.176334ms)
    Apr 18 08:45:52.622: INFO: (4) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 8.46174ms)
    Apr 18 08:45:52.622: INFO: (4) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 8.155626ms)
    Apr 18 08:45:52.622: INFO: (4) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 8.044739ms)
    Apr 18 08:45:52.628: INFO: (5) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 5.633095ms)
    Apr 18 08:45:52.629: INFO: (5) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.664482ms)
    Apr 18 08:45:52.629: INFO: (5) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 5.930227ms)
    Apr 18 08:45:52.629: INFO: (5) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.488405ms)
    Apr 18 08:45:52.629: INFO: (5) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 6.684374ms)
    Apr 18 08:45:52.630: INFO: (5) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 7.257354ms)
    Apr 18 08:45:52.630: INFO: (5) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 7.571187ms)
    Apr 18 08:45:52.630: INFO: (5) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 7.142636ms)
    Apr 18 08:45:52.630: INFO: (5) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 7.210061ms)
    Apr 18 08:45:52.630: INFO: (5) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.674553ms)
    Apr 18 08:45:52.631: INFO: (5) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 7.977488ms)
    Apr 18 08:45:52.631: INFO: (5) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 8.242403ms)
    Apr 18 08:45:52.631: INFO: (5) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 8.326696ms)
    Apr 18 08:45:52.631: INFO: (5) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 8.390727ms)
    Apr 18 08:45:52.631: INFO: (5) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 8.293332ms)
    Apr 18 08:45:52.631: INFO: (5) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 8.39852ms)
    Apr 18 08:45:52.636: INFO: (6) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 4.472411ms)
    Apr 18 08:45:52.636: INFO: (6) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 4.593969ms)
    Apr 18 08:45:52.637: INFO: (6) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.316635ms)
    Apr 18 08:45:52.637: INFO: (6) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 5.199098ms)
    Apr 18 08:45:52.638: INFO: (6) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 6.438253ms)
    Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 7.279777ms)
    Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 7.201608ms)
    Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.236433ms)
    Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 7.365626ms)
    Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 7.626323ms)
    Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 7.746122ms)
    Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 7.685914ms)
    Apr 18 08:45:52.639: INFO: (6) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 8.011667ms)
    Apr 18 08:45:52.640: INFO: (6) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 8.432056ms)
    Apr 18 08:45:52.640: INFO: (6) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 8.36864ms)
    Apr 18 08:45:52.640: INFO: (6) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 8.59354ms)
    Apr 18 08:45:52.651: INFO: (7) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 10.011469ms)
    Apr 18 08:45:52.651: INFO: (7) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 10.091275ms)
    Apr 18 08:45:52.652: INFO: (7) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 11.236287ms)
    Apr 18 08:45:52.652: INFO: (7) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 10.980911ms)
    Apr 18 08:45:52.652: INFO: (7) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 11.04658ms)
    Apr 18 08:45:52.652: INFO: (7) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 11.940118ms)
    Apr 18 08:45:52.652: INFO: (7) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 11.832142ms)
    Apr 18 08:45:52.652: INFO: (7) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 11.61472ms)
    Apr 18 08:45:52.653: INFO: (7) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 11.790575ms)
    Apr 18 08:45:52.653: INFO: (7) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 11.928635ms)
    Apr 18 08:45:52.653: INFO: (7) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 12.405573ms)
    Apr 18 08:45:52.653: INFO: (7) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 12.784197ms)
    Apr 18 08:45:52.653: INFO: (7) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 12.923478ms)
    Apr 18 08:45:52.654: INFO: (7) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 12.87174ms)
    Apr 18 08:45:52.654: INFO: (7) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 13.819532ms)
    Apr 18 08:45:52.654: INFO: (7) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 13.537275ms)
    Apr 18 08:45:52.660: INFO: (8) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.276734ms)
    Apr 18 08:45:52.661: INFO: (8) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 6.186867ms)
    Apr 18 08:45:52.661: INFO: (8) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.454781ms)
    Apr 18 08:45:52.661: INFO: (8) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.36192ms)
    Apr 18 08:45:52.661: INFO: (8) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.73197ms)
    Apr 18 08:45:52.660: INFO: (8) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 5.243645ms)
    Apr 18 08:45:52.662: INFO: (8) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 6.957253ms)
    Apr 18 08:45:52.662: INFO: (8) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 6.957152ms)
    Apr 18 08:45:52.683: INFO: (8) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 28.362872ms)
    Apr 18 08:45:52.684: INFO: (8) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 28.700878ms)
    Apr 18 08:45:52.684: INFO: (8) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 28.816919ms)
    Apr 18 08:45:52.684: INFO: (8) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 28.809253ms)
    Apr 18 08:45:52.684: INFO: (8) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 28.739034ms)
    Apr 18 08:45:52.684: INFO: (8) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 28.800978ms)
    Apr 18 08:45:52.685: INFO: (8) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 29.520009ms)
    Apr 18 08:45:52.686: INFO: (8) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 30.404976ms)
    Apr 18 08:45:52.689: INFO: (9) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 3.474956ms)
    Apr 18 08:45:52.690: INFO: (9) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 4.014875ms)
    Apr 18 08:45:52.691: INFO: (9) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 4.651631ms)
    Apr 18 08:45:52.691: INFO: (9) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 4.80068ms)
    Apr 18 08:45:52.691: INFO: (9) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 4.834673ms)
    Apr 18 08:45:52.692: INFO: (9) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.226791ms)
    Apr 18 08:45:52.692: INFO: (9) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 5.89965ms)
    Apr 18 08:45:52.692: INFO: (9) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.035473ms)
    Apr 18 08:45:52.693: INFO: (9) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.692301ms)
    Apr 18 08:45:52.693: INFO: (9) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.867507ms)
    Apr 18 08:45:52.693: INFO: (9) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 7.284315ms)
    Apr 18 08:45:52.693: INFO: (9) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 7.257542ms)
    Apr 18 08:45:52.694: INFO: (9) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 7.877869ms)
    Apr 18 08:45:52.694: INFO: (9) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 8.018834ms)
    Apr 18 08:45:52.694: INFO: (9) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 8.059619ms)
    Apr 18 08:45:52.695: INFO: (9) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 9.096884ms)
    Apr 18 08:45:52.701: INFO: (10) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 5.398573ms)
    Apr 18 08:45:52.701: INFO: (10) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 6.100086ms)
    Apr 18 08:45:52.701: INFO: (10) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 5.772528ms)
    Apr 18 08:45:52.702: INFO: (10) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 6.155146ms)
    Apr 18 08:45:52.702: INFO: (10) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.364709ms)
    Apr 18 08:45:52.702: INFO: (10) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.665459ms)
    Apr 18 08:45:52.702: INFO: (10) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.43581ms)
    Apr 18 08:45:52.702: INFO: (10) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 6.537704ms)
    Apr 18 08:45:52.702: INFO: (10) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 6.629095ms)
    Apr 18 08:45:52.702: INFO: (10) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.69177ms)
    Apr 18 08:45:52.703: INFO: (10) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.882341ms)
    Apr 18 08:45:52.703: INFO: (10) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 7.143345ms)
    Apr 18 08:45:52.703: INFO: (10) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 7.024505ms)
    Apr 18 08:45:52.703: INFO: (10) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 7.311758ms)
    Apr 18 08:45:52.704: INFO: (10) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 8.016769ms)
    Apr 18 08:45:52.704: INFO: (10) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 8.243592ms)
    Apr 18 08:45:52.709: INFO: (11) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 5.068365ms)
    Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 5.806676ms)
    Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 5.954315ms)
    Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 6.300545ms)
    Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 5.953736ms)
    Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.888454ms)
    Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 6.182645ms)
    Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.394372ms)
    Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.950854ms)
    Apr 18 08:45:52.710: INFO: (11) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.236047ms)
    Apr 18 08:45:52.712: INFO: (11) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 7.670657ms)
    Apr 18 08:45:52.712: INFO: (11) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 7.555379ms)
    Apr 18 08:45:52.712: INFO: (11) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 7.726885ms)
    Apr 18 08:45:52.712: INFO: (11) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 7.679059ms)
    Apr 18 08:45:52.712: INFO: (11) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 7.714019ms)
    Apr 18 08:45:52.712: INFO: (11) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 7.851264ms)
    Apr 18 08:45:52.720: INFO: (12) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 7.612417ms)
    Apr 18 08:45:52.720: INFO: (12) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 7.280988ms)
    Apr 18 08:45:52.720: INFO: (12) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 7.514229ms)
    Apr 18 08:45:52.720: INFO: (12) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 7.253811ms)
    Apr 18 08:45:52.720: INFO: (12) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 7.363641ms)
    Apr 18 08:45:52.720: INFO: (12) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 7.545885ms)
    Apr 18 08:45:52.721: INFO: (12) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 7.707328ms)
    Apr 18 08:45:52.721: INFO: (12) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 7.591413ms)
    Apr 18 08:45:52.721: INFO: (12) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 7.693307ms)
    Apr 18 08:45:52.721: INFO: (12) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 7.727084ms)
    Apr 18 08:45:52.721: INFO: (12) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 7.543392ms)
    Apr 18 08:45:52.721: INFO: (12) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.669688ms)
    Apr 18 08:45:52.721: INFO: (12) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 7.597133ms)
    Apr 18 08:45:52.723: INFO: (12) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 10.342943ms)
    Apr 18 08:45:52.723: INFO: (12) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 10.549373ms)
    Apr 18 08:45:52.723: INFO: (12) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 10.569751ms)
    Apr 18 08:45:52.730: INFO: (13) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 6.268325ms)
    Apr 18 08:45:52.730: INFO: (13) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.650844ms)
    Apr 18 08:45:52.730: INFO: (13) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.733152ms)
    Apr 18 08:45:52.730: INFO: (13) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 6.773865ms)
    Apr 18 08:45:52.730: INFO: (13) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 6.590404ms)
    Apr 18 08:45:52.730: INFO: (13) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.800192ms)
    Apr 18 08:45:52.731: INFO: (13) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 6.818753ms)
    Apr 18 08:45:52.731: INFO: (13) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 6.91305ms)
    Apr 18 08:45:52.731: INFO: (13) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 7.142079ms)
    Apr 18 08:45:52.731: INFO: (13) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.88904ms)
    Apr 18 08:45:52.731: INFO: (13) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 6.942293ms)
    Apr 18 08:45:52.731: INFO: (13) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.980497ms)
    Apr 18 08:45:52.731: INFO: (13) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.046512ms)
    Apr 18 08:45:52.734: INFO: (13) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 10.613166ms)
    Apr 18 08:45:52.734: INFO: (13) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 10.638984ms)
    Apr 18 08:45:52.734: INFO: (13) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 10.56008ms)
    Apr 18 08:45:52.739: INFO: (14) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 4.765536ms)
    Apr 18 08:45:52.741: INFO: (14) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.819909ms)
    Apr 18 08:45:52.741: INFO: (14) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 6.621963ms)
    Apr 18 08:45:52.741: INFO: (14) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.530172ms)
    Apr 18 08:45:52.741: INFO: (14) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.652699ms)
    Apr 18 08:45:52.742: INFO: (14) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 7.98838ms)
    Apr 18 08:45:52.742: INFO: (14) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 7.705867ms)
    Apr 18 08:45:52.742: INFO: (14) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.911036ms)
    Apr 18 08:45:52.742: INFO: (14) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 7.579664ms)
    Apr 18 08:45:52.742: INFO: (14) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 7.895561ms)
    Apr 18 08:45:52.743: INFO: (14) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 8.127623ms)
    Apr 18 08:45:52.743: INFO: (14) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 8.23871ms)
    Apr 18 08:45:52.745: INFO: (14) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 10.180507ms)
    Apr 18 08:45:52.745: INFO: (14) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 10.150733ms)
    Apr 18 08:45:52.745: INFO: (14) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 9.973599ms)
    Apr 18 08:45:52.745: INFO: (14) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 10.012486ms)
    Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 8.15308ms)
    Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 8.270358ms)
    Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 8.106939ms)
    Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 8.342642ms)
    Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 8.507624ms)
    Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 8.598622ms)
    Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 8.335643ms)
    Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 8.125163ms)
    Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 8.185459ms)
    Apr 18 08:45:52.753: INFO: (15) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 8.220347ms)
    Apr 18 08:45:52.754: INFO: (15) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 9.469171ms)
    Apr 18 08:45:52.755: INFO: (15) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 9.530171ms)
    Apr 18 08:45:52.755: INFO: (15) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 9.432933ms)
    Apr 18 08:45:52.755: INFO: (15) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 9.358443ms)
    Apr 18 08:45:52.755: INFO: (15) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 9.699536ms)
    Apr 18 08:45:52.755: INFO: (15) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 9.66875ms)
    Apr 18 08:45:52.759: INFO: (16) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 4.07884ms)
    Apr 18 08:45:52.760: INFO: (16) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 4.942084ms)
    Apr 18 08:45:52.760: INFO: (16) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 4.746634ms)
    Apr 18 08:45:52.761: INFO: (16) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.507197ms)
    Apr 18 08:45:52.762: INFO: (16) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.385262ms)
    Apr 18 08:45:52.762: INFO: (16) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 6.760708ms)
    Apr 18 08:45:52.762: INFO: (16) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.93938ms)
    Apr 18 08:45:52.762: INFO: (16) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.289064ms)
    Apr 18 08:45:52.762: INFO: (16) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 6.570054ms)
    Apr 18 08:45:52.762: INFO: (16) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 6.84957ms)
    Apr 18 08:45:52.762: INFO: (16) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 7.081085ms)
    Apr 18 08:45:52.763: INFO: (16) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 7.253455ms)
    Apr 18 08:45:52.763: INFO: (16) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 7.505054ms)
    Apr 18 08:45:52.763: INFO: (16) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 7.561716ms)
    Apr 18 08:45:52.763: INFO: (16) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 7.61305ms)
    Apr 18 08:45:52.763: INFO: (16) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 7.412768ms)
    Apr 18 08:45:52.766: INFO: (17) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 3.387311ms)
    Apr 18 08:45:52.768: INFO: (17) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 4.617192ms)
    Apr 18 08:45:52.769: INFO: (17) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.643168ms)
    Apr 18 08:45:52.769: INFO: (17) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 6.122413ms)
    Apr 18 08:45:52.769: INFO: (17) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 6.048203ms)
    Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 6.29013ms)
    Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 6.459982ms)
    Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 6.615786ms)
    Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 6.794968ms)
    Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.434031ms)
    Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.523506ms)
    Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 6.639788ms)
    Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 6.781655ms)
    Apr 18 08:45:52.770: INFO: (17) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 6.848179ms)
    Apr 18 08:45:52.771: INFO: (17) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 7.505144ms)
    Apr 18 08:45:52.771: INFO: (17) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 7.81993ms)
    Apr 18 08:45:52.776: INFO: (18) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 4.470329ms)
    Apr 18 08:45:52.777: INFO: (18) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 5.464888ms)
    Apr 18 08:45:52.778: INFO: (18) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.228136ms)
    Apr 18 08:45:52.778: INFO: (18) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 6.035909ms)
    Apr 18 08:45:52.778: INFO: (18) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 6.642759ms)
    Apr 18 08:45:52.778: INFO: (18) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 6.559472ms)
    Apr 18 08:45:52.778: INFO: (18) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.625384ms)
    Apr 18 08:45:52.779: INFO: (18) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 6.981265ms)
    Apr 18 08:45:52.779: INFO: (18) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 7.275444ms)
    Apr 18 08:45:52.780: INFO: (18) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 8.344666ms)
    Apr 18 08:45:52.780: INFO: (18) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 7.995142ms)
    Apr 18 08:45:52.780: INFO: (18) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 8.432154ms)
    Apr 18 08:45:52.780: INFO: (18) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 8.547809ms)
    Apr 18 08:45:52.781: INFO: (18) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 8.620072ms)
    Apr 18 08:45:52.783: INFO: (18) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 11.268199ms)
    Apr 18 08:45:52.783: INFO: (18) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 10.96743ms)
    Apr 18 08:45:52.789: INFO: (19) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:162/proxy/: bar (200; 5.970292ms)
    Apr 18 08:45:52.790: INFO: (19) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:160/proxy/: foo (200; 6.348465ms)
    Apr 18 08:45:52.790: INFO: (19) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:443/proxy/tlsrewritem... (200; 6.417569ms)
    Apr 18 08:45:52.790: INFO: (19) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:1080/proxy/rewriteme">... (200; 6.704069ms)
    Apr 18 08:45:52.790: INFO: (19) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn/proxy/rewriteme">test</a> (200; 6.907349ms)
    Apr 18 08:45:52.791: INFO: (19) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:160/proxy/: foo (200; 7.703577ms)
    Apr 18 08:45:52.791: INFO: (19) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:460/proxy/: tls baz (200; 8.311158ms)
    Apr 18 08:45:52.792: INFO: (19) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname2/proxy/: bar (200; 8.331857ms)
    Apr 18 08:45:52.792: INFO: (19) /api/v1/namespaces/proxy-1952/pods/http:proxy-service-5mffs-p94fn:162/proxy/: bar (200; 9.224272ms)
    Apr 18 08:45:52.793: INFO: (19) /api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/: <a href="/api/v1/namespaces/proxy-1952/pods/proxy-service-5mffs-p94fn:1080/proxy/rewriteme">test<... (200; 9.4ms)
    Apr 18 08:45:52.793: INFO: (19) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname2/proxy/: tls qux (200; 9.434066ms)
    Apr 18 08:45:52.793: INFO: (19) /api/v1/namespaces/proxy-1952/pods/https:proxy-service-5mffs-p94fn:462/proxy/: tls qux (200; 9.83914ms)
    Apr 18 08:45:52.793: INFO: (19) /api/v1/namespaces/proxy-1952/services/https:proxy-service-5mffs:tlsportname1/proxy/: tls baz (200; 9.66697ms)
    Apr 18 08:45:52.793: INFO: (19) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname1/proxy/: foo (200; 9.699841ms)
    Apr 18 08:45:52.793: INFO: (19) /api/v1/namespaces/proxy-1952/services/http:proxy-service-5mffs:portname1/proxy/: foo (200; 9.861907ms)
    Apr 18 08:45:52.793: INFO: (19) /api/v1/namespaces/proxy-1952/services/proxy-service-5mffs:portname2/proxy/: bar (200; 10.012957ms)
    STEP: deleting ReplicationController proxy-service-5mffs in namespace proxy-1952, will wait for the garbage collector to delete the pods 04/18/23 08:45:52.793
    Apr 18 08:45:52.853: INFO: Deleting ReplicationController proxy-service-5mffs took: 5.110727ms
    Apr 18 08:45:52.953: INFO: Terminating ReplicationController proxy-service-5mffs pods took: 100.14571ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Apr 18 08:45:54.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-1952" for this suite. 04/18/23 08:45:54.958
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:54.964
Apr 18 08:45:54.965: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename events 04/18/23 08:45:54.966
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:54.983
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:54.987
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 04/18/23 08:45:54.991
Apr 18 08:45:54.996: INFO: created test-event-1
Apr 18 08:45:55.001: INFO: created test-event-2
Apr 18 08:45:55.004: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 04/18/23 08:45:55.004
STEP: delete collection of events 04/18/23 08:45:55.007
Apr 18 08:45:55.007: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 04/18/23 08:45:55.017
Apr 18 08:45:55.017: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Apr 18 08:45:55.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6015" for this suite. 04/18/23 08:45:55.023
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":88,"skipped":1523,"failed":0}
------------------------------
• [0.062 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:54.964
    Apr 18 08:45:54.965: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename events 04/18/23 08:45:54.966
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:54.983
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:54.987
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 04/18/23 08:45:54.991
    Apr 18 08:45:54.996: INFO: created test-event-1
    Apr 18 08:45:55.001: INFO: created test-event-2
    Apr 18 08:45:55.004: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 04/18/23 08:45:55.004
    STEP: delete collection of events 04/18/23 08:45:55.007
    Apr 18 08:45:55.007: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 04/18/23 08:45:55.017
    Apr 18 08:45:55.017: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Apr 18 08:45:55.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-6015" for this suite. 04/18/23 08:45:55.023
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:45:55.027
Apr 18 08:45:55.028: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename pods 04/18/23 08:45:55.028
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:55.037
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:55.041
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 04/18/23 08:45:55.044
STEP: submitting the pod to kubernetes 04/18/23 08:45:55.045
Apr 18 08:45:55.050: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900" in namespace "pods-129" to be "running and ready"
Apr 18 08:45:55.053: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900": Phase="Pending", Reason="", readiness=false. Elapsed: 2.384078ms
Apr 18 08:45:55.053: INFO: The phase of Pod pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:45:57.057: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900": Phase="Running", Reason="", readiness=true. Elapsed: 2.006918501s
Apr 18 08:45:57.057: INFO: The phase of Pod pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900 is Running (Ready = true)
Apr 18 08:45:57.057: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 04/18/23 08:45:57.06
STEP: updating the pod 04/18/23 08:45:57.063
Apr 18 08:45:57.573: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900"
Apr 18 08:45:57.573: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900" in namespace "pods-129" to be "terminated with reason DeadlineExceeded"
Apr 18 08:45:57.575: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900": Phase="Running", Reason="", readiness=true. Elapsed: 2.506139ms
Apr 18 08:45:59.579: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900": Phase="Running", Reason="", readiness=true. Elapsed: 2.005836769s
Apr 18 08:46:01.579: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900": Phase="Running", Reason="", readiness=false. Elapsed: 4.006601124s
Apr 18 08:46:03.579: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.006271308s
Apr 18 08:46:03.579: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 08:46:03.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-129" for this suite. 04/18/23 08:46:03.583
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":89,"skipped":1533,"failed":0}
------------------------------
• [SLOW TEST] [8.560 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:45:55.027
    Apr 18 08:45:55.028: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename pods 04/18/23 08:45:55.028
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:45:55.037
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:45:55.041
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 04/18/23 08:45:55.044
    STEP: submitting the pod to kubernetes 04/18/23 08:45:55.045
    Apr 18 08:45:55.050: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900" in namespace "pods-129" to be "running and ready"
    Apr 18 08:45:55.053: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900": Phase="Pending", Reason="", readiness=false. Elapsed: 2.384078ms
    Apr 18 08:45:55.053: INFO: The phase of Pod pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:45:57.057: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900": Phase="Running", Reason="", readiness=true. Elapsed: 2.006918501s
    Apr 18 08:45:57.057: INFO: The phase of Pod pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900 is Running (Ready = true)
    Apr 18 08:45:57.057: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 04/18/23 08:45:57.06
    STEP: updating the pod 04/18/23 08:45:57.063
    Apr 18 08:45:57.573: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900"
    Apr 18 08:45:57.573: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900" in namespace "pods-129" to be "terminated with reason DeadlineExceeded"
    Apr 18 08:45:57.575: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900": Phase="Running", Reason="", readiness=true. Elapsed: 2.506139ms
    Apr 18 08:45:59.579: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900": Phase="Running", Reason="", readiness=true. Elapsed: 2.005836769s
    Apr 18 08:46:01.579: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900": Phase="Running", Reason="", readiness=false. Elapsed: 4.006601124s
    Apr 18 08:46:03.579: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.006271308s
    Apr 18 08:46:03.579: INFO: Pod "pod-update-activedeadlineseconds-c5abdefa-f0d7-457b-ae1e-1db4fef79900" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 08:46:03.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-129" for this suite. 04/18/23 08:46:03.583
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:46:03.589
Apr 18 08:46:03.589: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename security-context-test 04/18/23 08:46:03.59
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:03.6
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:03.604
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Apr 18 08:46:03.614: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-140c86eb-4d95-432d-9207-1b203705bd6e" in namespace "security-context-test-9179" to be "Succeeded or Failed"
Apr 18 08:46:03.616: INFO: Pod "alpine-nnp-false-140c86eb-4d95-432d-9207-1b203705bd6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.509912ms
Apr 18 08:46:05.619: INFO: Pod "alpine-nnp-false-140c86eb-4d95-432d-9207-1b203705bd6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005559028s
Apr 18 08:46:07.620: INFO: Pod "alpine-nnp-false-140c86eb-4d95-432d-9207-1b203705bd6e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005897051s
Apr 18 08:46:09.619: INFO: Pod "alpine-nnp-false-140c86eb-4d95-432d-9207-1b203705bd6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.005557362s
Apr 18 08:46:09.620: INFO: Pod "alpine-nnp-false-140c86eb-4d95-432d-9207-1b203705bd6e" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 18 08:46:09.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9179" for this suite. 04/18/23 08:46:09.629
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":90,"skipped":1551,"failed":0}
------------------------------
• [SLOW TEST] [6.044 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:46:03.589
    Apr 18 08:46:03.589: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename security-context-test 04/18/23 08:46:03.59
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:03.6
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:03.604
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Apr 18 08:46:03.614: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-140c86eb-4d95-432d-9207-1b203705bd6e" in namespace "security-context-test-9179" to be "Succeeded or Failed"
    Apr 18 08:46:03.616: INFO: Pod "alpine-nnp-false-140c86eb-4d95-432d-9207-1b203705bd6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.509912ms
    Apr 18 08:46:05.619: INFO: Pod "alpine-nnp-false-140c86eb-4d95-432d-9207-1b203705bd6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005559028s
    Apr 18 08:46:07.620: INFO: Pod "alpine-nnp-false-140c86eb-4d95-432d-9207-1b203705bd6e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005897051s
    Apr 18 08:46:09.619: INFO: Pod "alpine-nnp-false-140c86eb-4d95-432d-9207-1b203705bd6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.005557362s
    Apr 18 08:46:09.620: INFO: Pod "alpine-nnp-false-140c86eb-4d95-432d-9207-1b203705bd6e" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 18 08:46:09.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-9179" for this suite. 04/18/23 08:46:09.629
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:46:09.633
Apr 18 08:46:09.633: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename disruption 04/18/23 08:46:09.634
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:09.645
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:09.649
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 04/18/23 08:46:09.656
STEP: Updating PodDisruptionBudget status 04/18/23 08:46:11.662
STEP: Waiting for all pods to be running 04/18/23 08:46:11.668
Apr 18 08:46:11.671: INFO: running pods: 0 < 1
STEP: locating a running pod 04/18/23 08:46:13.675
STEP: Waiting for the pdb to be processed 04/18/23 08:46:13.686
STEP: Patching PodDisruptionBudget status 04/18/23 08:46:13.691
STEP: Waiting for the pdb to be processed 04/18/23 08:46:13.698
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 18 08:46:13.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9337" for this suite. 04/18/23 08:46:13.706
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":91,"skipped":1563,"failed":0}
------------------------------
• [4.078 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:46:09.633
    Apr 18 08:46:09.633: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename disruption 04/18/23 08:46:09.634
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:09.645
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:09.649
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 04/18/23 08:46:09.656
    STEP: Updating PodDisruptionBudget status 04/18/23 08:46:11.662
    STEP: Waiting for all pods to be running 04/18/23 08:46:11.668
    Apr 18 08:46:11.671: INFO: running pods: 0 < 1
    STEP: locating a running pod 04/18/23 08:46:13.675
    STEP: Waiting for the pdb to be processed 04/18/23 08:46:13.686
    STEP: Patching PodDisruptionBudget status 04/18/23 08:46:13.691
    STEP: Waiting for the pdb to be processed 04/18/23 08:46:13.698
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 18 08:46:13.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-9337" for this suite. 04/18/23 08:46:13.706
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:46:13.712
Apr 18 08:46:13.712: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename runtimeclass 04/18/23 08:46:13.713
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:13.721
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:13.725
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 04/18/23 08:46:13.728
STEP: getting /apis/node.k8s.io 04/18/23 08:46:13.731
STEP: getting /apis/node.k8s.io/v1 04/18/23 08:46:13.733
STEP: creating 04/18/23 08:46:13.735
STEP: watching 04/18/23 08:46:13.751
Apr 18 08:46:13.751: INFO: starting watch
STEP: getting 04/18/23 08:46:13.756
STEP: listing 04/18/23 08:46:13.759
STEP: patching 04/18/23 08:46:13.762
STEP: updating 04/18/23 08:46:13.765
Apr 18 08:46:13.769: INFO: waiting for watch events with expected annotations
STEP: deleting 04/18/23 08:46:13.769
STEP: deleting a collection 04/18/23 08:46:13.779
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 18 08:46:13.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-9954" for this suite. 04/18/23 08:46:13.792
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":92,"skipped":1569,"failed":0}
------------------------------
• [0.084 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:46:13.712
    Apr 18 08:46:13.712: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename runtimeclass 04/18/23 08:46:13.713
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:13.721
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:13.725
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 04/18/23 08:46:13.728
    STEP: getting /apis/node.k8s.io 04/18/23 08:46:13.731
    STEP: getting /apis/node.k8s.io/v1 04/18/23 08:46:13.733
    STEP: creating 04/18/23 08:46:13.735
    STEP: watching 04/18/23 08:46:13.751
    Apr 18 08:46:13.751: INFO: starting watch
    STEP: getting 04/18/23 08:46:13.756
    STEP: listing 04/18/23 08:46:13.759
    STEP: patching 04/18/23 08:46:13.762
    STEP: updating 04/18/23 08:46:13.765
    Apr 18 08:46:13.769: INFO: waiting for watch events with expected annotations
    STEP: deleting 04/18/23 08:46:13.769
    STEP: deleting a collection 04/18/23 08:46:13.779
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 18 08:46:13.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-9954" for this suite. 04/18/23 08:46:13.792
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:46:13.796
Apr 18 08:46:13.796: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename secrets 04/18/23 08:46:13.796
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:13.811
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:13.815
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-941d373f-5270-4059-a46e-5ab6d90274ab 04/18/23 08:46:13.819
STEP: Creating a pod to test consume secrets 04/18/23 08:46:13.823
Apr 18 08:46:13.830: INFO: Waiting up to 5m0s for pod "pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f" in namespace "secrets-5181" to be "Succeeded or Failed"
Apr 18 08:46:13.832: INFO: Pod "pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.359979ms
Apr 18 08:46:15.836: INFO: Pod "pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006294288s
Apr 18 08:46:17.836: INFO: Pod "pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005623654s
STEP: Saw pod success 04/18/23 08:46:17.836
Apr 18 08:46:17.836: INFO: Pod "pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f" satisfied condition "Succeeded or Failed"
Apr 18 08:46:17.839: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 08:46:17.844
Apr 18 08:46:17.855: INFO: Waiting for pod pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f to disappear
Apr 18 08:46:17.857: INFO: Pod pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 08:46:17.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5181" for this suite. 04/18/23 08:46:17.862
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":93,"skipped":1573,"failed":0}
------------------------------
• [4.071 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:46:13.796
    Apr 18 08:46:13.796: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename secrets 04/18/23 08:46:13.796
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:13.811
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:13.815
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-941d373f-5270-4059-a46e-5ab6d90274ab 04/18/23 08:46:13.819
    STEP: Creating a pod to test consume secrets 04/18/23 08:46:13.823
    Apr 18 08:46:13.830: INFO: Waiting up to 5m0s for pod "pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f" in namespace "secrets-5181" to be "Succeeded or Failed"
    Apr 18 08:46:13.832: INFO: Pod "pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.359979ms
    Apr 18 08:46:15.836: INFO: Pod "pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006294288s
    Apr 18 08:46:17.836: INFO: Pod "pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005623654s
    STEP: Saw pod success 04/18/23 08:46:17.836
    Apr 18 08:46:17.836: INFO: Pod "pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f" satisfied condition "Succeeded or Failed"
    Apr 18 08:46:17.839: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 08:46:17.844
    Apr 18 08:46:17.855: INFO: Waiting for pod pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f to disappear
    Apr 18 08:46:17.857: INFO: Pod pod-secrets-a35cd8e3-6613-4393-9714-616e6eaa484f no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 08:46:17.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5181" for this suite. 04/18/23 08:46:17.862
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:46:17.868
Apr 18 08:46:17.868: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename job 04/18/23 08:46:17.869
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:17.878
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:17.881
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 04/18/23 08:46:17.885
STEP: Ensuring job reaches completions 04/18/23 08:46:17.889
STEP: Ensuring pods with index for job exist 04/18/23 08:46:27.893
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 18 08:46:27.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4194" for this suite. 04/18/23 08:46:27.901
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":94,"skipped":1591,"failed":0}
------------------------------
• [SLOW TEST] [10.039 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:46:17.868
    Apr 18 08:46:17.868: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename job 04/18/23 08:46:17.869
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:17.878
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:17.881
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 04/18/23 08:46:17.885
    STEP: Ensuring job reaches completions 04/18/23 08:46:17.889
    STEP: Ensuring pods with index for job exist 04/18/23 08:46:27.893
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 18 08:46:27.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-4194" for this suite. 04/18/23 08:46:27.901
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:46:27.908
Apr 18 08:46:27.908: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 08:46:27.909
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:27.919
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:27.922
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Apr 18 08:46:27.926: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 04/18/23 08:46:30.115
Apr 18 08:46:30.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 create -f -'
Apr 18 08:46:30.906: INFO: stderr: ""
Apr 18 08:46:30.906: INFO: stdout: "e2e-test-crd-publish-openapi-2419-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 18 08:46:30.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 delete e2e-test-crd-publish-openapi-2419-crds test-foo'
Apr 18 08:46:30.968: INFO: stderr: ""
Apr 18 08:46:30.968: INFO: stdout: "e2e-test-crd-publish-openapi-2419-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Apr 18 08:46:30.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 apply -f -'
Apr 18 08:46:31.166: INFO: stderr: ""
Apr 18 08:46:31.166: INFO: stdout: "e2e-test-crd-publish-openapi-2419-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 18 08:46:31.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 delete e2e-test-crd-publish-openapi-2419-crds test-foo'
Apr 18 08:46:31.227: INFO: stderr: ""
Apr 18 08:46:31.227: INFO: stdout: "e2e-test-crd-publish-openapi-2419-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 04/18/23 08:46:31.227
Apr 18 08:46:31.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 create -f -'
Apr 18 08:46:31.405: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 04/18/23 08:46:31.405
Apr 18 08:46:31.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 create -f -'
Apr 18 08:46:31.553: INFO: rc: 1
Apr 18 08:46:31.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 apply -f -'
Apr 18 08:46:31.723: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 04/18/23 08:46:31.723
Apr 18 08:46:31.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 create -f -'
Apr 18 08:46:31.898: INFO: rc: 1
Apr 18 08:46:31.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 apply -f -'
Apr 18 08:46:32.056: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 04/18/23 08:46:32.056
Apr 18 08:46:32.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 explain e2e-test-crd-publish-openapi-2419-crds'
Apr 18 08:46:32.215: INFO: stderr: ""
Apr 18 08:46:32.215: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2419-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 04/18/23 08:46:32.215
Apr 18 08:46:32.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 explain e2e-test-crd-publish-openapi-2419-crds.metadata'
Apr 18 08:46:32.366: INFO: stderr: ""
Apr 18 08:46:32.366: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2419-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Apr 18 08:46:32.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 explain e2e-test-crd-publish-openapi-2419-crds.spec'
Apr 18 08:46:32.530: INFO: stderr: ""
Apr 18 08:46:32.530: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2419-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Apr 18 08:46:32.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 explain e2e-test-crd-publish-openapi-2419-crds.spec.bars'
Apr 18 08:46:32.690: INFO: stderr: ""
Apr 18 08:46:32.690: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2419-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 04/18/23 08:46:32.69
Apr 18 08:46:32.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 explain e2e-test-crd-publish-openapi-2419-crds.spec.bars2'
Apr 18 08:46:32.845: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 08:46:36.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3500" for this suite. 04/18/23 08:46:36.104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":95,"skipped":1613,"failed":0}
------------------------------
• [SLOW TEST] [8.201 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:46:27.908
    Apr 18 08:46:27.908: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 08:46:27.909
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:27.919
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:27.922
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Apr 18 08:46:27.926: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 04/18/23 08:46:30.115
    Apr 18 08:46:30.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 create -f -'
    Apr 18 08:46:30.906: INFO: stderr: ""
    Apr 18 08:46:30.906: INFO: stdout: "e2e-test-crd-publish-openapi-2419-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Apr 18 08:46:30.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 delete e2e-test-crd-publish-openapi-2419-crds test-foo'
    Apr 18 08:46:30.968: INFO: stderr: ""
    Apr 18 08:46:30.968: INFO: stdout: "e2e-test-crd-publish-openapi-2419-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Apr 18 08:46:30.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 apply -f -'
    Apr 18 08:46:31.166: INFO: stderr: ""
    Apr 18 08:46:31.166: INFO: stdout: "e2e-test-crd-publish-openapi-2419-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Apr 18 08:46:31.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 delete e2e-test-crd-publish-openapi-2419-crds test-foo'
    Apr 18 08:46:31.227: INFO: stderr: ""
    Apr 18 08:46:31.227: INFO: stdout: "e2e-test-crd-publish-openapi-2419-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 04/18/23 08:46:31.227
    Apr 18 08:46:31.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 create -f -'
    Apr 18 08:46:31.405: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 04/18/23 08:46:31.405
    Apr 18 08:46:31.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 create -f -'
    Apr 18 08:46:31.553: INFO: rc: 1
    Apr 18 08:46:31.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 apply -f -'
    Apr 18 08:46:31.723: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 04/18/23 08:46:31.723
    Apr 18 08:46:31.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 create -f -'
    Apr 18 08:46:31.898: INFO: rc: 1
    Apr 18 08:46:31.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 --namespace=crd-publish-openapi-3500 apply -f -'
    Apr 18 08:46:32.056: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 04/18/23 08:46:32.056
    Apr 18 08:46:32.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 explain e2e-test-crd-publish-openapi-2419-crds'
    Apr 18 08:46:32.215: INFO: stderr: ""
    Apr 18 08:46:32.215: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2419-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 04/18/23 08:46:32.215
    Apr 18 08:46:32.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 explain e2e-test-crd-publish-openapi-2419-crds.metadata'
    Apr 18 08:46:32.366: INFO: stderr: ""
    Apr 18 08:46:32.366: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2419-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Apr 18 08:46:32.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 explain e2e-test-crd-publish-openapi-2419-crds.spec'
    Apr 18 08:46:32.530: INFO: stderr: ""
    Apr 18 08:46:32.530: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2419-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Apr 18 08:46:32.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 explain e2e-test-crd-publish-openapi-2419-crds.spec.bars'
    Apr 18 08:46:32.690: INFO: stderr: ""
    Apr 18 08:46:32.690: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2419-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 04/18/23 08:46:32.69
    Apr 18 08:46:32.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-3500 explain e2e-test-crd-publish-openapi-2419-crds.spec.bars2'
    Apr 18 08:46:32.845: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 08:46:36.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-3500" for this suite. 04/18/23 08:46:36.104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:46:36.11
Apr 18 08:46:36.110: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 08:46:36.11
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:36.122
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:36.126
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 08:46:36.139
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:46:36.36
STEP: Deploying the webhook pod 04/18/23 08:46:36.366
STEP: Wait for the deployment to be ready 04/18/23 08:46:36.377
Apr 18 08:46:36.383: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 08:46:38.392
STEP: Verifying the service has paired with the endpoint 04/18/23 08:46:38.4
Apr 18 08:46:39.400: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 04/18/23 08:46:39.403
STEP: create a namespace for the webhook 04/18/23 08:46:39.416
STEP: create a configmap should be unconditionally rejected by the webhook 04/18/23 08:46:39.421
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 08:46:39.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4656" for this suite. 04/18/23 08:46:39.534
STEP: Destroying namespace "webhook-4656-markers" for this suite. 04/18/23 08:46:39.538
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":96,"skipped":1629,"failed":0}
------------------------------
• [3.457 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:46:36.11
    Apr 18 08:46:36.110: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 08:46:36.11
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:36.122
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:36.126
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 08:46:36.139
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:46:36.36
    STEP: Deploying the webhook pod 04/18/23 08:46:36.366
    STEP: Wait for the deployment to be ready 04/18/23 08:46:36.377
    Apr 18 08:46:36.383: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 08:46:38.392
    STEP: Verifying the service has paired with the endpoint 04/18/23 08:46:38.4
    Apr 18 08:46:39.400: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 04/18/23 08:46:39.403
    STEP: create a namespace for the webhook 04/18/23 08:46:39.416
    STEP: create a configmap should be unconditionally rejected by the webhook 04/18/23 08:46:39.421
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 08:46:39.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4656" for this suite. 04/18/23 08:46:39.534
    STEP: Destroying namespace "webhook-4656-markers" for this suite. 04/18/23 08:46:39.538
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:46:39.567
Apr 18 08:46:39.567: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename deployment 04/18/23 08:46:39.568
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:39.588
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:39.592
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 04/18/23 08:46:39.598
Apr 18 08:46:39.598: INFO: Creating simple deployment test-deployment-fm7xh
Apr 18 08:46:39.608: INFO: deployment "test-deployment-fm7xh" doesn't have the required revision set
STEP: Getting /status 04/18/23 08:46:41.618
Apr 18 08:46:41.621: INFO: Deployment test-deployment-fm7xh has Conditions: [{Available True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fm7xh-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 04/18/23 08:46:41.621
Apr 18 08:46:41.629: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 46, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 46, 41, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 46, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 46, 39, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-fm7xh-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 04/18/23 08:46:41.629
Apr 18 08:46:41.631: INFO: Observed &Deployment event: ADDED
Apr 18 08:46:41.631: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fm7xh-777898ffcc"}
Apr 18 08:46:41.632: INFO: Observed &Deployment event: MODIFIED
Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fm7xh-777898ffcc"}
Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 18 08:46:41.632: INFO: Observed &Deployment event: MODIFIED
Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-fm7xh-777898ffcc" is progressing.}
Apr 18 08:46:41.632: INFO: Observed &Deployment event: MODIFIED
Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fm7xh-777898ffcc" has successfully progressed.}
Apr 18 08:46:41.632: INFO: Observed &Deployment event: MODIFIED
Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fm7xh-777898ffcc" has successfully progressed.}
Apr 18 08:46:41.632: INFO: Found Deployment test-deployment-fm7xh in namespace deployment-9004 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 18 08:46:41.632: INFO: Deployment test-deployment-fm7xh has an updated status
STEP: patching the Statefulset Status 04/18/23 08:46:41.632
Apr 18 08:46:41.632: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 18 08:46:41.639: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 04/18/23 08:46:41.639
Apr 18 08:46:41.643: INFO: Observed &Deployment event: ADDED
Apr 18 08:46:41.643: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fm7xh-777898ffcc"}
Apr 18 08:46:41.643: INFO: Observed &Deployment event: MODIFIED
Apr 18 08:46:41.643: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fm7xh-777898ffcc"}
Apr 18 08:46:41.643: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 18 08:46:41.643: INFO: Observed &Deployment event: MODIFIED
Apr 18 08:46:41.643: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 18 08:46:41.643: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-fm7xh-777898ffcc" is progressing.}
Apr 18 08:46:41.644: INFO: Observed &Deployment event: MODIFIED
Apr 18 08:46:41.644: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 18 08:46:41.644: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fm7xh-777898ffcc" has successfully progressed.}
Apr 18 08:46:41.644: INFO: Observed &Deployment event: MODIFIED
Apr 18 08:46:41.644: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 18 08:46:41.644: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fm7xh-777898ffcc" has successfully progressed.}
Apr 18 08:46:41.644: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 18 08:46:41.644: INFO: Observed &Deployment event: MODIFIED
Apr 18 08:46:41.644: INFO: Found deployment test-deployment-fm7xh in namespace deployment-9004 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Apr 18 08:46:41.644: INFO: Deployment test-deployment-fm7xh has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 08:46:41.647: INFO: Deployment "test-deployment-fm7xh":
&Deployment{ObjectMeta:{test-deployment-fm7xh  deployment-9004  983c8fa5-21d7-4f1b-bad6-be35c9a84013 4179375 1 2023-04-18 08:46:39 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-18 08:46:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-04-18 08:46:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-04-18 08:46:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004997068 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-fm7xh-777898ffcc",LastUpdateTime:2023-04-18 08:46:41 +0000 UTC,LastTransitionTime:2023-04-18 08:46:41 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 18 08:46:41.655: INFO: New ReplicaSet "test-deployment-fm7xh-777898ffcc" of Deployment "test-deployment-fm7xh":
&ReplicaSet{ObjectMeta:{test-deployment-fm7xh-777898ffcc  deployment-9004  924414e3-1655-4f96-8693-b9f862816795 4179364 1 2023-04-18 08:46:39 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-fm7xh 983c8fa5-21d7-4f1b-bad6-be35c9a84013 0xc004997667 0xc004997668}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:46:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"983c8fa5-21d7-4f1b-bad6-be35c9a84013\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:46:41 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049978a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 18 08:46:41.658: INFO: Pod "test-deployment-fm7xh-777898ffcc-g22qj" is available:
&Pod{ObjectMeta:{test-deployment-fm7xh-777898ffcc-g22qj test-deployment-fm7xh-777898ffcc- deployment-9004  86306ba5-00fb-457d-88a2-88a826225068 4179363 0 2023-04-18 08:46:39 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-fm7xh-777898ffcc 924414e3-1655-4f96-8693-b9f862816795 0xc0049beab7 0xc0049beab8}] [] [{kube-controller-manager Update v1 2023-04-18 08:46:39 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"924414e3-1655-4f96-8693-b9f862816795\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:46:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.3\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s9qdm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s9qdm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:46:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:46:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:46:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:46:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.3,StartTime:2023-04-18 08:46:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:46:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://4b26c45394d2d05becbb83e51611a0a0b18576a8ae6d49dc7ece33738f1a41ac,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.3,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 08:46:41.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9004" for this suite. 04/18/23 08:46:41.661
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":97,"skipped":1630,"failed":0}
------------------------------
• [2.098 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:46:39.567
    Apr 18 08:46:39.567: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename deployment 04/18/23 08:46:39.568
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:39.588
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:39.592
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 04/18/23 08:46:39.598
    Apr 18 08:46:39.598: INFO: Creating simple deployment test-deployment-fm7xh
    Apr 18 08:46:39.608: INFO: deployment "test-deployment-fm7xh" doesn't have the required revision set
    STEP: Getting /status 04/18/23 08:46:41.618
    Apr 18 08:46:41.621: INFO: Deployment test-deployment-fm7xh has Conditions: [{Available True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fm7xh-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 04/18/23 08:46:41.621
    Apr 18 08:46:41.629: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 46, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 46, 41, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 8, 46, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 8, 46, 39, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-fm7xh-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 04/18/23 08:46:41.629
    Apr 18 08:46:41.631: INFO: Observed &Deployment event: ADDED
    Apr 18 08:46:41.631: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fm7xh-777898ffcc"}
    Apr 18 08:46:41.632: INFO: Observed &Deployment event: MODIFIED
    Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fm7xh-777898ffcc"}
    Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 18 08:46:41.632: INFO: Observed &Deployment event: MODIFIED
    Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-fm7xh-777898ffcc" is progressing.}
    Apr 18 08:46:41.632: INFO: Observed &Deployment event: MODIFIED
    Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fm7xh-777898ffcc" has successfully progressed.}
    Apr 18 08:46:41.632: INFO: Observed &Deployment event: MODIFIED
    Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 18 08:46:41.632: INFO: Observed Deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fm7xh-777898ffcc" has successfully progressed.}
    Apr 18 08:46:41.632: INFO: Found Deployment test-deployment-fm7xh in namespace deployment-9004 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 18 08:46:41.632: INFO: Deployment test-deployment-fm7xh has an updated status
    STEP: patching the Statefulset Status 04/18/23 08:46:41.632
    Apr 18 08:46:41.632: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 18 08:46:41.639: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 04/18/23 08:46:41.639
    Apr 18 08:46:41.643: INFO: Observed &Deployment event: ADDED
    Apr 18 08:46:41.643: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fm7xh-777898ffcc"}
    Apr 18 08:46:41.643: INFO: Observed &Deployment event: MODIFIED
    Apr 18 08:46:41.643: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-fm7xh-777898ffcc"}
    Apr 18 08:46:41.643: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 18 08:46:41.643: INFO: Observed &Deployment event: MODIFIED
    Apr 18 08:46:41.643: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 18 08:46:41.643: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:39 +0000 UTC 2023-04-18 08:46:39 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-fm7xh-777898ffcc" is progressing.}
    Apr 18 08:46:41.644: INFO: Observed &Deployment event: MODIFIED
    Apr 18 08:46:41.644: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 18 08:46:41.644: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fm7xh-777898ffcc" has successfully progressed.}
    Apr 18 08:46:41.644: INFO: Observed &Deployment event: MODIFIED
    Apr 18 08:46:41.644: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 18 08:46:41.644: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 08:46:41 +0000 UTC 2023-04-18 08:46:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-fm7xh-777898ffcc" has successfully progressed.}
    Apr 18 08:46:41.644: INFO: Observed deployment test-deployment-fm7xh in namespace deployment-9004 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 18 08:46:41.644: INFO: Observed &Deployment event: MODIFIED
    Apr 18 08:46:41.644: INFO: Found deployment test-deployment-fm7xh in namespace deployment-9004 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Apr 18 08:46:41.644: INFO: Deployment test-deployment-fm7xh has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 08:46:41.647: INFO: Deployment "test-deployment-fm7xh":
    &Deployment{ObjectMeta:{test-deployment-fm7xh  deployment-9004  983c8fa5-21d7-4f1b-bad6-be35c9a84013 4179375 1 2023-04-18 08:46:39 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-18 08:46:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-04-18 08:46:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-04-18 08:46:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004997068 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-fm7xh-777898ffcc",LastUpdateTime:2023-04-18 08:46:41 +0000 UTC,LastTransitionTime:2023-04-18 08:46:41 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 18 08:46:41.655: INFO: New ReplicaSet "test-deployment-fm7xh-777898ffcc" of Deployment "test-deployment-fm7xh":
    &ReplicaSet{ObjectMeta:{test-deployment-fm7xh-777898ffcc  deployment-9004  924414e3-1655-4f96-8693-b9f862816795 4179364 1 2023-04-18 08:46:39 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-fm7xh 983c8fa5-21d7-4f1b-bad6-be35c9a84013 0xc004997667 0xc004997668}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:46:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"983c8fa5-21d7-4f1b-bad6-be35c9a84013\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:46:41 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049978a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 08:46:41.658: INFO: Pod "test-deployment-fm7xh-777898ffcc-g22qj" is available:
    &Pod{ObjectMeta:{test-deployment-fm7xh-777898ffcc-g22qj test-deployment-fm7xh-777898ffcc- deployment-9004  86306ba5-00fb-457d-88a2-88a826225068 4179363 0 2023-04-18 08:46:39 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-fm7xh-777898ffcc 924414e3-1655-4f96-8693-b9f862816795 0xc0049beab7 0xc0049beab8}] [] [{kube-controller-manager Update v1 2023-04-18 08:46:39 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"924414e3-1655-4f96-8693-b9f862816795\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:46:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.3\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s9qdm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s9qdm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:46:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:46:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:46:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:46:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.3,StartTime:2023-04-18 08:46:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:46:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://4b26c45394d2d05becbb83e51611a0a0b18576a8ae6d49dc7ece33738f1a41ac,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.3,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 08:46:41.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9004" for this suite. 04/18/23 08:46:41.661
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:46:41.667
Apr 18 08:46:41.667: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename gc 04/18/23 08:46:41.668
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:41.684
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:41.687
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 04/18/23 08:46:41.693
STEP: Wait for the Deployment to create new ReplicaSet 04/18/23 08:46:41.697
STEP: delete the deployment 04/18/23 08:46:41.7
STEP: wait for all rs to be garbage collected 04/18/23 08:46:41.707
STEP: expected 0 rs, got 1 rs 04/18/23 08:46:41.716
STEP: expected 0 pods, got 2 pods 04/18/23 08:46:41.723
STEP: Gathering metrics 04/18/23 08:46:42.234
W0418 08:46:42.242713      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 18 08:46:42.242: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 18 08:46:42.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1176" for this suite. 04/18/23 08:46:42.247
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":98,"skipped":1671,"failed":0}
------------------------------
• [0.587 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:46:41.667
    Apr 18 08:46:41.667: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename gc 04/18/23 08:46:41.668
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:41.684
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:41.687
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 04/18/23 08:46:41.693
    STEP: Wait for the Deployment to create new ReplicaSet 04/18/23 08:46:41.697
    STEP: delete the deployment 04/18/23 08:46:41.7
    STEP: wait for all rs to be garbage collected 04/18/23 08:46:41.707
    STEP: expected 0 rs, got 1 rs 04/18/23 08:46:41.716
    STEP: expected 0 pods, got 2 pods 04/18/23 08:46:41.723
    STEP: Gathering metrics 04/18/23 08:46:42.234
    W0418 08:46:42.242713      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 18 08:46:42.242: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 18 08:46:42.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1176" for this suite. 04/18/23 08:46:42.247
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:46:42.255
Apr 18 08:46:42.255: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-runtime 04/18/23 08:46:42.256
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:42.264
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:42.268
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 04/18/23 08:46:42.271
STEP: wait for the container to reach Succeeded 04/18/23 08:46:42.278
STEP: get the container status 04/18/23 08:46:45.291
STEP: the container should be terminated 04/18/23 08:46:45.294
STEP: the termination message should be set 04/18/23 08:46:45.294
Apr 18 08:46:45.294: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 04/18/23 08:46:45.294
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 18 08:46:45.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3662" for this suite. 04/18/23 08:46:45.309
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":99,"skipped":1702,"failed":0}
------------------------------
• [3.058 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:46:42.255
    Apr 18 08:46:42.255: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-runtime 04/18/23 08:46:42.256
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:42.264
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:42.268
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 04/18/23 08:46:42.271
    STEP: wait for the container to reach Succeeded 04/18/23 08:46:42.278
    STEP: get the container status 04/18/23 08:46:45.291
    STEP: the container should be terminated 04/18/23 08:46:45.294
    STEP: the termination message should be set 04/18/23 08:46:45.294
    Apr 18 08:46:45.294: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 04/18/23 08:46:45.294
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 18 08:46:45.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-3662" for this suite. 04/18/23 08:46:45.309
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:46:45.315
Apr 18 08:46:45.315: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 08:46:45.315
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:45.325
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:45.329
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 04/18/23 08:46:45.332
Apr 18 08:46:45.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097" in namespace "projected-7958" to be "Succeeded or Failed"
Apr 18 08:46:45.342: INFO: Pod "downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097": Phase="Pending", Reason="", readiness=false. Elapsed: 2.716101ms
Apr 18 08:46:47.346: INFO: Pod "downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00698273s
Apr 18 08:46:49.346: INFO: Pod "downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007358922s
STEP: Saw pod success 04/18/23 08:46:49.346
Apr 18 08:46:49.346: INFO: Pod "downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097" satisfied condition "Succeeded or Failed"
Apr 18 08:46:49.349: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097 container client-container: <nil>
STEP: delete the pod 04/18/23 08:46:49.354
Apr 18 08:46:49.365: INFO: Waiting for pod downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097 to disappear
Apr 18 08:46:49.367: INFO: Pod downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 08:46:49.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7958" for this suite. 04/18/23 08:46:49.371
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":100,"skipped":1720,"failed":0}
------------------------------
• [4.060 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:46:45.315
    Apr 18 08:46:45.315: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 08:46:45.315
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:45.325
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:45.329
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 04/18/23 08:46:45.332
    Apr 18 08:46:45.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097" in namespace "projected-7958" to be "Succeeded or Failed"
    Apr 18 08:46:45.342: INFO: Pod "downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097": Phase="Pending", Reason="", readiness=false. Elapsed: 2.716101ms
    Apr 18 08:46:47.346: INFO: Pod "downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00698273s
    Apr 18 08:46:49.346: INFO: Pod "downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007358922s
    STEP: Saw pod success 04/18/23 08:46:49.346
    Apr 18 08:46:49.346: INFO: Pod "downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097" satisfied condition "Succeeded or Failed"
    Apr 18 08:46:49.349: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097 container client-container: <nil>
    STEP: delete the pod 04/18/23 08:46:49.354
    Apr 18 08:46:49.365: INFO: Waiting for pod downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097 to disappear
    Apr 18 08:46:49.367: INFO: Pod downwardapi-volume-cc5d3901-c427-4432-9c91-e803aa2b9097 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 08:46:49.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7958" for this suite. 04/18/23 08:46:49.371
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:46:49.376
Apr 18 08:46:49.376: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-runtime 04/18/23 08:46:49.377
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:49.385
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:49.389
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 04/18/23 08:46:49.392
STEP: wait for the container to reach Failed 04/18/23 08:46:49.397
STEP: get the container status 04/18/23 08:46:52.41
STEP: the container should be terminated 04/18/23 08:46:52.412
STEP: the termination message should be set 04/18/23 08:46:52.413
Apr 18 08:46:52.413: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 04/18/23 08:46:52.413
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 18 08:46:52.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4953" for this suite. 04/18/23 08:46:52.429
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":101,"skipped":1739,"failed":0}
------------------------------
• [3.056 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:46:49.376
    Apr 18 08:46:49.376: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-runtime 04/18/23 08:46:49.377
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:49.385
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:49.389
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 04/18/23 08:46:49.392
    STEP: wait for the container to reach Failed 04/18/23 08:46:49.397
    STEP: get the container status 04/18/23 08:46:52.41
    STEP: the container should be terminated 04/18/23 08:46:52.412
    STEP: the termination message should be set 04/18/23 08:46:52.413
    Apr 18 08:46:52.413: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 04/18/23 08:46:52.413
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 18 08:46:52.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-4953" for this suite. 04/18/23 08:46:52.429
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:46:52.433
Apr 18 08:46:52.433: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename ephemeral-containers-test 04/18/23 08:46:52.433
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:52.444
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:52.448
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 04/18/23 08:46:52.452
Apr 18 08:46:52.458: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4465" to be "running and ready"
Apr 18 08:46:52.460: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.26978ms
Apr 18 08:46:52.460: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:46:54.464: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.005695555s
Apr 18 08:46:54.464: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Apr 18 08:46:54.464: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 04/18/23 08:46:54.467
Apr 18 08:46:54.477: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4465" to be "container debugger running"
Apr 18 08:46:54.480: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.223818ms
Apr 18 08:46:56.484: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.006421682s
Apr 18 08:46:56.484: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 04/18/23 08:46:56.484
Apr 18 08:46:56.484: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-4465 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 08:46:56.484: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 08:46:56.484: INFO: ExecWithOptions: Clientset creation
Apr 18 08:46:56.484: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/ephemeral-containers-test-4465/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Apr 18 08:46:56.531: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 18 08:46:56.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-4465" for this suite. 04/18/23 08:46:56.54
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":102,"skipped":1747,"failed":0}
------------------------------
• [4.111 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:46:52.433
    Apr 18 08:46:52.433: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename ephemeral-containers-test 04/18/23 08:46:52.433
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:52.444
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:52.448
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 04/18/23 08:46:52.452
    Apr 18 08:46:52.458: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4465" to be "running and ready"
    Apr 18 08:46:52.460: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.26978ms
    Apr 18 08:46:52.460: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:46:54.464: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.005695555s
    Apr 18 08:46:54.464: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Apr 18 08:46:54.464: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 04/18/23 08:46:54.467
    Apr 18 08:46:54.477: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4465" to be "container debugger running"
    Apr 18 08:46:54.480: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.223818ms
    Apr 18 08:46:56.484: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.006421682s
    Apr 18 08:46:56.484: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 04/18/23 08:46:56.484
    Apr 18 08:46:56.484: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-4465 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 08:46:56.484: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 08:46:56.484: INFO: ExecWithOptions: Clientset creation
    Apr 18 08:46:56.484: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/ephemeral-containers-test-4465/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Apr 18 08:46:56.531: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 18 08:46:56.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-4465" for this suite. 04/18/23 08:46:56.54
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:46:56.544
Apr 18 08:46:56.545: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 08:46:56.545
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:56.559
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:56.562
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-ca804b27-1833-4ebc-95b8-f9f01f86a683 04/18/23 08:46:56.566
STEP: Creating a pod to test consume secrets 04/18/23 08:46:56.569
Apr 18 08:46:56.576: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996" in namespace "projected-6759" to be "Succeeded or Failed"
Apr 18 08:46:56.579: INFO: Pod "pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996": Phase="Pending", Reason="", readiness=false. Elapsed: 3.357703ms
Apr 18 08:46:58.583: INFO: Pod "pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007380396s
Apr 18 08:47:00.583: INFO: Pod "pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007279099s
STEP: Saw pod success 04/18/23 08:47:00.583
Apr 18 08:47:00.583: INFO: Pod "pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996" satisfied condition "Succeeded or Failed"
Apr 18 08:47:00.587: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/18/23 08:47:00.592
Apr 18 08:47:00.602: INFO: Waiting for pod pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996 to disappear
Apr 18 08:47:00.606: INFO: Pod pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 18 08:47:00.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6759" for this suite. 04/18/23 08:47:00.61
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":103,"skipped":1747,"failed":0}
------------------------------
• [4.070 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:46:56.544
    Apr 18 08:46:56.545: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 08:46:56.545
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:46:56.559
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:46:56.562
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-ca804b27-1833-4ebc-95b8-f9f01f86a683 04/18/23 08:46:56.566
    STEP: Creating a pod to test consume secrets 04/18/23 08:46:56.569
    Apr 18 08:46:56.576: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996" in namespace "projected-6759" to be "Succeeded or Failed"
    Apr 18 08:46:56.579: INFO: Pod "pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996": Phase="Pending", Reason="", readiness=false. Elapsed: 3.357703ms
    Apr 18 08:46:58.583: INFO: Pod "pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007380396s
    Apr 18 08:47:00.583: INFO: Pod "pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007279099s
    STEP: Saw pod success 04/18/23 08:47:00.583
    Apr 18 08:47:00.583: INFO: Pod "pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996" satisfied condition "Succeeded or Failed"
    Apr 18 08:47:00.587: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 08:47:00.592
    Apr 18 08:47:00.602: INFO: Waiting for pod pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996 to disappear
    Apr 18 08:47:00.606: INFO: Pod pod-projected-secrets-2731ee01-11c5-43ed-88e7-db99a6517996 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 18 08:47:00.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6759" for this suite. 04/18/23 08:47:00.61
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:47:00.617
Apr 18 08:47:00.617: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename containers 04/18/23 08:47:00.617
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:47:00.628
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:47:00.631
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 04/18/23 08:47:00.635
Apr 18 08:47:00.642: INFO: Waiting up to 5m0s for pod "client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0" in namespace "containers-6539" to be "Succeeded or Failed"
Apr 18 08:47:00.645: INFO: Pod "client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.547244ms
Apr 18 08:47:02.649: INFO: Pod "client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006822673s
Apr 18 08:47:04.650: INFO: Pod "client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008152993s
STEP: Saw pod success 04/18/23 08:47:04.65
Apr 18 08:47:04.650: INFO: Pod "client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0" satisfied condition "Succeeded or Failed"
Apr 18 08:47:04.653: INFO: Trying to get logs from node 192.168.1.152 pod client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 08:47:04.658
Apr 18 08:47:04.667: INFO: Waiting for pod client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0 to disappear
Apr 18 08:47:04.670: INFO: Pod client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 18 08:47:04.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6539" for this suite. 04/18/23 08:47:04.673
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":104,"skipped":1777,"failed":0}
------------------------------
• [4.060 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:47:00.617
    Apr 18 08:47:00.617: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename containers 04/18/23 08:47:00.617
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:47:00.628
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:47:00.631
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 04/18/23 08:47:00.635
    Apr 18 08:47:00.642: INFO: Waiting up to 5m0s for pod "client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0" in namespace "containers-6539" to be "Succeeded or Failed"
    Apr 18 08:47:00.645: INFO: Pod "client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.547244ms
    Apr 18 08:47:02.649: INFO: Pod "client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006822673s
    Apr 18 08:47:04.650: INFO: Pod "client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008152993s
    STEP: Saw pod success 04/18/23 08:47:04.65
    Apr 18 08:47:04.650: INFO: Pod "client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0" satisfied condition "Succeeded or Failed"
    Apr 18 08:47:04.653: INFO: Trying to get logs from node 192.168.1.152 pod client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 08:47:04.658
    Apr 18 08:47:04.667: INFO: Waiting for pod client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0 to disappear
    Apr 18 08:47:04.670: INFO: Pod client-containers-ebb1f508-1809-4c28-b7da-e799a91713f0 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 18 08:47:04.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-6539" for this suite. 04/18/23 08:47:04.673
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:47:04.678
Apr 18 08:47:04.678: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 08:47:04.678
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:47:04.688
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:47:04.691
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-83812ce6-c0f1-4e63-bec6-97167212077c 04/18/23 08:47:04.694
STEP: Creating a pod to test consume configMaps 04/18/23 08:47:04.698
Apr 18 08:47:04.704: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955" in namespace "projected-2835" to be "Succeeded or Failed"
Apr 18 08:47:04.706: INFO: Pod "pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955": Phase="Pending", Reason="", readiness=false. Elapsed: 2.399592ms
Apr 18 08:47:06.710: INFO: Pod "pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006240787s
Apr 18 08:47:08.710: INFO: Pod "pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00629133s
STEP: Saw pod success 04/18/23 08:47:08.71
Apr 18 08:47:08.710: INFO: Pod "pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955" satisfied condition "Succeeded or Failed"
Apr 18 08:47:08.713: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 08:47:08.719
Apr 18 08:47:08.731: INFO: Waiting for pod pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955 to disappear
Apr 18 08:47:08.733: INFO: Pod pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 08:47:08.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2835" for this suite. 04/18/23 08:47:08.737
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":105,"skipped":1785,"failed":0}
------------------------------
• [4.064 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:47:04.678
    Apr 18 08:47:04.678: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 08:47:04.678
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:47:04.688
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:47:04.691
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-83812ce6-c0f1-4e63-bec6-97167212077c 04/18/23 08:47:04.694
    STEP: Creating a pod to test consume configMaps 04/18/23 08:47:04.698
    Apr 18 08:47:04.704: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955" in namespace "projected-2835" to be "Succeeded or Failed"
    Apr 18 08:47:04.706: INFO: Pod "pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955": Phase="Pending", Reason="", readiness=false. Elapsed: 2.399592ms
    Apr 18 08:47:06.710: INFO: Pod "pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006240787s
    Apr 18 08:47:08.710: INFO: Pod "pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00629133s
    STEP: Saw pod success 04/18/23 08:47:08.71
    Apr 18 08:47:08.710: INFO: Pod "pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955" satisfied condition "Succeeded or Failed"
    Apr 18 08:47:08.713: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 08:47:08.719
    Apr 18 08:47:08.731: INFO: Waiting for pod pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955 to disappear
    Apr 18 08:47:08.733: INFO: Pod pod-projected-configmaps-58033d76-86f6-4f28-be25-286b347b7955 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 08:47:08.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2835" for this suite. 04/18/23 08:47:08.737
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:47:08.742
Apr 18 08:47:08.743: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename configmap 04/18/23 08:47:08.743
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:47:08.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:47:08.759
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-a46fca1e-7596-4c8b-af2c-f363d3d5655f 04/18/23 08:47:08.766
STEP: Creating the pod 04/18/23 08:47:08.77
Apr 18 08:47:08.779: INFO: Waiting up to 5m0s for pod "pod-configmaps-589c1e87-6543-46e0-90f9-c9f69dd1a575" in namespace "configmap-4384" to be "running and ready"
Apr 18 08:47:08.783: INFO: Pod "pod-configmaps-589c1e87-6543-46e0-90f9-c9f69dd1a575": Phase="Pending", Reason="", readiness=false. Elapsed: 3.613709ms
Apr 18 08:47:08.783: INFO: The phase of Pod pod-configmaps-589c1e87-6543-46e0-90f9-c9f69dd1a575 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:47:10.787: INFO: Pod "pod-configmaps-589c1e87-6543-46e0-90f9-c9f69dd1a575": Phase="Running", Reason="", readiness=true. Elapsed: 2.008079226s
Apr 18 08:47:10.787: INFO: The phase of Pod pod-configmaps-589c1e87-6543-46e0-90f9-c9f69dd1a575 is Running (Ready = true)
Apr 18 08:47:10.788: INFO: Pod "pod-configmaps-589c1e87-6543-46e0-90f9-c9f69dd1a575" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-a46fca1e-7596-4c8b-af2c-f363d3d5655f 04/18/23 08:47:10.795
STEP: waiting to observe update in volume 04/18/23 08:47:10.799
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 08:47:12.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4384" for this suite. 04/18/23 08:47:12.818
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":106,"skipped":1786,"failed":0}
------------------------------
• [4.080 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:47:08.742
    Apr 18 08:47:08.743: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename configmap 04/18/23 08:47:08.743
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:47:08.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:47:08.759
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-a46fca1e-7596-4c8b-af2c-f363d3d5655f 04/18/23 08:47:08.766
    STEP: Creating the pod 04/18/23 08:47:08.77
    Apr 18 08:47:08.779: INFO: Waiting up to 5m0s for pod "pod-configmaps-589c1e87-6543-46e0-90f9-c9f69dd1a575" in namespace "configmap-4384" to be "running and ready"
    Apr 18 08:47:08.783: INFO: Pod "pod-configmaps-589c1e87-6543-46e0-90f9-c9f69dd1a575": Phase="Pending", Reason="", readiness=false. Elapsed: 3.613709ms
    Apr 18 08:47:08.783: INFO: The phase of Pod pod-configmaps-589c1e87-6543-46e0-90f9-c9f69dd1a575 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:47:10.787: INFO: Pod "pod-configmaps-589c1e87-6543-46e0-90f9-c9f69dd1a575": Phase="Running", Reason="", readiness=true. Elapsed: 2.008079226s
    Apr 18 08:47:10.787: INFO: The phase of Pod pod-configmaps-589c1e87-6543-46e0-90f9-c9f69dd1a575 is Running (Ready = true)
    Apr 18 08:47:10.788: INFO: Pod "pod-configmaps-589c1e87-6543-46e0-90f9-c9f69dd1a575" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-a46fca1e-7596-4c8b-af2c-f363d3d5655f 04/18/23 08:47:10.795
    STEP: waiting to observe update in volume 04/18/23 08:47:10.799
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 08:47:12.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4384" for this suite. 04/18/23 08:47:12.818
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:47:12.825
Apr 18 08:47:12.825: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename taint-single-pod 04/18/23 08:47:12.826
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:47:12.84
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:47:12.843
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Apr 18 08:47:12.847: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 18 08:48:12.871: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Apr 18 08:48:12.874: INFO: Starting informer...
STEP: Starting pod... 04/18/23 08:48:12.874
Apr 18 08:48:13.086: INFO: Pod is running on 192.168.1.152. Tainting Node
STEP: Trying to apply a taint on the Node 04/18/23 08:48:13.086
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 08:48:13.1
STEP: Waiting short time to make sure Pod is queued for deletion 04/18/23 08:48:13.102
Apr 18 08:48:13.103: INFO: Pod wasn't evicted. Proceeding
Apr 18 08:48:13.103: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 08:48:13.113
STEP: Waiting some time to make sure that toleration time passed. 04/18/23 08:48:13.117
Apr 18 08:49:28.118: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Apr 18 08:49:28.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-2458" for this suite. 04/18/23 08:49:28.124
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":107,"skipped":1814,"failed":0}
------------------------------
• [SLOW TEST] [135.307 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:47:12.825
    Apr 18 08:47:12.825: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename taint-single-pod 04/18/23 08:47:12.826
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:47:12.84
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:47:12.843
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Apr 18 08:47:12.847: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 18 08:48:12.871: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Apr 18 08:48:12.874: INFO: Starting informer...
    STEP: Starting pod... 04/18/23 08:48:12.874
    Apr 18 08:48:13.086: INFO: Pod is running on 192.168.1.152. Tainting Node
    STEP: Trying to apply a taint on the Node 04/18/23 08:48:13.086
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 08:48:13.1
    STEP: Waiting short time to make sure Pod is queued for deletion 04/18/23 08:48:13.102
    Apr 18 08:48:13.103: INFO: Pod wasn't evicted. Proceeding
    Apr 18 08:48:13.103: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 08:48:13.113
    STEP: Waiting some time to make sure that toleration time passed. 04/18/23 08:48:13.117
    Apr 18 08:49:28.118: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 08:49:28.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-2458" for this suite. 04/18/23 08:49:28.124
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:49:28.134
Apr 18 08:49:28.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename secrets 04/18/23 08:49:28.135
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:49:28.147
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:49:28.153
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-21b567da-e7ac-4fdf-86ce-2a5dfa3b540d 04/18/23 08:49:28.158
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 18 08:49:28.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3818" for this suite. 04/18/23 08:49:28.171
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":108,"skipped":1857,"failed":0}
------------------------------
• [0.045 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:49:28.134
    Apr 18 08:49:28.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename secrets 04/18/23 08:49:28.135
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:49:28.147
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:49:28.153
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-21b567da-e7ac-4fdf-86ce-2a5dfa3b540d 04/18/23 08:49:28.158
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 08:49:28.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3818" for this suite. 04/18/23 08:49:28.171
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:49:28.179
Apr 18 08:49:28.179: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename deployment 04/18/23 08:49:28.18
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:49:28.189
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:49:28.192
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 04/18/23 08:49:28.199
STEP: waiting for Deployment to be created 04/18/23 08:49:28.204
STEP: waiting for all Replicas to be Ready 04/18/23 08:49:28.207
Apr 18 08:49:28.209: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 08:49:28.209: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 08:49:28.214: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 08:49:28.214: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 08:49:28.234: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 08:49:28.234: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 08:49:28.258: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 08:49:28.258: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 08:49:29.327: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr 18 08:49:29.327: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr 18 08:49:29.661: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 04/18/23 08:49:29.661
W0418 08:49:29.687580      18 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 18 08:49:29.689: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 04/18/23 08:49:29.689
Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
Apr 18 08:49:29.692: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
Apr 18 08:49:29.692: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
Apr 18 08:49:29.692: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
Apr 18 08:49:29.692: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
Apr 18 08:49:29.702: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
Apr 18 08:49:29.702: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
Apr 18 08:49:29.719: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
Apr 18 08:49:29.719: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
Apr 18 08:49:29.732: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
Apr 18 08:49:29.732: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
Apr 18 08:49:29.764: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
Apr 18 08:49:29.764: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
Apr 18 08:49:30.340: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
Apr 18 08:49:30.340: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
Apr 18 08:49:30.361: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
STEP: listing Deployments 04/18/23 08:49:30.361
Apr 18 08:49:30.364: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 04/18/23 08:49:30.364
Apr 18 08:49:30.372: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 04/18/23 08:49:30.372
Apr 18 08:49:30.378: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 08:49:30.382: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 08:49:30.400: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 08:49:30.416: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 08:49:30.426: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 08:49:31.035: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 08:49:31.344: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 08:49:31.366: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 08:49:31.384: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 08:49:32.046: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 04/18/23 08:49:32.062
STEP: fetching the DeploymentStatus 04/18/23 08:49:32.068
Apr 18 08:49:32.072: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
Apr 18 08:49:32.072: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
Apr 18 08:49:32.072: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
Apr 18 08:49:32.073: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
Apr 18 08:49:32.073: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
Apr 18 08:49:32.073: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
Apr 18 08:49:32.073: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 3
Apr 18 08:49:32.073: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
Apr 18 08:49:32.073: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
Apr 18 08:49:32.073: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 3
STEP: deleting the Deployment 04/18/23 08:49:32.073
Apr 18 08:49:32.081: INFO: observed event type MODIFIED
Apr 18 08:49:32.081: INFO: observed event type MODIFIED
Apr 18 08:49:32.081: INFO: observed event type MODIFIED
Apr 18 08:49:32.081: INFO: observed event type MODIFIED
Apr 18 08:49:32.081: INFO: observed event type MODIFIED
Apr 18 08:49:32.081: INFO: observed event type MODIFIED
Apr 18 08:49:32.081: INFO: observed event type MODIFIED
Apr 18 08:49:32.082: INFO: observed event type MODIFIED
Apr 18 08:49:32.082: INFO: observed event type MODIFIED
Apr 18 08:49:32.082: INFO: observed event type MODIFIED
Apr 18 08:49:32.082: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 08:49:32.088: INFO: Log out all the ReplicaSets if there is no deployment created
Apr 18 08:49:32.091: INFO: ReplicaSet "test-deployment-54cc775c4b":
&ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-8422  5a180d12-125d-4059-98cf-8ba659edd56f 4180416 4 2023-04-18 08:49:29 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 1fdd411d-8c47-4418-b006-b6750d11c385 0xc005cdce47 0xc005cdce48}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:49:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1fdd411d-8c47-4418-b006-b6750d11c385\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:49:32 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005cdced0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Apr 18 08:49:32.095: INFO: pod: "test-deployment-54cc775c4b-5fmfj":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-5fmfj test-deployment-54cc775c4b- deployment-8422  b17f43fa-0d53-4872-8a2b-c11ac9887914 4180396 0 2023-04-18 08:49:29 +0000 UTC 2023-04-18 08:49:32 +0000 UTC 0xc00144cd48 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 5a180d12-125d-4059-98cf-8ba659edd56f 0xc00144d197 0xc00144d198}] [] [{kube-controller-manager Update v1 2023-04-18 08:49:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a180d12-125d-4059-98cf-8ba659edd56f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:49:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.16\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dmnmr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dmnmr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.16,StartTime:2023-04-18 08:49:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:49:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://3faba3242f9f97e0159a172c3314c1de241ca05af06ec0d1c31c1f99019ad9da,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.16,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 18 08:49:32.095: INFO: pod: "test-deployment-54cc775c4b-5z4hs":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-5z4hs test-deployment-54cc775c4b- deployment-8422  c5b2b733-67c4-47d4-85d3-d53733583b4a 4180413 0 2023-04-18 08:49:30 +0000 UTC 2023-04-18 08:49:33 +0000 UTC 0xc00144d9b8 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 5a180d12-125d-4059-98cf-8ba659edd56f 0xc00144dad7 0xc00144dad8}] [] [{kube-controller-manager Update v1 2023-04-18 08:49:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a180d12-125d-4059-98cf-8ba659edd56f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:49:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.59\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-46h24,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-46h24,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.29,PodIP:172.16.0.59,StartTime:2023-04-18 08:49:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:49:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://c0a655ef18f73f2b44289f7de95a0fb583565b1c9411ab52f881e8494802c605,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.59,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 18 08:49:32.095: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
&ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-8422  3593ad0e-294f-40d1-9b2e-f51f72f997a9 4180411 2 2023-04-18 08:49:30 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 1fdd411d-8c47-4418-b006-b6750d11c385 0xc005cdcf37 0xc005cdcf38}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:49:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1fdd411d-8c47-4418-b006-b6750d11c385\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:49:32 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005cdcfc0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Apr 18 08:49:32.098: INFO: pod: "test-deployment-7c7d8d58c8-k6nv5":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-k6nv5 test-deployment-7c7d8d58c8- deployment-8422  83317583-71eb-4609-9bdc-ddf7a267224e 4180410 0 2023-04-18 08:49:31 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 3593ad0e-294f-40d1-9b2e-f51f72f997a9 0xc005cdd397 0xc005cdd398}] [] [{kube-controller-manager Update v1 2023-04-18 08:49:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3593ad0e-294f-40d1-9b2e-f51f72f997a9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:49:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.60\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m2cn4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m2cn4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.29,PodIP:172.16.0.60,StartTime:2023-04-18 08:49:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:49:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://ecf82a941ecae39f893bece71d013466fedb697d68ae96d008488ad37901b49e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.60,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 18 08:49:32.098: INFO: pod: "test-deployment-7c7d8d58c8-sfd4h":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-sfd4h test-deployment-7c7d8d58c8- deployment-8422  c1851a6c-e185-470b-9470-d42aab5ead0a 4180393 0 2023-04-18 08:49:30 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 3593ad0e-294f-40d1-9b2e-f51f72f997a9 0xc005cdd597 0xc005cdd598}] [] [{kube-controller-manager Update v1 2023-04-18 08:49:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3593ad0e-294f-40d1-9b2e-f51f72f997a9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:49:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.17\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zdbrr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zdbrr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.17,StartTime:2023-04-18 08:49:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:49:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://0ddfef473918e5f9c3ec9338fb184e906603f965d1d28fe26c851571f0da950a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.17,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 18 08:49:32.098: INFO: ReplicaSet "test-deployment-8594bb6fdd":
&ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-8422  78a4c4cd-6998-4199-8626-5fa123fb9831 4180365 3 2023-04-18 08:49:28 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 1fdd411d-8c47-4418-b006-b6750d11c385 0xc005cdd027 0xc005cdd028}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:49:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1fdd411d-8c47-4418-b006-b6750d11c385\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:49:30 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005cdd0b0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Apr 18 08:49:32.104: INFO: pod: "test-deployment-8594bb6fdd-5mxc4":
&Pod{ObjectMeta:{test-deployment-8594bb6fdd-5mxc4 test-deployment-8594bb6fdd- deployment-8422  3b6b96f5-4838-4088-85d3-2f8637f26c6d 4180362 0 2023-04-18 08:49:28 +0000 UTC 2023-04-18 08:49:31 +0000 UTC 0xc0017ff3f8 map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-8594bb6fdd 78a4c4cd-6998-4199-8626-5fa123fb9831 0xc0017ff427 0xc0017ff428}] [] [{kube-controller-manager Update v1 2023-04-18 08:49:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78a4c4cd-6998-4199-8626-5fa123fb9831\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:49:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.216\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-78ncd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-78ncd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.84,PodIP:172.16.0.216,StartTime:2023-04-18 08:49:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:49:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://daa7fee76144739a8326bca4b87f9c3b1fea1e4c9766bb752ab68228508a55b2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.216,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 18 08:49:32.105: INFO: pod: "test-deployment-8594bb6fdd-ld7tc":
&Pod{ObjectMeta:{test-deployment-8594bb6fdd-ld7tc test-deployment-8594bb6fdd- deployment-8422  e62b914c-ec9e-4d9a-b8c9-1eb9345e1b2d 4180345 0 2023-04-18 08:49:28 +0000 UTC 2023-04-18 08:49:30 +0000 UTC 0xc0017ff628 map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-8594bb6fdd 78a4c4cd-6998-4199-8626-5fa123fb9831 0xc0017ff657 0xc0017ff658}] [] [{kube-controller-manager Update v1 2023-04-18 08:49:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78a4c4cd-6998-4199-8626-5fa123fb9831\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:49:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-75wlq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-75wlq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.15,StartTime:2023-04-18 08:49:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:49:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://2e4ece3c35b695742444203f8a7319ec6abc934dd903ca0b59abe04872a0e694,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.15,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 08:49:32.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8422" for this suite. 04/18/23 08:49:32.108
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":109,"skipped":1878,"failed":0}
------------------------------
• [3.933 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:49:28.179
    Apr 18 08:49:28.179: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename deployment 04/18/23 08:49:28.18
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:49:28.189
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:49:28.192
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 04/18/23 08:49:28.199
    STEP: waiting for Deployment to be created 04/18/23 08:49:28.204
    STEP: waiting for all Replicas to be Ready 04/18/23 08:49:28.207
    Apr 18 08:49:28.209: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 08:49:28.209: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 08:49:28.214: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 08:49:28.214: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 08:49:28.234: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 08:49:28.234: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 08:49:28.258: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 08:49:28.258: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 08:49:29.327: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Apr 18 08:49:29.327: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Apr 18 08:49:29.661: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 04/18/23 08:49:29.661
    W0418 08:49:29.687580      18 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 18 08:49:29.689: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 04/18/23 08:49:29.689
    Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
    Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
    Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
    Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
    Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
    Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
    Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
    Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 0
    Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
    Apr 18 08:49:29.691: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
    Apr 18 08:49:29.692: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
    Apr 18 08:49:29.692: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
    Apr 18 08:49:29.692: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
    Apr 18 08:49:29.692: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
    Apr 18 08:49:29.702: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
    Apr 18 08:49:29.702: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
    Apr 18 08:49:29.719: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
    Apr 18 08:49:29.719: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
    Apr 18 08:49:29.732: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
    Apr 18 08:49:29.732: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
    Apr 18 08:49:29.764: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
    Apr 18 08:49:29.764: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
    Apr 18 08:49:30.340: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
    Apr 18 08:49:30.340: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
    Apr 18 08:49:30.361: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
    STEP: listing Deployments 04/18/23 08:49:30.361
    Apr 18 08:49:30.364: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 04/18/23 08:49:30.364
    Apr 18 08:49:30.372: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 04/18/23 08:49:30.372
    Apr 18 08:49:30.378: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 08:49:30.382: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 08:49:30.400: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 08:49:30.416: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 08:49:30.426: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 08:49:31.035: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 08:49:31.344: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 08:49:31.366: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 08:49:31.384: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 08:49:32.046: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 04/18/23 08:49:32.062
    STEP: fetching the DeploymentStatus 04/18/23 08:49:32.068
    Apr 18 08:49:32.072: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
    Apr 18 08:49:32.072: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
    Apr 18 08:49:32.072: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
    Apr 18 08:49:32.073: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
    Apr 18 08:49:32.073: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 1
    Apr 18 08:49:32.073: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
    Apr 18 08:49:32.073: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 3
    Apr 18 08:49:32.073: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
    Apr 18 08:49:32.073: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 2
    Apr 18 08:49:32.073: INFO: observed Deployment test-deployment in namespace deployment-8422 with ReadyReplicas 3
    STEP: deleting the Deployment 04/18/23 08:49:32.073
    Apr 18 08:49:32.081: INFO: observed event type MODIFIED
    Apr 18 08:49:32.081: INFO: observed event type MODIFIED
    Apr 18 08:49:32.081: INFO: observed event type MODIFIED
    Apr 18 08:49:32.081: INFO: observed event type MODIFIED
    Apr 18 08:49:32.081: INFO: observed event type MODIFIED
    Apr 18 08:49:32.081: INFO: observed event type MODIFIED
    Apr 18 08:49:32.081: INFO: observed event type MODIFIED
    Apr 18 08:49:32.082: INFO: observed event type MODIFIED
    Apr 18 08:49:32.082: INFO: observed event type MODIFIED
    Apr 18 08:49:32.082: INFO: observed event type MODIFIED
    Apr 18 08:49:32.082: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 08:49:32.088: INFO: Log out all the ReplicaSets if there is no deployment created
    Apr 18 08:49:32.091: INFO: ReplicaSet "test-deployment-54cc775c4b":
    &ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-8422  5a180d12-125d-4059-98cf-8ba659edd56f 4180416 4 2023-04-18 08:49:29 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 1fdd411d-8c47-4418-b006-b6750d11c385 0xc005cdce47 0xc005cdce48}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:49:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1fdd411d-8c47-4418-b006-b6750d11c385\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:49:32 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005cdced0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Apr 18 08:49:32.095: INFO: pod: "test-deployment-54cc775c4b-5fmfj":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-5fmfj test-deployment-54cc775c4b- deployment-8422  b17f43fa-0d53-4872-8a2b-c11ac9887914 4180396 0 2023-04-18 08:49:29 +0000 UTC 2023-04-18 08:49:32 +0000 UTC 0xc00144cd48 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 5a180d12-125d-4059-98cf-8ba659edd56f 0xc00144d197 0xc00144d198}] [] [{kube-controller-manager Update v1 2023-04-18 08:49:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a180d12-125d-4059-98cf-8ba659edd56f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:49:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.16\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dmnmr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dmnmr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.16,StartTime:2023-04-18 08:49:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:49:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://3faba3242f9f97e0159a172c3314c1de241ca05af06ec0d1c31c1f99019ad9da,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.16,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 18 08:49:32.095: INFO: pod: "test-deployment-54cc775c4b-5z4hs":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-5z4hs test-deployment-54cc775c4b- deployment-8422  c5b2b733-67c4-47d4-85d3-d53733583b4a 4180413 0 2023-04-18 08:49:30 +0000 UTC 2023-04-18 08:49:33 +0000 UTC 0xc00144d9b8 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 5a180d12-125d-4059-98cf-8ba659edd56f 0xc00144dad7 0xc00144dad8}] [] [{kube-controller-manager Update v1 2023-04-18 08:49:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5a180d12-125d-4059-98cf-8ba659edd56f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:49:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.59\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-46h24,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-46h24,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.29,PodIP:172.16.0.59,StartTime:2023-04-18 08:49:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:49:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://c0a655ef18f73f2b44289f7de95a0fb583565b1c9411ab52f881e8494802c605,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.59,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 18 08:49:32.095: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
    &ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-8422  3593ad0e-294f-40d1-9b2e-f51f72f997a9 4180411 2 2023-04-18 08:49:30 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 1fdd411d-8c47-4418-b006-b6750d11c385 0xc005cdcf37 0xc005cdcf38}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:49:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1fdd411d-8c47-4418-b006-b6750d11c385\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:49:32 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005cdcfc0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

    Apr 18 08:49:32.098: INFO: pod: "test-deployment-7c7d8d58c8-k6nv5":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-k6nv5 test-deployment-7c7d8d58c8- deployment-8422  83317583-71eb-4609-9bdc-ddf7a267224e 4180410 0 2023-04-18 08:49:31 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 3593ad0e-294f-40d1-9b2e-f51f72f997a9 0xc005cdd397 0xc005cdd398}] [] [{kube-controller-manager Update v1 2023-04-18 08:49:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3593ad0e-294f-40d1-9b2e-f51f72f997a9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:49:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.60\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m2cn4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m2cn4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.29,PodIP:172.16.0.60,StartTime:2023-04-18 08:49:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:49:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://ecf82a941ecae39f893bece71d013466fedb697d68ae96d008488ad37901b49e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.60,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 18 08:49:32.098: INFO: pod: "test-deployment-7c7d8d58c8-sfd4h":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-sfd4h test-deployment-7c7d8d58c8- deployment-8422  c1851a6c-e185-470b-9470-d42aab5ead0a 4180393 0 2023-04-18 08:49:30 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 3593ad0e-294f-40d1-9b2e-f51f72f997a9 0xc005cdd597 0xc005cdd598}] [] [{kube-controller-manager Update v1 2023-04-18 08:49:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3593ad0e-294f-40d1-9b2e-f51f72f997a9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:49:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.17\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zdbrr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zdbrr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.17,StartTime:2023-04-18 08:49:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:49:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://0ddfef473918e5f9c3ec9338fb184e906603f965d1d28fe26c851571f0da950a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.17,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 18 08:49:32.098: INFO: ReplicaSet "test-deployment-8594bb6fdd":
    &ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-8422  78a4c4cd-6998-4199-8626-5fa123fb9831 4180365 3 2023-04-18 08:49:28 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 1fdd411d-8c47-4418-b006-b6750d11c385 0xc005cdd027 0xc005cdd028}] [] [{kube-controller-manager Update apps/v1 2023-04-18 08:49:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1fdd411d-8c47-4418-b006-b6750d11c385\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 08:49:30 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005cdd0b0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Apr 18 08:49:32.104: INFO: pod: "test-deployment-8594bb6fdd-5mxc4":
    &Pod{ObjectMeta:{test-deployment-8594bb6fdd-5mxc4 test-deployment-8594bb6fdd- deployment-8422  3b6b96f5-4838-4088-85d3-2f8637f26c6d 4180362 0 2023-04-18 08:49:28 +0000 UTC 2023-04-18 08:49:31 +0000 UTC 0xc0017ff3f8 map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-8594bb6fdd 78a4c4cd-6998-4199-8626-5fa123fb9831 0xc0017ff427 0xc0017ff428}] [] [{kube-controller-manager Update v1 2023-04-18 08:49:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78a4c4cd-6998-4199-8626-5fa123fb9831\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:49:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.216\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-78ncd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-78ncd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.84,PodIP:172.16.0.216,StartTime:2023-04-18 08:49:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:49:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://daa7fee76144739a8326bca4b87f9c3b1fea1e4c9766bb752ab68228508a55b2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.216,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 18 08:49:32.105: INFO: pod: "test-deployment-8594bb6fdd-ld7tc":
    &Pod{ObjectMeta:{test-deployment-8594bb6fdd-ld7tc test-deployment-8594bb6fdd- deployment-8422  e62b914c-ec9e-4d9a-b8c9-1eb9345e1b2d 4180345 0 2023-04-18 08:49:28 +0000 UTC 2023-04-18 08:49:30 +0000 UTC 0xc0017ff628 map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-8594bb6fdd 78a4c4cd-6998-4199-8626-5fa123fb9831 0xc0017ff657 0xc0017ff658}] [] [{kube-controller-manager Update v1 2023-04-18 08:49:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78a4c4cd-6998-4199-8626-5fa123fb9831\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 08:49:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-75wlq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-75wlq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 08:49:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.15,StartTime:2023-04-18 08:49:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 08:49:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://2e4ece3c35b695742444203f8a7319ec6abc934dd903ca0b59abe04872a0e694,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.15,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 08:49:32.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8422" for this suite. 04/18/23 08:49:32.108
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:49:32.113
Apr 18 08:49:32.113: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename configmap 04/18/23 08:49:32.114
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:49:32.125
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:49:32.129
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-c3e94887-6e5d-4926-bbfd-862ebcdaebe6 04/18/23 08:49:32.133
STEP: Creating a pod to test consume configMaps 04/18/23 08:49:32.136
Apr 18 08:49:32.146: INFO: Waiting up to 5m0s for pod "pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00" in namespace "configmap-8912" to be "Succeeded or Failed"
Apr 18 08:49:32.150: INFO: Pod "pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125199ms
Apr 18 08:49:34.156: INFO: Pod "pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009255799s
Apr 18 08:49:36.154: INFO: Pod "pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007935984s
STEP: Saw pod success 04/18/23 08:49:36.154
Apr 18 08:49:36.154: INFO: Pod "pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00" satisfied condition "Succeeded or Failed"
Apr 18 08:49:36.157: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 08:49:36.167
Apr 18 08:49:36.176: INFO: Waiting for pod pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00 to disappear
Apr 18 08:49:36.179: INFO: Pod pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 08:49:36.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8912" for this suite. 04/18/23 08:49:36.184
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":110,"skipped":1886,"failed":0}
------------------------------
• [4.079 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:49:32.113
    Apr 18 08:49:32.113: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename configmap 04/18/23 08:49:32.114
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:49:32.125
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:49:32.129
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-c3e94887-6e5d-4926-bbfd-862ebcdaebe6 04/18/23 08:49:32.133
    STEP: Creating a pod to test consume configMaps 04/18/23 08:49:32.136
    Apr 18 08:49:32.146: INFO: Waiting up to 5m0s for pod "pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00" in namespace "configmap-8912" to be "Succeeded or Failed"
    Apr 18 08:49:32.150: INFO: Pod "pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125199ms
    Apr 18 08:49:34.156: INFO: Pod "pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009255799s
    Apr 18 08:49:36.154: INFO: Pod "pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007935984s
    STEP: Saw pod success 04/18/23 08:49:36.154
    Apr 18 08:49:36.154: INFO: Pod "pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00" satisfied condition "Succeeded or Failed"
    Apr 18 08:49:36.157: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 08:49:36.167
    Apr 18 08:49:36.176: INFO: Waiting for pod pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00 to disappear
    Apr 18 08:49:36.179: INFO: Pod pod-configmaps-d0b6138f-1276-4e19-b1ea-b1100e1bba00 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 08:49:36.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8912" for this suite. 04/18/23 08:49:36.184
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:49:36.193
Apr 18 08:49:36.193: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 08:49:36.194
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:49:36.21
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:49:36.216
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 04/18/23 08:49:36.224
Apr 18 08:49:36.232: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835" in namespace "downward-api-2011" to be "Succeeded or Failed"
Apr 18 08:49:36.234: INFO: Pod "downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835": Phase="Pending", Reason="", readiness=false. Elapsed: 2.4754ms
Apr 18 08:49:38.238: INFO: Pod "downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006419486s
Apr 18 08:49:40.239: INFO: Pod "downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007322735s
STEP: Saw pod success 04/18/23 08:49:40.239
Apr 18 08:49:40.239: INFO: Pod "downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835" satisfied condition "Succeeded or Failed"
Apr 18 08:49:40.242: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835 container client-container: <nil>
STEP: delete the pod 04/18/23 08:49:40.247
Apr 18 08:49:40.256: INFO: Waiting for pod downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835 to disappear
Apr 18 08:49:40.259: INFO: Pod downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 08:49:40.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2011" for this suite. 04/18/23 08:49:40.263
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":111,"skipped":1893,"failed":0}
------------------------------
• [4.075 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:49:36.193
    Apr 18 08:49:36.193: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 08:49:36.194
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:49:36.21
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:49:36.216
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 04/18/23 08:49:36.224
    Apr 18 08:49:36.232: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835" in namespace "downward-api-2011" to be "Succeeded or Failed"
    Apr 18 08:49:36.234: INFO: Pod "downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835": Phase="Pending", Reason="", readiness=false. Elapsed: 2.4754ms
    Apr 18 08:49:38.238: INFO: Pod "downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006419486s
    Apr 18 08:49:40.239: INFO: Pod "downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007322735s
    STEP: Saw pod success 04/18/23 08:49:40.239
    Apr 18 08:49:40.239: INFO: Pod "downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835" satisfied condition "Succeeded or Failed"
    Apr 18 08:49:40.242: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835 container client-container: <nil>
    STEP: delete the pod 04/18/23 08:49:40.247
    Apr 18 08:49:40.256: INFO: Waiting for pod downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835 to disappear
    Apr 18 08:49:40.259: INFO: Pod downwardapi-volume-8f9ec51d-abd0-46eb-81c2-2f17c8978835 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 08:49:40.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2011" for this suite. 04/18/23 08:49:40.263
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:49:40.27
Apr 18 08:49:40.270: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 08:49:40.27
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:49:40.279
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:49:40.282
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 04/18/23 08:49:40.286
Apr 18 08:49:40.292: INFO: Waiting up to 5m0s for pod "downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e" in namespace "downward-api-6819" to be "Succeeded or Failed"
Apr 18 08:49:40.295: INFO: Pod "downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.342062ms
Apr 18 08:49:42.298: INFO: Pod "downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005927893s
Apr 18 08:49:44.298: INFO: Pod "downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005638042s
STEP: Saw pod success 04/18/23 08:49:44.298
Apr 18 08:49:44.298: INFO: Pod "downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e" satisfied condition "Succeeded or Failed"
Apr 18 08:49:44.301: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e container client-container: <nil>
STEP: delete the pod 04/18/23 08:49:44.306
Apr 18 08:49:44.318: INFO: Waiting for pod downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e to disappear
Apr 18 08:49:44.321: INFO: Pod downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 08:49:44.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6819" for this suite. 04/18/23 08:49:44.324
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":112,"skipped":1928,"failed":0}
------------------------------
• [4.059 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:49:40.27
    Apr 18 08:49:40.270: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 08:49:40.27
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:49:40.279
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:49:40.282
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 04/18/23 08:49:40.286
    Apr 18 08:49:40.292: INFO: Waiting up to 5m0s for pod "downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e" in namespace "downward-api-6819" to be "Succeeded or Failed"
    Apr 18 08:49:40.295: INFO: Pod "downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.342062ms
    Apr 18 08:49:42.298: INFO: Pod "downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005927893s
    Apr 18 08:49:44.298: INFO: Pod "downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005638042s
    STEP: Saw pod success 04/18/23 08:49:44.298
    Apr 18 08:49:44.298: INFO: Pod "downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e" satisfied condition "Succeeded or Failed"
    Apr 18 08:49:44.301: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e container client-container: <nil>
    STEP: delete the pod 04/18/23 08:49:44.306
    Apr 18 08:49:44.318: INFO: Waiting for pod downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e to disappear
    Apr 18 08:49:44.321: INFO: Pod downwardapi-volume-476c6d7a-90f2-4f89-8d70-c611e8c3937e no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 08:49:44.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6819" for this suite. 04/18/23 08:49:44.324
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:49:44.328
Apr 18 08:49:44.329: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename cronjob 04/18/23 08:49:44.329
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:49:44.344
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:49:44.348
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 04/18/23 08:49:44.353
STEP: Ensuring a job is scheduled 04/18/23 08:49:44.361
STEP: Ensuring exactly one is scheduled 04/18/23 08:50:00.364
STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/18/23 08:50:00.367
STEP: Ensuring no more jobs are scheduled 04/18/23 08:50:00.369
STEP: Removing cronjob 04/18/23 08:55:00.376
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 18 08:55:00.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5071" for this suite. 04/18/23 08:55:00.384
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":113,"skipped":1935,"failed":0}
------------------------------
• [SLOW TEST] [316.063 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:49:44.328
    Apr 18 08:49:44.329: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename cronjob 04/18/23 08:49:44.329
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:49:44.344
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:49:44.348
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 04/18/23 08:49:44.353
    STEP: Ensuring a job is scheduled 04/18/23 08:49:44.361
    STEP: Ensuring exactly one is scheduled 04/18/23 08:50:00.364
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/18/23 08:50:00.367
    STEP: Ensuring no more jobs are scheduled 04/18/23 08:50:00.369
    STEP: Removing cronjob 04/18/23 08:55:00.376
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 18 08:55:00.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5071" for this suite. 04/18/23 08:55:00.384
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:55:00.393
Apr 18 08:55:00.393: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename replication-controller 04/18/23 08:55:00.394
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:00.407
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:00.41
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Apr 18 08:55:00.417: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 04/18/23 08:55:00.425
STEP: Checking rc "condition-test" has the desired failure condition set 04/18/23 08:55:00.429
STEP: Scaling down rc "condition-test" to satisfy pod quota 04/18/23 08:55:01.436
Apr 18 08:55:01.447: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 04/18/23 08:55:01.447
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 18 08:55:01.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1966" for this suite. 04/18/23 08:55:01.454
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":114,"skipped":1967,"failed":0}
------------------------------
• [1.068 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:55:00.393
    Apr 18 08:55:00.393: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename replication-controller 04/18/23 08:55:00.394
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:00.407
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:00.41
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Apr 18 08:55:00.417: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 04/18/23 08:55:00.425
    STEP: Checking rc "condition-test" has the desired failure condition set 04/18/23 08:55:00.429
    STEP: Scaling down rc "condition-test" to satisfy pod quota 04/18/23 08:55:01.436
    Apr 18 08:55:01.447: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 04/18/23 08:55:01.447
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 18 08:55:01.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1966" for this suite. 04/18/23 08:55:01.454
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:55:01.469
Apr 18 08:55:01.469: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename secrets 04/18/23 08:55:01.469
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:01.479
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:01.483
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-8fbf2c01-3173-455c-88be-38895f01103f 04/18/23 08:55:01.486
STEP: Creating a pod to test consume secrets 04/18/23 08:55:01.492
Apr 18 08:55:01.499: INFO: Waiting up to 5m0s for pod "pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab" in namespace "secrets-4694" to be "Succeeded or Failed"
Apr 18 08:55:01.502: INFO: Pod "pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.739554ms
Apr 18 08:55:03.506: INFO: Pod "pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006878326s
Apr 18 08:55:05.506: INFO: Pod "pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006494463s
STEP: Saw pod success 04/18/23 08:55:05.506
Apr 18 08:55:05.506: INFO: Pod "pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab" satisfied condition "Succeeded or Failed"
Apr 18 08:55:05.509: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 08:55:05.523
Apr 18 08:55:05.534: INFO: Waiting for pod pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab to disappear
Apr 18 08:55:05.537: INFO: Pod pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 08:55:05.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4694" for this suite. 04/18/23 08:55:05.541
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":115,"skipped":2041,"failed":0}
------------------------------
• [4.083 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:55:01.469
    Apr 18 08:55:01.469: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename secrets 04/18/23 08:55:01.469
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:01.479
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:01.483
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-8fbf2c01-3173-455c-88be-38895f01103f 04/18/23 08:55:01.486
    STEP: Creating a pod to test consume secrets 04/18/23 08:55:01.492
    Apr 18 08:55:01.499: INFO: Waiting up to 5m0s for pod "pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab" in namespace "secrets-4694" to be "Succeeded or Failed"
    Apr 18 08:55:01.502: INFO: Pod "pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.739554ms
    Apr 18 08:55:03.506: INFO: Pod "pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006878326s
    Apr 18 08:55:05.506: INFO: Pod "pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006494463s
    STEP: Saw pod success 04/18/23 08:55:05.506
    Apr 18 08:55:05.506: INFO: Pod "pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab" satisfied condition "Succeeded or Failed"
    Apr 18 08:55:05.509: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 08:55:05.523
    Apr 18 08:55:05.534: INFO: Waiting for pod pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab to disappear
    Apr 18 08:55:05.537: INFO: Pod pod-secrets-59bf65f8-2cd4-4e1f-b9ef-7833982da3ab no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 08:55:05.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4694" for this suite. 04/18/23 08:55:05.541
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:55:05.554
Apr 18 08:55:05.554: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 08:55:05.555
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:05.569
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:05.572
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 04/18/23 08:55:05.576
Apr 18 08:55:05.582: INFO: Waiting up to 5m0s for pod "annotationupdate4a71528b-7595-402e-a4a6-ed3736b89227" in namespace "projected-4065" to be "running and ready"
Apr 18 08:55:05.586: INFO: Pod "annotationupdate4a71528b-7595-402e-a4a6-ed3736b89227": Phase="Pending", Reason="", readiness=false. Elapsed: 3.175848ms
Apr 18 08:55:05.586: INFO: The phase of Pod annotationupdate4a71528b-7595-402e-a4a6-ed3736b89227 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:55:07.589: INFO: Pod "annotationupdate4a71528b-7595-402e-a4a6-ed3736b89227": Phase="Running", Reason="", readiness=true. Elapsed: 2.006304004s
Apr 18 08:55:07.589: INFO: The phase of Pod annotationupdate4a71528b-7595-402e-a4a6-ed3736b89227 is Running (Ready = true)
Apr 18 08:55:07.589: INFO: Pod "annotationupdate4a71528b-7595-402e-a4a6-ed3736b89227" satisfied condition "running and ready"
Apr 18 08:55:08.108: INFO: Successfully updated pod "annotationupdate4a71528b-7595-402e-a4a6-ed3736b89227"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 08:55:12.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4065" for this suite. 04/18/23 08:55:12.13
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":116,"skipped":2068,"failed":0}
------------------------------
• [SLOW TEST] [6.581 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:55:05.554
    Apr 18 08:55:05.554: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 08:55:05.555
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:05.569
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:05.572
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 04/18/23 08:55:05.576
    Apr 18 08:55:05.582: INFO: Waiting up to 5m0s for pod "annotationupdate4a71528b-7595-402e-a4a6-ed3736b89227" in namespace "projected-4065" to be "running and ready"
    Apr 18 08:55:05.586: INFO: Pod "annotationupdate4a71528b-7595-402e-a4a6-ed3736b89227": Phase="Pending", Reason="", readiness=false. Elapsed: 3.175848ms
    Apr 18 08:55:05.586: INFO: The phase of Pod annotationupdate4a71528b-7595-402e-a4a6-ed3736b89227 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:55:07.589: INFO: Pod "annotationupdate4a71528b-7595-402e-a4a6-ed3736b89227": Phase="Running", Reason="", readiness=true. Elapsed: 2.006304004s
    Apr 18 08:55:07.589: INFO: The phase of Pod annotationupdate4a71528b-7595-402e-a4a6-ed3736b89227 is Running (Ready = true)
    Apr 18 08:55:07.589: INFO: Pod "annotationupdate4a71528b-7595-402e-a4a6-ed3736b89227" satisfied condition "running and ready"
    Apr 18 08:55:08.108: INFO: Successfully updated pod "annotationupdate4a71528b-7595-402e-a4a6-ed3736b89227"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 08:55:12.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4065" for this suite. 04/18/23 08:55:12.13
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:55:12.136
Apr 18 08:55:12.136: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename pods 04/18/23 08:55:12.137
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:12.149
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:12.154
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Apr 18 08:55:12.158: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: creating the pod 04/18/23 08:55:12.158
STEP: submitting the pod to kubernetes 04/18/23 08:55:12.158
Apr 18 08:55:12.164: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-3fb5674b-a02c-4ac0-82ff-89faed6b612d" in namespace "pods-3814" to be "running and ready"
Apr 18 08:55:12.167: INFO: Pod "pod-exec-websocket-3fb5674b-a02c-4ac0-82ff-89faed6b612d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.919649ms
Apr 18 08:55:12.167: INFO: The phase of Pod pod-exec-websocket-3fb5674b-a02c-4ac0-82ff-89faed6b612d is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:55:14.170: INFO: Pod "pod-exec-websocket-3fb5674b-a02c-4ac0-82ff-89faed6b612d": Phase="Running", Reason="", readiness=true. Elapsed: 2.006091849s
Apr 18 08:55:14.170: INFO: The phase of Pod pod-exec-websocket-3fb5674b-a02c-4ac0-82ff-89faed6b612d is Running (Ready = true)
Apr 18 08:55:14.170: INFO: Pod "pod-exec-websocket-3fb5674b-a02c-4ac0-82ff-89faed6b612d" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 08:55:14.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3814" for this suite. 04/18/23 08:55:14.23
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":117,"skipped":2099,"failed":0}
------------------------------
• [2.099 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:55:12.136
    Apr 18 08:55:12.136: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename pods 04/18/23 08:55:12.137
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:12.149
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:12.154
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Apr 18 08:55:12.158: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: creating the pod 04/18/23 08:55:12.158
    STEP: submitting the pod to kubernetes 04/18/23 08:55:12.158
    Apr 18 08:55:12.164: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-3fb5674b-a02c-4ac0-82ff-89faed6b612d" in namespace "pods-3814" to be "running and ready"
    Apr 18 08:55:12.167: INFO: Pod "pod-exec-websocket-3fb5674b-a02c-4ac0-82ff-89faed6b612d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.919649ms
    Apr 18 08:55:12.167: INFO: The phase of Pod pod-exec-websocket-3fb5674b-a02c-4ac0-82ff-89faed6b612d is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:55:14.170: INFO: Pod "pod-exec-websocket-3fb5674b-a02c-4ac0-82ff-89faed6b612d": Phase="Running", Reason="", readiness=true. Elapsed: 2.006091849s
    Apr 18 08:55:14.170: INFO: The phase of Pod pod-exec-websocket-3fb5674b-a02c-4ac0-82ff-89faed6b612d is Running (Ready = true)
    Apr 18 08:55:14.170: INFO: Pod "pod-exec-websocket-3fb5674b-a02c-4ac0-82ff-89faed6b612d" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 08:55:14.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3814" for this suite. 04/18/23 08:55:14.23
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:55:14.236
Apr 18 08:55:14.236: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir 04/18/23 08:55:14.237
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:14.26
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:14.263
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 04/18/23 08:55:14.267
Apr 18 08:55:14.272: INFO: Waiting up to 5m0s for pod "pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd" in namespace "emptydir-4976" to be "Succeeded or Failed"
Apr 18 08:55:14.279: INFO: Pod "pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.096606ms
Apr 18 08:55:16.282: INFO: Pod "pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd": Phase="Running", Reason="", readiness=false. Elapsed: 2.009402975s
Apr 18 08:55:18.282: INFO: Pod "pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009728346s
STEP: Saw pod success 04/18/23 08:55:18.282
Apr 18 08:55:18.282: INFO: Pod "pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd" satisfied condition "Succeeded or Failed"
Apr 18 08:55:18.285: INFO: Trying to get logs from node 192.168.1.152 pod pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd container test-container: <nil>
STEP: delete the pod 04/18/23 08:55:18.29
Apr 18 08:55:18.297: INFO: Waiting for pod pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd to disappear
Apr 18 08:55:18.300: INFO: Pod pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 08:55:18.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4976" for this suite. 04/18/23 08:55:18.304
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":118,"skipped":2114,"failed":0}
------------------------------
• [4.073 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:55:14.236
    Apr 18 08:55:14.236: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir 04/18/23 08:55:14.237
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:14.26
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:14.263
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 04/18/23 08:55:14.267
    Apr 18 08:55:14.272: INFO: Waiting up to 5m0s for pod "pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd" in namespace "emptydir-4976" to be "Succeeded or Failed"
    Apr 18 08:55:14.279: INFO: Pod "pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.096606ms
    Apr 18 08:55:16.282: INFO: Pod "pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd": Phase="Running", Reason="", readiness=false. Elapsed: 2.009402975s
    Apr 18 08:55:18.282: INFO: Pod "pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009728346s
    STEP: Saw pod success 04/18/23 08:55:18.282
    Apr 18 08:55:18.282: INFO: Pod "pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd" satisfied condition "Succeeded or Failed"
    Apr 18 08:55:18.285: INFO: Trying to get logs from node 192.168.1.152 pod pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd container test-container: <nil>
    STEP: delete the pod 04/18/23 08:55:18.29
    Apr 18 08:55:18.297: INFO: Waiting for pod pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd to disappear
    Apr 18 08:55:18.300: INFO: Pod pod-41a4d8ce-2123-4cc1-8221-c1c5f428a8dd no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 08:55:18.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4976" for this suite. 04/18/23 08:55:18.304
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:55:18.31
Apr 18 08:55:18.310: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename tables 04/18/23 08:55:18.311
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:18.319
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:18.323
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Apr 18 08:55:18.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-477" for this suite. 04/18/23 08:55:18.335
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":119,"skipped":2138,"failed":0}
------------------------------
• [0.028 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:55:18.31
    Apr 18 08:55:18.310: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename tables 04/18/23 08:55:18.311
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:18.319
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:18.323
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Apr 18 08:55:18.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-477" for this suite. 04/18/23 08:55:18.335
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:55:18.339
Apr 18 08:55:18.339: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 08:55:18.34
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:18.353
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:18.356
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 04/18/23 08:55:18.36
Apr 18 08:55:18.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 create -f -'
Apr 18 08:55:18.952: INFO: stderr: ""
Apr 18 08:55:18.952: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 08:55:18.952
Apr 18 08:55:18.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 18 08:55:19.012: INFO: stderr: ""
Apr 18 08:55:19.012: INFO: stdout: "update-demo-nautilus-llw7t update-demo-nautilus-vtkfm "
Apr 18 08:55:19.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 08:55:19.067: INFO: stderr: ""
Apr 18 08:55:19.067: INFO: stdout: ""
Apr 18 08:55:19.067: INFO: update-demo-nautilus-llw7t is created but not running
Apr 18 08:55:24.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 18 08:55:24.129: INFO: stderr: ""
Apr 18 08:55:24.129: INFO: stdout: "update-demo-nautilus-llw7t update-demo-nautilus-vtkfm "
Apr 18 08:55:24.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 08:55:24.193: INFO: stderr: ""
Apr 18 08:55:24.193: INFO: stdout: ""
Apr 18 08:55:24.193: INFO: update-demo-nautilus-llw7t is created but not running
Apr 18 08:55:29.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 18 08:55:29.258: INFO: stderr: ""
Apr 18 08:55:29.258: INFO: stdout: "update-demo-nautilus-llw7t update-demo-nautilus-vtkfm "
Apr 18 08:55:29.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 08:55:29.316: INFO: stderr: ""
Apr 18 08:55:29.316: INFO: stdout: "true"
Apr 18 08:55:29.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 18 08:55:29.373: INFO: stderr: ""
Apr 18 08:55:29.373: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 18 08:55:29.373: INFO: validating pod update-demo-nautilus-llw7t
Apr 18 08:55:29.380: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 18 08:55:29.380: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 18 08:55:29.380: INFO: update-demo-nautilus-llw7t is verified up and running
Apr 18 08:55:29.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-vtkfm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 08:55:29.436: INFO: stderr: ""
Apr 18 08:55:29.436: INFO: stdout: "true"
Apr 18 08:55:29.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-vtkfm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 18 08:55:29.491: INFO: stderr: ""
Apr 18 08:55:29.491: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 18 08:55:29.491: INFO: validating pod update-demo-nautilus-vtkfm
Apr 18 08:55:29.496: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 18 08:55:29.496: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 18 08:55:29.496: INFO: update-demo-nautilus-vtkfm is verified up and running
STEP: scaling down the replication controller 04/18/23 08:55:29.496
Apr 18 08:55:29.497: INFO: scanned /root for discovery docs: <nil>
Apr 18 08:55:29.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Apr 18 08:55:30.576: INFO: stderr: ""
Apr 18 08:55:30.576: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 08:55:30.576
Apr 18 08:55:30.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 18 08:55:30.633: INFO: stderr: ""
Apr 18 08:55:30.633: INFO: stdout: "update-demo-nautilus-llw7t "
Apr 18 08:55:30.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 08:55:30.689: INFO: stderr: ""
Apr 18 08:55:30.689: INFO: stdout: "true"
Apr 18 08:55:30.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 18 08:55:30.744: INFO: stderr: ""
Apr 18 08:55:30.744: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 18 08:55:30.744: INFO: validating pod update-demo-nautilus-llw7t
Apr 18 08:55:30.748: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 18 08:55:30.748: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 18 08:55:30.748: INFO: update-demo-nautilus-llw7t is verified up and running
STEP: scaling up the replication controller 04/18/23 08:55:30.748
Apr 18 08:55:30.749: INFO: scanned /root for discovery docs: <nil>
Apr 18 08:55:30.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Apr 18 08:55:31.834: INFO: stderr: ""
Apr 18 08:55:31.834: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 08:55:31.834
Apr 18 08:55:31.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 18 08:55:31.898: INFO: stderr: ""
Apr 18 08:55:31.898: INFO: stdout: "update-demo-nautilus-llw7t update-demo-nautilus-n6ph2 "
Apr 18 08:55:31.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 08:55:31.953: INFO: stderr: ""
Apr 18 08:55:31.953: INFO: stdout: "true"
Apr 18 08:55:31.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 18 08:55:32.009: INFO: stderr: ""
Apr 18 08:55:32.009: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 18 08:55:32.009: INFO: validating pod update-demo-nautilus-llw7t
Apr 18 08:55:32.013: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 18 08:55:32.013: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 18 08:55:32.013: INFO: update-demo-nautilus-llw7t is verified up and running
Apr 18 08:55:32.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-n6ph2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 08:55:32.069: INFO: stderr: ""
Apr 18 08:55:32.069: INFO: stdout: "true"
Apr 18 08:55:32.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-n6ph2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 18 08:55:32.125: INFO: stderr: ""
Apr 18 08:55:32.125: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 18 08:55:32.125: INFO: validating pod update-demo-nautilus-n6ph2
Apr 18 08:55:32.130: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 18 08:55:32.130: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 18 08:55:32.130: INFO: update-demo-nautilus-n6ph2 is verified up and running
STEP: using delete to clean up resources 04/18/23 08:55:32.13
Apr 18 08:55:32.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 delete --grace-period=0 --force -f -'
Apr 18 08:55:32.183: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 08:55:32.183: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 18 08:55:32.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get rc,svc -l name=update-demo --no-headers'
Apr 18 08:55:32.314: INFO: stderr: "No resources found in kubectl-3528 namespace.\n"
Apr 18 08:55:32.314: INFO: stdout: ""
Apr 18 08:55:32.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 18 08:55:32.383: INFO: stderr: ""
Apr 18 08:55:32.383: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 08:55:32.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3528" for this suite. 04/18/23 08:55:32.387
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":120,"skipped":2145,"failed":0}
------------------------------
• [SLOW TEST] [14.052 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:55:18.339
    Apr 18 08:55:18.339: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 08:55:18.34
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:18.353
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:18.356
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 04/18/23 08:55:18.36
    Apr 18 08:55:18.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 create -f -'
    Apr 18 08:55:18.952: INFO: stderr: ""
    Apr 18 08:55:18.952: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 08:55:18.952
    Apr 18 08:55:18.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 18 08:55:19.012: INFO: stderr: ""
    Apr 18 08:55:19.012: INFO: stdout: "update-demo-nautilus-llw7t update-demo-nautilus-vtkfm "
    Apr 18 08:55:19.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 08:55:19.067: INFO: stderr: ""
    Apr 18 08:55:19.067: INFO: stdout: ""
    Apr 18 08:55:19.067: INFO: update-demo-nautilus-llw7t is created but not running
    Apr 18 08:55:24.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 18 08:55:24.129: INFO: stderr: ""
    Apr 18 08:55:24.129: INFO: stdout: "update-demo-nautilus-llw7t update-demo-nautilus-vtkfm "
    Apr 18 08:55:24.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 08:55:24.193: INFO: stderr: ""
    Apr 18 08:55:24.193: INFO: stdout: ""
    Apr 18 08:55:24.193: INFO: update-demo-nautilus-llw7t is created but not running
    Apr 18 08:55:29.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 18 08:55:29.258: INFO: stderr: ""
    Apr 18 08:55:29.258: INFO: stdout: "update-demo-nautilus-llw7t update-demo-nautilus-vtkfm "
    Apr 18 08:55:29.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 08:55:29.316: INFO: stderr: ""
    Apr 18 08:55:29.316: INFO: stdout: "true"
    Apr 18 08:55:29.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 18 08:55:29.373: INFO: stderr: ""
    Apr 18 08:55:29.373: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 18 08:55:29.373: INFO: validating pod update-demo-nautilus-llw7t
    Apr 18 08:55:29.380: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 18 08:55:29.380: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 18 08:55:29.380: INFO: update-demo-nautilus-llw7t is verified up and running
    Apr 18 08:55:29.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-vtkfm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 08:55:29.436: INFO: stderr: ""
    Apr 18 08:55:29.436: INFO: stdout: "true"
    Apr 18 08:55:29.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-vtkfm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 18 08:55:29.491: INFO: stderr: ""
    Apr 18 08:55:29.491: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 18 08:55:29.491: INFO: validating pod update-demo-nautilus-vtkfm
    Apr 18 08:55:29.496: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 18 08:55:29.496: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 18 08:55:29.496: INFO: update-demo-nautilus-vtkfm is verified up and running
    STEP: scaling down the replication controller 04/18/23 08:55:29.496
    Apr 18 08:55:29.497: INFO: scanned /root for discovery docs: <nil>
    Apr 18 08:55:29.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Apr 18 08:55:30.576: INFO: stderr: ""
    Apr 18 08:55:30.576: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 08:55:30.576
    Apr 18 08:55:30.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 18 08:55:30.633: INFO: stderr: ""
    Apr 18 08:55:30.633: INFO: stdout: "update-demo-nautilus-llw7t "
    Apr 18 08:55:30.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 08:55:30.689: INFO: stderr: ""
    Apr 18 08:55:30.689: INFO: stdout: "true"
    Apr 18 08:55:30.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 18 08:55:30.744: INFO: stderr: ""
    Apr 18 08:55:30.744: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 18 08:55:30.744: INFO: validating pod update-demo-nautilus-llw7t
    Apr 18 08:55:30.748: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 18 08:55:30.748: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 18 08:55:30.748: INFO: update-demo-nautilus-llw7t is verified up and running
    STEP: scaling up the replication controller 04/18/23 08:55:30.748
    Apr 18 08:55:30.749: INFO: scanned /root for discovery docs: <nil>
    Apr 18 08:55:30.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Apr 18 08:55:31.834: INFO: stderr: ""
    Apr 18 08:55:31.834: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 08:55:31.834
    Apr 18 08:55:31.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 18 08:55:31.898: INFO: stderr: ""
    Apr 18 08:55:31.898: INFO: stdout: "update-demo-nautilus-llw7t update-demo-nautilus-n6ph2 "
    Apr 18 08:55:31.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 08:55:31.953: INFO: stderr: ""
    Apr 18 08:55:31.953: INFO: stdout: "true"
    Apr 18 08:55:31.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-llw7t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 18 08:55:32.009: INFO: stderr: ""
    Apr 18 08:55:32.009: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 18 08:55:32.009: INFO: validating pod update-demo-nautilus-llw7t
    Apr 18 08:55:32.013: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 18 08:55:32.013: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 18 08:55:32.013: INFO: update-demo-nautilus-llw7t is verified up and running
    Apr 18 08:55:32.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-n6ph2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 08:55:32.069: INFO: stderr: ""
    Apr 18 08:55:32.069: INFO: stdout: "true"
    Apr 18 08:55:32.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods update-demo-nautilus-n6ph2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 18 08:55:32.125: INFO: stderr: ""
    Apr 18 08:55:32.125: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 18 08:55:32.125: INFO: validating pod update-demo-nautilus-n6ph2
    Apr 18 08:55:32.130: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 18 08:55:32.130: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 18 08:55:32.130: INFO: update-demo-nautilus-n6ph2 is verified up and running
    STEP: using delete to clean up resources 04/18/23 08:55:32.13
    Apr 18 08:55:32.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 delete --grace-period=0 --force -f -'
    Apr 18 08:55:32.183: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 08:55:32.183: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Apr 18 08:55:32.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get rc,svc -l name=update-demo --no-headers'
    Apr 18 08:55:32.314: INFO: stderr: "No resources found in kubectl-3528 namespace.\n"
    Apr 18 08:55:32.314: INFO: stdout: ""
    Apr 18 08:55:32.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3528 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 18 08:55:32.383: INFO: stderr: ""
    Apr 18 08:55:32.383: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 08:55:32.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3528" for this suite. 04/18/23 08:55:32.387
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:55:32.392
Apr 18 08:55:32.392: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 08:55:32.393
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:32.403
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:32.407
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-7556 04/18/23 08:55:32.411
Apr 18 08:55:32.417: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-7556" to be "running and ready"
Apr 18 08:55:32.421: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 3.769145ms
Apr 18 08:55:32.421: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:55:34.424: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.007346652s
Apr 18 08:55:34.424: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Apr 18 08:55:34.424: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Apr 18 08:55:34.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Apr 18 08:55:34.536: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Apr 18 08:55:34.536: INFO: stdout: "iptables"
Apr 18 08:55:34.536: INFO: proxyMode: iptables
Apr 18 08:55:34.548: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Apr 18 08:55:34.551: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-7556 04/18/23 08:55:34.551
STEP: creating replication controller affinity-nodeport-timeout in namespace services-7556 04/18/23 08:55:34.562
I0418 08:55:34.569434      18 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-7556, replica count: 3
I0418 08:55:37.620296      18 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 08:55:37.629: INFO: Creating new exec pod
Apr 18 08:55:37.633: INFO: Waiting up to 5m0s for pod "execpod-affinityqgl5m" in namespace "services-7556" to be "running"
Apr 18 08:55:37.635: INFO: Pod "execpod-affinityqgl5m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.883306ms
Apr 18 08:55:39.639: INFO: Pod "execpod-affinityqgl5m": Phase="Running", Reason="", readiness=true. Elapsed: 2.006796622s
Apr 18 08:55:39.639: INFO: Pod "execpod-affinityqgl5m" satisfied condition "running"
Apr 18 08:55:40.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec execpod-affinityqgl5m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Apr 18 08:55:40.759: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Apr 18 08:55:40.759: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 08:55:40.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec execpod-affinityqgl5m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.61.196 80'
Apr 18 08:55:40.870: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.61.196 80\nConnection to 10.247.61.196 80 port [tcp/http] succeeded!\n"
Apr 18 08:55:40.870: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 08:55:40.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec execpod-affinityqgl5m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.84 30526'
Apr 18 08:55:40.981: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.84 30526\nConnection to 192.168.1.84 30526 port [tcp/*] succeeded!\n"
Apr 18 08:55:40.981: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 08:55:40.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec execpod-affinityqgl5m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.152 30526'
Apr 18 08:55:41.091: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.152 30526\nConnection to 192.168.1.152 30526 port [tcp/*] succeeded!\n"
Apr 18 08:55:41.091: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 08:55:41.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec execpod-affinityqgl5m -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.152:30526/ ; done'
Apr 18 08:55:41.242: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n"
Apr 18 08:55:41.242: INFO: stdout: "\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7"
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
Apr 18 08:55:41.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec execpod-affinityqgl5m -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.1.152:30526/'
Apr 18 08:55:41.344: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n"
Apr 18 08:55:41.344: INFO: stdout: "affinity-nodeport-timeout-bvkg7"
Apr 18 08:56:01.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec execpod-affinityqgl5m -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.1.152:30526/'
Apr 18 08:56:01.450: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n"
Apr 18 08:56:01.450: INFO: stdout: "affinity-nodeport-timeout-4rz7m"
Apr 18 08:56:01.450: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-7556, will wait for the garbage collector to delete the pods 04/18/23 08:56:01.46
Apr 18 08:56:01.520: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 5.786326ms
Apr 18 08:56:01.620: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.678712ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 08:56:03.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7556" for this suite. 04/18/23 08:56:03.641
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":121,"skipped":2185,"failed":0}
------------------------------
• [SLOW TEST] [31.256 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:55:32.392
    Apr 18 08:55:32.392: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 08:55:32.393
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:55:32.403
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:55:32.407
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-7556 04/18/23 08:55:32.411
    Apr 18 08:55:32.417: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-7556" to be "running and ready"
    Apr 18 08:55:32.421: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 3.769145ms
    Apr 18 08:55:32.421: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:55:34.424: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.007346652s
    Apr 18 08:55:34.424: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Apr 18 08:55:34.424: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Apr 18 08:55:34.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Apr 18 08:55:34.536: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Apr 18 08:55:34.536: INFO: stdout: "iptables"
    Apr 18 08:55:34.536: INFO: proxyMode: iptables
    Apr 18 08:55:34.548: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Apr 18 08:55:34.551: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-7556 04/18/23 08:55:34.551
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-7556 04/18/23 08:55:34.562
    I0418 08:55:34.569434      18 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-7556, replica count: 3
    I0418 08:55:37.620296      18 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 08:55:37.629: INFO: Creating new exec pod
    Apr 18 08:55:37.633: INFO: Waiting up to 5m0s for pod "execpod-affinityqgl5m" in namespace "services-7556" to be "running"
    Apr 18 08:55:37.635: INFO: Pod "execpod-affinityqgl5m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.883306ms
    Apr 18 08:55:39.639: INFO: Pod "execpod-affinityqgl5m": Phase="Running", Reason="", readiness=true. Elapsed: 2.006796622s
    Apr 18 08:55:39.639: INFO: Pod "execpod-affinityqgl5m" satisfied condition "running"
    Apr 18 08:55:40.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec execpod-affinityqgl5m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Apr 18 08:55:40.759: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Apr 18 08:55:40.759: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 08:55:40.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec execpod-affinityqgl5m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.61.196 80'
    Apr 18 08:55:40.870: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.61.196 80\nConnection to 10.247.61.196 80 port [tcp/http] succeeded!\n"
    Apr 18 08:55:40.870: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 08:55:40.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec execpod-affinityqgl5m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.84 30526'
    Apr 18 08:55:40.981: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.84 30526\nConnection to 192.168.1.84 30526 port [tcp/*] succeeded!\n"
    Apr 18 08:55:40.981: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 08:55:40.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec execpod-affinityqgl5m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.152 30526'
    Apr 18 08:55:41.091: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.152 30526\nConnection to 192.168.1.152 30526 port [tcp/*] succeeded!\n"
    Apr 18 08:55:41.091: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 08:55:41.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec execpod-affinityqgl5m -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.152:30526/ ; done'
    Apr 18 08:55:41.242: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n"
    Apr 18 08:55:41.242: INFO: stdout: "\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7\naffinity-nodeport-timeout-bvkg7"
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.242: INFO: Received response from host: affinity-nodeport-timeout-bvkg7
    Apr 18 08:55:41.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec execpod-affinityqgl5m -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.1.152:30526/'
    Apr 18 08:55:41.344: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n"
    Apr 18 08:55:41.344: INFO: stdout: "affinity-nodeport-timeout-bvkg7"
    Apr 18 08:56:01.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7556 exec execpod-affinityqgl5m -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.1.152:30526/'
    Apr 18 08:56:01.450: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.1.152:30526/\n"
    Apr 18 08:56:01.450: INFO: stdout: "affinity-nodeport-timeout-4rz7m"
    Apr 18 08:56:01.450: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-7556, will wait for the garbage collector to delete the pods 04/18/23 08:56:01.46
    Apr 18 08:56:01.520: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 5.786326ms
    Apr 18 08:56:01.620: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.678712ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 08:56:03.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7556" for this suite. 04/18/23 08:56:03.641
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:56:03.648
Apr 18 08:56:03.648: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 08:56:03.649
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:56:03.658
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:56:03.661
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 04/18/23 08:56:03.665
Apr 18 08:56:03.672: INFO: Waiting up to 5m0s for pod "labelsupdatef84deedf-9eac-4a56-8e6f-7f1e92ab41ef" in namespace "projected-899" to be "running and ready"
Apr 18 08:56:03.678: INFO: Pod "labelsupdatef84deedf-9eac-4a56-8e6f-7f1e92ab41ef": Phase="Pending", Reason="", readiness=false. Elapsed: 5.348794ms
Apr 18 08:56:03.678: INFO: The phase of Pod labelsupdatef84deedf-9eac-4a56-8e6f-7f1e92ab41ef is Pending, waiting for it to be Running (with Ready = true)
Apr 18 08:56:05.681: INFO: Pod "labelsupdatef84deedf-9eac-4a56-8e6f-7f1e92ab41ef": Phase="Running", Reason="", readiness=true. Elapsed: 2.008940343s
Apr 18 08:56:05.681: INFO: The phase of Pod labelsupdatef84deedf-9eac-4a56-8e6f-7f1e92ab41ef is Running (Ready = true)
Apr 18 08:56:05.681: INFO: Pod "labelsupdatef84deedf-9eac-4a56-8e6f-7f1e92ab41ef" satisfied condition "running and ready"
Apr 18 08:56:06.200: INFO: Successfully updated pod "labelsupdatef84deedf-9eac-4a56-8e6f-7f1e92ab41ef"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 08:56:10.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-899" for this suite. 04/18/23 08:56:10.222
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":122,"skipped":2187,"failed":0}
------------------------------
• [SLOW TEST] [6.578 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:56:03.648
    Apr 18 08:56:03.648: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 08:56:03.649
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:56:03.658
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:56:03.661
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 04/18/23 08:56:03.665
    Apr 18 08:56:03.672: INFO: Waiting up to 5m0s for pod "labelsupdatef84deedf-9eac-4a56-8e6f-7f1e92ab41ef" in namespace "projected-899" to be "running and ready"
    Apr 18 08:56:03.678: INFO: Pod "labelsupdatef84deedf-9eac-4a56-8e6f-7f1e92ab41ef": Phase="Pending", Reason="", readiness=false. Elapsed: 5.348794ms
    Apr 18 08:56:03.678: INFO: The phase of Pod labelsupdatef84deedf-9eac-4a56-8e6f-7f1e92ab41ef is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 08:56:05.681: INFO: Pod "labelsupdatef84deedf-9eac-4a56-8e6f-7f1e92ab41ef": Phase="Running", Reason="", readiness=true. Elapsed: 2.008940343s
    Apr 18 08:56:05.681: INFO: The phase of Pod labelsupdatef84deedf-9eac-4a56-8e6f-7f1e92ab41ef is Running (Ready = true)
    Apr 18 08:56:05.681: INFO: Pod "labelsupdatef84deedf-9eac-4a56-8e6f-7f1e92ab41ef" satisfied condition "running and ready"
    Apr 18 08:56:06.200: INFO: Successfully updated pod "labelsupdatef84deedf-9eac-4a56-8e6f-7f1e92ab41ef"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 08:56:10.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-899" for this suite. 04/18/23 08:56:10.222
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:56:10.227
Apr 18 08:56:10.227: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename containers 04/18/23 08:56:10.228
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:56:10.237
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:56:10.241
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Apr 18 08:56:10.253: INFO: Waiting up to 5m0s for pod "client-containers-836a40bd-1736-47d6-a5ba-99f73eb8da84" in namespace "containers-924" to be "running"
Apr 18 08:56:10.256: INFO: Pod "client-containers-836a40bd-1736-47d6-a5ba-99f73eb8da84": Phase="Pending", Reason="", readiness=false. Elapsed: 2.48276ms
Apr 18 08:56:12.260: INFO: Pod "client-containers-836a40bd-1736-47d6-a5ba-99f73eb8da84": Phase="Running", Reason="", readiness=true. Elapsed: 2.006779028s
Apr 18 08:56:12.260: INFO: Pod "client-containers-836a40bd-1736-47d6-a5ba-99f73eb8da84" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 18 08:56:12.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-924" for this suite. 04/18/23 08:56:12.271
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":123,"skipped":2212,"failed":0}
------------------------------
• [2.050 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:56:10.227
    Apr 18 08:56:10.227: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename containers 04/18/23 08:56:10.228
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:56:10.237
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:56:10.241
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Apr 18 08:56:10.253: INFO: Waiting up to 5m0s for pod "client-containers-836a40bd-1736-47d6-a5ba-99f73eb8da84" in namespace "containers-924" to be "running"
    Apr 18 08:56:10.256: INFO: Pod "client-containers-836a40bd-1736-47d6-a5ba-99f73eb8da84": Phase="Pending", Reason="", readiness=false. Elapsed: 2.48276ms
    Apr 18 08:56:12.260: INFO: Pod "client-containers-836a40bd-1736-47d6-a5ba-99f73eb8da84": Phase="Running", Reason="", readiness=true. Elapsed: 2.006779028s
    Apr 18 08:56:12.260: INFO: Pod "client-containers-836a40bd-1736-47d6-a5ba-99f73eb8da84" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 18 08:56:12.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-924" for this suite. 04/18/23 08:56:12.271
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:56:12.28
Apr 18 08:56:12.280: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename statefulset 04/18/23 08:56:12.281
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:56:12.292
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:56:12.295
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4592 04/18/23 08:56:12.299
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 04/18/23 08:56:12.303
Apr 18 08:56:12.312: INFO: Found 0 stateful pods, waiting for 3
Apr 18 08:56:22.316: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 08:56:22.316: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 08:56:22.316: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/18/23 08:56:22.325
Apr 18 08:56:22.345: INFO: Updating stateful set ss2
STEP: Creating a new revision 04/18/23 08:56:22.345
STEP: Not applying an update when the partition is greater than the number of replicas 04/18/23 08:56:32.357
STEP: Performing a canary update 04/18/23 08:56:32.358
Apr 18 08:56:32.375: INFO: Updating stateful set ss2
Apr 18 08:56:32.382: INFO: Waiting for Pod statefulset-4592/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 04/18/23 08:56:42.39
Apr 18 08:56:42.416: INFO: Found 1 stateful pods, waiting for 3
Apr 18 08:56:52.423: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 08:56:52.423: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 08:56:52.423: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 04/18/23 08:56:52.429
Apr 18 08:56:52.446: INFO: Updating stateful set ss2
Apr 18 08:56:52.453: INFO: Waiting for Pod statefulset-4592/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Apr 18 08:57:02.480: INFO: Updating stateful set ss2
Apr 18 08:57:02.485: INFO: Waiting for StatefulSet statefulset-4592/ss2 to complete update
Apr 18 08:57:02.485: INFO: Waiting for Pod statefulset-4592/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 08:57:12.494: INFO: Deleting all statefulset in ns statefulset-4592
Apr 18 08:57:12.496: INFO: Scaling statefulset ss2 to 0
Apr 18 08:57:22.514: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 08:57:22.517: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 08:57:22.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4592" for this suite. 04/18/23 08:57:22.535
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":124,"skipped":2266,"failed":0}
------------------------------
• [SLOW TEST] [70.260 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:56:12.28
    Apr 18 08:56:12.280: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename statefulset 04/18/23 08:56:12.281
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:56:12.292
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:56:12.295
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4592 04/18/23 08:56:12.299
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 04/18/23 08:56:12.303
    Apr 18 08:56:12.312: INFO: Found 0 stateful pods, waiting for 3
    Apr 18 08:56:22.316: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 08:56:22.316: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 08:56:22.316: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/18/23 08:56:22.325
    Apr 18 08:56:22.345: INFO: Updating stateful set ss2
    STEP: Creating a new revision 04/18/23 08:56:22.345
    STEP: Not applying an update when the partition is greater than the number of replicas 04/18/23 08:56:32.357
    STEP: Performing a canary update 04/18/23 08:56:32.358
    Apr 18 08:56:32.375: INFO: Updating stateful set ss2
    Apr 18 08:56:32.382: INFO: Waiting for Pod statefulset-4592/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 04/18/23 08:56:42.39
    Apr 18 08:56:42.416: INFO: Found 1 stateful pods, waiting for 3
    Apr 18 08:56:52.423: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 08:56:52.423: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 08:56:52.423: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 04/18/23 08:56:52.429
    Apr 18 08:56:52.446: INFO: Updating stateful set ss2
    Apr 18 08:56:52.453: INFO: Waiting for Pod statefulset-4592/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Apr 18 08:57:02.480: INFO: Updating stateful set ss2
    Apr 18 08:57:02.485: INFO: Waiting for StatefulSet statefulset-4592/ss2 to complete update
    Apr 18 08:57:02.485: INFO: Waiting for Pod statefulset-4592/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 08:57:12.494: INFO: Deleting all statefulset in ns statefulset-4592
    Apr 18 08:57:12.496: INFO: Scaling statefulset ss2 to 0
    Apr 18 08:57:22.514: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 08:57:22.517: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 08:57:22.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4592" for this suite. 04/18/23 08:57:22.535
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:57:22.543
Apr 18 08:57:22.543: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename pods 04/18/23 08:57:22.543
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:57:22.558
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:57:22.562
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 04/18/23 08:57:22.57
STEP: watching for Pod to be ready 04/18/23 08:57:22.576
Apr 18 08:57:22.578: INFO: observed Pod pod-test in namespace pods-3759 in phase Pending with labels: map[test-pod-static:true] & conditions []
Apr 18 08:57:22.581: INFO: observed Pod pod-test in namespace pods-3759 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:22 +0000 UTC  }]
Apr 18 08:57:22.592: INFO: observed Pod pod-test in namespace pods-3759 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:22 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:22 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:22 +0000 UTC  }]
Apr 18 08:57:24.117: INFO: Found Pod pod-test in namespace pods-3759 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:22 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 04/18/23 08:57:24.121
STEP: getting the Pod and ensuring that it's patched 04/18/23 08:57:24.132
STEP: replacing the Pod's status Ready condition to False 04/18/23 08:57:24.139
STEP: check the Pod again to ensure its Ready conditions are False 04/18/23 08:57:24.158
STEP: deleting the Pod via a Collection with a LabelSelector 04/18/23 08:57:24.158
STEP: watching for the Pod to be deleted 04/18/23 08:57:24.179
Apr 18 08:57:24.181: INFO: observed event type MODIFIED
Apr 18 08:57:26.112: INFO: observed event type MODIFIED
Apr 18 08:57:27.113: INFO: observed event type MODIFIED
Apr 18 08:57:27.120: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 08:57:27.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3759" for this suite. 04/18/23 08:57:27.137
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":125,"skipped":2274,"failed":0}
------------------------------
• [4.599 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:57:22.543
    Apr 18 08:57:22.543: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename pods 04/18/23 08:57:22.543
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:57:22.558
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:57:22.562
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 04/18/23 08:57:22.57
    STEP: watching for Pod to be ready 04/18/23 08:57:22.576
    Apr 18 08:57:22.578: INFO: observed Pod pod-test in namespace pods-3759 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Apr 18 08:57:22.581: INFO: observed Pod pod-test in namespace pods-3759 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:22 +0000 UTC  }]
    Apr 18 08:57:22.592: INFO: observed Pod pod-test in namespace pods-3759 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:22 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:22 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:22 +0000 UTC  }]
    Apr 18 08:57:24.117: INFO: Found Pod pod-test in namespace pods-3759 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 08:57:22 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 04/18/23 08:57:24.121
    STEP: getting the Pod and ensuring that it's patched 04/18/23 08:57:24.132
    STEP: replacing the Pod's status Ready condition to False 04/18/23 08:57:24.139
    STEP: check the Pod again to ensure its Ready conditions are False 04/18/23 08:57:24.158
    STEP: deleting the Pod via a Collection with a LabelSelector 04/18/23 08:57:24.158
    STEP: watching for the Pod to be deleted 04/18/23 08:57:24.179
    Apr 18 08:57:24.181: INFO: observed event type MODIFIED
    Apr 18 08:57:26.112: INFO: observed event type MODIFIED
    Apr 18 08:57:27.113: INFO: observed event type MODIFIED
    Apr 18 08:57:27.120: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 08:57:27.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3759" for this suite. 04/18/23 08:57:27.137
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:57:27.144
Apr 18 08:57:27.144: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 08:57:27.145
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:57:27.155
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:57:27.158
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 08:57:27.172
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:57:27.634
STEP: Deploying the webhook pod 04/18/23 08:57:27.645
STEP: Wait for the deployment to be ready 04/18/23 08:57:27.655
Apr 18 08:57:27.663: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 08:57:29.673
STEP: Verifying the service has paired with the endpoint 04/18/23 08:57:29.681
Apr 18 08:57:30.682: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Apr 18 08:57:30.685: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3783-crds.webhook.example.com via the AdmissionRegistration API 04/18/23 08:57:31.197
STEP: Creating a custom resource while v1 is storage version 04/18/23 08:57:31.212
STEP: Patching Custom Resource Definition to set v2 as storage 04/18/23 08:57:33.282
STEP: Patching the custom resource while v2 is storage version 04/18/23 08:57:33.296
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 08:57:33.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1415" for this suite. 04/18/23 08:57:33.835
STEP: Destroying namespace "webhook-1415-markers" for this suite. 04/18/23 08:57:33.841
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":126,"skipped":2304,"failed":0}
------------------------------
• [SLOW TEST] [6.735 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:57:27.144
    Apr 18 08:57:27.144: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 08:57:27.145
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:57:27.155
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:57:27.158
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 08:57:27.172
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 08:57:27.634
    STEP: Deploying the webhook pod 04/18/23 08:57:27.645
    STEP: Wait for the deployment to be ready 04/18/23 08:57:27.655
    Apr 18 08:57:27.663: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 08:57:29.673
    STEP: Verifying the service has paired with the endpoint 04/18/23 08:57:29.681
    Apr 18 08:57:30.682: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Apr 18 08:57:30.685: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3783-crds.webhook.example.com via the AdmissionRegistration API 04/18/23 08:57:31.197
    STEP: Creating a custom resource while v1 is storage version 04/18/23 08:57:31.212
    STEP: Patching Custom Resource Definition to set v2 as storage 04/18/23 08:57:33.282
    STEP: Patching the custom resource while v2 is storage version 04/18/23 08:57:33.296
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 08:57:33.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1415" for this suite. 04/18/23 08:57:33.835
    STEP: Destroying namespace "webhook-1415-markers" for this suite. 04/18/23 08:57:33.841
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:57:33.88
Apr 18 08:57:33.880: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename configmap 04/18/23 08:57:33.881
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:57:33.9
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:57:33.904
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-59db2ec4-5a05-4ae5-abe1-64074112a44c 04/18/23 08:57:33.908
STEP: Creating a pod to test consume configMaps 04/18/23 08:57:33.912
Apr 18 08:57:33.919: INFO: Waiting up to 5m0s for pod "pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae" in namespace "configmap-6856" to be "Succeeded or Failed"
Apr 18 08:57:33.922: INFO: Pod "pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.781874ms
Apr 18 08:57:35.926: INFO: Pod "pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006337829s
Apr 18 08:57:37.927: INFO: Pod "pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007140761s
STEP: Saw pod success 04/18/23 08:57:37.927
Apr 18 08:57:37.927: INFO: Pod "pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae" satisfied condition "Succeeded or Failed"
Apr 18 08:57:37.930: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae container agnhost-container: <nil>
STEP: delete the pod 04/18/23 08:57:37.934
Apr 18 08:57:37.945: INFO: Waiting for pod pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae to disappear
Apr 18 08:57:37.947: INFO: Pod pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 08:57:37.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6856" for this suite. 04/18/23 08:57:37.953
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":127,"skipped":2308,"failed":0}
------------------------------
• [4.077 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:57:33.88
    Apr 18 08:57:33.880: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename configmap 04/18/23 08:57:33.881
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:57:33.9
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:57:33.904
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-59db2ec4-5a05-4ae5-abe1-64074112a44c 04/18/23 08:57:33.908
    STEP: Creating a pod to test consume configMaps 04/18/23 08:57:33.912
    Apr 18 08:57:33.919: INFO: Waiting up to 5m0s for pod "pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae" in namespace "configmap-6856" to be "Succeeded or Failed"
    Apr 18 08:57:33.922: INFO: Pod "pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.781874ms
    Apr 18 08:57:35.926: INFO: Pod "pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006337829s
    Apr 18 08:57:37.927: INFO: Pod "pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007140761s
    STEP: Saw pod success 04/18/23 08:57:37.927
    Apr 18 08:57:37.927: INFO: Pod "pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae" satisfied condition "Succeeded or Failed"
    Apr 18 08:57:37.930: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 08:57:37.934
    Apr 18 08:57:37.945: INFO: Waiting for pod pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae to disappear
    Apr 18 08:57:37.947: INFO: Pod pod-configmaps-79e91cdc-a695-4bcb-952d-db524ee7d5ae no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 08:57:37.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6856" for this suite. 04/18/23 08:57:37.953
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:57:37.958
Apr 18 08:57:37.958: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 08:57:37.959
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:57:37.969
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:57:37.972
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-1556 04/18/23 08:57:37.976
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/18/23 08:57:37.985
STEP: creating service externalsvc in namespace services-1556 04/18/23 08:57:37.985
STEP: creating replication controller externalsvc in namespace services-1556 04/18/23 08:57:37.994
I0418 08:57:37.998202      18 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1556, replica count: 2
I0418 08:57:41.050190      18 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 04/18/23 08:57:41.053
Apr 18 08:57:41.064: INFO: Creating new exec pod
Apr 18 08:57:41.069: INFO: Waiting up to 5m0s for pod "execpod56796" in namespace "services-1556" to be "running"
Apr 18 08:57:41.075: INFO: Pod "execpod56796": Phase="Pending", Reason="", readiness=false. Elapsed: 5.985647ms
Apr 18 08:57:43.079: INFO: Pod "execpod56796": Phase="Running", Reason="", readiness=true. Elapsed: 2.009435088s
Apr 18 08:57:43.079: INFO: Pod "execpod56796" satisfied condition "running"
Apr 18 08:57:43.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-1556 exec execpod56796 -- /bin/sh -x -c nslookup clusterip-service.services-1556.svc.cluster.local'
Apr 18 08:57:43.198: INFO: stderr: "+ nslookup clusterip-service.services-1556.svc.cluster.local\n"
Apr 18 08:57:43.198: INFO: stdout: "Server:\t\t10.247.3.10\nAddress:\t10.247.3.10#53\n\nclusterip-service.services-1556.svc.cluster.local\tcanonical name = externalsvc.services-1556.svc.cluster.local.\nName:\texternalsvc.services-1556.svc.cluster.local\nAddress: 10.247.118.99\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1556, will wait for the garbage collector to delete the pods 04/18/23 08:57:43.198
Apr 18 08:57:43.258: INFO: Deleting ReplicationController externalsvc took: 5.400325ms
Apr 18 08:57:43.358: INFO: Terminating ReplicationController externalsvc pods took: 100.580916ms
Apr 18 08:57:45.271: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 08:57:45.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1556" for this suite. 04/18/23 08:57:45.285
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":128,"skipped":2330,"failed":0}
------------------------------
• [SLOW TEST] [7.348 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:57:37.958
    Apr 18 08:57:37.958: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 08:57:37.959
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:57:37.969
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:57:37.972
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-1556 04/18/23 08:57:37.976
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/18/23 08:57:37.985
    STEP: creating service externalsvc in namespace services-1556 04/18/23 08:57:37.985
    STEP: creating replication controller externalsvc in namespace services-1556 04/18/23 08:57:37.994
    I0418 08:57:37.998202      18 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1556, replica count: 2
    I0418 08:57:41.050190      18 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 04/18/23 08:57:41.053
    Apr 18 08:57:41.064: INFO: Creating new exec pod
    Apr 18 08:57:41.069: INFO: Waiting up to 5m0s for pod "execpod56796" in namespace "services-1556" to be "running"
    Apr 18 08:57:41.075: INFO: Pod "execpod56796": Phase="Pending", Reason="", readiness=false. Elapsed: 5.985647ms
    Apr 18 08:57:43.079: INFO: Pod "execpod56796": Phase="Running", Reason="", readiness=true. Elapsed: 2.009435088s
    Apr 18 08:57:43.079: INFO: Pod "execpod56796" satisfied condition "running"
    Apr 18 08:57:43.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-1556 exec execpod56796 -- /bin/sh -x -c nslookup clusterip-service.services-1556.svc.cluster.local'
    Apr 18 08:57:43.198: INFO: stderr: "+ nslookup clusterip-service.services-1556.svc.cluster.local\n"
    Apr 18 08:57:43.198: INFO: stdout: "Server:\t\t10.247.3.10\nAddress:\t10.247.3.10#53\n\nclusterip-service.services-1556.svc.cluster.local\tcanonical name = externalsvc.services-1556.svc.cluster.local.\nName:\texternalsvc.services-1556.svc.cluster.local\nAddress: 10.247.118.99\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-1556, will wait for the garbage collector to delete the pods 04/18/23 08:57:43.198
    Apr 18 08:57:43.258: INFO: Deleting ReplicationController externalsvc took: 5.400325ms
    Apr 18 08:57:43.358: INFO: Terminating ReplicationController externalsvc pods took: 100.580916ms
    Apr 18 08:57:45.271: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 08:57:45.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1556" for this suite. 04/18/23 08:57:45.285
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:57:45.306
Apr 18 08:57:45.306: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename containers 04/18/23 08:57:45.307
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:57:45.331
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:57:45.335
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 04/18/23 08:57:45.339
Apr 18 08:57:45.344: INFO: Waiting up to 5m0s for pod "client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010" in namespace "containers-5915" to be "Succeeded or Failed"
Apr 18 08:57:45.347: INFO: Pod "client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010": Phase="Pending", Reason="", readiness=false. Elapsed: 2.370584ms
Apr 18 08:57:47.351: INFO: Pod "client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006539863s
Apr 18 08:57:49.351: INFO: Pod "client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006853774s
STEP: Saw pod success 04/18/23 08:57:49.351
Apr 18 08:57:49.351: INFO: Pod "client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010" satisfied condition "Succeeded or Failed"
Apr 18 08:57:49.354: INFO: Trying to get logs from node 192.168.1.152 pod client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 08:57:49.365
Apr 18 08:57:49.377: INFO: Waiting for pod client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010 to disappear
Apr 18 08:57:49.380: INFO: Pod client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 18 08:57:49.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5915" for this suite. 04/18/23 08:57:49.384
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":129,"skipped":2331,"failed":0}
------------------------------
• [4.082 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:57:45.306
    Apr 18 08:57:45.306: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename containers 04/18/23 08:57:45.307
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:57:45.331
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:57:45.335
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 04/18/23 08:57:45.339
    Apr 18 08:57:45.344: INFO: Waiting up to 5m0s for pod "client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010" in namespace "containers-5915" to be "Succeeded or Failed"
    Apr 18 08:57:45.347: INFO: Pod "client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010": Phase="Pending", Reason="", readiness=false. Elapsed: 2.370584ms
    Apr 18 08:57:47.351: INFO: Pod "client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006539863s
    Apr 18 08:57:49.351: INFO: Pod "client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006853774s
    STEP: Saw pod success 04/18/23 08:57:49.351
    Apr 18 08:57:49.351: INFO: Pod "client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010" satisfied condition "Succeeded or Failed"
    Apr 18 08:57:49.354: INFO: Trying to get logs from node 192.168.1.152 pod client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 08:57:49.365
    Apr 18 08:57:49.377: INFO: Waiting for pod client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010 to disappear
    Apr 18 08:57:49.380: INFO: Pod client-containers-b9905471-4eda-41ad-a7bf-d8fb69b92010 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 18 08:57:49.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-5915" for this suite. 04/18/23 08:57:49.384
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 08:57:49.391
Apr 18 08:57:49.391: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-probe 04/18/23 08:57:49.392
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:57:49.405
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:57:49.409
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-914fac70-0276-4cf2-acf3-df9d43305a78 in namespace container-probe-7965 04/18/23 08:57:49.413
Apr 18 08:57:49.420: INFO: Waiting up to 5m0s for pod "liveness-914fac70-0276-4cf2-acf3-df9d43305a78" in namespace "container-probe-7965" to be "not pending"
Apr 18 08:57:49.423: INFO: Pod "liveness-914fac70-0276-4cf2-acf3-df9d43305a78": Phase="Pending", Reason="", readiness=false. Elapsed: 2.352234ms
Apr 18 08:57:51.427: INFO: Pod "liveness-914fac70-0276-4cf2-acf3-df9d43305a78": Phase="Running", Reason="", readiness=true. Elapsed: 2.006740692s
Apr 18 08:57:51.427: INFO: Pod "liveness-914fac70-0276-4cf2-acf3-df9d43305a78" satisfied condition "not pending"
Apr 18 08:57:51.427: INFO: Started pod liveness-914fac70-0276-4cf2-acf3-df9d43305a78 in namespace container-probe-7965
STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 08:57:51.427
Apr 18 08:57:51.430: INFO: Initial restart count of pod liveness-914fac70-0276-4cf2-acf3-df9d43305a78 is 0
Apr 18 08:58:11.476: INFO: Restart count of pod container-probe-7965/liveness-914fac70-0276-4cf2-acf3-df9d43305a78 is now 1 (20.04524827s elapsed)
Apr 18 08:58:31.513: INFO: Restart count of pod container-probe-7965/liveness-914fac70-0276-4cf2-acf3-df9d43305a78 is now 2 (40.08290033s elapsed)
Apr 18 08:58:51.553: INFO: Restart count of pod container-probe-7965/liveness-914fac70-0276-4cf2-acf3-df9d43305a78 is now 3 (1m0.122557281s elapsed)
Apr 18 08:59:11.590: INFO: Restart count of pod container-probe-7965/liveness-914fac70-0276-4cf2-acf3-df9d43305a78 is now 4 (1m20.159851985s elapsed)
Apr 18 09:00:13.712: INFO: Restart count of pod container-probe-7965/liveness-914fac70-0276-4cf2-acf3-df9d43305a78 is now 5 (2m22.281323772s elapsed)
STEP: deleting the pod 04/18/23 09:00:13.712
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 09:00:13.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7965" for this suite. 04/18/23 09:00:13.732
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":130,"skipped":2349,"failed":0}
------------------------------
• [SLOW TEST] [144.345 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 08:57:49.391
    Apr 18 08:57:49.391: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-probe 04/18/23 08:57:49.392
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 08:57:49.405
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 08:57:49.409
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-914fac70-0276-4cf2-acf3-df9d43305a78 in namespace container-probe-7965 04/18/23 08:57:49.413
    Apr 18 08:57:49.420: INFO: Waiting up to 5m0s for pod "liveness-914fac70-0276-4cf2-acf3-df9d43305a78" in namespace "container-probe-7965" to be "not pending"
    Apr 18 08:57:49.423: INFO: Pod "liveness-914fac70-0276-4cf2-acf3-df9d43305a78": Phase="Pending", Reason="", readiness=false. Elapsed: 2.352234ms
    Apr 18 08:57:51.427: INFO: Pod "liveness-914fac70-0276-4cf2-acf3-df9d43305a78": Phase="Running", Reason="", readiness=true. Elapsed: 2.006740692s
    Apr 18 08:57:51.427: INFO: Pod "liveness-914fac70-0276-4cf2-acf3-df9d43305a78" satisfied condition "not pending"
    Apr 18 08:57:51.427: INFO: Started pod liveness-914fac70-0276-4cf2-acf3-df9d43305a78 in namespace container-probe-7965
    STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 08:57:51.427
    Apr 18 08:57:51.430: INFO: Initial restart count of pod liveness-914fac70-0276-4cf2-acf3-df9d43305a78 is 0
    Apr 18 08:58:11.476: INFO: Restart count of pod container-probe-7965/liveness-914fac70-0276-4cf2-acf3-df9d43305a78 is now 1 (20.04524827s elapsed)
    Apr 18 08:58:31.513: INFO: Restart count of pod container-probe-7965/liveness-914fac70-0276-4cf2-acf3-df9d43305a78 is now 2 (40.08290033s elapsed)
    Apr 18 08:58:51.553: INFO: Restart count of pod container-probe-7965/liveness-914fac70-0276-4cf2-acf3-df9d43305a78 is now 3 (1m0.122557281s elapsed)
    Apr 18 08:59:11.590: INFO: Restart count of pod container-probe-7965/liveness-914fac70-0276-4cf2-acf3-df9d43305a78 is now 4 (1m20.159851985s elapsed)
    Apr 18 09:00:13.712: INFO: Restart count of pod container-probe-7965/liveness-914fac70-0276-4cf2-acf3-df9d43305a78 is now 5 (2m22.281323772s elapsed)
    STEP: deleting the pod 04/18/23 09:00:13.712
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 09:00:13.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7965" for this suite. 04/18/23 09:00:13.732
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:00:13.74
Apr 18 09:00:13.740: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename resourcequota 04/18/23 09:00:13.74
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:00:13.752
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:00:13.756
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 04/18/23 09:00:13.76
STEP: Creating a ResourceQuota 04/18/23 09:00:18.763
STEP: Ensuring resource quota status is calculated 04/18/23 09:00:18.768
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 09:00:20.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-527" for this suite. 04/18/23 09:00:20.776
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":131,"skipped":2369,"failed":0}
------------------------------
• [SLOW TEST] [7.041 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:00:13.74
    Apr 18 09:00:13.740: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename resourcequota 04/18/23 09:00:13.74
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:00:13.752
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:00:13.756
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 04/18/23 09:00:13.76
    STEP: Creating a ResourceQuota 04/18/23 09:00:18.763
    STEP: Ensuring resource quota status is calculated 04/18/23 09:00:18.768
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 09:00:20.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-527" for this suite. 04/18/23 09:00:20.776
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:00:20.784
Apr 18 09:00:20.784: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 09:00:20.785
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:00:20.822
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:00:20.831
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 04/18/23 09:00:20.845
STEP: waiting for available Endpoint 04/18/23 09:00:20.849
STEP: listing all Endpoints 04/18/23 09:00:20.852
STEP: updating the Endpoint 04/18/23 09:00:20.857
STEP: fetching the Endpoint 04/18/23 09:00:20.868
STEP: patching the Endpoint 04/18/23 09:00:20.87
STEP: fetching the Endpoint 04/18/23 09:00:20.879
STEP: deleting the Endpoint by Collection 04/18/23 09:00:20.882
STEP: waiting for Endpoint deletion 04/18/23 09:00:20.888
STEP: fetching the Endpoint 04/18/23 09:00:20.89
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 09:00:20.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1398" for this suite. 04/18/23 09:00:20.896
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":132,"skipped":2396,"failed":0}
------------------------------
• [0.119 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:00:20.784
    Apr 18 09:00:20.784: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 09:00:20.785
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:00:20.822
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:00:20.831
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 04/18/23 09:00:20.845
    STEP: waiting for available Endpoint 04/18/23 09:00:20.849
    STEP: listing all Endpoints 04/18/23 09:00:20.852
    STEP: updating the Endpoint 04/18/23 09:00:20.857
    STEP: fetching the Endpoint 04/18/23 09:00:20.868
    STEP: patching the Endpoint 04/18/23 09:00:20.87
    STEP: fetching the Endpoint 04/18/23 09:00:20.879
    STEP: deleting the Endpoint by Collection 04/18/23 09:00:20.882
    STEP: waiting for Endpoint deletion 04/18/23 09:00:20.888
    STEP: fetching the Endpoint 04/18/23 09:00:20.89
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 09:00:20.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1398" for this suite. 04/18/23 09:00:20.896
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:00:20.904
Apr 18 09:00:20.904: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename hostport 04/18/23 09:00:20.904
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:00:20.914
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:00:20.917
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 04/18/23 09:00:20.925
Apr 18 09:00:20.932: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-2882" to be "running and ready"
Apr 18 09:00:20.937: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.098873ms
Apr 18 09:00:20.937: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:00:22.941: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.00890401s
Apr 18 09:00:22.941: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 18 09:00:22.941: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.1.84 on the node which pod1 resides and expect scheduled 04/18/23 09:00:22.941
Apr 18 09:00:22.946: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-2882" to be "running and ready"
Apr 18 09:00:22.948: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.597854ms
Apr 18 09:00:22.948: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:00:24.952: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.006103427s
Apr 18 09:00:24.952: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 18 09:00:24.952: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.1.84 but use UDP protocol on the node which pod2 resides 04/18/23 09:00:24.952
Apr 18 09:00:24.959: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-2882" to be "running and ready"
Apr 18 09:00:24.961: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.637194ms
Apr 18 09:00:24.961: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:00:26.966: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.006983843s
Apr 18 09:00:26.966: INFO: The phase of Pod pod3 is Running (Ready = true)
Apr 18 09:00:26.966: INFO: Pod "pod3" satisfied condition "running and ready"
Apr 18 09:00:26.972: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-2882" to be "running and ready"
Apr 18 09:00:26.975: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.595624ms
Apr 18 09:00:26.975: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:00:28.979: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.006867s
Apr 18 09:00:28.979: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Apr 18 09:00:28.979: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 04/18/23 09:00:28.982
Apr 18 09:00:28.982: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.1.84 http://127.0.0.1:54323/hostname] Namespace:hostport-2882 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 09:00:28.982: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 09:00:28.982: INFO: ExecWithOptions: Clientset creation
Apr 18 09:00:28.982: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/hostport-2882/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.1.84+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.1.84, port: 54323 04/18/23 09:00:29.041
Apr 18 09:00:29.041: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.1.84:54323/hostname] Namespace:hostport-2882 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 09:00:29.041: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 09:00:29.042: INFO: ExecWithOptions: Clientset creation
Apr 18 09:00:29.042: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/hostport-2882/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.1.84%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.1.84, port: 54323 UDP 04/18/23 09:00:29.092
Apr 18 09:00:29.092: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.1.84 54323] Namespace:hostport-2882 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 09:00:29.092: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 09:00:29.092: INFO: ExecWithOptions: Clientset creation
Apr 18 09:00:29.093: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/hostport-2882/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.1.84+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Apr 18 09:00:34.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-2882" for this suite. 04/18/23 09:00:34.141
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":133,"skipped":2397,"failed":0}
------------------------------
• [SLOW TEST] [13.243 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:00:20.904
    Apr 18 09:00:20.904: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename hostport 04/18/23 09:00:20.904
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:00:20.914
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:00:20.917
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 04/18/23 09:00:20.925
    Apr 18 09:00:20.932: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-2882" to be "running and ready"
    Apr 18 09:00:20.937: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.098873ms
    Apr 18 09:00:20.937: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:00:22.941: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.00890401s
    Apr 18 09:00:22.941: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 18 09:00:22.941: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.1.84 on the node which pod1 resides and expect scheduled 04/18/23 09:00:22.941
    Apr 18 09:00:22.946: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-2882" to be "running and ready"
    Apr 18 09:00:22.948: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.597854ms
    Apr 18 09:00:22.948: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:00:24.952: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.006103427s
    Apr 18 09:00:24.952: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 18 09:00:24.952: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.1.84 but use UDP protocol on the node which pod2 resides 04/18/23 09:00:24.952
    Apr 18 09:00:24.959: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-2882" to be "running and ready"
    Apr 18 09:00:24.961: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.637194ms
    Apr 18 09:00:24.961: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:00:26.966: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.006983843s
    Apr 18 09:00:26.966: INFO: The phase of Pod pod3 is Running (Ready = true)
    Apr 18 09:00:26.966: INFO: Pod "pod3" satisfied condition "running and ready"
    Apr 18 09:00:26.972: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-2882" to be "running and ready"
    Apr 18 09:00:26.975: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.595624ms
    Apr 18 09:00:26.975: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:00:28.979: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.006867s
    Apr 18 09:00:28.979: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Apr 18 09:00:28.979: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 04/18/23 09:00:28.982
    Apr 18 09:00:28.982: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.1.84 http://127.0.0.1:54323/hostname] Namespace:hostport-2882 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 09:00:28.982: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 09:00:28.982: INFO: ExecWithOptions: Clientset creation
    Apr 18 09:00:28.982: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/hostport-2882/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.1.84+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.1.84, port: 54323 04/18/23 09:00:29.041
    Apr 18 09:00:29.041: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.1.84:54323/hostname] Namespace:hostport-2882 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 09:00:29.041: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 09:00:29.042: INFO: ExecWithOptions: Clientset creation
    Apr 18 09:00:29.042: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/hostport-2882/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.1.84%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.1.84, port: 54323 UDP 04/18/23 09:00:29.092
    Apr 18 09:00:29.092: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.1.84 54323] Namespace:hostport-2882 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 09:00:29.092: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 09:00:29.092: INFO: ExecWithOptions: Clientset creation
    Apr 18 09:00:29.093: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/hostport-2882/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.1.84+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Apr 18 09:00:34.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-2882" for this suite. 04/18/23 09:00:34.141
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:00:34.148
Apr 18 09:00:34.148: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-probe 04/18/23 09:00:34.149
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:00:34.174
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:00:34.177
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b in namespace container-probe-3203 04/18/23 09:00:34.181
Apr 18 09:00:34.188: INFO: Waiting up to 5m0s for pod "busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b" in namespace "container-probe-3203" to be "not pending"
Apr 18 09:00:34.193: INFO: Pod "busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.722135ms
Apr 18 09:00:36.201: INFO: Pod "busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b": Phase="Running", Reason="", readiness=true. Elapsed: 2.012163311s
Apr 18 09:00:36.201: INFO: Pod "busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b" satisfied condition "not pending"
Apr 18 09:00:36.201: INFO: Started pod busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b in namespace container-probe-3203
STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 09:00:36.201
Apr 18 09:00:36.203: INFO: Initial restart count of pod busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b is 0
Apr 18 09:01:26.303: INFO: Restart count of pod container-probe-3203/busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b is now 1 (50.100035911s elapsed)
STEP: deleting the pod 04/18/23 09:01:26.303
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 09:01:26.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3203" for this suite. 04/18/23 09:01:26.318
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":134,"skipped":2418,"failed":0}
------------------------------
• [SLOW TEST] [52.175 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:00:34.148
    Apr 18 09:00:34.148: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-probe 04/18/23 09:00:34.149
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:00:34.174
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:00:34.177
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b in namespace container-probe-3203 04/18/23 09:00:34.181
    Apr 18 09:00:34.188: INFO: Waiting up to 5m0s for pod "busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b" in namespace "container-probe-3203" to be "not pending"
    Apr 18 09:00:34.193: INFO: Pod "busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.722135ms
    Apr 18 09:00:36.201: INFO: Pod "busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b": Phase="Running", Reason="", readiness=true. Elapsed: 2.012163311s
    Apr 18 09:00:36.201: INFO: Pod "busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b" satisfied condition "not pending"
    Apr 18 09:00:36.201: INFO: Started pod busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b in namespace container-probe-3203
    STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 09:00:36.201
    Apr 18 09:00:36.203: INFO: Initial restart count of pod busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b is 0
    Apr 18 09:01:26.303: INFO: Restart count of pod container-probe-3203/busybox-b3ffd266-0c35-4f9d-8d7c-51fecc4b526b is now 1 (50.100035911s elapsed)
    STEP: deleting the pod 04/18/23 09:01:26.303
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 09:01:26.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3203" for this suite. 04/18/23 09:01:26.318
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:01:26.324
Apr 18 09:01:26.324: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename svcaccounts 04/18/23 09:01:26.325
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:01:26.334
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:01:26.337
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Apr 18 09:01:26.359: INFO: created pod pod-service-account-defaultsa
Apr 18 09:01:26.359: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 18 09:01:26.366: INFO: created pod pod-service-account-mountsa
Apr 18 09:01:26.366: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 18 09:01:26.374: INFO: created pod pod-service-account-nomountsa
Apr 18 09:01:26.374: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 18 09:01:26.382: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 18 09:01:26.382: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 18 09:01:26.388: INFO: created pod pod-service-account-mountsa-mountspec
Apr 18 09:01:26.388: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 18 09:01:26.396: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 18 09:01:26.396: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 18 09:01:26.405: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 18 09:01:26.405: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 18 09:01:26.413: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 18 09:01:26.413: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 18 09:01:26.425: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 18 09:01:26.426: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 18 09:01:26.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2128" for this suite. 04/18/23 09:01:26.429
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":135,"skipped":2430,"failed":0}
------------------------------
• [0.123 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:01:26.324
    Apr 18 09:01:26.324: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename svcaccounts 04/18/23 09:01:26.325
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:01:26.334
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:01:26.337
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Apr 18 09:01:26.359: INFO: created pod pod-service-account-defaultsa
    Apr 18 09:01:26.359: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Apr 18 09:01:26.366: INFO: created pod pod-service-account-mountsa
    Apr 18 09:01:26.366: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Apr 18 09:01:26.374: INFO: created pod pod-service-account-nomountsa
    Apr 18 09:01:26.374: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Apr 18 09:01:26.382: INFO: created pod pod-service-account-defaultsa-mountspec
    Apr 18 09:01:26.382: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Apr 18 09:01:26.388: INFO: created pod pod-service-account-mountsa-mountspec
    Apr 18 09:01:26.388: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Apr 18 09:01:26.396: INFO: created pod pod-service-account-nomountsa-mountspec
    Apr 18 09:01:26.396: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Apr 18 09:01:26.405: INFO: created pod pod-service-account-defaultsa-nomountspec
    Apr 18 09:01:26.405: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Apr 18 09:01:26.413: INFO: created pod pod-service-account-mountsa-nomountspec
    Apr 18 09:01:26.413: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Apr 18 09:01:26.425: INFO: created pod pod-service-account-nomountsa-nomountspec
    Apr 18 09:01:26.426: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 18 09:01:26.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2128" for this suite. 04/18/23 09:01:26.429
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:01:26.451
Apr 18 09:01:26.451: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename subpath 04/18/23 09:01:26.452
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:01:26.469
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:01:26.472
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/18/23 09:01:26.476
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-p2gs 04/18/23 09:01:26.485
STEP: Creating a pod to test atomic-volume-subpath 04/18/23 09:01:26.485
Apr 18 09:01:26.493: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-p2gs" in namespace "subpath-5477" to be "Succeeded or Failed"
Apr 18 09:01:26.496: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.942829ms
Apr 18 09:01:28.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 2.007129937s
Apr 18 09:01:30.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 4.006884405s
Apr 18 09:01:32.499: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 6.006105481s
Apr 18 09:01:34.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 8.007079913s
Apr 18 09:01:36.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 10.007314636s
Apr 18 09:01:38.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 12.007182764s
Apr 18 09:01:40.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 14.007507061s
Apr 18 09:01:42.499: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 16.006130877s
Apr 18 09:01:44.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 18.007336213s
Apr 18 09:01:46.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 20.007129742s
Apr 18 09:01:48.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=false. Elapsed: 22.007267337s
Apr 18 09:01:50.499: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.006410923s
STEP: Saw pod success 04/18/23 09:01:50.499
Apr 18 09:01:50.499: INFO: Pod "pod-subpath-test-downwardapi-p2gs" satisfied condition "Succeeded or Failed"
Apr 18 09:01:50.503: INFO: Trying to get logs from node 192.168.1.29 pod pod-subpath-test-downwardapi-p2gs container test-container-subpath-downwardapi-p2gs: <nil>
STEP: delete the pod 04/18/23 09:01:50.516
Apr 18 09:01:50.528: INFO: Waiting for pod pod-subpath-test-downwardapi-p2gs to disappear
Apr 18 09:01:50.530: INFO: Pod pod-subpath-test-downwardapi-p2gs no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-p2gs 04/18/23 09:01:50.53
Apr 18 09:01:50.530: INFO: Deleting pod "pod-subpath-test-downwardapi-p2gs" in namespace "subpath-5477"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 18 09:01:50.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5477" for this suite. 04/18/23 09:01:50.537
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":136,"skipped":2481,"failed":0}
------------------------------
• [SLOW TEST] [24.090 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:01:26.451
    Apr 18 09:01:26.451: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename subpath 04/18/23 09:01:26.452
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:01:26.469
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:01:26.472
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/18/23 09:01:26.476
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-p2gs 04/18/23 09:01:26.485
    STEP: Creating a pod to test atomic-volume-subpath 04/18/23 09:01:26.485
    Apr 18 09:01:26.493: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-p2gs" in namespace "subpath-5477" to be "Succeeded or Failed"
    Apr 18 09:01:26.496: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.942829ms
    Apr 18 09:01:28.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 2.007129937s
    Apr 18 09:01:30.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 4.006884405s
    Apr 18 09:01:32.499: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 6.006105481s
    Apr 18 09:01:34.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 8.007079913s
    Apr 18 09:01:36.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 10.007314636s
    Apr 18 09:01:38.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 12.007182764s
    Apr 18 09:01:40.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 14.007507061s
    Apr 18 09:01:42.499: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 16.006130877s
    Apr 18 09:01:44.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 18.007336213s
    Apr 18 09:01:46.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=true. Elapsed: 20.007129742s
    Apr 18 09:01:48.500: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Running", Reason="", readiness=false. Elapsed: 22.007267337s
    Apr 18 09:01:50.499: INFO: Pod "pod-subpath-test-downwardapi-p2gs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.006410923s
    STEP: Saw pod success 04/18/23 09:01:50.499
    Apr 18 09:01:50.499: INFO: Pod "pod-subpath-test-downwardapi-p2gs" satisfied condition "Succeeded or Failed"
    Apr 18 09:01:50.503: INFO: Trying to get logs from node 192.168.1.29 pod pod-subpath-test-downwardapi-p2gs container test-container-subpath-downwardapi-p2gs: <nil>
    STEP: delete the pod 04/18/23 09:01:50.516
    Apr 18 09:01:50.528: INFO: Waiting for pod pod-subpath-test-downwardapi-p2gs to disappear
    Apr 18 09:01:50.530: INFO: Pod pod-subpath-test-downwardapi-p2gs no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-p2gs 04/18/23 09:01:50.53
    Apr 18 09:01:50.530: INFO: Deleting pod "pod-subpath-test-downwardapi-p2gs" in namespace "subpath-5477"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 18 09:01:50.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-5477" for this suite. 04/18/23 09:01:50.537
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:01:50.544
Apr 18 09:01:50.544: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename limitrange 04/18/23 09:01:50.545
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:01:50.558
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:01:50.561
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 04/18/23 09:01:50.564
STEP: Setting up watch 04/18/23 09:01:50.565
STEP: Submitting a LimitRange 04/18/23 09:01:50.668
STEP: Verifying LimitRange creation was observed 04/18/23 09:01:50.712
STEP: Fetching the LimitRange to ensure it has proper values 04/18/23 09:01:50.713
Apr 18 09:01:50.716: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 18 09:01:50.716: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 04/18/23 09:01:50.716
STEP: Ensuring Pod has resource requirements applied from LimitRange 04/18/23 09:01:50.76
Apr 18 09:01:50.771: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 18 09:01:50.771: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 04/18/23 09:01:50.771
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 04/18/23 09:01:50.78
Apr 18 09:01:50.803: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Apr 18 09:01:50.803: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 04/18/23 09:01:50.803
STEP: Failing to create a Pod with more than max resources 04/18/23 09:01:50.811
STEP: Updating a LimitRange 04/18/23 09:01:50.813
STEP: Verifying LimitRange updating is effective 04/18/23 09:01:50.82
STEP: Creating a Pod with less than former min resources 04/18/23 09:01:52.825
STEP: Failing to create a Pod with more than max resources 04/18/23 09:01:52.831
STEP: Deleting a LimitRange 04/18/23 09:01:52.835
STEP: Verifying the LimitRange was deleted 04/18/23 09:01:52.843
Apr 18 09:01:57.847: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 04/18/23 09:01:57.847
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Apr 18 09:01:57.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-984" for this suite. 04/18/23 09:01:57.862
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":137,"skipped":2516,"failed":0}
------------------------------
• [SLOW TEST] [7.322 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:01:50.544
    Apr 18 09:01:50.544: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename limitrange 04/18/23 09:01:50.545
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:01:50.558
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:01:50.561
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 04/18/23 09:01:50.564
    STEP: Setting up watch 04/18/23 09:01:50.565
    STEP: Submitting a LimitRange 04/18/23 09:01:50.668
    STEP: Verifying LimitRange creation was observed 04/18/23 09:01:50.712
    STEP: Fetching the LimitRange to ensure it has proper values 04/18/23 09:01:50.713
    Apr 18 09:01:50.716: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Apr 18 09:01:50.716: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 04/18/23 09:01:50.716
    STEP: Ensuring Pod has resource requirements applied from LimitRange 04/18/23 09:01:50.76
    Apr 18 09:01:50.771: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Apr 18 09:01:50.771: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 04/18/23 09:01:50.771
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 04/18/23 09:01:50.78
    Apr 18 09:01:50.803: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Apr 18 09:01:50.803: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 04/18/23 09:01:50.803
    STEP: Failing to create a Pod with more than max resources 04/18/23 09:01:50.811
    STEP: Updating a LimitRange 04/18/23 09:01:50.813
    STEP: Verifying LimitRange updating is effective 04/18/23 09:01:50.82
    STEP: Creating a Pod with less than former min resources 04/18/23 09:01:52.825
    STEP: Failing to create a Pod with more than max resources 04/18/23 09:01:52.831
    STEP: Deleting a LimitRange 04/18/23 09:01:52.835
    STEP: Verifying the LimitRange was deleted 04/18/23 09:01:52.843
    Apr 18 09:01:57.847: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 04/18/23 09:01:57.847
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Apr 18 09:01:57.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-984" for this suite. 04/18/23 09:01:57.862
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:01:57.866
Apr 18 09:01:57.867: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename statefulset 04/18/23 09:01:57.867
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:01:57.876
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:01:57.879
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-510 04/18/23 09:01:57.883
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-510 04/18/23 09:01:57.887
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-510 04/18/23 09:01:57.893
Apr 18 09:01:57.896: INFO: Found 0 stateful pods, waiting for 1
Apr 18 09:02:07.900: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 04/18/23 09:02:07.9
Apr 18 09:02:07.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-510 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 09:02:08.010: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 09:02:08.010: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 09:02:08.010: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 09:02:08.013: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 18 09:02:18.017: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 09:02:18.017: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 09:02:18.031: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Apr 18 09:02:18.031: INFO: ss-0  192.168.1.152  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:01:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:01:57 +0000 UTC  }]
Apr 18 09:02:18.031: INFO: 
Apr 18 09:02:18.031: INFO: StatefulSet ss has not reached scale 3, at 1
Apr 18 09:02:19.034: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996547733s
Apr 18 09:02:20.038: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993154402s
Apr 18 09:02:21.043: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98821705s
Apr 18 09:02:22.047: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984493327s
Apr 18 09:02:23.051: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979601657s
Apr 18 09:02:24.055: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.975893126s
Apr 18 09:02:25.058: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.972614915s
Apr 18 09:02:26.062: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.968994702s
Apr 18 09:02:27.066: INFO: Verifying statefulset ss doesn't scale past 3 for another 964.698249ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-510 04/18/23 09:02:28.067
Apr 18 09:02:28.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-510 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 09:02:28.172: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 18 09:02:28.172: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 09:02:28.172: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 18 09:02:28.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-510 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 09:02:28.283: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 18 09:02:28.283: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 09:02:28.283: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 18 09:02:28.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-510 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 09:02:28.389: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 18 09:02:28.390: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 09:02:28.390: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 18 09:02:28.393: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 09:02:28.393: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 09:02:28.393: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 04/18/23 09:02:28.393
Apr 18 09:02:28.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-510 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 09:02:28.495: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 09:02:28.495: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 09:02:28.495: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 09:02:28.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-510 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 09:02:28.603: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 09:02:28.603: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 09:02:28.603: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 09:02:28.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-510 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 09:02:28.701: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 09:02:28.701: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 09:02:28.701: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 09:02:28.701: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 09:02:28.704: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Apr 18 09:02:38.710: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 09:02:38.710: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 09:02:38.710: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 09:02:38.721: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Apr 18 09:02:38.721: INFO: ss-0  192.168.1.152  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:01:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:01:57 +0000 UTC  }]
Apr 18 09:02:38.721: INFO: ss-1  192.168.1.29   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:18 +0000 UTC  }]
Apr 18 09:02:38.721: INFO: ss-2  192.168.1.84   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:18 +0000 UTC  }]
Apr 18 09:02:38.721: INFO: 
Apr 18 09:02:38.721: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 18 09:02:39.724: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 18 09:02:39.724: INFO: ss-2  192.168.1.84  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:18 +0000 UTC  }]
Apr 18 09:02:39.724: INFO: 
Apr 18 09:02:39.724: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 18 09:02:40.727: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.993322997s
Apr 18 09:02:41.730: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.990108047s
Apr 18 09:02:42.734: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.987195642s
Apr 18 09:02:43.737: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.983633001s
Apr 18 09:02:44.740: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.980929718s
Apr 18 09:02:45.743: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.977967448s
Apr 18 09:02:46.746: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.974820874s
Apr 18 09:02:47.750: INFO: Verifying statefulset ss doesn't scale past 0 for another 971.816534ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-510 04/18/23 09:02:48.75
Apr 18 09:02:48.753: INFO: Scaling statefulset ss to 0
Apr 18 09:02:48.762: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 09:02:48.765: INFO: Deleting all statefulset in ns statefulset-510
Apr 18 09:02:48.767: INFO: Scaling statefulset ss to 0
Apr 18 09:02:48.775: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 09:02:48.778: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 09:02:48.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-510" for this suite. 04/18/23 09:02:48.794
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":138,"skipped":2523,"failed":0}
------------------------------
• [SLOW TEST] [50.932 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:01:57.866
    Apr 18 09:01:57.867: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename statefulset 04/18/23 09:01:57.867
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:01:57.876
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:01:57.879
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-510 04/18/23 09:01:57.883
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-510 04/18/23 09:01:57.887
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-510 04/18/23 09:01:57.893
    Apr 18 09:01:57.896: INFO: Found 0 stateful pods, waiting for 1
    Apr 18 09:02:07.900: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 04/18/23 09:02:07.9
    Apr 18 09:02:07.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-510 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 09:02:08.010: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 09:02:08.010: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 09:02:08.010: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 09:02:08.013: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Apr 18 09:02:18.017: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 09:02:18.017: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 09:02:18.031: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
    Apr 18 09:02:18.031: INFO: ss-0  192.168.1.152  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:01:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:01:57 +0000 UTC  }]
    Apr 18 09:02:18.031: INFO: 
    Apr 18 09:02:18.031: INFO: StatefulSet ss has not reached scale 3, at 1
    Apr 18 09:02:19.034: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996547733s
    Apr 18 09:02:20.038: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993154402s
    Apr 18 09:02:21.043: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98821705s
    Apr 18 09:02:22.047: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984493327s
    Apr 18 09:02:23.051: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979601657s
    Apr 18 09:02:24.055: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.975893126s
    Apr 18 09:02:25.058: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.972614915s
    Apr 18 09:02:26.062: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.968994702s
    Apr 18 09:02:27.066: INFO: Verifying statefulset ss doesn't scale past 3 for another 964.698249ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-510 04/18/23 09:02:28.067
    Apr 18 09:02:28.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-510 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 09:02:28.172: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 18 09:02:28.172: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 09:02:28.172: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 18 09:02:28.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-510 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 09:02:28.283: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Apr 18 09:02:28.283: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 09:02:28.283: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 18 09:02:28.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-510 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 09:02:28.389: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Apr 18 09:02:28.390: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 09:02:28.390: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 18 09:02:28.393: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 09:02:28.393: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 09:02:28.393: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 04/18/23 09:02:28.393
    Apr 18 09:02:28.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-510 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 09:02:28.495: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 09:02:28.495: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 09:02:28.495: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 09:02:28.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-510 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 09:02:28.603: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 09:02:28.603: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 09:02:28.603: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 09:02:28.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-510 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 09:02:28.701: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 09:02:28.701: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 09:02:28.701: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 09:02:28.701: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 09:02:28.704: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Apr 18 09:02:38.710: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 09:02:38.710: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 09:02:38.710: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 09:02:38.721: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
    Apr 18 09:02:38.721: INFO: ss-0  192.168.1.152  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:01:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:01:57 +0000 UTC  }]
    Apr 18 09:02:38.721: INFO: ss-1  192.168.1.29   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:18 +0000 UTC  }]
    Apr 18 09:02:38.721: INFO: ss-2  192.168.1.84   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:18 +0000 UTC  }]
    Apr 18 09:02:38.721: INFO: 
    Apr 18 09:02:38.721: INFO: StatefulSet ss has not reached scale 0, at 3
    Apr 18 09:02:39.724: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
    Apr 18 09:02:39.724: INFO: ss-2  192.168.1.84  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 09:02:18 +0000 UTC  }]
    Apr 18 09:02:39.724: INFO: 
    Apr 18 09:02:39.724: INFO: StatefulSet ss has not reached scale 0, at 1
    Apr 18 09:02:40.727: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.993322997s
    Apr 18 09:02:41.730: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.990108047s
    Apr 18 09:02:42.734: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.987195642s
    Apr 18 09:02:43.737: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.983633001s
    Apr 18 09:02:44.740: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.980929718s
    Apr 18 09:02:45.743: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.977967448s
    Apr 18 09:02:46.746: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.974820874s
    Apr 18 09:02:47.750: INFO: Verifying statefulset ss doesn't scale past 0 for another 971.816534ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-510 04/18/23 09:02:48.75
    Apr 18 09:02:48.753: INFO: Scaling statefulset ss to 0
    Apr 18 09:02:48.762: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 09:02:48.765: INFO: Deleting all statefulset in ns statefulset-510
    Apr 18 09:02:48.767: INFO: Scaling statefulset ss to 0
    Apr 18 09:02:48.775: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 09:02:48.778: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 09:02:48.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-510" for this suite. 04/18/23 09:02:48.794
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:02:48.799
Apr 18 09:02:48.800: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir 04/18/23 09:02:48.8
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:02:48.81
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:02:48.813
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 04/18/23 09:02:48.816
Apr 18 09:02:48.822: INFO: Waiting up to 5m0s for pod "pod-a934ff85-5932-4578-897b-e23365a1b421" in namespace "emptydir-4125" to be "Succeeded or Failed"
Apr 18 09:02:48.824: INFO: Pod "pod-a934ff85-5932-4578-897b-e23365a1b421": Phase="Pending", Reason="", readiness=false. Elapsed: 2.156382ms
Apr 18 09:02:50.828: INFO: Pod "pod-a934ff85-5932-4578-897b-e23365a1b421": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00631333s
Apr 18 09:02:52.828: INFO: Pod "pod-a934ff85-5932-4578-897b-e23365a1b421": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0057174s
STEP: Saw pod success 04/18/23 09:02:52.828
Apr 18 09:02:52.828: INFO: Pod "pod-a934ff85-5932-4578-897b-e23365a1b421" satisfied condition "Succeeded or Failed"
Apr 18 09:02:52.830: INFO: Trying to get logs from node 192.168.1.152 pod pod-a934ff85-5932-4578-897b-e23365a1b421 container test-container: <nil>
STEP: delete the pod 04/18/23 09:02:52.843
Apr 18 09:02:52.857: INFO: Waiting for pod pod-a934ff85-5932-4578-897b-e23365a1b421 to disappear
Apr 18 09:02:52.860: INFO: Pod pod-a934ff85-5932-4578-897b-e23365a1b421 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 09:02:52.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4125" for this suite. 04/18/23 09:02:52.864
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":139,"skipped":2545,"failed":0}
------------------------------
• [4.069 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:02:48.799
    Apr 18 09:02:48.800: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir 04/18/23 09:02:48.8
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:02:48.81
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:02:48.813
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 04/18/23 09:02:48.816
    Apr 18 09:02:48.822: INFO: Waiting up to 5m0s for pod "pod-a934ff85-5932-4578-897b-e23365a1b421" in namespace "emptydir-4125" to be "Succeeded or Failed"
    Apr 18 09:02:48.824: INFO: Pod "pod-a934ff85-5932-4578-897b-e23365a1b421": Phase="Pending", Reason="", readiness=false. Elapsed: 2.156382ms
    Apr 18 09:02:50.828: INFO: Pod "pod-a934ff85-5932-4578-897b-e23365a1b421": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00631333s
    Apr 18 09:02:52.828: INFO: Pod "pod-a934ff85-5932-4578-897b-e23365a1b421": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0057174s
    STEP: Saw pod success 04/18/23 09:02:52.828
    Apr 18 09:02:52.828: INFO: Pod "pod-a934ff85-5932-4578-897b-e23365a1b421" satisfied condition "Succeeded or Failed"
    Apr 18 09:02:52.830: INFO: Trying to get logs from node 192.168.1.152 pod pod-a934ff85-5932-4578-897b-e23365a1b421 container test-container: <nil>
    STEP: delete the pod 04/18/23 09:02:52.843
    Apr 18 09:02:52.857: INFO: Waiting for pod pod-a934ff85-5932-4578-897b-e23365a1b421 to disappear
    Apr 18 09:02:52.860: INFO: Pod pod-a934ff85-5932-4578-897b-e23365a1b421 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 09:02:52.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4125" for this suite. 04/18/23 09:02:52.864
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:02:52.869
Apr 18 09:02:52.869: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 09:02:52.87
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:02:52.88
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:02:52.884
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Apr 18 09:02:52.888: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/18/23 09:02:55.046
Apr 18 09:02:55.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-5113 --namespace=crd-publish-openapi-5113 create -f -'
Apr 18 09:02:55.764: INFO: stderr: ""
Apr 18 09:02:55.764: INFO: stdout: "e2e-test-crd-publish-openapi-1949-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 18 09:02:55.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-5113 --namespace=crd-publish-openapi-5113 delete e2e-test-crd-publish-openapi-1949-crds test-cr'
Apr 18 09:02:55.825: INFO: stderr: ""
Apr 18 09:02:55.825: INFO: stdout: "e2e-test-crd-publish-openapi-1949-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Apr 18 09:02:55.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-5113 --namespace=crd-publish-openapi-5113 apply -f -'
Apr 18 09:02:55.995: INFO: stderr: ""
Apr 18 09:02:55.995: INFO: stdout: "e2e-test-crd-publish-openapi-1949-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 18 09:02:55.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-5113 --namespace=crd-publish-openapi-5113 delete e2e-test-crd-publish-openapi-1949-crds test-cr'
Apr 18 09:02:56.058: INFO: stderr: ""
Apr 18 09:02:56.058: INFO: stdout: "e2e-test-crd-publish-openapi-1949-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 04/18/23 09:02:56.058
Apr 18 09:02:56.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-5113 explain e2e-test-crd-publish-openapi-1949-crds'
Apr 18 09:02:56.256: INFO: stderr: ""
Apr 18 09:02:56.256: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1949-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:02:58.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5113" for this suite. 04/18/23 09:02:58.459
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":140,"skipped":2552,"failed":0}
------------------------------
• [SLOW TEST] [5.603 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:02:52.869
    Apr 18 09:02:52.869: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 09:02:52.87
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:02:52.88
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:02:52.884
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Apr 18 09:02:52.888: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/18/23 09:02:55.046
    Apr 18 09:02:55.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-5113 --namespace=crd-publish-openapi-5113 create -f -'
    Apr 18 09:02:55.764: INFO: stderr: ""
    Apr 18 09:02:55.764: INFO: stdout: "e2e-test-crd-publish-openapi-1949-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Apr 18 09:02:55.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-5113 --namespace=crd-publish-openapi-5113 delete e2e-test-crd-publish-openapi-1949-crds test-cr'
    Apr 18 09:02:55.825: INFO: stderr: ""
    Apr 18 09:02:55.825: INFO: stdout: "e2e-test-crd-publish-openapi-1949-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Apr 18 09:02:55.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-5113 --namespace=crd-publish-openapi-5113 apply -f -'
    Apr 18 09:02:55.995: INFO: stderr: ""
    Apr 18 09:02:55.995: INFO: stdout: "e2e-test-crd-publish-openapi-1949-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Apr 18 09:02:55.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-5113 --namespace=crd-publish-openapi-5113 delete e2e-test-crd-publish-openapi-1949-crds test-cr'
    Apr 18 09:02:56.058: INFO: stderr: ""
    Apr 18 09:02:56.058: INFO: stdout: "e2e-test-crd-publish-openapi-1949-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 04/18/23 09:02:56.058
    Apr 18 09:02:56.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-5113 explain e2e-test-crd-publish-openapi-1949-crds'
    Apr 18 09:02:56.256: INFO: stderr: ""
    Apr 18 09:02:56.256: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1949-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:02:58.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5113" for this suite. 04/18/23 09:02:58.459
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:02:58.473
Apr 18 09:02:58.473: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename endpointslice 04/18/23 09:02:58.473
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:02:58.504
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:02:58.513
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Apr 18 09:02:58.524: INFO: Endpoints addresses: [192.168.1.249] , ports: [5444]
Apr 18 09:02:58.525: INFO: EndpointSlices addresses: [192.168.1.249] , ports: [5444]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 18 09:02:58.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-8423" for this suite. 04/18/23 09:02:58.529
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":141,"skipped":2561,"failed":0}
------------------------------
• [0.060 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:02:58.473
    Apr 18 09:02:58.473: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename endpointslice 04/18/23 09:02:58.473
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:02:58.504
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:02:58.513
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Apr 18 09:02:58.524: INFO: Endpoints addresses: [192.168.1.249] , ports: [5444]
    Apr 18 09:02:58.525: INFO: EndpointSlices addresses: [192.168.1.249] , ports: [5444]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 18 09:02:58.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-8423" for this suite. 04/18/23 09:02:58.529
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:02:58.538
Apr 18 09:02:58.540: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 09:02:58.541
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:02:58.55
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:02:58.554
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 04/18/23 09:02:58.558
Apr 18 09:02:58.564: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e" in namespace "projected-1409" to be "Succeeded or Failed"
Apr 18 09:02:58.566: INFO: Pod "downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.415296ms
Apr 18 09:03:00.570: INFO: Pod "downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006404783s
Apr 18 09:03:02.580: INFO: Pod "downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016193608s
STEP: Saw pod success 04/18/23 09:03:02.58
Apr 18 09:03:02.580: INFO: Pod "downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e" satisfied condition "Succeeded or Failed"
Apr 18 09:03:02.596: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e container client-container: <nil>
STEP: delete the pod 04/18/23 09:03:02.611
Apr 18 09:03:02.632: INFO: Waiting for pod downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e to disappear
Apr 18 09:03:02.635: INFO: Pod downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 09:03:02.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1409" for this suite. 04/18/23 09:03:02.639
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":142,"skipped":2659,"failed":0}
------------------------------
• [4.112 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:02:58.538
    Apr 18 09:02:58.540: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 09:02:58.541
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:02:58.55
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:02:58.554
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 04/18/23 09:02:58.558
    Apr 18 09:02:58.564: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e" in namespace "projected-1409" to be "Succeeded or Failed"
    Apr 18 09:02:58.566: INFO: Pod "downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.415296ms
    Apr 18 09:03:00.570: INFO: Pod "downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006404783s
    Apr 18 09:03:02.580: INFO: Pod "downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016193608s
    STEP: Saw pod success 04/18/23 09:03:02.58
    Apr 18 09:03:02.580: INFO: Pod "downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e" satisfied condition "Succeeded or Failed"
    Apr 18 09:03:02.596: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e container client-container: <nil>
    STEP: delete the pod 04/18/23 09:03:02.611
    Apr 18 09:03:02.632: INFO: Waiting for pod downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e to disappear
    Apr 18 09:03:02.635: INFO: Pod downwardapi-volume-0408f30a-ab2a-4774-bd98-dad815cf2e6e no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 09:03:02.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1409" for this suite. 04/18/23 09:03:02.639
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:03:02.651
Apr 18 09:03:02.651: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename disruption 04/18/23 09:03:02.652
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:03:02.662
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:03:02.665
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 04/18/23 09:03:02.673
STEP: Waiting for all pods to be running 04/18/23 09:03:04.702
Apr 18 09:03:04.709: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 18 09:03:06.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9151" for this suite. 04/18/23 09:03:06.767
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":143,"skipped":2668,"failed":0}
------------------------------
• [4.135 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:03:02.651
    Apr 18 09:03:02.651: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename disruption 04/18/23 09:03:02.652
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:03:02.662
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:03:02.665
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 04/18/23 09:03:02.673
    STEP: Waiting for all pods to be running 04/18/23 09:03:04.702
    Apr 18 09:03:04.709: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 18 09:03:06.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-9151" for this suite. 04/18/23 09:03:06.767
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:03:06.786
Apr 18 09:03:06.786: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename security-context-test 04/18/23 09:03:06.787
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:03:06.807
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:03:06.81
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Apr 18 09:03:06.820: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-371e998b-7959-4e83-8e45-6d312cc12a27" in namespace "security-context-test-9703" to be "Succeeded or Failed"
Apr 18 09:03:06.824: INFO: Pod "busybox-privileged-false-371e998b-7959-4e83-8e45-6d312cc12a27": Phase="Pending", Reason="", readiness=false. Elapsed: 4.330301ms
Apr 18 09:03:08.828: INFO: Pod "busybox-privileged-false-371e998b-7959-4e83-8e45-6d312cc12a27": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008401101s
Apr 18 09:03:10.838: INFO: Pod "busybox-privileged-false-371e998b-7959-4e83-8e45-6d312cc12a27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018279271s
Apr 18 09:03:10.838: INFO: Pod "busybox-privileged-false-371e998b-7959-4e83-8e45-6d312cc12a27" satisfied condition "Succeeded or Failed"
Apr 18 09:03:10.850: INFO: Got logs for pod "busybox-privileged-false-371e998b-7959-4e83-8e45-6d312cc12a27": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 18 09:03:10.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9703" for this suite. 04/18/23 09:03:10.857
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":144,"skipped":2672,"failed":0}
------------------------------
• [4.076 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:03:06.786
    Apr 18 09:03:06.786: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename security-context-test 04/18/23 09:03:06.787
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:03:06.807
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:03:06.81
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Apr 18 09:03:06.820: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-371e998b-7959-4e83-8e45-6d312cc12a27" in namespace "security-context-test-9703" to be "Succeeded or Failed"
    Apr 18 09:03:06.824: INFO: Pod "busybox-privileged-false-371e998b-7959-4e83-8e45-6d312cc12a27": Phase="Pending", Reason="", readiness=false. Elapsed: 4.330301ms
    Apr 18 09:03:08.828: INFO: Pod "busybox-privileged-false-371e998b-7959-4e83-8e45-6d312cc12a27": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008401101s
    Apr 18 09:03:10.838: INFO: Pod "busybox-privileged-false-371e998b-7959-4e83-8e45-6d312cc12a27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018279271s
    Apr 18 09:03:10.838: INFO: Pod "busybox-privileged-false-371e998b-7959-4e83-8e45-6d312cc12a27" satisfied condition "Succeeded or Failed"
    Apr 18 09:03:10.850: INFO: Got logs for pod "busybox-privileged-false-371e998b-7959-4e83-8e45-6d312cc12a27": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 18 09:03:10.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-9703" for this suite. 04/18/23 09:03:10.857
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:03:10.865
Apr 18 09:03:10.865: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename csistoragecapacity 04/18/23 09:03:10.865
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:03:10.882
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:03:10.887
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 04/18/23 09:03:10.89
STEP: getting /apis/storage.k8s.io 04/18/23 09:03:10.894
STEP: getting /apis/storage.k8s.io/v1 04/18/23 09:03:10.896
STEP: creating 04/18/23 09:03:10.897
STEP: watching 04/18/23 09:03:10.911
Apr 18 09:03:10.911: INFO: starting watch
STEP: getting 04/18/23 09:03:10.924
STEP: listing in namespace 04/18/23 09:03:10.927
STEP: listing across namespaces 04/18/23 09:03:10.931
STEP: patching 04/18/23 09:03:10.933
STEP: updating 04/18/23 09:03:10.94
Apr 18 09:03:10.945: INFO: waiting for watch events with expected annotations in namespace
Apr 18 09:03:10.945: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 04/18/23 09:03:10.945
STEP: deleting a collection 04/18/23 09:03:10.955
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Apr 18 09:03:10.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-3164" for this suite. 04/18/23 09:03:10.971
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":145,"skipped":2711,"failed":0}
------------------------------
• [0.112 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:03:10.865
    Apr 18 09:03:10.865: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename csistoragecapacity 04/18/23 09:03:10.865
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:03:10.882
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:03:10.887
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 04/18/23 09:03:10.89
    STEP: getting /apis/storage.k8s.io 04/18/23 09:03:10.894
    STEP: getting /apis/storage.k8s.io/v1 04/18/23 09:03:10.896
    STEP: creating 04/18/23 09:03:10.897
    STEP: watching 04/18/23 09:03:10.911
    Apr 18 09:03:10.911: INFO: starting watch
    STEP: getting 04/18/23 09:03:10.924
    STEP: listing in namespace 04/18/23 09:03:10.927
    STEP: listing across namespaces 04/18/23 09:03:10.931
    STEP: patching 04/18/23 09:03:10.933
    STEP: updating 04/18/23 09:03:10.94
    Apr 18 09:03:10.945: INFO: waiting for watch events with expected annotations in namespace
    Apr 18 09:03:10.945: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 04/18/23 09:03:10.945
    STEP: deleting a collection 04/18/23 09:03:10.955
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Apr 18 09:03:10.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-3164" for this suite. 04/18/23 09:03:10.971
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:03:10.978
Apr 18 09:03:10.978: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename cronjob 04/18/23 09:03:10.978
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:03:10.987
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:03:10.991
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 04/18/23 09:03:10.995
STEP: Ensuring a job is scheduled 04/18/23 09:03:11
STEP: Ensuring exactly one is scheduled 04/18/23 09:04:01.004
STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/18/23 09:04:01.007
STEP: Ensuring the job is replaced with a new one 04/18/23 09:04:01.011
STEP: Removing cronjob 04/18/23 09:05:01.029
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 18 09:05:01.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6118" for this suite. 04/18/23 09:05:01.081
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":146,"skipped":2742,"failed":0}
------------------------------
• [SLOW TEST] [110.120 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:03:10.978
    Apr 18 09:03:10.978: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename cronjob 04/18/23 09:03:10.978
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:03:10.987
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:03:10.991
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 04/18/23 09:03:10.995
    STEP: Ensuring a job is scheduled 04/18/23 09:03:11
    STEP: Ensuring exactly one is scheduled 04/18/23 09:04:01.004
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/18/23 09:04:01.007
    STEP: Ensuring the job is replaced with a new one 04/18/23 09:04:01.011
    STEP: Removing cronjob 04/18/23 09:05:01.029
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 18 09:05:01.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-6118" for this suite. 04/18/23 09:05:01.081
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:05:01.102
Apr 18 09:05:01.103: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename cronjob 04/18/23 09:05:01.104
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:05:01.114
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:05:01.118
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 04/18/23 09:05:01.122
STEP: Ensuring more than one job is running at a time 04/18/23 09:05:01.126
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 04/18/23 09:07:01.131
STEP: Removing cronjob 04/18/23 09:07:01.134
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 18 09:07:01.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5266" for this suite. 04/18/23 09:07:01.142
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":147,"skipped":2806,"failed":0}
------------------------------
• [SLOW TEST] [120.052 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:05:01.102
    Apr 18 09:05:01.103: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename cronjob 04/18/23 09:05:01.104
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:05:01.114
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:05:01.118
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 04/18/23 09:05:01.122
    STEP: Ensuring more than one job is running at a time 04/18/23 09:05:01.126
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 04/18/23 09:07:01.131
    STEP: Removing cronjob 04/18/23 09:07:01.134
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 18 09:07:01.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5266" for this suite. 04/18/23 09:07:01.142
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:07:01.155
Apr 18 09:07:01.155: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename var-expansion 04/18/23 09:07:01.155
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:07:01.169
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:07:01.179
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Apr 18 09:07:01.193: INFO: Waiting up to 2m0s for pod "var-expansion-f628dc4b-64f0-4305-ac37-a3eaa751695c" in namespace "var-expansion-9888" to be "container 0 failed with reason CreateContainerConfigError"
Apr 18 09:07:01.196: INFO: Pod "var-expansion-f628dc4b-64f0-4305-ac37-a3eaa751695c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.714359ms
Apr 18 09:07:03.199: INFO: Pod "var-expansion-f628dc4b-64f0-4305-ac37-a3eaa751695c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006393549s
Apr 18 09:07:03.199: INFO: Pod "var-expansion-f628dc4b-64f0-4305-ac37-a3eaa751695c" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Apr 18 09:07:03.199: INFO: Deleting pod "var-expansion-f628dc4b-64f0-4305-ac37-a3eaa751695c" in namespace "var-expansion-9888"
Apr 18 09:07:03.206: INFO: Wait up to 5m0s for pod "var-expansion-f628dc4b-64f0-4305-ac37-a3eaa751695c" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 09:07:05.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9888" for this suite. 04/18/23 09:07:05.218
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":148,"skipped":2806,"failed":0}
------------------------------
• [4.069 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:07:01.155
    Apr 18 09:07:01.155: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename var-expansion 04/18/23 09:07:01.155
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:07:01.169
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:07:01.179
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Apr 18 09:07:01.193: INFO: Waiting up to 2m0s for pod "var-expansion-f628dc4b-64f0-4305-ac37-a3eaa751695c" in namespace "var-expansion-9888" to be "container 0 failed with reason CreateContainerConfigError"
    Apr 18 09:07:01.196: INFO: Pod "var-expansion-f628dc4b-64f0-4305-ac37-a3eaa751695c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.714359ms
    Apr 18 09:07:03.199: INFO: Pod "var-expansion-f628dc4b-64f0-4305-ac37-a3eaa751695c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006393549s
    Apr 18 09:07:03.199: INFO: Pod "var-expansion-f628dc4b-64f0-4305-ac37-a3eaa751695c" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Apr 18 09:07:03.199: INFO: Deleting pod "var-expansion-f628dc4b-64f0-4305-ac37-a3eaa751695c" in namespace "var-expansion-9888"
    Apr 18 09:07:03.206: INFO: Wait up to 5m0s for pod "var-expansion-f628dc4b-64f0-4305-ac37-a3eaa751695c" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 09:07:05.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-9888" for this suite. 04/18/23 09:07:05.218
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:07:05.225
Apr 18 09:07:05.225: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename cronjob 04/18/23 09:07:05.225
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:07:05.236
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:07:05.24
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 04/18/23 09:07:05.244
STEP: Ensuring no jobs are scheduled 04/18/23 09:07:05.25
STEP: Ensuring no job exists by listing jobs explicitly 04/18/23 09:12:05.257
STEP: Removing cronjob 04/18/23 09:12:05.26
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 18 09:12:05.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9528" for this suite. 04/18/23 09:12:05.271
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":149,"skipped":2818,"failed":0}
------------------------------
• [SLOW TEST] [300.052 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:07:05.225
    Apr 18 09:07:05.225: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename cronjob 04/18/23 09:07:05.225
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:07:05.236
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:07:05.24
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 04/18/23 09:07:05.244
    STEP: Ensuring no jobs are scheduled 04/18/23 09:07:05.25
    STEP: Ensuring no job exists by listing jobs explicitly 04/18/23 09:12:05.257
    STEP: Removing cronjob 04/18/23 09:12:05.26
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 18 09:12:05.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9528" for this suite. 04/18/23 09:12:05.271
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:12:05.277
Apr 18 09:12:05.277: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename svcaccounts 04/18/23 09:12:05.277
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:12:05.287
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:12:05.291
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Apr 18 09:12:05.304: INFO: created pod
Apr 18 09:12:05.304: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-7161" to be "Succeeded or Failed"
Apr 18 09:12:05.308: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.129708ms
Apr 18 09:12:07.311: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006693248s
Apr 18 09:12:09.312: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007636574s
STEP: Saw pod success 04/18/23 09:12:09.312
Apr 18 09:12:09.312: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Apr 18 09:12:39.313: INFO: polling logs
Apr 18 09:12:39.327: INFO: Pod logs: 
I0418 09:12:05.860481       1 log.go:195] OK: Got token
I0418 09:12:05.860507       1 log.go:195] validating with in-cluster discovery
I0418 09:12:05.860730       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
I0418 09:12:05.860750       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7161:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1681809725, NotBefore:1681809125, IssuedAt:1681809125, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7161", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"4ba770be-e81a-4ba5-98f4-24e05d027476"}}}
I0418 09:12:05.883478       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
I0418 09:12:05.891272       1 log.go:195] OK: Validated signature on JWT
I0418 09:12:05.891328       1 log.go:195] OK: Got valid claims from token!
I0418 09:12:05.891344       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7161:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1681809725, NotBefore:1681809125, IssuedAt:1681809125, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7161", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"4ba770be-e81a-4ba5-98f4-24e05d027476"}}}

Apr 18 09:12:39.327: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 18 09:12:39.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7161" for this suite. 04/18/23 09:12:39.336
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":150,"skipped":2837,"failed":0}
------------------------------
• [SLOW TEST] [34.064 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:12:05.277
    Apr 18 09:12:05.277: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename svcaccounts 04/18/23 09:12:05.277
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:12:05.287
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:12:05.291
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Apr 18 09:12:05.304: INFO: created pod
    Apr 18 09:12:05.304: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-7161" to be "Succeeded or Failed"
    Apr 18 09:12:05.308: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.129708ms
    Apr 18 09:12:07.311: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006693248s
    Apr 18 09:12:09.312: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007636574s
    STEP: Saw pod success 04/18/23 09:12:09.312
    Apr 18 09:12:09.312: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Apr 18 09:12:39.313: INFO: polling logs
    Apr 18 09:12:39.327: INFO: Pod logs: 
    I0418 09:12:05.860481       1 log.go:195] OK: Got token
    I0418 09:12:05.860507       1 log.go:195] validating with in-cluster discovery
    I0418 09:12:05.860730       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
    I0418 09:12:05.860750       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7161:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1681809725, NotBefore:1681809125, IssuedAt:1681809125, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7161", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"4ba770be-e81a-4ba5-98f4-24e05d027476"}}}
    I0418 09:12:05.883478       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
    I0418 09:12:05.891272       1 log.go:195] OK: Validated signature on JWT
    I0418 09:12:05.891328       1 log.go:195] OK: Got valid claims from token!
    I0418 09:12:05.891344       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7161:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1681809725, NotBefore:1681809125, IssuedAt:1681809125, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7161", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"4ba770be-e81a-4ba5-98f4-24e05d027476"}}}

    Apr 18 09:12:39.327: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 18 09:12:39.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-7161" for this suite. 04/18/23 09:12:39.336
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:12:39.342
Apr 18 09:12:39.342: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-probe 04/18/23 09:12:39.343
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:12:39.354
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:12:39.358
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Apr 18 09:12:39.368: INFO: Waiting up to 5m0s for pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a" in namespace "container-probe-6633" to be "running and ready"
Apr 18 09:12:39.371: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.552819ms
Apr 18 09:12:39.371: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:12:41.375: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 2.006473781s
Apr 18 09:12:41.375: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
Apr 18 09:12:43.374: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 4.006070388s
Apr 18 09:12:43.374: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
Apr 18 09:12:45.374: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 6.005879063s
Apr 18 09:12:45.374: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
Apr 18 09:12:47.374: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 8.00599435s
Apr 18 09:12:47.374: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
Apr 18 09:12:49.375: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 10.00652191s
Apr 18 09:12:49.375: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
Apr 18 09:12:51.376: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 12.00785678s
Apr 18 09:12:51.376: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
Apr 18 09:12:53.375: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 14.006400692s
Apr 18 09:12:53.375: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
Apr 18 09:12:55.374: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 16.005892957s
Apr 18 09:12:55.374: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
Apr 18 09:12:57.385: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 18.016274812s
Apr 18 09:12:57.385: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
Apr 18 09:12:59.376: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 20.007903135s
Apr 18 09:12:59.376: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
Apr 18 09:13:01.375: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=true. Elapsed: 22.0067985s
Apr 18 09:13:01.375: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = true)
Apr 18 09:13:01.375: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a" satisfied condition "running and ready"
Apr 18 09:13:01.378: INFO: Container started at 2023-04-18 09:12:39 +0000 UTC, pod became ready at 2023-04-18 09:12:59 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 09:13:01.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6633" for this suite. 04/18/23 09:13:01.383
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":151,"skipped":2861,"failed":0}
------------------------------
• [SLOW TEST] [22.045 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:12:39.342
    Apr 18 09:12:39.342: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-probe 04/18/23 09:12:39.343
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:12:39.354
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:12:39.358
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Apr 18 09:12:39.368: INFO: Waiting up to 5m0s for pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a" in namespace "container-probe-6633" to be "running and ready"
    Apr 18 09:12:39.371: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.552819ms
    Apr 18 09:12:39.371: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:12:41.375: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 2.006473781s
    Apr 18 09:12:41.375: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
    Apr 18 09:12:43.374: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 4.006070388s
    Apr 18 09:12:43.374: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
    Apr 18 09:12:45.374: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 6.005879063s
    Apr 18 09:12:45.374: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
    Apr 18 09:12:47.374: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 8.00599435s
    Apr 18 09:12:47.374: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
    Apr 18 09:12:49.375: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 10.00652191s
    Apr 18 09:12:49.375: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
    Apr 18 09:12:51.376: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 12.00785678s
    Apr 18 09:12:51.376: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
    Apr 18 09:12:53.375: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 14.006400692s
    Apr 18 09:12:53.375: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
    Apr 18 09:12:55.374: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 16.005892957s
    Apr 18 09:12:55.374: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
    Apr 18 09:12:57.385: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 18.016274812s
    Apr 18 09:12:57.385: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
    Apr 18 09:12:59.376: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=false. Elapsed: 20.007903135s
    Apr 18 09:12:59.376: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = false)
    Apr 18 09:13:01.375: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a": Phase="Running", Reason="", readiness=true. Elapsed: 22.0067985s
    Apr 18 09:13:01.375: INFO: The phase of Pod test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a is Running (Ready = true)
    Apr 18 09:13:01.375: INFO: Pod "test-webserver-71d85aa6-2241-4077-9c87-fe63a939d03a" satisfied condition "running and ready"
    Apr 18 09:13:01.378: INFO: Container started at 2023-04-18 09:12:39 +0000 UTC, pod became ready at 2023-04-18 09:12:59 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 09:13:01.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6633" for this suite. 04/18/23 09:13:01.383
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:13:01.388
Apr 18 09:13:01.388: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename podtemplate 04/18/23 09:13:01.388
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:01.398
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:01.402
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 04/18/23 09:13:01.406
STEP: Replace a pod template 04/18/23 09:13:01.411
Apr 18 09:13:01.418: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Apr 18 09:13:01.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-7958" for this suite. 04/18/23 09:13:01.424
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":152,"skipped":2881,"failed":0}
------------------------------
• [0.040 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:13:01.388
    Apr 18 09:13:01.388: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename podtemplate 04/18/23 09:13:01.388
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:01.398
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:01.402
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 04/18/23 09:13:01.406
    STEP: Replace a pod template 04/18/23 09:13:01.411
    Apr 18 09:13:01.418: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Apr 18 09:13:01.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-7958" for this suite. 04/18/23 09:13:01.424
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:13:01.43
Apr 18 09:13:01.430: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 09:13:01.431
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:01.44
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:01.444
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 04/18/23 09:13:01.45
Apr 18 09:13:01.450: INFO: Creating e2e-svc-a-cdrdc
Apr 18 09:13:01.457: INFO: Creating e2e-svc-b-h4x6k
Apr 18 09:13:01.465: INFO: Creating e2e-svc-c-g5pk4
STEP: deleting service collection 04/18/23 09:13:01.474
Apr 18 09:13:01.493: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 09:13:01.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8561" for this suite. 04/18/23 09:13:01.497
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":153,"skipped":2886,"failed":0}
------------------------------
• [0.071 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:13:01.43
    Apr 18 09:13:01.430: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 09:13:01.431
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:01.44
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:01.444
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 04/18/23 09:13:01.45
    Apr 18 09:13:01.450: INFO: Creating e2e-svc-a-cdrdc
    Apr 18 09:13:01.457: INFO: Creating e2e-svc-b-h4x6k
    Apr 18 09:13:01.465: INFO: Creating e2e-svc-c-g5pk4
    STEP: deleting service collection 04/18/23 09:13:01.474
    Apr 18 09:13:01.493: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 09:13:01.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8561" for this suite. 04/18/23 09:13:01.497
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:13:01.502
Apr 18 09:13:01.502: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename resourcequota 04/18/23 09:13:01.503
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:01.512
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:01.516
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 04/18/23 09:13:01.52
STEP: Creating a ResourceQuota 04/18/23 09:13:06.522
STEP: Ensuring resource quota status is calculated 04/18/23 09:13:06.528
STEP: Creating a ReplicaSet 04/18/23 09:13:08.533
STEP: Ensuring resource quota status captures replicaset creation 04/18/23 09:13:08.581
STEP: Deleting a ReplicaSet 04/18/23 09:13:10.585
STEP: Ensuring resource quota status released usage 04/18/23 09:13:10.59
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 09:13:12.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2722" for this suite. 04/18/23 09:13:12.598
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":154,"skipped":2903,"failed":0}
------------------------------
• [SLOW TEST] [11.100 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:13:01.502
    Apr 18 09:13:01.502: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename resourcequota 04/18/23 09:13:01.503
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:01.512
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:01.516
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 04/18/23 09:13:01.52
    STEP: Creating a ResourceQuota 04/18/23 09:13:06.522
    STEP: Ensuring resource quota status is calculated 04/18/23 09:13:06.528
    STEP: Creating a ReplicaSet 04/18/23 09:13:08.533
    STEP: Ensuring resource quota status captures replicaset creation 04/18/23 09:13:08.581
    STEP: Deleting a ReplicaSet 04/18/23 09:13:10.585
    STEP: Ensuring resource quota status released usage 04/18/23 09:13:10.59
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 09:13:12.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2722" for this suite. 04/18/23 09:13:12.598
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:13:12.603
Apr 18 09:13:12.604: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename configmap 04/18/23 09:13:12.604
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:12.616
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:12.62
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 09:13:12.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9770" for this suite. 04/18/23 09:13:12.66
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":155,"skipped":2935,"failed":0}
------------------------------
• [0.061 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:13:12.603
    Apr 18 09:13:12.604: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename configmap 04/18/23 09:13:12.604
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:12.616
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:12.62
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 09:13:12.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9770" for this suite. 04/18/23 09:13:12.66
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:13:12.666
Apr 18 09:13:12.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename resourcequota 04/18/23 09:13:12.666
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:12.678
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:12.682
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 04/18/23 09:13:29.691
STEP: Creating a ResourceQuota 04/18/23 09:13:34.694
STEP: Ensuring resource quota status is calculated 04/18/23 09:13:34.7
STEP: Creating a ConfigMap 04/18/23 09:13:36.704
STEP: Ensuring resource quota status captures configMap creation 04/18/23 09:13:36.714
STEP: Deleting a ConfigMap 04/18/23 09:13:38.717
STEP: Ensuring resource quota status released usage 04/18/23 09:13:38.721
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 09:13:40.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5285" for this suite. 04/18/23 09:13:40.73
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":156,"skipped":2937,"failed":0}
------------------------------
• [SLOW TEST] [28.070 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:13:12.666
    Apr 18 09:13:12.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename resourcequota 04/18/23 09:13:12.666
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:12.678
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:12.682
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 04/18/23 09:13:29.691
    STEP: Creating a ResourceQuota 04/18/23 09:13:34.694
    STEP: Ensuring resource quota status is calculated 04/18/23 09:13:34.7
    STEP: Creating a ConfigMap 04/18/23 09:13:36.704
    STEP: Ensuring resource quota status captures configMap creation 04/18/23 09:13:36.714
    STEP: Deleting a ConfigMap 04/18/23 09:13:38.717
    STEP: Ensuring resource quota status released usage 04/18/23 09:13:38.721
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 09:13:40.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5285" for this suite. 04/18/23 09:13:40.73
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:13:40.736
Apr 18 09:13:40.736: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir 04/18/23 09:13:40.737
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:40.762
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:40.766
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 04/18/23 09:13:40.771
Apr 18 09:13:40.778: INFO: Waiting up to 5m0s for pod "pod-a7e27429-3a81-4f00-ab59-753c2b1293a5" in namespace "emptydir-4402" to be "Succeeded or Failed"
Apr 18 09:13:40.781: INFO: Pod "pod-a7e27429-3a81-4f00-ab59-753c2b1293a5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.056342ms
Apr 18 09:13:42.785: INFO: Pod "pod-a7e27429-3a81-4f00-ab59-753c2b1293a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007170637s
Apr 18 09:13:44.784: INFO: Pod "pod-a7e27429-3a81-4f00-ab59-753c2b1293a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00651576s
STEP: Saw pod success 04/18/23 09:13:44.784
Apr 18 09:13:44.784: INFO: Pod "pod-a7e27429-3a81-4f00-ab59-753c2b1293a5" satisfied condition "Succeeded or Failed"
Apr 18 09:13:44.787: INFO: Trying to get logs from node 192.168.1.152 pod pod-a7e27429-3a81-4f00-ab59-753c2b1293a5 container test-container: <nil>
STEP: delete the pod 04/18/23 09:13:44.792
Apr 18 09:13:44.802: INFO: Waiting for pod pod-a7e27429-3a81-4f00-ab59-753c2b1293a5 to disappear
Apr 18 09:13:44.805: INFO: Pod pod-a7e27429-3a81-4f00-ab59-753c2b1293a5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 09:13:44.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4402" for this suite. 04/18/23 09:13:44.809
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":157,"skipped":2949,"failed":0}
------------------------------
• [4.077 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:13:40.736
    Apr 18 09:13:40.736: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir 04/18/23 09:13:40.737
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:40.762
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:40.766
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 04/18/23 09:13:40.771
    Apr 18 09:13:40.778: INFO: Waiting up to 5m0s for pod "pod-a7e27429-3a81-4f00-ab59-753c2b1293a5" in namespace "emptydir-4402" to be "Succeeded or Failed"
    Apr 18 09:13:40.781: INFO: Pod "pod-a7e27429-3a81-4f00-ab59-753c2b1293a5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.056342ms
    Apr 18 09:13:42.785: INFO: Pod "pod-a7e27429-3a81-4f00-ab59-753c2b1293a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007170637s
    Apr 18 09:13:44.784: INFO: Pod "pod-a7e27429-3a81-4f00-ab59-753c2b1293a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00651576s
    STEP: Saw pod success 04/18/23 09:13:44.784
    Apr 18 09:13:44.784: INFO: Pod "pod-a7e27429-3a81-4f00-ab59-753c2b1293a5" satisfied condition "Succeeded or Failed"
    Apr 18 09:13:44.787: INFO: Trying to get logs from node 192.168.1.152 pod pod-a7e27429-3a81-4f00-ab59-753c2b1293a5 container test-container: <nil>
    STEP: delete the pod 04/18/23 09:13:44.792
    Apr 18 09:13:44.802: INFO: Waiting for pod pod-a7e27429-3a81-4f00-ab59-753c2b1293a5 to disappear
    Apr 18 09:13:44.805: INFO: Pod pod-a7e27429-3a81-4f00-ab59-753c2b1293a5 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 09:13:44.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4402" for this suite. 04/18/23 09:13:44.809
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:13:44.816
Apr 18 09:13:44.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename var-expansion 04/18/23 09:13:44.817
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:44.826
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:44.83
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 04/18/23 09:13:44.834
Apr 18 09:13:44.839: INFO: Waiting up to 5m0s for pod "var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032" in namespace "var-expansion-8291" to be "Succeeded or Failed"
Apr 18 09:13:44.842: INFO: Pod "var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032": Phase="Pending", Reason="", readiness=false. Elapsed: 2.653891ms
Apr 18 09:13:46.846: INFO: Pod "var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006506627s
Apr 18 09:13:48.846: INFO: Pod "var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006839809s
STEP: Saw pod success 04/18/23 09:13:48.846
Apr 18 09:13:48.846: INFO: Pod "var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032" satisfied condition "Succeeded or Failed"
Apr 18 09:13:48.849: INFO: Trying to get logs from node 192.168.1.152 pod var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032 container dapi-container: <nil>
STEP: delete the pod 04/18/23 09:13:48.854
Apr 18 09:13:48.864: INFO: Waiting for pod var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032 to disappear
Apr 18 09:13:48.866: INFO: Pod var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 09:13:48.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8291" for this suite. 04/18/23 09:13:48.87
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":158,"skipped":2978,"failed":0}
------------------------------
• [4.059 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:13:44.816
    Apr 18 09:13:44.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename var-expansion 04/18/23 09:13:44.817
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:44.826
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:44.83
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 04/18/23 09:13:44.834
    Apr 18 09:13:44.839: INFO: Waiting up to 5m0s for pod "var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032" in namespace "var-expansion-8291" to be "Succeeded or Failed"
    Apr 18 09:13:44.842: INFO: Pod "var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032": Phase="Pending", Reason="", readiness=false. Elapsed: 2.653891ms
    Apr 18 09:13:46.846: INFO: Pod "var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006506627s
    Apr 18 09:13:48.846: INFO: Pod "var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006839809s
    STEP: Saw pod success 04/18/23 09:13:48.846
    Apr 18 09:13:48.846: INFO: Pod "var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032" satisfied condition "Succeeded or Failed"
    Apr 18 09:13:48.849: INFO: Trying to get logs from node 192.168.1.152 pod var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032 container dapi-container: <nil>
    STEP: delete the pod 04/18/23 09:13:48.854
    Apr 18 09:13:48.864: INFO: Waiting for pod var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032 to disappear
    Apr 18 09:13:48.866: INFO: Pod var-expansion-44a00148-bd86-44aa-a368-5b43de1cb032 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 09:13:48.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-8291" for this suite. 04/18/23 09:13:48.87
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:13:48.876
Apr 18 09:13:48.876: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 09:13:48.877
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:48.886
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:48.89
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Apr 18 09:13:48.894: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:13:49.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7087" for this suite. 04/18/23 09:13:49.505
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":159,"skipped":2985,"failed":0}
------------------------------
• [0.634 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:13:48.876
    Apr 18 09:13:48.876: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 09:13:48.877
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:48.886
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:48.89
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Apr 18 09:13:48.894: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:13:49.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-7087" for this suite. 04/18/23 09:13:49.505
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:13:49.512
Apr 18 09:13:49.512: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename pod-network-test 04/18/23 09:13:49.513
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:49.522
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:49.526
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-6366 04/18/23 09:13:49.529
STEP: creating a selector 04/18/23 09:13:49.53
STEP: Creating the service pods in kubernetes 04/18/23 09:13:49.53
Apr 18 09:13:49.530: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 18 09:13:49.557: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6366" to be "running and ready"
Apr 18 09:13:49.560: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.627192ms
Apr 18 09:13:49.560: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:13:51.564: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.007020045s
Apr 18 09:13:51.564: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:13:53.563: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.006084975s
Apr 18 09:13:53.563: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:13:55.564: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.007135885s
Apr 18 09:13:55.564: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:13:57.565: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.007207748s
Apr 18 09:13:57.565: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:13:59.564: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.006889379s
Apr 18 09:13:59.564: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:14:01.565: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.007873334s
Apr 18 09:14:01.565: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:14:03.565: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.007230515s
Apr 18 09:14:03.565: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:14:05.565: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.007556344s
Apr 18 09:14:05.565: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:14:07.564: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.006199064s
Apr 18 09:14:07.564: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:14:09.564: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.006896964s
Apr 18 09:14:09.564: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:14:11.564: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.00622336s
Apr 18 09:14:11.564: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 18 09:14:11.564: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 18 09:14:11.567: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6366" to be "running and ready"
Apr 18 09:14:11.569: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.564491ms
Apr 18 09:14:11.569: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 18 09:14:11.569: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 18 09:14:11.572: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6366" to be "running and ready"
Apr 18 09:14:11.574: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.442168ms
Apr 18 09:14:11.574: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 18 09:14:11.574: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/18/23 09:14:11.577
Apr 18 09:14:11.587: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6366" to be "running"
Apr 18 09:14:11.592: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.206394ms
Apr 18 09:14:13.596: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009424503s
Apr 18 09:14:13.596: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 18 09:14:13.599: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-6366" to be "running"
Apr 18 09:14:13.602: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.679858ms
Apr 18 09:14:13.602: INFO: Pod "host-test-container-pod" satisfied condition "running"
Apr 18 09:14:13.604: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 18 09:14:13.604: INFO: Going to poll 172.16.1.63 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Apr 18 09:14:13.607: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.1.63 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6366 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 09:14:13.607: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 09:14:13.607: INFO: ExecWithOptions: Clientset creation
Apr 18 09:14:13.607: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-6366/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.1.63+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 18 09:14:14.660: INFO: Found all 1 expected endpoints: [netserver-0]
Apr 18 09:14:14.660: INFO: Going to poll 172.16.0.68 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Apr 18 09:14:14.663: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.0.68 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6366 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 09:14:14.663: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 09:14:14.663: INFO: ExecWithOptions: Clientset creation
Apr 18 09:14:14.663: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-6366/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.0.68+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 18 09:14:15.707: INFO: Found all 1 expected endpoints: [netserver-1]
Apr 18 09:14:15.707: INFO: Going to poll 172.16.0.227 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Apr 18 09:14:15.710: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.0.227 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6366 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 09:14:15.710: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 09:14:15.710: INFO: ExecWithOptions: Clientset creation
Apr 18 09:14:15.710: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-6366/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.0.227+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 18 09:14:16.758: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 18 09:14:16.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6366" for this suite. 04/18/23 09:14:16.766
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":160,"skipped":2991,"failed":0}
------------------------------
• [SLOW TEST] [27.269 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:13:49.512
    Apr 18 09:13:49.512: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename pod-network-test 04/18/23 09:13:49.513
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:13:49.522
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:13:49.526
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-6366 04/18/23 09:13:49.529
    STEP: creating a selector 04/18/23 09:13:49.53
    STEP: Creating the service pods in kubernetes 04/18/23 09:13:49.53
    Apr 18 09:13:49.530: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 18 09:13:49.557: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6366" to be "running and ready"
    Apr 18 09:13:49.560: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.627192ms
    Apr 18 09:13:49.560: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:13:51.564: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.007020045s
    Apr 18 09:13:51.564: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:13:53.563: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.006084975s
    Apr 18 09:13:53.563: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:13:55.564: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.007135885s
    Apr 18 09:13:55.564: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:13:57.565: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.007207748s
    Apr 18 09:13:57.565: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:13:59.564: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.006889379s
    Apr 18 09:13:59.564: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:14:01.565: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.007873334s
    Apr 18 09:14:01.565: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:14:03.565: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.007230515s
    Apr 18 09:14:03.565: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:14:05.565: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.007556344s
    Apr 18 09:14:05.565: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:14:07.564: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.006199064s
    Apr 18 09:14:07.564: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:14:09.564: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.006896964s
    Apr 18 09:14:09.564: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:14:11.564: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.00622336s
    Apr 18 09:14:11.564: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 18 09:14:11.564: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 18 09:14:11.567: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6366" to be "running and ready"
    Apr 18 09:14:11.569: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.564491ms
    Apr 18 09:14:11.569: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 18 09:14:11.569: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 18 09:14:11.572: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6366" to be "running and ready"
    Apr 18 09:14:11.574: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.442168ms
    Apr 18 09:14:11.574: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 18 09:14:11.574: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/18/23 09:14:11.577
    Apr 18 09:14:11.587: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6366" to be "running"
    Apr 18 09:14:11.592: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.206394ms
    Apr 18 09:14:13.596: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009424503s
    Apr 18 09:14:13.596: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 18 09:14:13.599: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-6366" to be "running"
    Apr 18 09:14:13.602: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.679858ms
    Apr 18 09:14:13.602: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Apr 18 09:14:13.604: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 18 09:14:13.604: INFO: Going to poll 172.16.1.63 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Apr 18 09:14:13.607: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.1.63 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6366 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 09:14:13.607: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 09:14:13.607: INFO: ExecWithOptions: Clientset creation
    Apr 18 09:14:13.607: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-6366/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.1.63+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 18 09:14:14.660: INFO: Found all 1 expected endpoints: [netserver-0]
    Apr 18 09:14:14.660: INFO: Going to poll 172.16.0.68 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Apr 18 09:14:14.663: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.0.68 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6366 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 09:14:14.663: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 09:14:14.663: INFO: ExecWithOptions: Clientset creation
    Apr 18 09:14:14.663: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-6366/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.0.68+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 18 09:14:15.707: INFO: Found all 1 expected endpoints: [netserver-1]
    Apr 18 09:14:15.707: INFO: Going to poll 172.16.0.227 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Apr 18 09:14:15.710: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.0.227 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6366 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 09:14:15.710: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 09:14:15.710: INFO: ExecWithOptions: Clientset creation
    Apr 18 09:14:15.710: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-6366/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.0.227+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 18 09:14:16.758: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 18 09:14:16.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-6366" for this suite. 04/18/23 09:14:16.766
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:14:16.785
Apr 18 09:14:16.785: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 09:14:16.786
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:14:16.799
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:14:16.802
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 09:14:16.816
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:14:16.999
STEP: Deploying the webhook pod 04/18/23 09:14:17.005
STEP: Wait for the deployment to be ready 04/18/23 09:14:17.015
Apr 18 09:14:17.021: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 09:14:19.03
STEP: Verifying the service has paired with the endpoint 04/18/23 09:14:19.038
Apr 18 09:14:20.038: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 04/18/23 09:14:20.041
STEP: Creating a custom resource definition that should be denied by the webhook 04/18/23 09:14:20.059
Apr 18 09:14:20.059: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:14:20.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3799" for this suite. 04/18/23 09:14:20.079
STEP: Destroying namespace "webhook-3799-markers" for this suite. 04/18/23 09:14:20.083
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":161,"skipped":3017,"failed":0}
------------------------------
• [3.335 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:14:16.785
    Apr 18 09:14:16.785: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 09:14:16.786
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:14:16.799
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:14:16.802
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 09:14:16.816
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:14:16.999
    STEP: Deploying the webhook pod 04/18/23 09:14:17.005
    STEP: Wait for the deployment to be ready 04/18/23 09:14:17.015
    Apr 18 09:14:17.021: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 09:14:19.03
    STEP: Verifying the service has paired with the endpoint 04/18/23 09:14:19.038
    Apr 18 09:14:20.038: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 04/18/23 09:14:20.041
    STEP: Creating a custom resource definition that should be denied by the webhook 04/18/23 09:14:20.059
    Apr 18 09:14:20.059: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:14:20.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3799" for this suite. 04/18/23 09:14:20.079
    STEP: Destroying namespace "webhook-3799-markers" for this suite. 04/18/23 09:14:20.083
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:14:20.119
Apr 18 09:14:20.120: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename crd-webhook 04/18/23 09:14:20.12
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:14:20.134
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:14:20.138
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 04/18/23 09:14:20.142
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/18/23 09:14:20.421
STEP: Deploying the custom resource conversion webhook pod 04/18/23 09:14:20.425
STEP: Wait for the deployment to be ready 04/18/23 09:14:20.436
Apr 18 09:14:20.442: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 09:14:22.451
STEP: Verifying the service has paired with the endpoint 04/18/23 09:14:22.459
Apr 18 09:14:23.459: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Apr 18 09:14:23.463: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Creating a v1 custom resource 04/18/23 09:14:26.132
STEP: v2 custom resource should be converted 04/18/23 09:14:26.137
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:14:26.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7990" for this suite. 04/18/23 09:14:26.659
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":162,"skipped":3020,"failed":0}
------------------------------
• [SLOW TEST] [6.576 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:14:20.119
    Apr 18 09:14:20.120: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename crd-webhook 04/18/23 09:14:20.12
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:14:20.134
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:14:20.138
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 04/18/23 09:14:20.142
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/18/23 09:14:20.421
    STEP: Deploying the custom resource conversion webhook pod 04/18/23 09:14:20.425
    STEP: Wait for the deployment to be ready 04/18/23 09:14:20.436
    Apr 18 09:14:20.442: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 09:14:22.451
    STEP: Verifying the service has paired with the endpoint 04/18/23 09:14:22.459
    Apr 18 09:14:23.459: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Apr 18 09:14:23.463: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Creating a v1 custom resource 04/18/23 09:14:26.132
    STEP: v2 custom resource should be converted 04/18/23 09:14:26.137
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:14:26.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-7990" for this suite. 04/18/23 09:14:26.659
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:14:26.696
Apr 18 09:14:26.696: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 09:14:26.697
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:14:26.73
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:14:26.735
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 04/18/23 09:14:26.739
Apr 18 09:14:26.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Apr 18 09:14:26.800: INFO: stderr: ""
Apr 18 09:14:26.800: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 04/18/23 09:14:26.8
Apr 18 09:14:26.800: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Apr 18 09:14:26.800: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-7343" to be "running and ready, or succeeded"
Apr 18 09:14:26.804: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.884381ms
Apr 18 09:14:26.804: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '192.168.1.152' to be 'Running' but was 'Pending'
Apr 18 09:14:28.810: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.009281019s
Apr 18 09:14:28.810: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Apr 18 09:14:28.810: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 04/18/23 09:14:28.81
Apr 18 09:14:28.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 logs logs-generator logs-generator'
Apr 18 09:14:28.890: INFO: stderr: ""
Apr 18 09:14:28.890: INFO: stdout: "I0418 09:14:27.368136       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/blbs 591\nI0418 09:14:27.568269       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/pfql 288\nI0418 09:14:27.768482       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/jc6 575\nI0418 09:14:27.968772       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/466 468\nI0418 09:14:28.169095       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/thc 281\nI0418 09:14:28.368238       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/vvb 575\nI0418 09:14:28.568486       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/7zjv 263\nI0418 09:14:28.768776       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/2gnt 394\n"
STEP: limiting log lines 04/18/23 09:14:28.89
Apr 18 09:14:28.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 logs logs-generator logs-generator --tail=1'
Apr 18 09:14:28.955: INFO: stderr: ""
Apr 18 09:14:28.955: INFO: stdout: "I0418 09:14:28.768776       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/2gnt 394\n"
Apr 18 09:14:28.955: INFO: got output "I0418 09:14:28.768776       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/2gnt 394\n"
STEP: limiting log bytes 04/18/23 09:14:28.955
Apr 18 09:14:28.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 logs logs-generator logs-generator --limit-bytes=1'
Apr 18 09:14:29.012: INFO: stderr: ""
Apr 18 09:14:29.012: INFO: stdout: "I"
Apr 18 09:14:29.012: INFO: got output "I"
STEP: exposing timestamps 04/18/23 09:14:29.012
Apr 18 09:14:29.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 logs logs-generator logs-generator --tail=1 --timestamps'
Apr 18 09:14:29.069: INFO: stderr: ""
Apr 18 09:14:29.069: INFO: stdout: "2023-04-18T09:14:28.969139500Z I0418 09:14:28.969086       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/5945 225\n"
Apr 18 09:14:29.069: INFO: got output "2023-04-18T09:14:28.969139500Z I0418 09:14:28.969086       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/5945 225\n"
STEP: restricting to a time range 04/18/23 09:14:29.069
Apr 18 09:14:31.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 logs logs-generator logs-generator --since=1s'
Apr 18 09:14:31.628: INFO: stderr: ""
Apr 18 09:14:31.628: INFO: stdout: "I0418 09:14:30.768780       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/8l5n 591\nI0418 09:14:30.969088       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/4wt 309\nI0418 09:14:31.168229       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/jct 447\nI0418 09:14:31.368548       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/vlfd 290\nI0418 09:14:31.568858       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/5vq 335\n"
Apr 18 09:14:31.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 logs logs-generator logs-generator --since=24h'
Apr 18 09:14:31.687: INFO: stderr: ""
Apr 18 09:14:31.687: INFO: stdout: "I0418 09:14:27.368136       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/blbs 591\nI0418 09:14:27.568269       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/pfql 288\nI0418 09:14:27.768482       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/jc6 575\nI0418 09:14:27.968772       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/466 468\nI0418 09:14:28.169095       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/thc 281\nI0418 09:14:28.368238       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/vvb 575\nI0418 09:14:28.568486       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/7zjv 263\nI0418 09:14:28.768776       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/2gnt 394\nI0418 09:14:28.969086       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/5945 225\nI0418 09:14:29.168317       1 logs_generator.go:76] 9 POST /api/v1/namespaces/kube-system/pods/9z97 580\nI0418 09:14:29.368632       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/8kk 354\nI0418 09:14:29.568949       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/q2g 386\nI0418 09:14:29.769216       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/d9k 319\nI0418 09:14:29.968535       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/6dh 419\nI0418 09:14:30.168851       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/66sm 338\nI0418 09:14:30.369160       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/kc45 352\nI0418 09:14:30.568481       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/dng 509\nI0418 09:14:30.768780       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/8l5n 591\nI0418 09:14:30.969088       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/4wt 309\nI0418 09:14:31.168229       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/jct 447\nI0418 09:14:31.368548       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/vlfd 290\nI0418 09:14:31.568858       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/5vq 335\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Apr 18 09:14:31.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 delete pod logs-generator'
Apr 18 09:14:32.666: INFO: stderr: ""
Apr 18 09:14:32.666: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 09:14:32.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7343" for this suite. 04/18/23 09:14:32.671
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":163,"skipped":3035,"failed":0}
------------------------------
• [SLOW TEST] [5.979 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:14:26.696
    Apr 18 09:14:26.696: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 09:14:26.697
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:14:26.73
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:14:26.735
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 04/18/23 09:14:26.739
    Apr 18 09:14:26.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Apr 18 09:14:26.800: INFO: stderr: ""
    Apr 18 09:14:26.800: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 04/18/23 09:14:26.8
    Apr 18 09:14:26.800: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Apr 18 09:14:26.800: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-7343" to be "running and ready, or succeeded"
    Apr 18 09:14:26.804: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.884381ms
    Apr 18 09:14:26.804: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '192.168.1.152' to be 'Running' but was 'Pending'
    Apr 18 09:14:28.810: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.009281019s
    Apr 18 09:14:28.810: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Apr 18 09:14:28.810: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 04/18/23 09:14:28.81
    Apr 18 09:14:28.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 logs logs-generator logs-generator'
    Apr 18 09:14:28.890: INFO: stderr: ""
    Apr 18 09:14:28.890: INFO: stdout: "I0418 09:14:27.368136       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/blbs 591\nI0418 09:14:27.568269       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/pfql 288\nI0418 09:14:27.768482       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/jc6 575\nI0418 09:14:27.968772       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/466 468\nI0418 09:14:28.169095       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/thc 281\nI0418 09:14:28.368238       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/vvb 575\nI0418 09:14:28.568486       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/7zjv 263\nI0418 09:14:28.768776       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/2gnt 394\n"
    STEP: limiting log lines 04/18/23 09:14:28.89
    Apr 18 09:14:28.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 logs logs-generator logs-generator --tail=1'
    Apr 18 09:14:28.955: INFO: stderr: ""
    Apr 18 09:14:28.955: INFO: stdout: "I0418 09:14:28.768776       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/2gnt 394\n"
    Apr 18 09:14:28.955: INFO: got output "I0418 09:14:28.768776       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/2gnt 394\n"
    STEP: limiting log bytes 04/18/23 09:14:28.955
    Apr 18 09:14:28.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 logs logs-generator logs-generator --limit-bytes=1'
    Apr 18 09:14:29.012: INFO: stderr: ""
    Apr 18 09:14:29.012: INFO: stdout: "I"
    Apr 18 09:14:29.012: INFO: got output "I"
    STEP: exposing timestamps 04/18/23 09:14:29.012
    Apr 18 09:14:29.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 logs logs-generator logs-generator --tail=1 --timestamps'
    Apr 18 09:14:29.069: INFO: stderr: ""
    Apr 18 09:14:29.069: INFO: stdout: "2023-04-18T09:14:28.969139500Z I0418 09:14:28.969086       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/5945 225\n"
    Apr 18 09:14:29.069: INFO: got output "2023-04-18T09:14:28.969139500Z I0418 09:14:28.969086       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/5945 225\n"
    STEP: restricting to a time range 04/18/23 09:14:29.069
    Apr 18 09:14:31.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 logs logs-generator logs-generator --since=1s'
    Apr 18 09:14:31.628: INFO: stderr: ""
    Apr 18 09:14:31.628: INFO: stdout: "I0418 09:14:30.768780       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/8l5n 591\nI0418 09:14:30.969088       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/4wt 309\nI0418 09:14:31.168229       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/jct 447\nI0418 09:14:31.368548       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/vlfd 290\nI0418 09:14:31.568858       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/5vq 335\n"
    Apr 18 09:14:31.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 logs logs-generator logs-generator --since=24h'
    Apr 18 09:14:31.687: INFO: stderr: ""
    Apr 18 09:14:31.687: INFO: stdout: "I0418 09:14:27.368136       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/blbs 591\nI0418 09:14:27.568269       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/pfql 288\nI0418 09:14:27.768482       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/jc6 575\nI0418 09:14:27.968772       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/466 468\nI0418 09:14:28.169095       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/thc 281\nI0418 09:14:28.368238       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/vvb 575\nI0418 09:14:28.568486       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/7zjv 263\nI0418 09:14:28.768776       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/2gnt 394\nI0418 09:14:28.969086       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/5945 225\nI0418 09:14:29.168317       1 logs_generator.go:76] 9 POST /api/v1/namespaces/kube-system/pods/9z97 580\nI0418 09:14:29.368632       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/8kk 354\nI0418 09:14:29.568949       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/q2g 386\nI0418 09:14:29.769216       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/d9k 319\nI0418 09:14:29.968535       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/6dh 419\nI0418 09:14:30.168851       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/66sm 338\nI0418 09:14:30.369160       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/kc45 352\nI0418 09:14:30.568481       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/dng 509\nI0418 09:14:30.768780       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/8l5n 591\nI0418 09:14:30.969088       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/4wt 309\nI0418 09:14:31.168229       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/jct 447\nI0418 09:14:31.368548       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/vlfd 290\nI0418 09:14:31.568858       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/5vq 335\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Apr 18 09:14:31.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7343 delete pod logs-generator'
    Apr 18 09:14:32.666: INFO: stderr: ""
    Apr 18 09:14:32.666: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 09:14:32.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7343" for this suite. 04/18/23 09:14:32.671
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:14:32.677
Apr 18 09:14:32.677: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename replicaset 04/18/23 09:14:32.678
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:14:32.688
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:14:32.692
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Apr 18 09:14:32.696: INFO: Creating ReplicaSet my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408
Apr 18 09:14:32.704: INFO: Pod name my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408: Found 0 pods out of 1
Apr 18 09:14:37.707: INFO: Pod name my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408: Found 1 pods out of 1
Apr 18 09:14:37.707: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408" is running
Apr 18 09:14:37.707: INFO: Waiting up to 5m0s for pod "my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408-drjh9" in namespace "replicaset-3942" to be "running"
Apr 18 09:14:37.710: INFO: Pod "my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408-drjh9": Phase="Running", Reason="", readiness=true. Elapsed: 3.188282ms
Apr 18 09:14:37.710: INFO: Pod "my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408-drjh9" satisfied condition "running"
Apr 18 09:14:37.710: INFO: Pod "my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408-drjh9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 09:14:32 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 09:14:33 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 09:14:33 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 09:14:32 +0000 UTC Reason: Message:}])
Apr 18 09:14:37.710: INFO: Trying to dial the pod
Apr 18 09:14:42.723: INFO: Controller my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408: Got expected result from replica 1 [my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408-drjh9]: "my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408-drjh9", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 18 09:14:42.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3942" for this suite. 04/18/23 09:14:42.728
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":164,"skipped":3096,"failed":0}
------------------------------
• [SLOW TEST] [10.056 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:14:32.677
    Apr 18 09:14:32.677: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename replicaset 04/18/23 09:14:32.678
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:14:32.688
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:14:32.692
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Apr 18 09:14:32.696: INFO: Creating ReplicaSet my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408
    Apr 18 09:14:32.704: INFO: Pod name my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408: Found 0 pods out of 1
    Apr 18 09:14:37.707: INFO: Pod name my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408: Found 1 pods out of 1
    Apr 18 09:14:37.707: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408" is running
    Apr 18 09:14:37.707: INFO: Waiting up to 5m0s for pod "my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408-drjh9" in namespace "replicaset-3942" to be "running"
    Apr 18 09:14:37.710: INFO: Pod "my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408-drjh9": Phase="Running", Reason="", readiness=true. Elapsed: 3.188282ms
    Apr 18 09:14:37.710: INFO: Pod "my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408-drjh9" satisfied condition "running"
    Apr 18 09:14:37.710: INFO: Pod "my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408-drjh9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 09:14:32 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 09:14:33 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 09:14:33 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 09:14:32 +0000 UTC Reason: Message:}])
    Apr 18 09:14:37.710: INFO: Trying to dial the pod
    Apr 18 09:14:42.723: INFO: Controller my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408: Got expected result from replica 1 [my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408-drjh9]: "my-hostname-basic-3cb146c5-03b7-4338-8f3d-17c6335fb408-drjh9", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 18 09:14:42.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-3942" for this suite. 04/18/23 09:14:42.728
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:14:42.745
Apr 18 09:14:42.745: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 09:14:42.746
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:14:42.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:14:42.76
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 04/18/23 09:14:42.764
Apr 18 09:14:42.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 create -f -'
Apr 18 09:14:43.713: INFO: stderr: ""
Apr 18 09:14:43.713: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 09:14:43.713
Apr 18 09:14:43.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 18 09:14:43.777: INFO: stderr: ""
Apr 18 09:14:43.777: INFO: stdout: "update-demo-nautilus-ft2kc update-demo-nautilus-h6tdp "
Apr 18 09:14:43.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods update-demo-nautilus-ft2kc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 09:14:43.838: INFO: stderr: ""
Apr 18 09:14:43.838: INFO: stdout: ""
Apr 18 09:14:43.838: INFO: update-demo-nautilus-ft2kc is created but not running
Apr 18 09:14:48.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 18 09:14:48.905: INFO: stderr: ""
Apr 18 09:14:48.905: INFO: stdout: "update-demo-nautilus-ft2kc update-demo-nautilus-h6tdp "
Apr 18 09:14:48.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods update-demo-nautilus-ft2kc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 09:14:48.969: INFO: stderr: ""
Apr 18 09:14:48.969: INFO: stdout: "true"
Apr 18 09:14:48.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods update-demo-nautilus-ft2kc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 18 09:14:49.029: INFO: stderr: ""
Apr 18 09:14:49.029: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 18 09:14:49.029: INFO: validating pod update-demo-nautilus-ft2kc
Apr 18 09:14:49.036: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 18 09:14:49.036: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 18 09:14:49.036: INFO: update-demo-nautilus-ft2kc is verified up and running
Apr 18 09:14:49.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods update-demo-nautilus-h6tdp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 09:14:49.092: INFO: stderr: ""
Apr 18 09:14:49.092: INFO: stdout: "true"
Apr 18 09:14:49.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods update-demo-nautilus-h6tdp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 18 09:14:49.151: INFO: stderr: ""
Apr 18 09:14:49.151: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 18 09:14:49.152: INFO: validating pod update-demo-nautilus-h6tdp
Apr 18 09:14:49.157: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 18 09:14:49.157: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 18 09:14:49.157: INFO: update-demo-nautilus-h6tdp is verified up and running
STEP: using delete to clean up resources 04/18/23 09:14:49.157
Apr 18 09:14:49.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 delete --grace-period=0 --force -f -'
Apr 18 09:14:49.208: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 09:14:49.208: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 18 09:14:49.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get rc,svc -l name=update-demo --no-headers'
Apr 18 09:14:49.277: INFO: stderr: "No resources found in kubectl-7034 namespace.\n"
Apr 18 09:14:49.278: INFO: stdout: ""
Apr 18 09:14:49.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 18 09:14:49.341: INFO: stderr: ""
Apr 18 09:14:49.341: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 09:14:49.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7034" for this suite. 04/18/23 09:14:49.345
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":165,"skipped":3144,"failed":0}
------------------------------
• [SLOW TEST] [6.607 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:14:42.745
    Apr 18 09:14:42.745: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 09:14:42.746
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:14:42.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:14:42.76
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 04/18/23 09:14:42.764
    Apr 18 09:14:42.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 create -f -'
    Apr 18 09:14:43.713: INFO: stderr: ""
    Apr 18 09:14:43.713: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 09:14:43.713
    Apr 18 09:14:43.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 18 09:14:43.777: INFO: stderr: ""
    Apr 18 09:14:43.777: INFO: stdout: "update-demo-nautilus-ft2kc update-demo-nautilus-h6tdp "
    Apr 18 09:14:43.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods update-demo-nautilus-ft2kc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 09:14:43.838: INFO: stderr: ""
    Apr 18 09:14:43.838: INFO: stdout: ""
    Apr 18 09:14:43.838: INFO: update-demo-nautilus-ft2kc is created but not running
    Apr 18 09:14:48.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 18 09:14:48.905: INFO: stderr: ""
    Apr 18 09:14:48.905: INFO: stdout: "update-demo-nautilus-ft2kc update-demo-nautilus-h6tdp "
    Apr 18 09:14:48.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods update-demo-nautilus-ft2kc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 09:14:48.969: INFO: stderr: ""
    Apr 18 09:14:48.969: INFO: stdout: "true"
    Apr 18 09:14:48.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods update-demo-nautilus-ft2kc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 18 09:14:49.029: INFO: stderr: ""
    Apr 18 09:14:49.029: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 18 09:14:49.029: INFO: validating pod update-demo-nautilus-ft2kc
    Apr 18 09:14:49.036: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 18 09:14:49.036: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 18 09:14:49.036: INFO: update-demo-nautilus-ft2kc is verified up and running
    Apr 18 09:14:49.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods update-demo-nautilus-h6tdp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 09:14:49.092: INFO: stderr: ""
    Apr 18 09:14:49.092: INFO: stdout: "true"
    Apr 18 09:14:49.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods update-demo-nautilus-h6tdp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 18 09:14:49.151: INFO: stderr: ""
    Apr 18 09:14:49.151: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 18 09:14:49.152: INFO: validating pod update-demo-nautilus-h6tdp
    Apr 18 09:14:49.157: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 18 09:14:49.157: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 18 09:14:49.157: INFO: update-demo-nautilus-h6tdp is verified up and running
    STEP: using delete to clean up resources 04/18/23 09:14:49.157
    Apr 18 09:14:49.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 delete --grace-period=0 --force -f -'
    Apr 18 09:14:49.208: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 09:14:49.208: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Apr 18 09:14:49.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get rc,svc -l name=update-demo --no-headers'
    Apr 18 09:14:49.277: INFO: stderr: "No resources found in kubectl-7034 namespace.\n"
    Apr 18 09:14:49.278: INFO: stdout: ""
    Apr 18 09:14:49.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7034 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 18 09:14:49.341: INFO: stderr: ""
    Apr 18 09:14:49.341: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 09:14:49.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7034" for this suite. 04/18/23 09:14:49.345
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:14:49.352
Apr 18 09:14:49.352: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename configmap 04/18/23 09:14:49.353
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:14:49.362
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:14:49.366
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-c88c0e42-35c4-4d0f-92e8-f3b254d77fc3 04/18/23 09:14:49.369
STEP: Creating a pod to test consume configMaps 04/18/23 09:14:49.374
Apr 18 09:14:49.380: INFO: Waiting up to 5m0s for pod "pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0" in namespace "configmap-1909" to be "Succeeded or Failed"
Apr 18 09:14:49.382: INFO: Pod "pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.439098ms
Apr 18 09:14:51.386: INFO: Pod "pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00592113s
Apr 18 09:14:53.386: INFO: Pod "pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006259376s
STEP: Saw pod success 04/18/23 09:14:53.386
Apr 18 09:14:53.386: INFO: Pod "pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0" satisfied condition "Succeeded or Failed"
Apr 18 09:14:53.389: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 09:14:53.394
Apr 18 09:14:53.403: INFO: Waiting for pod pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0 to disappear
Apr 18 09:14:53.405: INFO: Pod pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 09:14:53.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1909" for this suite. 04/18/23 09:14:53.41
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":166,"skipped":3149,"failed":0}
------------------------------
• [4.062 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:14:49.352
    Apr 18 09:14:49.352: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename configmap 04/18/23 09:14:49.353
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:14:49.362
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:14:49.366
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-c88c0e42-35c4-4d0f-92e8-f3b254d77fc3 04/18/23 09:14:49.369
    STEP: Creating a pod to test consume configMaps 04/18/23 09:14:49.374
    Apr 18 09:14:49.380: INFO: Waiting up to 5m0s for pod "pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0" in namespace "configmap-1909" to be "Succeeded or Failed"
    Apr 18 09:14:49.382: INFO: Pod "pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.439098ms
    Apr 18 09:14:51.386: INFO: Pod "pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00592113s
    Apr 18 09:14:53.386: INFO: Pod "pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006259376s
    STEP: Saw pod success 04/18/23 09:14:53.386
    Apr 18 09:14:53.386: INFO: Pod "pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0" satisfied condition "Succeeded or Failed"
    Apr 18 09:14:53.389: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 09:14:53.394
    Apr 18 09:14:53.403: INFO: Waiting for pod pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0 to disappear
    Apr 18 09:14:53.405: INFO: Pod pod-configmaps-be99d813-a2ac-4391-9569-c09625de0dd0 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 09:14:53.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1909" for this suite. 04/18/23 09:14:53.41
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:14:53.414
Apr 18 09:14:53.414: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 09:14:53.415
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:14:53.425
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:14:53.429
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-274 04/18/23 09:14:53.433
STEP: changing the ExternalName service to type=ClusterIP 04/18/23 09:14:53.437
STEP: creating replication controller externalname-service in namespace services-274 04/18/23 09:14:53.45
I0418 09:14:53.459258      18 runners.go:193] Created replication controller with name: externalname-service, namespace: services-274, replica count: 2
I0418 09:14:56.509924      18 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 09:14:56.509: INFO: Creating new exec pod
Apr 18 09:14:56.514: INFO: Waiting up to 5m0s for pod "execpodjtmhx" in namespace "services-274" to be "running"
Apr 18 09:14:56.517: INFO: Pod "execpodjtmhx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.951973ms
Apr 18 09:14:58.521: INFO: Pod "execpodjtmhx": Phase="Running", Reason="", readiness=true. Elapsed: 2.006599175s
Apr 18 09:14:58.521: INFO: Pod "execpodjtmhx" satisfied condition "running"
Apr 18 09:14:59.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-274 exec execpodjtmhx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 18 09:14:59.623: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 18 09:14:59.623: INFO: stdout: ""
Apr 18 09:15:00.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-274 exec execpodjtmhx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 18 09:15:00.730: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 18 09:15:00.730: INFO: stdout: "externalname-service-d7zb7"
Apr 18 09:15:00.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-274 exec execpodjtmhx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.90.105 80'
Apr 18 09:15:00.831: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.90.105 80\nConnection to 10.247.90.105 80 port [tcp/http] succeeded!\n"
Apr 18 09:15:00.831: INFO: stdout: ""
Apr 18 09:15:01.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-274 exec execpodjtmhx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.90.105 80'
Apr 18 09:15:01.940: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.90.105 80\nConnection to 10.247.90.105 80 port [tcp/http] succeeded!\n"
Apr 18 09:15:01.940: INFO: stdout: ""
Apr 18 09:15:02.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-274 exec execpodjtmhx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.90.105 80'
Apr 18 09:15:02.935: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.90.105 80\nConnection to 10.247.90.105 80 port [tcp/http] succeeded!\n"
Apr 18 09:15:02.935: INFO: stdout: "externalname-service-tfr64"
Apr 18 09:15:02.935: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 09:15:02.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-274" for this suite. 04/18/23 09:15:02.979
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":167,"skipped":3157,"failed":0}
------------------------------
• [SLOW TEST] [9.569 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:14:53.414
    Apr 18 09:14:53.414: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 09:14:53.415
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:14:53.425
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:14:53.429
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-274 04/18/23 09:14:53.433
    STEP: changing the ExternalName service to type=ClusterIP 04/18/23 09:14:53.437
    STEP: creating replication controller externalname-service in namespace services-274 04/18/23 09:14:53.45
    I0418 09:14:53.459258      18 runners.go:193] Created replication controller with name: externalname-service, namespace: services-274, replica count: 2
    I0418 09:14:56.509924      18 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 09:14:56.509: INFO: Creating new exec pod
    Apr 18 09:14:56.514: INFO: Waiting up to 5m0s for pod "execpodjtmhx" in namespace "services-274" to be "running"
    Apr 18 09:14:56.517: INFO: Pod "execpodjtmhx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.951973ms
    Apr 18 09:14:58.521: INFO: Pod "execpodjtmhx": Phase="Running", Reason="", readiness=true. Elapsed: 2.006599175s
    Apr 18 09:14:58.521: INFO: Pod "execpodjtmhx" satisfied condition "running"
    Apr 18 09:14:59.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-274 exec execpodjtmhx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 18 09:14:59.623: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 18 09:14:59.623: INFO: stdout: ""
    Apr 18 09:15:00.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-274 exec execpodjtmhx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 18 09:15:00.730: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 18 09:15:00.730: INFO: stdout: "externalname-service-d7zb7"
    Apr 18 09:15:00.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-274 exec execpodjtmhx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.90.105 80'
    Apr 18 09:15:00.831: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.90.105 80\nConnection to 10.247.90.105 80 port [tcp/http] succeeded!\n"
    Apr 18 09:15:00.831: INFO: stdout: ""
    Apr 18 09:15:01.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-274 exec execpodjtmhx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.90.105 80'
    Apr 18 09:15:01.940: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.90.105 80\nConnection to 10.247.90.105 80 port [tcp/http] succeeded!\n"
    Apr 18 09:15:01.940: INFO: stdout: ""
    Apr 18 09:15:02.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-274 exec execpodjtmhx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.90.105 80'
    Apr 18 09:15:02.935: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.90.105 80\nConnection to 10.247.90.105 80 port [tcp/http] succeeded!\n"
    Apr 18 09:15:02.935: INFO: stdout: "externalname-service-tfr64"
    Apr 18 09:15:02.935: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 09:15:02.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-274" for this suite. 04/18/23 09:15:02.979
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:15:02.984
Apr 18 09:15:02.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename discovery 04/18/23 09:15:02.985
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:02.996
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:03.002
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 04/18/23 09:15:03.008
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Apr 18 09:15:03.510: INFO: Checking APIGroup: apiregistration.k8s.io
Apr 18 09:15:03.512: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Apr 18 09:15:03.512: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Apr 18 09:15:03.512: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Apr 18 09:15:03.512: INFO: Checking APIGroup: apps
Apr 18 09:15:03.514: INFO: PreferredVersion.GroupVersion: apps/v1
Apr 18 09:15:03.514: INFO: Versions found [{apps/v1 v1}]
Apr 18 09:15:03.514: INFO: apps/v1 matches apps/v1
Apr 18 09:15:03.514: INFO: Checking APIGroup: events.k8s.io
Apr 18 09:15:03.516: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Apr 18 09:15:03.516: INFO: Versions found [{events.k8s.io/v1 v1}]
Apr 18 09:15:03.516: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Apr 18 09:15:03.516: INFO: Checking APIGroup: authentication.k8s.io
Apr 18 09:15:03.518: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Apr 18 09:15:03.518: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Apr 18 09:15:03.518: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Apr 18 09:15:03.518: INFO: Checking APIGroup: authorization.k8s.io
Apr 18 09:15:03.520: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Apr 18 09:15:03.520: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Apr 18 09:15:03.520: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Apr 18 09:15:03.520: INFO: Checking APIGroup: autoscaling
Apr 18 09:15:03.521: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Apr 18 09:15:03.521: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Apr 18 09:15:03.521: INFO: autoscaling/v2 matches autoscaling/v2
Apr 18 09:15:03.521: INFO: Checking APIGroup: batch
Apr 18 09:15:03.524: INFO: PreferredVersion.GroupVersion: batch/v1
Apr 18 09:15:03.524: INFO: Versions found [{batch/v1 v1}]
Apr 18 09:15:03.524: INFO: batch/v1 matches batch/v1
Apr 18 09:15:03.524: INFO: Checking APIGroup: certificates.k8s.io
Apr 18 09:15:03.525: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Apr 18 09:15:03.525: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Apr 18 09:15:03.525: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Apr 18 09:15:03.525: INFO: Checking APIGroup: networking.k8s.io
Apr 18 09:15:03.527: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Apr 18 09:15:03.527: INFO: Versions found [{networking.k8s.io/v1 v1}]
Apr 18 09:15:03.527: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Apr 18 09:15:03.527: INFO: Checking APIGroup: policy
Apr 18 09:15:03.529: INFO: PreferredVersion.GroupVersion: policy/v1
Apr 18 09:15:03.529: INFO: Versions found [{policy/v1 v1}]
Apr 18 09:15:03.529: INFO: policy/v1 matches policy/v1
Apr 18 09:15:03.529: INFO: Checking APIGroup: rbac.authorization.k8s.io
Apr 18 09:15:03.531: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Apr 18 09:15:03.531: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Apr 18 09:15:03.531: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Apr 18 09:15:03.531: INFO: Checking APIGroup: storage.k8s.io
Apr 18 09:15:03.532: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Apr 18 09:15:03.532: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Apr 18 09:15:03.532: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Apr 18 09:15:03.532: INFO: Checking APIGroup: admissionregistration.k8s.io
Apr 18 09:15:03.534: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Apr 18 09:15:03.534: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Apr 18 09:15:03.534: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Apr 18 09:15:03.534: INFO: Checking APIGroup: apiextensions.k8s.io
Apr 18 09:15:03.536: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Apr 18 09:15:03.536: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Apr 18 09:15:03.536: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Apr 18 09:15:03.536: INFO: Checking APIGroup: scheduling.k8s.io
Apr 18 09:15:03.538: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Apr 18 09:15:03.538: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Apr 18 09:15:03.538: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Apr 18 09:15:03.538: INFO: Checking APIGroup: coordination.k8s.io
Apr 18 09:15:03.540: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Apr 18 09:15:03.540: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Apr 18 09:15:03.540: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Apr 18 09:15:03.540: INFO: Checking APIGroup: node.k8s.io
Apr 18 09:15:03.542: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Apr 18 09:15:03.542: INFO: Versions found [{node.k8s.io/v1 v1}]
Apr 18 09:15:03.542: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Apr 18 09:15:03.542: INFO: Checking APIGroup: discovery.k8s.io
Apr 18 09:15:03.546: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Apr 18 09:15:03.546: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Apr 18 09:15:03.546: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Apr 18 09:15:03.546: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Apr 18 09:15:03.548: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Apr 18 09:15:03.548: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Apr 18 09:15:03.548: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Apr 18 09:15:03.548: INFO: Checking APIGroup: crd.yangtse.cni
Apr 18 09:15:03.549: INFO: PreferredVersion.GroupVersion: crd.yangtse.cni/v1
Apr 18 09:15:03.549: INFO: Versions found [{crd.yangtse.cni/v1 v1}]
Apr 18 09:15:03.549: INFO: crd.yangtse.cni/v1 matches crd.yangtse.cni/v1
Apr 18 09:15:03.549: INFO: Checking APIGroup: k8s.cni.cncf.io
Apr 18 09:15:03.551: INFO: PreferredVersion.GroupVersion: k8s.cni.cncf.io/v1
Apr 18 09:15:03.551: INFO: Versions found [{k8s.cni.cncf.io/v1 v1}]
Apr 18 09:15:03.551: INFO: k8s.cni.cncf.io/v1 matches k8s.cni.cncf.io/v1
Apr 18 09:15:03.551: INFO: Checking APIGroup: localvolume.everest.io
Apr 18 09:15:03.553: INFO: PreferredVersion.GroupVersion: localvolume.everest.io/v1
Apr 18 09:15:03.553: INFO: Versions found [{localvolume.everest.io/v1 v1}]
Apr 18 09:15:03.553: INFO: localvolume.everest.io/v1 matches localvolume.everest.io/v1
Apr 18 09:15:03.553: INFO: Checking APIGroup: config.k8s.io
Apr 18 09:15:03.555: INFO: PreferredVersion.GroupVersion: config.k8s.io/v1beta1
Apr 18 09:15:03.555: INFO: Versions found [{config.k8s.io/v1beta1 v1beta1}]
Apr 18 09:15:03.555: INFO: config.k8s.io/v1beta1 matches config.k8s.io/v1beta1
Apr 18 09:15:03.555: INFO: Checking APIGroup: rbac.cce.io
Apr 18 09:15:03.556: INFO: PreferredVersion.GroupVersion: rbac.cce.io/v1beta1
Apr 18 09:15:03.556: INFO: Versions found [{rbac.cce.io/v1beta1 v1beta1}]
Apr 18 09:15:03.556: INFO: rbac.cce.io/v1beta1 matches rbac.cce.io/v1beta1
Apr 18 09:15:03.556: INFO: Checking APIGroup: snapshot.storage.k8s.io
Apr 18 09:15:03.558: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1beta1
Apr 18 09:15:03.558: INFO: Versions found [{snapshot.storage.k8s.io/v1beta1 v1beta1}]
Apr 18 09:15:03.558: INFO: snapshot.storage.k8s.io/v1beta1 matches snapshot.storage.k8s.io/v1beta1
Apr 18 09:15:03.558: INFO: Checking APIGroup: version.cce.io
Apr 18 09:15:03.560: INFO: PreferredVersion.GroupVersion: version.cce.io/v1beta1
Apr 18 09:15:03.560: INFO: Versions found [{version.cce.io/v1beta1 v1beta1}]
Apr 18 09:15:03.560: INFO: version.cce.io/v1beta1 matches version.cce.io/v1beta1
Apr 18 09:15:03.560: INFO: Checking APIGroup: proxy.exporter.k8s.io
Apr 18 09:15:03.562: INFO: PreferredVersion.GroupVersion: proxy.exporter.k8s.io/v1beta1
Apr 18 09:15:03.562: INFO: Versions found [{proxy.exporter.k8s.io/v1beta1 v1beta1}]
Apr 18 09:15:03.562: INFO: proxy.exporter.k8s.io/v1beta1 matches proxy.exporter.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Apr 18 09:15:03.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-9231" for this suite. 04/18/23 09:15:03.567
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":168,"skipped":3170,"failed":0}
------------------------------
• [0.589 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:15:02.984
    Apr 18 09:15:02.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename discovery 04/18/23 09:15:02.985
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:02.996
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:03.002
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 04/18/23 09:15:03.008
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Apr 18 09:15:03.510: INFO: Checking APIGroup: apiregistration.k8s.io
    Apr 18 09:15:03.512: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Apr 18 09:15:03.512: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Apr 18 09:15:03.512: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Apr 18 09:15:03.512: INFO: Checking APIGroup: apps
    Apr 18 09:15:03.514: INFO: PreferredVersion.GroupVersion: apps/v1
    Apr 18 09:15:03.514: INFO: Versions found [{apps/v1 v1}]
    Apr 18 09:15:03.514: INFO: apps/v1 matches apps/v1
    Apr 18 09:15:03.514: INFO: Checking APIGroup: events.k8s.io
    Apr 18 09:15:03.516: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Apr 18 09:15:03.516: INFO: Versions found [{events.k8s.io/v1 v1}]
    Apr 18 09:15:03.516: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Apr 18 09:15:03.516: INFO: Checking APIGroup: authentication.k8s.io
    Apr 18 09:15:03.518: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Apr 18 09:15:03.518: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Apr 18 09:15:03.518: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Apr 18 09:15:03.518: INFO: Checking APIGroup: authorization.k8s.io
    Apr 18 09:15:03.520: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Apr 18 09:15:03.520: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Apr 18 09:15:03.520: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Apr 18 09:15:03.520: INFO: Checking APIGroup: autoscaling
    Apr 18 09:15:03.521: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Apr 18 09:15:03.521: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Apr 18 09:15:03.521: INFO: autoscaling/v2 matches autoscaling/v2
    Apr 18 09:15:03.521: INFO: Checking APIGroup: batch
    Apr 18 09:15:03.524: INFO: PreferredVersion.GroupVersion: batch/v1
    Apr 18 09:15:03.524: INFO: Versions found [{batch/v1 v1}]
    Apr 18 09:15:03.524: INFO: batch/v1 matches batch/v1
    Apr 18 09:15:03.524: INFO: Checking APIGroup: certificates.k8s.io
    Apr 18 09:15:03.525: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Apr 18 09:15:03.525: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Apr 18 09:15:03.525: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Apr 18 09:15:03.525: INFO: Checking APIGroup: networking.k8s.io
    Apr 18 09:15:03.527: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Apr 18 09:15:03.527: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Apr 18 09:15:03.527: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Apr 18 09:15:03.527: INFO: Checking APIGroup: policy
    Apr 18 09:15:03.529: INFO: PreferredVersion.GroupVersion: policy/v1
    Apr 18 09:15:03.529: INFO: Versions found [{policy/v1 v1}]
    Apr 18 09:15:03.529: INFO: policy/v1 matches policy/v1
    Apr 18 09:15:03.529: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Apr 18 09:15:03.531: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Apr 18 09:15:03.531: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Apr 18 09:15:03.531: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Apr 18 09:15:03.531: INFO: Checking APIGroup: storage.k8s.io
    Apr 18 09:15:03.532: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Apr 18 09:15:03.532: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Apr 18 09:15:03.532: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Apr 18 09:15:03.532: INFO: Checking APIGroup: admissionregistration.k8s.io
    Apr 18 09:15:03.534: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Apr 18 09:15:03.534: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Apr 18 09:15:03.534: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Apr 18 09:15:03.534: INFO: Checking APIGroup: apiextensions.k8s.io
    Apr 18 09:15:03.536: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Apr 18 09:15:03.536: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Apr 18 09:15:03.536: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Apr 18 09:15:03.536: INFO: Checking APIGroup: scheduling.k8s.io
    Apr 18 09:15:03.538: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Apr 18 09:15:03.538: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Apr 18 09:15:03.538: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Apr 18 09:15:03.538: INFO: Checking APIGroup: coordination.k8s.io
    Apr 18 09:15:03.540: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Apr 18 09:15:03.540: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Apr 18 09:15:03.540: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Apr 18 09:15:03.540: INFO: Checking APIGroup: node.k8s.io
    Apr 18 09:15:03.542: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Apr 18 09:15:03.542: INFO: Versions found [{node.k8s.io/v1 v1}]
    Apr 18 09:15:03.542: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Apr 18 09:15:03.542: INFO: Checking APIGroup: discovery.k8s.io
    Apr 18 09:15:03.546: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Apr 18 09:15:03.546: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Apr 18 09:15:03.546: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Apr 18 09:15:03.546: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Apr 18 09:15:03.548: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Apr 18 09:15:03.548: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Apr 18 09:15:03.548: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Apr 18 09:15:03.548: INFO: Checking APIGroup: crd.yangtse.cni
    Apr 18 09:15:03.549: INFO: PreferredVersion.GroupVersion: crd.yangtse.cni/v1
    Apr 18 09:15:03.549: INFO: Versions found [{crd.yangtse.cni/v1 v1}]
    Apr 18 09:15:03.549: INFO: crd.yangtse.cni/v1 matches crd.yangtse.cni/v1
    Apr 18 09:15:03.549: INFO: Checking APIGroup: k8s.cni.cncf.io
    Apr 18 09:15:03.551: INFO: PreferredVersion.GroupVersion: k8s.cni.cncf.io/v1
    Apr 18 09:15:03.551: INFO: Versions found [{k8s.cni.cncf.io/v1 v1}]
    Apr 18 09:15:03.551: INFO: k8s.cni.cncf.io/v1 matches k8s.cni.cncf.io/v1
    Apr 18 09:15:03.551: INFO: Checking APIGroup: localvolume.everest.io
    Apr 18 09:15:03.553: INFO: PreferredVersion.GroupVersion: localvolume.everest.io/v1
    Apr 18 09:15:03.553: INFO: Versions found [{localvolume.everest.io/v1 v1}]
    Apr 18 09:15:03.553: INFO: localvolume.everest.io/v1 matches localvolume.everest.io/v1
    Apr 18 09:15:03.553: INFO: Checking APIGroup: config.k8s.io
    Apr 18 09:15:03.555: INFO: PreferredVersion.GroupVersion: config.k8s.io/v1beta1
    Apr 18 09:15:03.555: INFO: Versions found [{config.k8s.io/v1beta1 v1beta1}]
    Apr 18 09:15:03.555: INFO: config.k8s.io/v1beta1 matches config.k8s.io/v1beta1
    Apr 18 09:15:03.555: INFO: Checking APIGroup: rbac.cce.io
    Apr 18 09:15:03.556: INFO: PreferredVersion.GroupVersion: rbac.cce.io/v1beta1
    Apr 18 09:15:03.556: INFO: Versions found [{rbac.cce.io/v1beta1 v1beta1}]
    Apr 18 09:15:03.556: INFO: rbac.cce.io/v1beta1 matches rbac.cce.io/v1beta1
    Apr 18 09:15:03.556: INFO: Checking APIGroup: snapshot.storage.k8s.io
    Apr 18 09:15:03.558: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1beta1
    Apr 18 09:15:03.558: INFO: Versions found [{snapshot.storage.k8s.io/v1beta1 v1beta1}]
    Apr 18 09:15:03.558: INFO: snapshot.storage.k8s.io/v1beta1 matches snapshot.storage.k8s.io/v1beta1
    Apr 18 09:15:03.558: INFO: Checking APIGroup: version.cce.io
    Apr 18 09:15:03.560: INFO: PreferredVersion.GroupVersion: version.cce.io/v1beta1
    Apr 18 09:15:03.560: INFO: Versions found [{version.cce.io/v1beta1 v1beta1}]
    Apr 18 09:15:03.560: INFO: version.cce.io/v1beta1 matches version.cce.io/v1beta1
    Apr 18 09:15:03.560: INFO: Checking APIGroup: proxy.exporter.k8s.io
    Apr 18 09:15:03.562: INFO: PreferredVersion.GroupVersion: proxy.exporter.k8s.io/v1beta1
    Apr 18 09:15:03.562: INFO: Versions found [{proxy.exporter.k8s.io/v1beta1 v1beta1}]
    Apr 18 09:15:03.562: INFO: proxy.exporter.k8s.io/v1beta1 matches proxy.exporter.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Apr 18 09:15:03.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-9231" for this suite. 04/18/23 09:15:03.567
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:15:03.573
Apr 18 09:15:03.573: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename proxy 04/18/23 09:15:03.574
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:03.583
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:03.587
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Apr 18 09:15:03.592: INFO: Creating pod...
Apr 18 09:15:03.599: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-6317" to be "running"
Apr 18 09:15:03.602: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 3.1221ms
Apr 18 09:15:05.606: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.007424269s
Apr 18 09:15:05.606: INFO: Pod "agnhost" satisfied condition "running"
Apr 18 09:15:05.606: INFO: Creating service...
Apr 18 09:15:05.616: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/pods/agnhost/proxy?method=DELETE
Apr 18 09:15:05.622: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 18 09:15:05.623: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/pods/agnhost/proxy?method=OPTIONS
Apr 18 09:15:05.639: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 18 09:15:05.639: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/pods/agnhost/proxy?method=PATCH
Apr 18 09:15:05.649: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 18 09:15:05.649: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/pods/agnhost/proxy?method=POST
Apr 18 09:15:05.653: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 18 09:15:05.653: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/pods/agnhost/proxy?method=PUT
Apr 18 09:15:05.657: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 18 09:15:05.657: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/services/e2e-proxy-test-service/proxy?method=DELETE
Apr 18 09:15:05.661: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 18 09:15:05.661: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/services/e2e-proxy-test-service/proxy?method=OPTIONS
Apr 18 09:15:05.666: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 18 09:15:05.666: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/services/e2e-proxy-test-service/proxy?method=PATCH
Apr 18 09:15:05.671: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 18 09:15:05.671: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/services/e2e-proxy-test-service/proxy?method=POST
Apr 18 09:15:05.675: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 18 09:15:05.675: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/services/e2e-proxy-test-service/proxy?method=PUT
Apr 18 09:15:05.679: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 18 09:15:05.679: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/pods/agnhost/proxy?method=GET
Apr 18 09:15:05.682: INFO: http.Client request:GET StatusCode:301
Apr 18 09:15:05.682: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/services/e2e-proxy-test-service/proxy?method=GET
Apr 18 09:15:05.685: INFO: http.Client request:GET StatusCode:301
Apr 18 09:15:05.685: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/pods/agnhost/proxy?method=HEAD
Apr 18 09:15:05.687: INFO: http.Client request:HEAD StatusCode:301
Apr 18 09:15:05.687: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/services/e2e-proxy-test-service/proxy?method=HEAD
Apr 18 09:15:05.690: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Apr 18 09:15:05.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6317" for this suite. 04/18/23 09:15:05.694
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":169,"skipped":3174,"failed":0}
------------------------------
• [2.129 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:15:03.573
    Apr 18 09:15:03.573: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename proxy 04/18/23 09:15:03.574
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:03.583
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:03.587
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Apr 18 09:15:03.592: INFO: Creating pod...
    Apr 18 09:15:03.599: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-6317" to be "running"
    Apr 18 09:15:03.602: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 3.1221ms
    Apr 18 09:15:05.606: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.007424269s
    Apr 18 09:15:05.606: INFO: Pod "agnhost" satisfied condition "running"
    Apr 18 09:15:05.606: INFO: Creating service...
    Apr 18 09:15:05.616: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/pods/agnhost/proxy?method=DELETE
    Apr 18 09:15:05.622: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 18 09:15:05.623: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/pods/agnhost/proxy?method=OPTIONS
    Apr 18 09:15:05.639: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 18 09:15:05.639: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/pods/agnhost/proxy?method=PATCH
    Apr 18 09:15:05.649: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 18 09:15:05.649: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/pods/agnhost/proxy?method=POST
    Apr 18 09:15:05.653: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 18 09:15:05.653: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/pods/agnhost/proxy?method=PUT
    Apr 18 09:15:05.657: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 18 09:15:05.657: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/services/e2e-proxy-test-service/proxy?method=DELETE
    Apr 18 09:15:05.661: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 18 09:15:05.661: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Apr 18 09:15:05.666: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 18 09:15:05.666: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/services/e2e-proxy-test-service/proxy?method=PATCH
    Apr 18 09:15:05.671: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 18 09:15:05.671: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/services/e2e-proxy-test-service/proxy?method=POST
    Apr 18 09:15:05.675: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 18 09:15:05.675: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/services/e2e-proxy-test-service/proxy?method=PUT
    Apr 18 09:15:05.679: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 18 09:15:05.679: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/pods/agnhost/proxy?method=GET
    Apr 18 09:15:05.682: INFO: http.Client request:GET StatusCode:301
    Apr 18 09:15:05.682: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/services/e2e-proxy-test-service/proxy?method=GET
    Apr 18 09:15:05.685: INFO: http.Client request:GET StatusCode:301
    Apr 18 09:15:05.685: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/pods/agnhost/proxy?method=HEAD
    Apr 18 09:15:05.687: INFO: http.Client request:HEAD StatusCode:301
    Apr 18 09:15:05.687: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-6317/services/e2e-proxy-test-service/proxy?method=HEAD
    Apr 18 09:15:05.690: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Apr 18 09:15:05.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-6317" for this suite. 04/18/23 09:15:05.694
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:15:05.702
Apr 18 09:15:05.702: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename secrets 04/18/23 09:15:05.703
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:05.723
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:05.728
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-aed5d6be-c077-4a56-b92e-84b5194b007e 04/18/23 09:15:05.732
STEP: Creating a pod to test consume secrets 04/18/23 09:15:05.76
Apr 18 09:15:05.776: INFO: Waiting up to 5m0s for pod "pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498" in namespace "secrets-4748" to be "Succeeded or Failed"
Apr 18 09:15:05.784: INFO: Pod "pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498": Phase="Pending", Reason="", readiness=false. Elapsed: 7.854181ms
Apr 18 09:15:07.789: INFO: Pod "pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012383136s
Apr 18 09:15:09.788: INFO: Pod "pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011382306s
STEP: Saw pod success 04/18/23 09:15:09.788
Apr 18 09:15:09.788: INFO: Pod "pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498" satisfied condition "Succeeded or Failed"
Apr 18 09:15:09.791: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498 container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 09:15:09.796
Apr 18 09:15:09.805: INFO: Waiting for pod pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498 to disappear
Apr 18 09:15:09.807: INFO: Pod pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 09:15:09.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4748" for this suite. 04/18/23 09:15:09.812
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":170,"skipped":3174,"failed":0}
------------------------------
• [4.114 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:15:05.702
    Apr 18 09:15:05.702: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename secrets 04/18/23 09:15:05.703
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:05.723
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:05.728
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-aed5d6be-c077-4a56-b92e-84b5194b007e 04/18/23 09:15:05.732
    STEP: Creating a pod to test consume secrets 04/18/23 09:15:05.76
    Apr 18 09:15:05.776: INFO: Waiting up to 5m0s for pod "pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498" in namespace "secrets-4748" to be "Succeeded or Failed"
    Apr 18 09:15:05.784: INFO: Pod "pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498": Phase="Pending", Reason="", readiness=false. Elapsed: 7.854181ms
    Apr 18 09:15:07.789: INFO: Pod "pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012383136s
    Apr 18 09:15:09.788: INFO: Pod "pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011382306s
    STEP: Saw pod success 04/18/23 09:15:09.788
    Apr 18 09:15:09.788: INFO: Pod "pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498" satisfied condition "Succeeded or Failed"
    Apr 18 09:15:09.791: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498 container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 09:15:09.796
    Apr 18 09:15:09.805: INFO: Waiting for pod pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498 to disappear
    Apr 18 09:15:09.807: INFO: Pod pod-secrets-fb730a5b-969b-4dd3-b962-5b3a64574498 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 09:15:09.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4748" for this suite. 04/18/23 09:15:09.812
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:15:09.816
Apr 18 09:15:09.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 09:15:09.817
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:09.826
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:09.83
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 04/18/23 09:15:09.833
Apr 18 09:15:09.839: INFO: Waiting up to 5m0s for pod "downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b" in namespace "downward-api-1830" to be "Succeeded or Failed"
Apr 18 09:15:09.841: INFO: Pod "downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.309861ms
Apr 18 09:15:11.846: INFO: Pod "downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006935746s
Apr 18 09:15:13.847: INFO: Pod "downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0079539s
STEP: Saw pod success 04/18/23 09:15:13.847
Apr 18 09:15:13.847: INFO: Pod "downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b" satisfied condition "Succeeded or Failed"
Apr 18 09:15:13.857: INFO: Trying to get logs from node 192.168.1.152 pod downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b container dapi-container: <nil>
STEP: delete the pod 04/18/23 09:15:13.876
Apr 18 09:15:13.900: INFO: Waiting for pod downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b to disappear
Apr 18 09:15:13.917: INFO: Pod downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 18 09:15:13.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1830" for this suite. 04/18/23 09:15:13.95
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":171,"skipped":3180,"failed":0}
------------------------------
• [4.152 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:15:09.816
    Apr 18 09:15:09.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 09:15:09.817
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:09.826
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:09.83
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 04/18/23 09:15:09.833
    Apr 18 09:15:09.839: INFO: Waiting up to 5m0s for pod "downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b" in namespace "downward-api-1830" to be "Succeeded or Failed"
    Apr 18 09:15:09.841: INFO: Pod "downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.309861ms
    Apr 18 09:15:11.846: INFO: Pod "downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006935746s
    Apr 18 09:15:13.847: INFO: Pod "downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0079539s
    STEP: Saw pod success 04/18/23 09:15:13.847
    Apr 18 09:15:13.847: INFO: Pod "downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b" satisfied condition "Succeeded or Failed"
    Apr 18 09:15:13.857: INFO: Trying to get logs from node 192.168.1.152 pod downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b container dapi-container: <nil>
    STEP: delete the pod 04/18/23 09:15:13.876
    Apr 18 09:15:13.900: INFO: Waiting for pod downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b to disappear
    Apr 18 09:15:13.917: INFO: Pod downward-api-079d3406-756a-4f78-8e57-fba7ae0f419b no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 18 09:15:13.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1830" for this suite. 04/18/23 09:15:13.95
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:15:13.969
Apr 18 09:15:13.969: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 09:15:13.97
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:14.014
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:14.018
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 04/18/23 09:15:14.022
Apr 18 09:15:14.029: INFO: Waiting up to 5m0s for pod "downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56" in namespace "downward-api-7720" to be "Succeeded or Failed"
Apr 18 09:15:14.041: INFO: Pod "downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56": Phase="Pending", Reason="", readiness=false. Elapsed: 11.696903ms
Apr 18 09:15:16.044: INFO: Pod "downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015041121s
Apr 18 09:15:18.047: INFO: Pod "downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018642182s
STEP: Saw pod success 04/18/23 09:15:18.047
Apr 18 09:15:18.048: INFO: Pod "downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56" satisfied condition "Succeeded or Failed"
Apr 18 09:15:18.053: INFO: Trying to get logs from node 192.168.1.152 pod downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56 container dapi-container: <nil>
STEP: delete the pod 04/18/23 09:15:18.058
Apr 18 09:15:18.067: INFO: Waiting for pod downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56 to disappear
Apr 18 09:15:18.069: INFO: Pod downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 18 09:15:18.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7720" for this suite. 04/18/23 09:15:18.073
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":172,"skipped":3181,"failed":0}
------------------------------
• [4.110 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:15:13.969
    Apr 18 09:15:13.969: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 09:15:13.97
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:14.014
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:14.018
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 04/18/23 09:15:14.022
    Apr 18 09:15:14.029: INFO: Waiting up to 5m0s for pod "downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56" in namespace "downward-api-7720" to be "Succeeded or Failed"
    Apr 18 09:15:14.041: INFO: Pod "downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56": Phase="Pending", Reason="", readiness=false. Elapsed: 11.696903ms
    Apr 18 09:15:16.044: INFO: Pod "downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015041121s
    Apr 18 09:15:18.047: INFO: Pod "downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018642182s
    STEP: Saw pod success 04/18/23 09:15:18.047
    Apr 18 09:15:18.048: INFO: Pod "downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56" satisfied condition "Succeeded or Failed"
    Apr 18 09:15:18.053: INFO: Trying to get logs from node 192.168.1.152 pod downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56 container dapi-container: <nil>
    STEP: delete the pod 04/18/23 09:15:18.058
    Apr 18 09:15:18.067: INFO: Waiting for pod downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56 to disappear
    Apr 18 09:15:18.069: INFO: Pod downward-api-4e364672-2012-4a57-83ec-4ce5df4c0c56 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 18 09:15:18.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7720" for this suite. 04/18/23 09:15:18.073
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:15:18.08
Apr 18 09:15:18.080: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename proxy 04/18/23 09:15:18.081
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:18.089
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:18.093
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Apr 18 09:15:18.097: INFO: Creating pod...
Apr 18 09:15:18.104: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-3589" to be "running"
Apr 18 09:15:18.107: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.526451ms
Apr 18 09:15:20.111: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.006815894s
Apr 18 09:15:20.111: INFO: Pod "agnhost" satisfied condition "running"
Apr 18 09:15:20.111: INFO: Creating service...
Apr 18 09:15:20.120: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/pods/agnhost/proxy/some/path/with/DELETE
Apr 18 09:15:20.129: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 18 09:15:20.129: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/pods/agnhost/proxy/some/path/with/GET
Apr 18 09:15:20.133: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr 18 09:15:20.133: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/pods/agnhost/proxy/some/path/with/HEAD
Apr 18 09:15:20.137: INFO: http.Client request:HEAD | StatusCode:200
Apr 18 09:15:20.137: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/pods/agnhost/proxy/some/path/with/OPTIONS
Apr 18 09:15:20.140: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 18 09:15:20.140: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/pods/agnhost/proxy/some/path/with/PATCH
Apr 18 09:15:20.144: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 18 09:15:20.144: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/pods/agnhost/proxy/some/path/with/POST
Apr 18 09:15:20.147: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 18 09:15:20.147: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/pods/agnhost/proxy/some/path/with/PUT
Apr 18 09:15:20.152: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 18 09:15:20.152: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/services/test-service/proxy/some/path/with/DELETE
Apr 18 09:15:20.156: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 18 09:15:20.156: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/services/test-service/proxy/some/path/with/GET
Apr 18 09:15:20.160: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr 18 09:15:20.160: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/services/test-service/proxy/some/path/with/HEAD
Apr 18 09:15:20.164: INFO: http.Client request:HEAD | StatusCode:200
Apr 18 09:15:20.164: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/services/test-service/proxy/some/path/with/OPTIONS
Apr 18 09:15:20.168: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 18 09:15:20.168: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/services/test-service/proxy/some/path/with/PATCH
Apr 18 09:15:20.174: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 18 09:15:20.174: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/services/test-service/proxy/some/path/with/POST
Apr 18 09:15:20.179: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 18 09:15:20.179: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/services/test-service/proxy/some/path/with/PUT
Apr 18 09:15:20.188: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Apr 18 09:15:20.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3589" for this suite. 04/18/23 09:15:20.217
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":173,"skipped":3208,"failed":0}
------------------------------
• [2.156 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:15:18.08
    Apr 18 09:15:18.080: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename proxy 04/18/23 09:15:18.081
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:18.089
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:18.093
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Apr 18 09:15:18.097: INFO: Creating pod...
    Apr 18 09:15:18.104: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-3589" to be "running"
    Apr 18 09:15:18.107: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.526451ms
    Apr 18 09:15:20.111: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.006815894s
    Apr 18 09:15:20.111: INFO: Pod "agnhost" satisfied condition "running"
    Apr 18 09:15:20.111: INFO: Creating service...
    Apr 18 09:15:20.120: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/pods/agnhost/proxy/some/path/with/DELETE
    Apr 18 09:15:20.129: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 18 09:15:20.129: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/pods/agnhost/proxy/some/path/with/GET
    Apr 18 09:15:20.133: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Apr 18 09:15:20.133: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/pods/agnhost/proxy/some/path/with/HEAD
    Apr 18 09:15:20.137: INFO: http.Client request:HEAD | StatusCode:200
    Apr 18 09:15:20.137: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/pods/agnhost/proxy/some/path/with/OPTIONS
    Apr 18 09:15:20.140: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 18 09:15:20.140: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/pods/agnhost/proxy/some/path/with/PATCH
    Apr 18 09:15:20.144: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 18 09:15:20.144: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/pods/agnhost/proxy/some/path/with/POST
    Apr 18 09:15:20.147: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 18 09:15:20.147: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/pods/agnhost/proxy/some/path/with/PUT
    Apr 18 09:15:20.152: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 18 09:15:20.152: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/services/test-service/proxy/some/path/with/DELETE
    Apr 18 09:15:20.156: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 18 09:15:20.156: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/services/test-service/proxy/some/path/with/GET
    Apr 18 09:15:20.160: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Apr 18 09:15:20.160: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/services/test-service/proxy/some/path/with/HEAD
    Apr 18 09:15:20.164: INFO: http.Client request:HEAD | StatusCode:200
    Apr 18 09:15:20.164: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/services/test-service/proxy/some/path/with/OPTIONS
    Apr 18 09:15:20.168: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 18 09:15:20.168: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/services/test-service/proxy/some/path/with/PATCH
    Apr 18 09:15:20.174: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 18 09:15:20.174: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/services/test-service/proxy/some/path/with/POST
    Apr 18 09:15:20.179: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 18 09:15:20.179: INFO: Starting http.Client for https://10.247.0.1:443/api/v1/namespaces/proxy-3589/services/test-service/proxy/some/path/with/PUT
    Apr 18 09:15:20.188: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Apr 18 09:15:20.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-3589" for this suite. 04/18/23 09:15:20.217
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:15:20.241
Apr 18 09:15:20.241: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 09:15:20.241
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:20.302
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:20.336
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 04/18/23 09:15:20.348
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 09:15:20.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4033" for this suite. 04/18/23 09:15:20.356
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":174,"skipped":3326,"failed":0}
------------------------------
• [0.120 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:15:20.241
    Apr 18 09:15:20.241: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 09:15:20.241
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:20.302
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:20.336
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 04/18/23 09:15:20.348
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 09:15:20.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4033" for this suite. 04/18/23 09:15:20.356
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:15:20.362
Apr 18 09:15:20.362: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 09:15:20.363
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:20.374
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:20.378
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-1352 04/18/23 09:15:20.381
STEP: creating replication controller nodeport-test in namespace services-1352 04/18/23 09:15:20.392
I0418 09:15:20.399187      18 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-1352, replica count: 2
I0418 09:15:23.450240      18 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 09:15:23.450: INFO: Creating new exec pod
Apr 18 09:15:23.456: INFO: Waiting up to 5m0s for pod "execpodw7kvs" in namespace "services-1352" to be "running"
Apr 18 09:15:23.459: INFO: Pod "execpodw7kvs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.893921ms
Apr 18 09:15:25.463: INFO: Pod "execpodw7kvs": Phase="Running", Reason="", readiness=true. Elapsed: 2.007016958s
Apr 18 09:15:25.463: INFO: Pod "execpodw7kvs" satisfied condition "running"
Apr 18 09:15:26.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-1352 exec execpodw7kvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Apr 18 09:15:26.571: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr 18 09:15:26.571: INFO: stdout: ""
Apr 18 09:15:27.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-1352 exec execpodw7kvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Apr 18 09:15:27.685: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr 18 09:15:27.685: INFO: stdout: "nodeport-test-9kj4s"
Apr 18 09:15:27.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-1352 exec execpodw7kvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.103.60 80'
Apr 18 09:15:27.785: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.103.60 80\nConnection to 10.247.103.60 80 port [tcp/http] succeeded!\n"
Apr 18 09:15:27.785: INFO: stdout: "nodeport-test-l9px2"
Apr 18 09:15:27.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-1352 exec execpodw7kvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.152 32124'
Apr 18 09:15:27.886: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.152 32124\nConnection to 192.168.1.152 32124 port [tcp/*] succeeded!\n"
Apr 18 09:15:27.886: INFO: stdout: "nodeport-test-l9px2"
Apr 18 09:15:27.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-1352 exec execpodw7kvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.29 32124'
Apr 18 09:15:27.997: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.29 32124\nConnection to 192.168.1.29 32124 port [tcp/*] succeeded!\n"
Apr 18 09:15:27.997: INFO: stdout: "nodeport-test-9kj4s"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 09:15:27.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1352" for this suite. 04/18/23 09:15:28.002
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":175,"skipped":3328,"failed":0}
------------------------------
• [SLOW TEST] [7.644 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:15:20.362
    Apr 18 09:15:20.362: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 09:15:20.363
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:20.374
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:20.378
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-1352 04/18/23 09:15:20.381
    STEP: creating replication controller nodeport-test in namespace services-1352 04/18/23 09:15:20.392
    I0418 09:15:20.399187      18 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-1352, replica count: 2
    I0418 09:15:23.450240      18 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 09:15:23.450: INFO: Creating new exec pod
    Apr 18 09:15:23.456: INFO: Waiting up to 5m0s for pod "execpodw7kvs" in namespace "services-1352" to be "running"
    Apr 18 09:15:23.459: INFO: Pod "execpodw7kvs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.893921ms
    Apr 18 09:15:25.463: INFO: Pod "execpodw7kvs": Phase="Running", Reason="", readiness=true. Elapsed: 2.007016958s
    Apr 18 09:15:25.463: INFO: Pod "execpodw7kvs" satisfied condition "running"
    Apr 18 09:15:26.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-1352 exec execpodw7kvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Apr 18 09:15:26.571: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Apr 18 09:15:26.571: INFO: stdout: ""
    Apr 18 09:15:27.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-1352 exec execpodw7kvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Apr 18 09:15:27.685: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Apr 18 09:15:27.685: INFO: stdout: "nodeport-test-9kj4s"
    Apr 18 09:15:27.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-1352 exec execpodw7kvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.103.60 80'
    Apr 18 09:15:27.785: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.103.60 80\nConnection to 10.247.103.60 80 port [tcp/http] succeeded!\n"
    Apr 18 09:15:27.785: INFO: stdout: "nodeport-test-l9px2"
    Apr 18 09:15:27.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-1352 exec execpodw7kvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.152 32124'
    Apr 18 09:15:27.886: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.152 32124\nConnection to 192.168.1.152 32124 port [tcp/*] succeeded!\n"
    Apr 18 09:15:27.886: INFO: stdout: "nodeport-test-l9px2"
    Apr 18 09:15:27.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-1352 exec execpodw7kvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.29 32124'
    Apr 18 09:15:27.997: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.29 32124\nConnection to 192.168.1.29 32124 port [tcp/*] succeeded!\n"
    Apr 18 09:15:27.997: INFO: stdout: "nodeport-test-9kj4s"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 09:15:27.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1352" for this suite. 04/18/23 09:15:28.002
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:15:28.007
Apr 18 09:15:28.008: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename dns 04/18/23 09:15:28.008
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:28.018
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:28.022
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 04/18/23 09:15:28.026
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-2751.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-2751.svc.cluster.local;sleep 1; done
 04/18/23 09:15:28.029
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-2751.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-2751.svc.cluster.local;sleep 1; done
 04/18/23 09:15:28.029
STEP: creating a pod to probe DNS 04/18/23 09:15:28.029
STEP: submitting the pod to kubernetes 04/18/23 09:15:28.03
Apr 18 09:15:28.037: INFO: Waiting up to 15m0s for pod "dns-test-e4416510-0577-4405-80fb-c15d63e07070" in namespace "dns-2751" to be "running"
Apr 18 09:15:28.043: INFO: Pod "dns-test-e4416510-0577-4405-80fb-c15d63e07070": Phase="Pending", Reason="", readiness=false. Elapsed: 5.598252ms
Apr 18 09:15:30.052: INFO: Pod "dns-test-e4416510-0577-4405-80fb-c15d63e07070": Phase="Running", Reason="", readiness=true. Elapsed: 2.015385565s
Apr 18 09:15:30.053: INFO: Pod "dns-test-e4416510-0577-4405-80fb-c15d63e07070" satisfied condition "running"
STEP: retrieving the pod 04/18/23 09:15:30.053
STEP: looking for the results for each expected name from probers 04/18/23 09:15:30.063
Apr 18 09:15:30.077: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local from pod dns-2751/dns-test-e4416510-0577-4405-80fb-c15d63e07070: the server could not find the requested resource (get pods dns-test-e4416510-0577-4405-80fb-c15d63e07070)
Apr 18 09:15:30.091: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local from pod dns-2751/dns-test-e4416510-0577-4405-80fb-c15d63e07070: the server could not find the requested resource (get pods dns-test-e4416510-0577-4405-80fb-c15d63e07070)
Apr 18 09:15:30.133: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local from pod dns-2751/dns-test-e4416510-0577-4405-80fb-c15d63e07070: the server could not find the requested resource (get pods dns-test-e4416510-0577-4405-80fb-c15d63e07070)
Apr 18 09:15:30.147: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local from pod dns-2751/dns-test-e4416510-0577-4405-80fb-c15d63e07070: the server could not find the requested resource (get pods dns-test-e4416510-0577-4405-80fb-c15d63e07070)
Apr 18 09:15:30.152: INFO: Unable to read jessie_udp@dns-test-service-2.dns-2751.svc.cluster.local from pod dns-2751/dns-test-e4416510-0577-4405-80fb-c15d63e07070: the server could not find the requested resource (get pods dns-test-e4416510-0577-4405-80fb-c15d63e07070)
Apr 18 09:15:30.156: INFO: Lookups using dns-2751/dns-test-e4416510-0577-4405-80fb-c15d63e07070 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local jessie_udp@dns-test-service-2.dns-2751.svc.cluster.local]

Apr 18 09:15:35.188: INFO: DNS probes using dns-2751/dns-test-e4416510-0577-4405-80fb-c15d63e07070 succeeded

STEP: deleting the pod 04/18/23 09:15:35.188
STEP: deleting the test headless service 04/18/23 09:15:35.198
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 09:15:35.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2751" for this suite. 04/18/23 09:15:35.227
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":176,"skipped":3385,"failed":0}
------------------------------
• [SLOW TEST] [7.224 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:15:28.007
    Apr 18 09:15:28.008: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename dns 04/18/23 09:15:28.008
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:28.018
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:28.022
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 04/18/23 09:15:28.026
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-2751.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-2751.svc.cluster.local;sleep 1; done
     04/18/23 09:15:28.029
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-2751.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2751.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-2751.svc.cluster.local;sleep 1; done
     04/18/23 09:15:28.029
    STEP: creating a pod to probe DNS 04/18/23 09:15:28.029
    STEP: submitting the pod to kubernetes 04/18/23 09:15:28.03
    Apr 18 09:15:28.037: INFO: Waiting up to 15m0s for pod "dns-test-e4416510-0577-4405-80fb-c15d63e07070" in namespace "dns-2751" to be "running"
    Apr 18 09:15:28.043: INFO: Pod "dns-test-e4416510-0577-4405-80fb-c15d63e07070": Phase="Pending", Reason="", readiness=false. Elapsed: 5.598252ms
    Apr 18 09:15:30.052: INFO: Pod "dns-test-e4416510-0577-4405-80fb-c15d63e07070": Phase="Running", Reason="", readiness=true. Elapsed: 2.015385565s
    Apr 18 09:15:30.053: INFO: Pod "dns-test-e4416510-0577-4405-80fb-c15d63e07070" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 09:15:30.053
    STEP: looking for the results for each expected name from probers 04/18/23 09:15:30.063
    Apr 18 09:15:30.077: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local from pod dns-2751/dns-test-e4416510-0577-4405-80fb-c15d63e07070: the server could not find the requested resource (get pods dns-test-e4416510-0577-4405-80fb-c15d63e07070)
    Apr 18 09:15:30.091: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local from pod dns-2751/dns-test-e4416510-0577-4405-80fb-c15d63e07070: the server could not find the requested resource (get pods dns-test-e4416510-0577-4405-80fb-c15d63e07070)
    Apr 18 09:15:30.133: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local from pod dns-2751/dns-test-e4416510-0577-4405-80fb-c15d63e07070: the server could not find the requested resource (get pods dns-test-e4416510-0577-4405-80fb-c15d63e07070)
    Apr 18 09:15:30.147: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local from pod dns-2751/dns-test-e4416510-0577-4405-80fb-c15d63e07070: the server could not find the requested resource (get pods dns-test-e4416510-0577-4405-80fb-c15d63e07070)
    Apr 18 09:15:30.152: INFO: Unable to read jessie_udp@dns-test-service-2.dns-2751.svc.cluster.local from pod dns-2751/dns-test-e4416510-0577-4405-80fb-c15d63e07070: the server could not find the requested resource (get pods dns-test-e4416510-0577-4405-80fb-c15d63e07070)
    Apr 18 09:15:30.156: INFO: Lookups using dns-2751/dns-test-e4416510-0577-4405-80fb-c15d63e07070 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2751.svc.cluster.local jessie_udp@dns-test-service-2.dns-2751.svc.cluster.local]

    Apr 18 09:15:35.188: INFO: DNS probes using dns-2751/dns-test-e4416510-0577-4405-80fb-c15d63e07070 succeeded

    STEP: deleting the pod 04/18/23 09:15:35.188
    STEP: deleting the test headless service 04/18/23 09:15:35.198
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 09:15:35.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2751" for this suite. 04/18/23 09:15:35.227
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:15:35.233
Apr 18 09:15:35.233: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 09:15:35.234
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:35.245
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:35.25
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-a765b98d-dd22-4e8c-8c79-e4f28b09c114 04/18/23 09:15:35.254
STEP: Creating a pod to test consume secrets 04/18/23 09:15:35.257
Apr 18 09:15:35.264: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047" in namespace "projected-5048" to be "Succeeded or Failed"
Apr 18 09:15:35.267: INFO: Pod "pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047": Phase="Pending", Reason="", readiness=false. Elapsed: 2.594766ms
Apr 18 09:15:37.271: INFO: Pod "pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006483381s
Apr 18 09:15:39.271: INFO: Pod "pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006124152s
STEP: Saw pod success 04/18/23 09:15:39.271
Apr 18 09:15:39.271: INFO: Pod "pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047" satisfied condition "Succeeded or Failed"
Apr 18 09:15:39.274: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/18/23 09:15:39.279
Apr 18 09:15:39.287: INFO: Waiting for pod pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047 to disappear
Apr 18 09:15:39.290: INFO: Pod pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 18 09:15:39.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5048" for this suite. 04/18/23 09:15:39.294
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":177,"skipped":3393,"failed":0}
------------------------------
• [4.066 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:15:35.233
    Apr 18 09:15:35.233: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 09:15:35.234
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:35.245
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:35.25
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-a765b98d-dd22-4e8c-8c79-e4f28b09c114 04/18/23 09:15:35.254
    STEP: Creating a pod to test consume secrets 04/18/23 09:15:35.257
    Apr 18 09:15:35.264: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047" in namespace "projected-5048" to be "Succeeded or Failed"
    Apr 18 09:15:35.267: INFO: Pod "pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047": Phase="Pending", Reason="", readiness=false. Elapsed: 2.594766ms
    Apr 18 09:15:37.271: INFO: Pod "pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006483381s
    Apr 18 09:15:39.271: INFO: Pod "pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006124152s
    STEP: Saw pod success 04/18/23 09:15:39.271
    Apr 18 09:15:39.271: INFO: Pod "pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047" satisfied condition "Succeeded or Failed"
    Apr 18 09:15:39.274: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 09:15:39.279
    Apr 18 09:15:39.287: INFO: Waiting for pod pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047 to disappear
    Apr 18 09:15:39.290: INFO: Pod pod-projected-secrets-e4f049d6-233d-4f95-9694-150ea8e06047 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 18 09:15:39.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5048" for this suite. 04/18/23 09:15:39.294
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:15:39.299
Apr 18 09:15:39.299: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename subpath 04/18/23 09:15:39.3
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:39.31
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:39.314
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/18/23 09:15:39.318
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-vzpb 04/18/23 09:15:39.327
STEP: Creating a pod to test atomic-volume-subpath 04/18/23 09:15:39.327
Apr 18 09:15:39.334: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-vzpb" in namespace "subpath-7389" to be "Succeeded or Failed"
Apr 18 09:15:39.337: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.264612ms
Apr 18 09:15:41.341: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 2.007111583s
Apr 18 09:15:43.341: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 4.007546191s
Apr 18 09:15:45.341: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 6.00709685s
Apr 18 09:15:47.342: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 8.008255229s
Apr 18 09:15:49.341: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 10.006883094s
Apr 18 09:15:51.340: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 12.006722558s
Apr 18 09:15:53.340: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 14.00685498s
Apr 18 09:15:55.342: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 16.00794726s
Apr 18 09:15:57.341: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 18.007344414s
Apr 18 09:15:59.340: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 20.006857062s
Apr 18 09:16:01.342: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=false. Elapsed: 22.008275862s
Apr 18 09:16:03.341: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.006948261s
STEP: Saw pod success 04/18/23 09:16:03.341
Apr 18 09:16:03.341: INFO: Pod "pod-subpath-test-secret-vzpb" satisfied condition "Succeeded or Failed"
Apr 18 09:16:03.344: INFO: Trying to get logs from node 192.168.1.152 pod pod-subpath-test-secret-vzpb container test-container-subpath-secret-vzpb: <nil>
STEP: delete the pod 04/18/23 09:16:03.349
Apr 18 09:16:03.359: INFO: Waiting for pod pod-subpath-test-secret-vzpb to disappear
Apr 18 09:16:03.362: INFO: Pod pod-subpath-test-secret-vzpb no longer exists
STEP: Deleting pod pod-subpath-test-secret-vzpb 04/18/23 09:16:03.362
Apr 18 09:16:03.362: INFO: Deleting pod "pod-subpath-test-secret-vzpb" in namespace "subpath-7389"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 18 09:16:03.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7389" for this suite. 04/18/23 09:16:03.369
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":178,"skipped":3409,"failed":0}
------------------------------
• [SLOW TEST] [24.074 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:15:39.299
    Apr 18 09:15:39.299: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename subpath 04/18/23 09:15:39.3
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:15:39.31
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:15:39.314
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/18/23 09:15:39.318
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-vzpb 04/18/23 09:15:39.327
    STEP: Creating a pod to test atomic-volume-subpath 04/18/23 09:15:39.327
    Apr 18 09:15:39.334: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-vzpb" in namespace "subpath-7389" to be "Succeeded or Failed"
    Apr 18 09:15:39.337: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.264612ms
    Apr 18 09:15:41.341: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 2.007111583s
    Apr 18 09:15:43.341: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 4.007546191s
    Apr 18 09:15:45.341: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 6.00709685s
    Apr 18 09:15:47.342: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 8.008255229s
    Apr 18 09:15:49.341: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 10.006883094s
    Apr 18 09:15:51.340: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 12.006722558s
    Apr 18 09:15:53.340: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 14.00685498s
    Apr 18 09:15:55.342: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 16.00794726s
    Apr 18 09:15:57.341: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 18.007344414s
    Apr 18 09:15:59.340: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=true. Elapsed: 20.006857062s
    Apr 18 09:16:01.342: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Running", Reason="", readiness=false. Elapsed: 22.008275862s
    Apr 18 09:16:03.341: INFO: Pod "pod-subpath-test-secret-vzpb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.006948261s
    STEP: Saw pod success 04/18/23 09:16:03.341
    Apr 18 09:16:03.341: INFO: Pod "pod-subpath-test-secret-vzpb" satisfied condition "Succeeded or Failed"
    Apr 18 09:16:03.344: INFO: Trying to get logs from node 192.168.1.152 pod pod-subpath-test-secret-vzpb container test-container-subpath-secret-vzpb: <nil>
    STEP: delete the pod 04/18/23 09:16:03.349
    Apr 18 09:16:03.359: INFO: Waiting for pod pod-subpath-test-secret-vzpb to disappear
    Apr 18 09:16:03.362: INFO: Pod pod-subpath-test-secret-vzpb no longer exists
    STEP: Deleting pod pod-subpath-test-secret-vzpb 04/18/23 09:16:03.362
    Apr 18 09:16:03.362: INFO: Deleting pod "pod-subpath-test-secret-vzpb" in namespace "subpath-7389"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 18 09:16:03.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-7389" for this suite. 04/18/23 09:16:03.369
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:16:03.374
Apr 18 09:16:03.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename daemonsets 04/18/23 09:16:03.375
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:03.385
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:03.388
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 04/18/23 09:16:03.41
STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 09:16:03.416
Apr 18 09:16:03.422: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:16:03.422: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
Apr 18 09:16:04.430: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 18 09:16:04.430: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
Apr 18 09:16:05.435: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 09:16:05.435: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 04/18/23 09:16:05.438
Apr 18 09:16:05.441: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 04/18/23 09:16:05.441
Apr 18 09:16:05.452: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 04/18/23 09:16:05.452
Apr 18 09:16:05.455: INFO: Observed &DaemonSet event: ADDED
Apr 18 09:16:05.455: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 09:16:05.455: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 09:16:05.455: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 09:16:05.456: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 09:16:05.456: INFO: Found daemon set daemon-set in namespace daemonsets-8999 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 18 09:16:05.456: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 04/18/23 09:16:05.456
STEP: watching for the daemon set status to be patched 04/18/23 09:16:05.463
Apr 18 09:16:05.465: INFO: Observed &DaemonSet event: ADDED
Apr 18 09:16:05.465: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 09:16:05.465: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 09:16:05.465: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 09:16:05.465: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 09:16:05.465: INFO: Observed daemon set daemon-set in namespace daemonsets-8999 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 18 09:16:05.465: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 09:16:05.466: INFO: Found daemon set daemon-set in namespace daemonsets-8999 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Apr 18 09:16:05.466: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/18/23 09:16:05.469
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8999, will wait for the garbage collector to delete the pods 04/18/23 09:16:05.469
Apr 18 09:16:05.527: INFO: Deleting DaemonSet.extensions daemon-set took: 4.977604ms
Apr 18 09:16:05.627: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.113141ms
Apr 18 09:16:08.031: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:16:08.031: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 18 09:16:08.034: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4189581"},"items":null}

Apr 18 09:16:08.036: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4189581"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:16:08.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8999" for this suite. 04/18/23 09:16:08.053
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":179,"skipped":3435,"failed":0}
------------------------------
• [4.684 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:16:03.374
    Apr 18 09:16:03.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename daemonsets 04/18/23 09:16:03.375
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:03.385
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:03.388
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 04/18/23 09:16:03.41
    STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 09:16:03.416
    Apr 18 09:16:03.422: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:16:03.422: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
    Apr 18 09:16:04.430: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 18 09:16:04.430: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
    Apr 18 09:16:05.435: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 09:16:05.435: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 04/18/23 09:16:05.438
    Apr 18 09:16:05.441: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 04/18/23 09:16:05.441
    Apr 18 09:16:05.452: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 04/18/23 09:16:05.452
    Apr 18 09:16:05.455: INFO: Observed &DaemonSet event: ADDED
    Apr 18 09:16:05.455: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 09:16:05.455: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 09:16:05.455: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 09:16:05.456: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 09:16:05.456: INFO: Found daemon set daemon-set in namespace daemonsets-8999 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 18 09:16:05.456: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 04/18/23 09:16:05.456
    STEP: watching for the daemon set status to be patched 04/18/23 09:16:05.463
    Apr 18 09:16:05.465: INFO: Observed &DaemonSet event: ADDED
    Apr 18 09:16:05.465: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 09:16:05.465: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 09:16:05.465: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 09:16:05.465: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 09:16:05.465: INFO: Observed daemon set daemon-set in namespace daemonsets-8999 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 18 09:16:05.465: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 09:16:05.466: INFO: Found daemon set daemon-set in namespace daemonsets-8999 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Apr 18 09:16:05.466: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/18/23 09:16:05.469
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8999, will wait for the garbage collector to delete the pods 04/18/23 09:16:05.469
    Apr 18 09:16:05.527: INFO: Deleting DaemonSet.extensions daemon-set took: 4.977604ms
    Apr 18 09:16:05.627: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.113141ms
    Apr 18 09:16:08.031: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:16:08.031: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 18 09:16:08.034: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4189581"},"items":null}

    Apr 18 09:16:08.036: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4189581"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:16:08.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8999" for this suite. 04/18/23 09:16:08.053
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:16:08.06
Apr 18 09:16:08.060: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 09:16:08.061
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:08.07
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:08.074
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 04/18/23 09:16:08.078
Apr 18 09:16:08.084: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d" in namespace "downward-api-740" to be "Succeeded or Failed"
Apr 18 09:16:08.087: INFO: Pod "downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.538742ms
Apr 18 09:16:10.090: INFO: Pod "downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005889322s
Apr 18 09:16:12.091: INFO: Pod "downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006931669s
STEP: Saw pod success 04/18/23 09:16:12.091
Apr 18 09:16:12.092: INFO: Pod "downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d" satisfied condition "Succeeded or Failed"
Apr 18 09:16:12.094: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d container client-container: <nil>
STEP: delete the pod 04/18/23 09:16:12.099
Apr 18 09:16:12.108: INFO: Waiting for pod downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d to disappear
Apr 18 09:16:12.110: INFO: Pod downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 09:16:12.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-740" for this suite. 04/18/23 09:16:12.115
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":180,"skipped":3479,"failed":0}
------------------------------
• [4.059 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:16:08.06
    Apr 18 09:16:08.060: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 09:16:08.061
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:08.07
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:08.074
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 04/18/23 09:16:08.078
    Apr 18 09:16:08.084: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d" in namespace "downward-api-740" to be "Succeeded or Failed"
    Apr 18 09:16:08.087: INFO: Pod "downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.538742ms
    Apr 18 09:16:10.090: INFO: Pod "downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005889322s
    Apr 18 09:16:12.091: INFO: Pod "downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006931669s
    STEP: Saw pod success 04/18/23 09:16:12.091
    Apr 18 09:16:12.092: INFO: Pod "downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d" satisfied condition "Succeeded or Failed"
    Apr 18 09:16:12.094: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d container client-container: <nil>
    STEP: delete the pod 04/18/23 09:16:12.099
    Apr 18 09:16:12.108: INFO: Waiting for pod downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d to disappear
    Apr 18 09:16:12.110: INFO: Pod downwardapi-volume-25572d11-de2f-47df-a454-60c75d71e77d no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 09:16:12.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-740" for this suite. 04/18/23 09:16:12.115
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:16:12.12
Apr 18 09:16:12.120: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename containers 04/18/23 09:16:12.12
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:12.131
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:12.135
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 04/18/23 09:16:12.138
Apr 18 09:16:12.144: INFO: Waiting up to 5m0s for pod "client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98" in namespace "containers-4935" to be "Succeeded or Failed"
Apr 18 09:16:12.149: INFO: Pod "client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98": Phase="Pending", Reason="", readiness=false. Elapsed: 4.286338ms
Apr 18 09:16:14.152: INFO: Pod "client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007592138s
Apr 18 09:16:16.153: INFO: Pod "client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008562579s
STEP: Saw pod success 04/18/23 09:16:16.153
Apr 18 09:16:16.153: INFO: Pod "client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98" satisfied condition "Succeeded or Failed"
Apr 18 09:16:16.156: INFO: Trying to get logs from node 192.168.1.152 pod client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 09:16:16.161
Apr 18 09:16:16.171: INFO: Waiting for pod client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98 to disappear
Apr 18 09:16:16.173: INFO: Pod client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 18 09:16:16.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4935" for this suite. 04/18/23 09:16:16.178
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":181,"skipped":3496,"failed":0}
------------------------------
• [4.062 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:16:12.12
    Apr 18 09:16:12.120: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename containers 04/18/23 09:16:12.12
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:12.131
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:12.135
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 04/18/23 09:16:12.138
    Apr 18 09:16:12.144: INFO: Waiting up to 5m0s for pod "client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98" in namespace "containers-4935" to be "Succeeded or Failed"
    Apr 18 09:16:12.149: INFO: Pod "client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98": Phase="Pending", Reason="", readiness=false. Elapsed: 4.286338ms
    Apr 18 09:16:14.152: INFO: Pod "client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007592138s
    Apr 18 09:16:16.153: INFO: Pod "client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008562579s
    STEP: Saw pod success 04/18/23 09:16:16.153
    Apr 18 09:16:16.153: INFO: Pod "client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98" satisfied condition "Succeeded or Failed"
    Apr 18 09:16:16.156: INFO: Trying to get logs from node 192.168.1.152 pod client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 09:16:16.161
    Apr 18 09:16:16.171: INFO: Waiting for pod client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98 to disappear
    Apr 18 09:16:16.173: INFO: Pod client-containers-5813e3f4-e186-40c7-b1e5-58b74506eb98 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 18 09:16:16.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-4935" for this suite. 04/18/23 09:16:16.178
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:16:16.184
Apr 18 09:16:16.185: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename secrets 04/18/23 09:16:16.185
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:16.195
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:16.199
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-c72c5688-f0ff-45b8-ba90-a5a65ee14ade 04/18/23 09:16:16.207
STEP: Creating secret with name s-test-opt-upd-9739f4f7-1489-472a-8381-b1372af76bda 04/18/23 09:16:16.211
STEP: Creating the pod 04/18/23 09:16:16.215
Apr 18 09:16:16.223: INFO: Waiting up to 5m0s for pod "pod-secrets-f48ee230-765b-4b6a-81b6-5140b76f9a23" in namespace "secrets-2573" to be "running and ready"
Apr 18 09:16:16.225: INFO: Pod "pod-secrets-f48ee230-765b-4b6a-81b6-5140b76f9a23": Phase="Pending", Reason="", readiness=false. Elapsed: 2.688559ms
Apr 18 09:16:16.225: INFO: The phase of Pod pod-secrets-f48ee230-765b-4b6a-81b6-5140b76f9a23 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:16:18.230: INFO: Pod "pod-secrets-f48ee230-765b-4b6a-81b6-5140b76f9a23": Phase="Running", Reason="", readiness=true. Elapsed: 2.007272205s
Apr 18 09:16:18.230: INFO: The phase of Pod pod-secrets-f48ee230-765b-4b6a-81b6-5140b76f9a23 is Running (Ready = true)
Apr 18 09:16:18.230: INFO: Pod "pod-secrets-f48ee230-765b-4b6a-81b6-5140b76f9a23" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-c72c5688-f0ff-45b8-ba90-a5a65ee14ade 04/18/23 09:16:18.249
STEP: Updating secret s-test-opt-upd-9739f4f7-1489-472a-8381-b1372af76bda 04/18/23 09:16:18.255
STEP: Creating secret with name s-test-opt-create-c05fc534-e267-4b17-bf26-be70244abe7f 04/18/23 09:16:18.262
STEP: waiting to observe update in volume 04/18/23 09:16:18.265
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 09:16:22.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2573" for this suite. 04/18/23 09:16:22.296
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":182,"skipped":3542,"failed":0}
------------------------------
• [SLOW TEST] [6.116 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:16:16.184
    Apr 18 09:16:16.185: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename secrets 04/18/23 09:16:16.185
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:16.195
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:16.199
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-c72c5688-f0ff-45b8-ba90-a5a65ee14ade 04/18/23 09:16:16.207
    STEP: Creating secret with name s-test-opt-upd-9739f4f7-1489-472a-8381-b1372af76bda 04/18/23 09:16:16.211
    STEP: Creating the pod 04/18/23 09:16:16.215
    Apr 18 09:16:16.223: INFO: Waiting up to 5m0s for pod "pod-secrets-f48ee230-765b-4b6a-81b6-5140b76f9a23" in namespace "secrets-2573" to be "running and ready"
    Apr 18 09:16:16.225: INFO: Pod "pod-secrets-f48ee230-765b-4b6a-81b6-5140b76f9a23": Phase="Pending", Reason="", readiness=false. Elapsed: 2.688559ms
    Apr 18 09:16:16.225: INFO: The phase of Pod pod-secrets-f48ee230-765b-4b6a-81b6-5140b76f9a23 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:16:18.230: INFO: Pod "pod-secrets-f48ee230-765b-4b6a-81b6-5140b76f9a23": Phase="Running", Reason="", readiness=true. Elapsed: 2.007272205s
    Apr 18 09:16:18.230: INFO: The phase of Pod pod-secrets-f48ee230-765b-4b6a-81b6-5140b76f9a23 is Running (Ready = true)
    Apr 18 09:16:18.230: INFO: Pod "pod-secrets-f48ee230-765b-4b6a-81b6-5140b76f9a23" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-c72c5688-f0ff-45b8-ba90-a5a65ee14ade 04/18/23 09:16:18.249
    STEP: Updating secret s-test-opt-upd-9739f4f7-1489-472a-8381-b1372af76bda 04/18/23 09:16:18.255
    STEP: Creating secret with name s-test-opt-create-c05fc534-e267-4b17-bf26-be70244abe7f 04/18/23 09:16:18.262
    STEP: waiting to observe update in volume 04/18/23 09:16:18.265
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 09:16:22.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2573" for this suite. 04/18/23 09:16:22.296
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:16:22.3
Apr 18 09:16:22.301: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 09:16:22.301
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:22.312
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:22.316
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7322 04/18/23 09:16:22.32
STEP: changing the ExternalName service to type=NodePort 04/18/23 09:16:22.323
STEP: creating replication controller externalname-service in namespace services-7322 04/18/23 09:16:22.336
I0418 09:16:22.343323      18 runners.go:193] Created replication controller with name: externalname-service, namespace: services-7322, replica count: 2
I0418 09:16:25.395053      18 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 09:16:25.395: INFO: Creating new exec pod
Apr 18 09:16:25.399: INFO: Waiting up to 5m0s for pod "execpod6gqmb" in namespace "services-7322" to be "running"
Apr 18 09:16:25.402: INFO: Pod "execpod6gqmb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.831966ms
Apr 18 09:16:27.406: INFO: Pod "execpod6gqmb": Phase="Running", Reason="", readiness=true. Elapsed: 2.006683754s
Apr 18 09:16:27.406: INFO: Pod "execpod6gqmb" satisfied condition "running"
Apr 18 09:16:28.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7322 exec execpod6gqmb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 18 09:16:28.517: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 18 09:16:28.517: INFO: stdout: "externalname-service-fk5s4"
Apr 18 09:16:28.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7322 exec execpod6gqmb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.43.105 80'
Apr 18 09:16:28.618: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.43.105 80\nConnection to 10.247.43.105 80 port [tcp/http] succeeded!\n"
Apr 18 09:16:28.618: INFO: stdout: ""
Apr 18 09:16:29.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7322 exec execpod6gqmb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.43.105 80'
Apr 18 09:16:29.716: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.43.105 80\nConnection to 10.247.43.105 80 port [tcp/http] succeeded!\n"
Apr 18 09:16:29.716: INFO: stdout: "externalname-service-fk5s4"
Apr 18 09:16:29.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7322 exec execpod6gqmb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.84 30951'
Apr 18 09:16:29.827: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.84 30951\nConnection to 192.168.1.84 30951 port [tcp/*] succeeded!\n"
Apr 18 09:16:29.827: INFO: stdout: ""
Apr 18 09:16:30.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7322 exec execpod6gqmb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.84 30951'
Apr 18 09:16:30.985: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.84 30951\nConnection to 192.168.1.84 30951 port [tcp/*] succeeded!\n"
Apr 18 09:16:30.985: INFO: stdout: "externalname-service-fk5s4"
Apr 18 09:16:30.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7322 exec execpod6gqmb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.152 30951'
Apr 18 09:16:31.085: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.152 30951\nConnection to 192.168.1.152 30951 port [tcp/*] succeeded!\n"
Apr 18 09:16:31.085: INFO: stdout: "externalname-service-fk5s4"
Apr 18 09:16:31.085: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 09:16:31.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7322" for this suite. 04/18/23 09:16:31.11
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":183,"skipped":3550,"failed":0}
------------------------------
• [SLOW TEST] [8.814 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:16:22.3
    Apr 18 09:16:22.301: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 09:16:22.301
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:22.312
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:22.316
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-7322 04/18/23 09:16:22.32
    STEP: changing the ExternalName service to type=NodePort 04/18/23 09:16:22.323
    STEP: creating replication controller externalname-service in namespace services-7322 04/18/23 09:16:22.336
    I0418 09:16:22.343323      18 runners.go:193] Created replication controller with name: externalname-service, namespace: services-7322, replica count: 2
    I0418 09:16:25.395053      18 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 09:16:25.395: INFO: Creating new exec pod
    Apr 18 09:16:25.399: INFO: Waiting up to 5m0s for pod "execpod6gqmb" in namespace "services-7322" to be "running"
    Apr 18 09:16:25.402: INFO: Pod "execpod6gqmb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.831966ms
    Apr 18 09:16:27.406: INFO: Pod "execpod6gqmb": Phase="Running", Reason="", readiness=true. Elapsed: 2.006683754s
    Apr 18 09:16:27.406: INFO: Pod "execpod6gqmb" satisfied condition "running"
    Apr 18 09:16:28.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7322 exec execpod6gqmb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 18 09:16:28.517: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 18 09:16:28.517: INFO: stdout: "externalname-service-fk5s4"
    Apr 18 09:16:28.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7322 exec execpod6gqmb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.43.105 80'
    Apr 18 09:16:28.618: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.43.105 80\nConnection to 10.247.43.105 80 port [tcp/http] succeeded!\n"
    Apr 18 09:16:28.618: INFO: stdout: ""
    Apr 18 09:16:29.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7322 exec execpod6gqmb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.43.105 80'
    Apr 18 09:16:29.716: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.43.105 80\nConnection to 10.247.43.105 80 port [tcp/http] succeeded!\n"
    Apr 18 09:16:29.716: INFO: stdout: "externalname-service-fk5s4"
    Apr 18 09:16:29.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7322 exec execpod6gqmb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.84 30951'
    Apr 18 09:16:29.827: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.84 30951\nConnection to 192.168.1.84 30951 port [tcp/*] succeeded!\n"
    Apr 18 09:16:29.827: INFO: stdout: ""
    Apr 18 09:16:30.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7322 exec execpod6gqmb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.84 30951'
    Apr 18 09:16:30.985: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.84 30951\nConnection to 192.168.1.84 30951 port [tcp/*] succeeded!\n"
    Apr 18 09:16:30.985: INFO: stdout: "externalname-service-fk5s4"
    Apr 18 09:16:30.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7322 exec execpod6gqmb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.152 30951'
    Apr 18 09:16:31.085: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.152 30951\nConnection to 192.168.1.152 30951 port [tcp/*] succeeded!\n"
    Apr 18 09:16:31.085: INFO: stdout: "externalname-service-fk5s4"
    Apr 18 09:16:31.085: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 09:16:31.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7322" for this suite. 04/18/23 09:16:31.11
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:16:31.115
Apr 18 09:16:31.115: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename secrets 04/18/23 09:16:31.116
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:31.126
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:31.13
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-9988/secret-test-bcd498be-437a-4bb0-b43f-8cdc89bd75c7 04/18/23 09:16:31.134
STEP: Creating a pod to test consume secrets 04/18/23 09:16:31.137
Apr 18 09:16:31.147: INFO: Waiting up to 5m0s for pod "pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158" in namespace "secrets-9988" to be "Succeeded or Failed"
Apr 18 09:16:31.149: INFO: Pod "pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158": Phase="Pending", Reason="", readiness=false. Elapsed: 2.447582ms
Apr 18 09:16:33.154: INFO: Pod "pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006825599s
Apr 18 09:16:35.155: INFO: Pod "pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0077137s
STEP: Saw pod success 04/18/23 09:16:35.155
Apr 18 09:16:35.155: INFO: Pod "pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158" satisfied condition "Succeeded or Failed"
Apr 18 09:16:35.158: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158 container env-test: <nil>
STEP: delete the pod 04/18/23 09:16:35.164
Apr 18 09:16:35.175: INFO: Waiting for pod pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158 to disappear
Apr 18 09:16:35.177: INFO: Pod pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 18 09:16:35.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9988" for this suite. 04/18/23 09:16:35.182
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":184,"skipped":3589,"failed":0}
------------------------------
• [4.072 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:16:31.115
    Apr 18 09:16:31.115: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename secrets 04/18/23 09:16:31.116
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:31.126
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:31.13
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-9988/secret-test-bcd498be-437a-4bb0-b43f-8cdc89bd75c7 04/18/23 09:16:31.134
    STEP: Creating a pod to test consume secrets 04/18/23 09:16:31.137
    Apr 18 09:16:31.147: INFO: Waiting up to 5m0s for pod "pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158" in namespace "secrets-9988" to be "Succeeded or Failed"
    Apr 18 09:16:31.149: INFO: Pod "pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158": Phase="Pending", Reason="", readiness=false. Elapsed: 2.447582ms
    Apr 18 09:16:33.154: INFO: Pod "pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006825599s
    Apr 18 09:16:35.155: INFO: Pod "pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0077137s
    STEP: Saw pod success 04/18/23 09:16:35.155
    Apr 18 09:16:35.155: INFO: Pod "pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158" satisfied condition "Succeeded or Failed"
    Apr 18 09:16:35.158: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158 container env-test: <nil>
    STEP: delete the pod 04/18/23 09:16:35.164
    Apr 18 09:16:35.175: INFO: Waiting for pod pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158 to disappear
    Apr 18 09:16:35.177: INFO: Pod pod-configmaps-71ea8eab-1985-4b6b-8682-548fe5fe3158 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 09:16:35.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9988" for this suite. 04/18/23 09:16:35.182
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:16:35.187
Apr 18 09:16:35.187: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename namespaces 04/18/23 09:16:35.188
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:35.198
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:35.202
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 04/18/23 09:16:35.206
Apr 18 09:16:35.209: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 04/18/23 09:16:35.209
Apr 18 09:16:35.214: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 04/18/23 09:16:35.214
Apr 18 09:16:35.221: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:16:35.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7417" for this suite. 04/18/23 09:16:35.224
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":185,"skipped":3595,"failed":0}
------------------------------
• [0.040 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:16:35.187
    Apr 18 09:16:35.187: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename namespaces 04/18/23 09:16:35.188
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:35.198
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:35.202
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 04/18/23 09:16:35.206
    Apr 18 09:16:35.209: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 04/18/23 09:16:35.209
    Apr 18 09:16:35.214: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 04/18/23 09:16:35.214
    Apr 18 09:16:35.221: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:16:35.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-7417" for this suite. 04/18/23 09:16:35.224
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:16:35.228
Apr 18 09:16:35.228: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 09:16:35.229
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:35.238
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:35.241
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-489af45b-9a11-4fec-a618-1b9d460d01b8 04/18/23 09:16:35.245
STEP: Creating a pod to test consume secrets 04/18/23 09:16:35.249
Apr 18 09:16:35.255: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e" in namespace "projected-6560" to be "Succeeded or Failed"
Apr 18 09:16:35.258: INFO: Pod "pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.1817ms
Apr 18 09:16:37.262: INFO: Pod "pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007161834s
Apr 18 09:16:39.263: INFO: Pod "pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007711668s
STEP: Saw pod success 04/18/23 09:16:39.263
Apr 18 09:16:39.263: INFO: Pod "pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e" satisfied condition "Succeeded or Failed"
Apr 18 09:16:39.266: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e container projected-secret-volume-test: <nil>
STEP: delete the pod 04/18/23 09:16:39.271
Apr 18 09:16:39.280: INFO: Waiting for pod pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e to disappear
Apr 18 09:16:39.282: INFO: Pod pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 18 09:16:39.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6560" for this suite. 04/18/23 09:16:39.287
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":186,"skipped":3597,"failed":0}
------------------------------
• [4.064 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:16:35.228
    Apr 18 09:16:35.228: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 09:16:35.229
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:35.238
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:35.241
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-489af45b-9a11-4fec-a618-1b9d460d01b8 04/18/23 09:16:35.245
    STEP: Creating a pod to test consume secrets 04/18/23 09:16:35.249
    Apr 18 09:16:35.255: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e" in namespace "projected-6560" to be "Succeeded or Failed"
    Apr 18 09:16:35.258: INFO: Pod "pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.1817ms
    Apr 18 09:16:37.262: INFO: Pod "pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007161834s
    Apr 18 09:16:39.263: INFO: Pod "pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007711668s
    STEP: Saw pod success 04/18/23 09:16:39.263
    Apr 18 09:16:39.263: INFO: Pod "pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e" satisfied condition "Succeeded or Failed"
    Apr 18 09:16:39.266: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 09:16:39.271
    Apr 18 09:16:39.280: INFO: Waiting for pod pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e to disappear
    Apr 18 09:16:39.282: INFO: Pod pod-projected-secrets-b2a99166-3c1d-499f-ab06-6e063c84bc2e no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 18 09:16:39.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6560" for this suite. 04/18/23 09:16:39.287
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:16:39.292
Apr 18 09:16:39.292: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename resourcequota 04/18/23 09:16:39.293
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:39.302
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:39.306
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 04/18/23 09:16:39.309
STEP: Creating a ResourceQuota 04/18/23 09:16:44.312
STEP: Ensuring resource quota status is calculated 04/18/23 09:16:44.319
STEP: Creating a Service 04/18/23 09:16:46.323
STEP: Creating a NodePort Service 04/18/23 09:16:46.347
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 04/18/23 09:16:46.367
STEP: Ensuring resource quota status captures service creation 04/18/23 09:16:46.382
STEP: Deleting Services 04/18/23 09:16:48.386
STEP: Ensuring resource quota status released usage 04/18/23 09:16:48.411
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 09:16:50.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3276" for this suite. 04/18/23 09:16:50.421
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":187,"skipped":3599,"failed":0}
------------------------------
• [SLOW TEST] [11.134 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:16:39.292
    Apr 18 09:16:39.292: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename resourcequota 04/18/23 09:16:39.293
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:39.302
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:39.306
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 04/18/23 09:16:39.309
    STEP: Creating a ResourceQuota 04/18/23 09:16:44.312
    STEP: Ensuring resource quota status is calculated 04/18/23 09:16:44.319
    STEP: Creating a Service 04/18/23 09:16:46.323
    STEP: Creating a NodePort Service 04/18/23 09:16:46.347
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 04/18/23 09:16:46.367
    STEP: Ensuring resource quota status captures service creation 04/18/23 09:16:46.382
    STEP: Deleting Services 04/18/23 09:16:48.386
    STEP: Ensuring resource quota status released usage 04/18/23 09:16:48.411
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 09:16:50.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3276" for this suite. 04/18/23 09:16:50.421
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:16:50.427
Apr 18 09:16:50.427: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename replicaset 04/18/23 09:16:50.428
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:50.437
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:50.443
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 04/18/23 09:16:50.447
Apr 18 09:16:50.454: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 18 09:16:55.459: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/18/23 09:16:55.459
STEP: getting scale subresource 04/18/23 09:16:55.459
STEP: updating a scale subresource 04/18/23 09:16:55.462
STEP: verifying the replicaset Spec.Replicas was modified 04/18/23 09:16:55.466
STEP: Patch a scale subresource 04/18/23 09:16:55.471
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 18 09:16:55.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3042" for this suite. 04/18/23 09:16:55.505
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":188,"skipped":3615,"failed":0}
------------------------------
• [SLOW TEST] [5.099 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:16:50.427
    Apr 18 09:16:50.427: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename replicaset 04/18/23 09:16:50.428
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:50.437
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:50.443
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 04/18/23 09:16:50.447
    Apr 18 09:16:50.454: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 18 09:16:55.459: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/18/23 09:16:55.459
    STEP: getting scale subresource 04/18/23 09:16:55.459
    STEP: updating a scale subresource 04/18/23 09:16:55.462
    STEP: verifying the replicaset Spec.Replicas was modified 04/18/23 09:16:55.466
    STEP: Patch a scale subresource 04/18/23 09:16:55.471
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 18 09:16:55.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-3042" for this suite. 04/18/23 09:16:55.505
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:16:55.526
Apr 18 09:16:55.526: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename pods 04/18/23 09:16:55.527
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:55.578
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:55.606
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 04/18/23 09:16:55.611
Apr 18 09:16:55.617: INFO: Waiting up to 5m0s for pod "pod-4ss9r" in namespace "pods-7489" to be "running"
Apr 18 09:16:55.619: INFO: Pod "pod-4ss9r": Phase="Pending", Reason="", readiness=false. Elapsed: 2.559237ms
Apr 18 09:16:57.623: INFO: Pod "pod-4ss9r": Phase="Running", Reason="", readiness=true. Elapsed: 2.00611059s
Apr 18 09:16:57.623: INFO: Pod "pod-4ss9r" satisfied condition "running"
STEP: patching /status 04/18/23 09:16:57.623
Apr 18 09:16:57.630: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 09:16:57.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7489" for this suite. 04/18/23 09:16:57.634
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":189,"skipped":3619,"failed":0}
------------------------------
• [2.113 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:16:55.526
    Apr 18 09:16:55.526: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename pods 04/18/23 09:16:55.527
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:55.578
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:55.606
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 04/18/23 09:16:55.611
    Apr 18 09:16:55.617: INFO: Waiting up to 5m0s for pod "pod-4ss9r" in namespace "pods-7489" to be "running"
    Apr 18 09:16:55.619: INFO: Pod "pod-4ss9r": Phase="Pending", Reason="", readiness=false. Elapsed: 2.559237ms
    Apr 18 09:16:57.623: INFO: Pod "pod-4ss9r": Phase="Running", Reason="", readiness=true. Elapsed: 2.00611059s
    Apr 18 09:16:57.623: INFO: Pod "pod-4ss9r" satisfied condition "running"
    STEP: patching /status 04/18/23 09:16:57.623
    Apr 18 09:16:57.630: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 09:16:57.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7489" for this suite. 04/18/23 09:16:57.634
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:16:57.64
Apr 18 09:16:57.640: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename configmap 04/18/23 09:16:57.641
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:57.651
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:57.655
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-4a06490e-667a-4c99-a7eb-fc00bccd3d3e 04/18/23 09:16:57.662
STEP: Creating configMap with name cm-test-opt-upd-a216106d-a306-44c4-98c2-ddd55bce51d3 04/18/23 09:16:57.665
STEP: Creating the pod 04/18/23 09:16:57.669
Apr 18 09:16:57.676: INFO: Waiting up to 5m0s for pod "pod-configmaps-7c97d087-4010-465a-b115-43ddbc6bcb85" in namespace "configmap-2964" to be "running and ready"
Apr 18 09:16:57.678: INFO: Pod "pod-configmaps-7c97d087-4010-465a-b115-43ddbc6bcb85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.690122ms
Apr 18 09:16:57.678: INFO: The phase of Pod pod-configmaps-7c97d087-4010-465a-b115-43ddbc6bcb85 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:16:59.692: INFO: Pod "pod-configmaps-7c97d087-4010-465a-b115-43ddbc6bcb85": Phase="Running", Reason="", readiness=true. Elapsed: 2.016421924s
Apr 18 09:16:59.692: INFO: The phase of Pod pod-configmaps-7c97d087-4010-465a-b115-43ddbc6bcb85 is Running (Ready = true)
Apr 18 09:16:59.692: INFO: Pod "pod-configmaps-7c97d087-4010-465a-b115-43ddbc6bcb85" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-4a06490e-667a-4c99-a7eb-fc00bccd3d3e 04/18/23 09:16:59.727
STEP: Updating configmap cm-test-opt-upd-a216106d-a306-44c4-98c2-ddd55bce51d3 04/18/23 09:16:59.733
STEP: Creating configMap with name cm-test-opt-create-28e3a61a-3905-4621-b14c-7c90a027b4ae 04/18/23 09:16:59.737
STEP: waiting to observe update in volume 04/18/23 09:16:59.742
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 09:17:01.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2964" for this suite. 04/18/23 09:17:01.767
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":190,"skipped":3632,"failed":0}
------------------------------
• [4.132 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:16:57.64
    Apr 18 09:16:57.640: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename configmap 04/18/23 09:16:57.641
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:16:57.651
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:16:57.655
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-4a06490e-667a-4c99-a7eb-fc00bccd3d3e 04/18/23 09:16:57.662
    STEP: Creating configMap with name cm-test-opt-upd-a216106d-a306-44c4-98c2-ddd55bce51d3 04/18/23 09:16:57.665
    STEP: Creating the pod 04/18/23 09:16:57.669
    Apr 18 09:16:57.676: INFO: Waiting up to 5m0s for pod "pod-configmaps-7c97d087-4010-465a-b115-43ddbc6bcb85" in namespace "configmap-2964" to be "running and ready"
    Apr 18 09:16:57.678: INFO: Pod "pod-configmaps-7c97d087-4010-465a-b115-43ddbc6bcb85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.690122ms
    Apr 18 09:16:57.678: INFO: The phase of Pod pod-configmaps-7c97d087-4010-465a-b115-43ddbc6bcb85 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:16:59.692: INFO: Pod "pod-configmaps-7c97d087-4010-465a-b115-43ddbc6bcb85": Phase="Running", Reason="", readiness=true. Elapsed: 2.016421924s
    Apr 18 09:16:59.692: INFO: The phase of Pod pod-configmaps-7c97d087-4010-465a-b115-43ddbc6bcb85 is Running (Ready = true)
    Apr 18 09:16:59.692: INFO: Pod "pod-configmaps-7c97d087-4010-465a-b115-43ddbc6bcb85" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-4a06490e-667a-4c99-a7eb-fc00bccd3d3e 04/18/23 09:16:59.727
    STEP: Updating configmap cm-test-opt-upd-a216106d-a306-44c4-98c2-ddd55bce51d3 04/18/23 09:16:59.733
    STEP: Creating configMap with name cm-test-opt-create-28e3a61a-3905-4621-b14c-7c90a027b4ae 04/18/23 09:16:59.737
    STEP: waiting to observe update in volume 04/18/23 09:16:59.742
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 09:17:01.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2964" for this suite. 04/18/23 09:17:01.767
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:01.772
Apr 18 09:17:01.772: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename runtimeclass 04/18/23 09:17:01.773
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:01.784
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:01.788
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-1794-delete-me 04/18/23 09:17:01.796
STEP: Waiting for the RuntimeClass to disappear 04/18/23 09:17:01.8
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 18 09:17:01.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1794" for this suite. 04/18/23 09:17:01.811
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":191,"skipped":3640,"failed":0}
------------------------------
• [0.043 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:01.772
    Apr 18 09:17:01.772: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename runtimeclass 04/18/23 09:17:01.773
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:01.784
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:01.788
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-1794-delete-me 04/18/23 09:17:01.796
    STEP: Waiting for the RuntimeClass to disappear 04/18/23 09:17:01.8
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 18 09:17:01.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1794" for this suite. 04/18/23 09:17:01.811
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:01.816
Apr 18 09:17:01.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename daemonsets 04/18/23 09:17:01.816
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:01.827
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:01.832
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Apr 18 09:17:01.853: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 09:17:01.858
Apr 18 09:17:01.863: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:17:01.863: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
Apr 18 09:17:02.872: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:17:02.872: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
Apr 18 09:17:03.871: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 09:17:03.871: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 04/18/23 09:17:03.895
STEP: Check that daemon pods images are updated. 04/18/23 09:17:03.942
Apr 18 09:17:03.958: INFO: Wrong image for pod: daemon-set-7dpzz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 09:17:03.958: INFO: Wrong image for pod: daemon-set-x5j6r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 09:17:04.979: INFO: Wrong image for pod: daemon-set-7dpzz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 09:17:04.979: INFO: Wrong image for pod: daemon-set-x5j6r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 09:17:05.979: INFO: Wrong image for pod: daemon-set-7dpzz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 09:17:05.979: INFO: Wrong image for pod: daemon-set-x5j6r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 09:17:06.978: INFO: Wrong image for pod: daemon-set-7dpzz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 09:17:06.978: INFO: Pod daemon-set-wldb6 is not available
Apr 18 09:17:06.978: INFO: Wrong image for pod: daemon-set-x5j6r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 09:17:07.979: INFO: Wrong image for pod: daemon-set-7dpzz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 09:17:07.979: INFO: Pod daemon-set-gx9r4 is not available
Apr 18 09:17:09.978: INFO: Pod daemon-set-7hl5t is not available
STEP: Check that daemon pods are still running on every node of the cluster. 04/18/23 09:17:09.983
Apr 18 09:17:09.989: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 09:17:09.989: INFO: Node 192.168.1.84 is running 0 daemon pod, expected 1
Apr 18 09:17:11.027: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 09:17:11.027: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/18/23 09:17:11.066
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4244, will wait for the garbage collector to delete the pods 04/18/23 09:17:11.066
Apr 18 09:17:11.124: INFO: Deleting DaemonSet.extensions daemon-set took: 4.865858ms
Apr 18 09:17:11.225: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.768047ms
Apr 18 09:17:13.129: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:17:13.129: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 18 09:17:13.131: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4190246"},"items":null}

Apr 18 09:17:13.134: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4190246"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:17:13.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4244" for this suite. 04/18/23 09:17:13.149
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":192,"skipped":3649,"failed":0}
------------------------------
• [SLOW TEST] [11.342 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:01.816
    Apr 18 09:17:01.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename daemonsets 04/18/23 09:17:01.816
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:01.827
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:01.832
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Apr 18 09:17:01.853: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 09:17:01.858
    Apr 18 09:17:01.863: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:17:01.863: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
    Apr 18 09:17:02.872: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:17:02.872: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
    Apr 18 09:17:03.871: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 09:17:03.871: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 04/18/23 09:17:03.895
    STEP: Check that daemon pods images are updated. 04/18/23 09:17:03.942
    Apr 18 09:17:03.958: INFO: Wrong image for pod: daemon-set-7dpzz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 09:17:03.958: INFO: Wrong image for pod: daemon-set-x5j6r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 09:17:04.979: INFO: Wrong image for pod: daemon-set-7dpzz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 09:17:04.979: INFO: Wrong image for pod: daemon-set-x5j6r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 09:17:05.979: INFO: Wrong image for pod: daemon-set-7dpzz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 09:17:05.979: INFO: Wrong image for pod: daemon-set-x5j6r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 09:17:06.978: INFO: Wrong image for pod: daemon-set-7dpzz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 09:17:06.978: INFO: Pod daemon-set-wldb6 is not available
    Apr 18 09:17:06.978: INFO: Wrong image for pod: daemon-set-x5j6r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 09:17:07.979: INFO: Wrong image for pod: daemon-set-7dpzz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 09:17:07.979: INFO: Pod daemon-set-gx9r4 is not available
    Apr 18 09:17:09.978: INFO: Pod daemon-set-7hl5t is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 04/18/23 09:17:09.983
    Apr 18 09:17:09.989: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 09:17:09.989: INFO: Node 192.168.1.84 is running 0 daemon pod, expected 1
    Apr 18 09:17:11.027: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 09:17:11.027: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/18/23 09:17:11.066
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4244, will wait for the garbage collector to delete the pods 04/18/23 09:17:11.066
    Apr 18 09:17:11.124: INFO: Deleting DaemonSet.extensions daemon-set took: 4.865858ms
    Apr 18 09:17:11.225: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.768047ms
    Apr 18 09:17:13.129: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:17:13.129: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 18 09:17:13.131: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4190246"},"items":null}

    Apr 18 09:17:13.134: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4190246"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:17:13.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4244" for this suite. 04/18/23 09:17:13.149
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:13.162
Apr 18 09:17:13.162: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename svcaccounts 04/18/23 09:17:13.163
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:13.173
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:13.178
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 04/18/23 09:17:13.182
STEP: watching for the ServiceAccount to be added 04/18/23 09:17:13.189
STEP: patching the ServiceAccount 04/18/23 09:17:13.191
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 04/18/23 09:17:13.195
STEP: deleting the ServiceAccount 04/18/23 09:17:13.198
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 18 09:17:13.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3875" for this suite. 04/18/23 09:17:13.211
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":193,"skipped":3674,"failed":0}
------------------------------
• [0.055 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:13.162
    Apr 18 09:17:13.162: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename svcaccounts 04/18/23 09:17:13.163
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:13.173
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:13.178
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 04/18/23 09:17:13.182
    STEP: watching for the ServiceAccount to be added 04/18/23 09:17:13.189
    STEP: patching the ServiceAccount 04/18/23 09:17:13.191
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 04/18/23 09:17:13.195
    STEP: deleting the ServiceAccount 04/18/23 09:17:13.198
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 18 09:17:13.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-3875" for this suite. 04/18/23 09:17:13.211
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:13.226
Apr 18 09:17:13.226: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 09:17:13.226
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:13.236
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:13.24
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 09:17:13.254
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:17:13.673
STEP: Deploying the webhook pod 04/18/23 09:17:13.679
STEP: Wait for the deployment to be ready 04/18/23 09:17:13.691
Apr 18 09:17:13.696: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 04/18/23 09:17:15.705
STEP: Verifying the service has paired with the endpoint 04/18/23 09:17:15.714
Apr 18 09:17:16.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Apr 18 09:17:16.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9360-crds.webhook.example.com via the AdmissionRegistration API 04/18/23 09:17:17.228
STEP: Creating a custom resource that should be mutated by the webhook 04/18/23 09:17:17.244
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:17:19.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7576" for this suite. 04/18/23 09:17:19.813
STEP: Destroying namespace "webhook-7576-markers" for this suite. 04/18/23 09:17:19.82
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":194,"skipped":3755,"failed":0}
------------------------------
• [SLOW TEST] [6.639 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:13.226
    Apr 18 09:17:13.226: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 09:17:13.226
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:13.236
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:13.24
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 09:17:13.254
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:17:13.673
    STEP: Deploying the webhook pod 04/18/23 09:17:13.679
    STEP: Wait for the deployment to be ready 04/18/23 09:17:13.691
    Apr 18 09:17:13.696: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 04/18/23 09:17:15.705
    STEP: Verifying the service has paired with the endpoint 04/18/23 09:17:15.714
    Apr 18 09:17:16.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Apr 18 09:17:16.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9360-crds.webhook.example.com via the AdmissionRegistration API 04/18/23 09:17:17.228
    STEP: Creating a custom resource that should be mutated by the webhook 04/18/23 09:17:17.244
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:17:19.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7576" for this suite. 04/18/23 09:17:19.813
    STEP: Destroying namespace "webhook-7576-markers" for this suite. 04/18/23 09:17:19.82
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:19.865
Apr 18 09:17:19.865: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename var-expansion 04/18/23 09:17:19.865
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:19.879
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:19.883
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 04/18/23 09:17:19.887
Apr 18 09:17:19.898: INFO: Waiting up to 5m0s for pod "var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994" in namespace "var-expansion-4356" to be "Succeeded or Failed"
Apr 18 09:17:19.900: INFO: Pod "var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994": Phase="Pending", Reason="", readiness=false. Elapsed: 2.778688ms
Apr 18 09:17:21.904: INFO: Pod "var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006176476s
Apr 18 09:17:23.906: INFO: Pod "var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008520616s
STEP: Saw pod success 04/18/23 09:17:23.906
Apr 18 09:17:23.906: INFO: Pod "var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994" satisfied condition "Succeeded or Failed"
Apr 18 09:17:23.909: INFO: Trying to get logs from node 192.168.1.152 pod var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994 container dapi-container: <nil>
STEP: delete the pod 04/18/23 09:17:23.914
Apr 18 09:17:23.923: INFO: Waiting for pod var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994 to disappear
Apr 18 09:17:23.926: INFO: Pod var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 09:17:23.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4356" for this suite. 04/18/23 09:17:23.931
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":195,"skipped":3764,"failed":0}
------------------------------
• [4.070 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:19.865
    Apr 18 09:17:19.865: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename var-expansion 04/18/23 09:17:19.865
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:19.879
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:19.883
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 04/18/23 09:17:19.887
    Apr 18 09:17:19.898: INFO: Waiting up to 5m0s for pod "var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994" in namespace "var-expansion-4356" to be "Succeeded or Failed"
    Apr 18 09:17:19.900: INFO: Pod "var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994": Phase="Pending", Reason="", readiness=false. Elapsed: 2.778688ms
    Apr 18 09:17:21.904: INFO: Pod "var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006176476s
    Apr 18 09:17:23.906: INFO: Pod "var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008520616s
    STEP: Saw pod success 04/18/23 09:17:23.906
    Apr 18 09:17:23.906: INFO: Pod "var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994" satisfied condition "Succeeded or Failed"
    Apr 18 09:17:23.909: INFO: Trying to get logs from node 192.168.1.152 pod var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994 container dapi-container: <nil>
    STEP: delete the pod 04/18/23 09:17:23.914
    Apr 18 09:17:23.923: INFO: Waiting for pod var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994 to disappear
    Apr 18 09:17:23.926: INFO: Pod var-expansion-7a4f3bdb-caee-4234-8eb8-f2e31ea17994 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 09:17:23.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4356" for this suite. 04/18/23 09:17:23.931
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:23.935
Apr 18 09:17:23.935: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 09:17:23.936
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:23.947
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:23.952
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 09:17:23.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5544" for this suite. 04/18/23 09:17:23.962
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":196,"skipped":3764,"failed":0}
------------------------------
• [0.031 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:23.935
    Apr 18 09:17:23.935: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 09:17:23.936
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:23.947
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:23.952
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 09:17:23.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5544" for this suite. 04/18/23 09:17:23.962
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:23.969
Apr 18 09:17:23.969: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 09:17:23.97
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:23.98
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:23.986
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 04/18/23 09:17:23.991
Apr 18 09:17:23.992: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-834 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 04/18/23 09:17:24.026
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 09:17:24.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-834" for this suite. 04/18/23 09:17:24.038
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":197,"skipped":3818,"failed":0}
------------------------------
• [0.080 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:23.969
    Apr 18 09:17:23.969: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 09:17:23.97
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:23.98
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:23.986
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 04/18/23 09:17:23.991
    Apr 18 09:17:23.992: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-834 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 04/18/23 09:17:24.026
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 09:17:24.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-834" for this suite. 04/18/23 09:17:24.038
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:24.05
Apr 18 09:17:24.051: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename ingressclass 04/18/23 09:17:24.052
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:24.064
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:24.068
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 04/18/23 09:17:24.072
STEP: getting /apis/networking.k8s.io 04/18/23 09:17:24.075
STEP: getting /apis/networking.k8s.iov1 04/18/23 09:17:24.077
STEP: creating 04/18/23 09:17:24.079
STEP: getting 04/18/23 09:17:24.09
STEP: listing 04/18/23 09:17:24.093
STEP: watching 04/18/23 09:17:24.095
Apr 18 09:17:24.096: INFO: starting watch
STEP: patching 04/18/23 09:17:24.097
STEP: updating 04/18/23 09:17:24.103
Apr 18 09:17:24.108: INFO: waiting for watch events with expected annotations
Apr 18 09:17:24.108: INFO: saw patched and updated annotations
STEP: deleting 04/18/23 09:17:24.108
STEP: deleting a collection 04/18/23 09:17:24.117
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Apr 18 09:17:24.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-4105" for this suite. 04/18/23 09:17:24.135
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":198,"skipped":3829,"failed":0}
------------------------------
• [0.093 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:24.05
    Apr 18 09:17:24.051: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename ingressclass 04/18/23 09:17:24.052
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:24.064
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:24.068
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 04/18/23 09:17:24.072
    STEP: getting /apis/networking.k8s.io 04/18/23 09:17:24.075
    STEP: getting /apis/networking.k8s.iov1 04/18/23 09:17:24.077
    STEP: creating 04/18/23 09:17:24.079
    STEP: getting 04/18/23 09:17:24.09
    STEP: listing 04/18/23 09:17:24.093
    STEP: watching 04/18/23 09:17:24.095
    Apr 18 09:17:24.096: INFO: starting watch
    STEP: patching 04/18/23 09:17:24.097
    STEP: updating 04/18/23 09:17:24.103
    Apr 18 09:17:24.108: INFO: waiting for watch events with expected annotations
    Apr 18 09:17:24.108: INFO: saw patched and updated annotations
    STEP: deleting 04/18/23 09:17:24.108
    STEP: deleting a collection 04/18/23 09:17:24.117
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Apr 18 09:17:24.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-4105" for this suite. 04/18/23 09:17:24.135
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:24.147
Apr 18 09:17:24.147: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 09:17:24.148
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:24.172
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:24.176
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/18/23 09:17:24.183
Apr 18 09:17:24.189: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8735" to be "running and ready"
Apr 18 09:17:24.192: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.993829ms
Apr 18 09:17:24.192: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:17:26.196: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.006516222s
Apr 18 09:17:26.196: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 18 09:17:26.196: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 04/18/23 09:17:26.199
Apr 18 09:17:26.205: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-8735" to be "running and ready"
Apr 18 09:17:26.208: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.763793ms
Apr 18 09:17:26.208: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:17:28.212: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.007222759s
Apr 18 09:17:28.212: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Apr 18 09:17:28.212: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 04/18/23 09:17:28.215
STEP: delete the pod with lifecycle hook 04/18/23 09:17:28.22
Apr 18 09:17:28.226: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 18 09:17:28.229: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 18 09:17:30.229: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 18 09:17:30.232: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 18 09:17:30.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8735" for this suite. 04/18/23 09:17:30.237
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":199,"skipped":3843,"failed":0}
------------------------------
• [SLOW TEST] [6.096 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:24.147
    Apr 18 09:17:24.147: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 09:17:24.148
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:24.172
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:24.176
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/18/23 09:17:24.183
    Apr 18 09:17:24.189: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8735" to be "running and ready"
    Apr 18 09:17:24.192: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.993829ms
    Apr 18 09:17:24.192: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:17:26.196: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.006516222s
    Apr 18 09:17:26.196: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 18 09:17:26.196: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 04/18/23 09:17:26.199
    Apr 18 09:17:26.205: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-8735" to be "running and ready"
    Apr 18 09:17:26.208: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.763793ms
    Apr 18 09:17:26.208: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:17:28.212: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.007222759s
    Apr 18 09:17:28.212: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Apr 18 09:17:28.212: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 04/18/23 09:17:28.215
    STEP: delete the pod with lifecycle hook 04/18/23 09:17:28.22
    Apr 18 09:17:28.226: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Apr 18 09:17:28.229: INFO: Pod pod-with-poststart-exec-hook still exists
    Apr 18 09:17:30.229: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Apr 18 09:17:30.232: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 18 09:17:30.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-8735" for this suite. 04/18/23 09:17:30.237
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:30.243
Apr 18 09:17:30.243: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename dns 04/18/23 09:17:30.244
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:30.253
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:30.257
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 04/18/23 09:17:30.261
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 04/18/23 09:17:30.261
STEP: creating a pod to probe DNS 04/18/23 09:17:30.261
STEP: submitting the pod to kubernetes 04/18/23 09:17:30.261
Apr 18 09:17:30.268: INFO: Waiting up to 15m0s for pod "dns-test-8e232fca-35a4-4398-8e11-0dc9953a38b9" in namespace "dns-607" to be "running"
Apr 18 09:17:30.272: INFO: Pod "dns-test-8e232fca-35a4-4398-8e11-0dc9953a38b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.334989ms
Apr 18 09:17:32.275: INFO: Pod "dns-test-8e232fca-35a4-4398-8e11-0dc9953a38b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.007082844s
Apr 18 09:17:32.275: INFO: Pod "dns-test-8e232fca-35a4-4398-8e11-0dc9953a38b9" satisfied condition "running"
STEP: retrieving the pod 04/18/23 09:17:32.275
STEP: looking for the results for each expected name from probers 04/18/23 09:17:32.278
Apr 18 09:17:32.295: INFO: DNS probes using dns-607/dns-test-8e232fca-35a4-4398-8e11-0dc9953a38b9 succeeded

STEP: deleting the pod 04/18/23 09:17:32.295
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 09:17:32.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-607" for this suite. 04/18/23 09:17:32.309
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":200,"skipped":3843,"failed":0}
------------------------------
• [2.070 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:30.243
    Apr 18 09:17:30.243: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename dns 04/18/23 09:17:30.244
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:30.253
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:30.257
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     04/18/23 09:17:30.261
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     04/18/23 09:17:30.261
    STEP: creating a pod to probe DNS 04/18/23 09:17:30.261
    STEP: submitting the pod to kubernetes 04/18/23 09:17:30.261
    Apr 18 09:17:30.268: INFO: Waiting up to 15m0s for pod "dns-test-8e232fca-35a4-4398-8e11-0dc9953a38b9" in namespace "dns-607" to be "running"
    Apr 18 09:17:30.272: INFO: Pod "dns-test-8e232fca-35a4-4398-8e11-0dc9953a38b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.334989ms
    Apr 18 09:17:32.275: INFO: Pod "dns-test-8e232fca-35a4-4398-8e11-0dc9953a38b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.007082844s
    Apr 18 09:17:32.275: INFO: Pod "dns-test-8e232fca-35a4-4398-8e11-0dc9953a38b9" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 09:17:32.275
    STEP: looking for the results for each expected name from probers 04/18/23 09:17:32.278
    Apr 18 09:17:32.295: INFO: DNS probes using dns-607/dns-test-8e232fca-35a4-4398-8e11-0dc9953a38b9 succeeded

    STEP: deleting the pod 04/18/23 09:17:32.295
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 09:17:32.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-607" for this suite. 04/18/23 09:17:32.309
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:32.314
Apr 18 09:17:32.314: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename runtimeclass 04/18/23 09:17:32.314
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:32.329
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:32.333
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Apr 18 09:17:32.350: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-8589 to be scheduled
Apr 18 09:17:32.353: INFO: 1 pods are not scheduled: [runtimeclass-8589/test-runtimeclass-runtimeclass-8589-preconfigured-handler-cnjzw(e3b9a4af-421a-43ef-9d55-ddba7654e45b)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 18 09:17:34.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-8589" for this suite. 04/18/23 09:17:34.367
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":201,"skipped":3852,"failed":0}
------------------------------
• [2.061 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:32.314
    Apr 18 09:17:32.314: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename runtimeclass 04/18/23 09:17:32.314
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:32.329
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:32.333
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Apr 18 09:17:32.350: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-8589 to be scheduled
    Apr 18 09:17:32.353: INFO: 1 pods are not scheduled: [runtimeclass-8589/test-runtimeclass-runtimeclass-8589-preconfigured-handler-cnjzw(e3b9a4af-421a-43ef-9d55-ddba7654e45b)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 18 09:17:34.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-8589" for this suite. 04/18/23 09:17:34.367
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:34.375
Apr 18 09:17:34.375: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename namespaces 04/18/23 09:17:34.376
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:34.385
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:34.389
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 04/18/23 09:17:34.393
STEP: patching the Namespace 04/18/23 09:17:34.424
STEP: get the Namespace and ensuring it has the label 04/18/23 09:17:34.443
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:17:34.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8412" for this suite. 04/18/23 09:17:34.485
STEP: Destroying namespace "nspatchtest-66d54fa6-7992-4813-a1b3-f55819c96641-7952" for this suite. 04/18/23 09:17:34.497
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":202,"skipped":3870,"failed":0}
------------------------------
• [0.126 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:34.375
    Apr 18 09:17:34.375: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename namespaces 04/18/23 09:17:34.376
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:34.385
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:34.389
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 04/18/23 09:17:34.393
    STEP: patching the Namespace 04/18/23 09:17:34.424
    STEP: get the Namespace and ensuring it has the label 04/18/23 09:17:34.443
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:17:34.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-8412" for this suite. 04/18/23 09:17:34.485
    STEP: Destroying namespace "nspatchtest-66d54fa6-7992-4813-a1b3-f55819c96641-7952" for this suite. 04/18/23 09:17:34.497
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:34.502
Apr 18 09:17:34.502: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 09:17:34.504
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:34.514
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:34.518
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 04/18/23 09:17:34.522
Apr 18 09:17:34.528: INFO: Waiting up to 5m0s for pod "downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d" in namespace "downward-api-4048" to be "Succeeded or Failed"
Apr 18 09:17:34.531: INFO: Pod "downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.761668ms
Apr 18 09:17:36.534: INFO: Pod "downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006066237s
Apr 18 09:17:38.535: INFO: Pod "downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006631852s
STEP: Saw pod success 04/18/23 09:17:38.535
Apr 18 09:17:38.535: INFO: Pod "downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d" satisfied condition "Succeeded or Failed"
Apr 18 09:17:38.538: INFO: Trying to get logs from node 192.168.1.152 pod downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d container dapi-container: <nil>
STEP: delete the pod 04/18/23 09:17:38.543
Apr 18 09:17:38.558: INFO: Waiting for pod downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d to disappear
Apr 18 09:17:38.561: INFO: Pod downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 18 09:17:38.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4048" for this suite. 04/18/23 09:17:38.565
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":203,"skipped":3873,"failed":0}
------------------------------
• [4.067 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:34.502
    Apr 18 09:17:34.502: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 09:17:34.504
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:34.514
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:34.518
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 04/18/23 09:17:34.522
    Apr 18 09:17:34.528: INFO: Waiting up to 5m0s for pod "downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d" in namespace "downward-api-4048" to be "Succeeded or Failed"
    Apr 18 09:17:34.531: INFO: Pod "downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.761668ms
    Apr 18 09:17:36.534: INFO: Pod "downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006066237s
    Apr 18 09:17:38.535: INFO: Pod "downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006631852s
    STEP: Saw pod success 04/18/23 09:17:38.535
    Apr 18 09:17:38.535: INFO: Pod "downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d" satisfied condition "Succeeded or Failed"
    Apr 18 09:17:38.538: INFO: Trying to get logs from node 192.168.1.152 pod downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d container dapi-container: <nil>
    STEP: delete the pod 04/18/23 09:17:38.543
    Apr 18 09:17:38.558: INFO: Waiting for pod downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d to disappear
    Apr 18 09:17:38.561: INFO: Pod downward-api-e020527f-d72d-476a-9b52-d0ef6fa14e8d no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 18 09:17:38.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4048" for this suite. 04/18/23 09:17:38.565
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:38.57
Apr 18 09:17:38.570: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-runtime 04/18/23 09:17:38.571
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:38.58
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:38.584
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 04/18/23 09:17:38.59
STEP: wait for the container to reach Succeeded 04/18/23 09:17:38.595
STEP: get the container status 04/18/23 09:17:42.612
STEP: the container should be terminated 04/18/23 09:17:42.615
STEP: the termination message should be set 04/18/23 09:17:42.615
Apr 18 09:17:42.615: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 04/18/23 09:17:42.615
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 18 09:17:42.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9076" for this suite. 04/18/23 09:17:42.633
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":204,"skipped":3884,"failed":0}
------------------------------
• [4.067 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:38.57
    Apr 18 09:17:38.570: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-runtime 04/18/23 09:17:38.571
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:38.58
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:38.584
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 04/18/23 09:17:38.59
    STEP: wait for the container to reach Succeeded 04/18/23 09:17:38.595
    STEP: get the container status 04/18/23 09:17:42.612
    STEP: the container should be terminated 04/18/23 09:17:42.615
    STEP: the termination message should be set 04/18/23 09:17:42.615
    Apr 18 09:17:42.615: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 04/18/23 09:17:42.615
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 18 09:17:42.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-9076" for this suite. 04/18/23 09:17:42.633
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:42.638
Apr 18 09:17:42.638: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 09:17:42.639
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:42.651
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:42.655
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-9698 04/18/23 09:17:42.658
STEP: creating service affinity-clusterip-transition in namespace services-9698 04/18/23 09:17:42.658
STEP: creating replication controller affinity-clusterip-transition in namespace services-9698 04/18/23 09:17:42.668
I0418 09:17:42.684622      18 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-9698, replica count: 3
I0418 09:17:45.736102      18 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 09:17:45.742: INFO: Creating new exec pod
Apr 18 09:17:45.748: INFO: Waiting up to 5m0s for pod "execpod-affinity68thn" in namespace "services-9698" to be "running"
Apr 18 09:17:45.750: INFO: Pod "execpod-affinity68thn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.627955ms
Apr 18 09:17:47.754: INFO: Pod "execpod-affinity68thn": Phase="Running", Reason="", readiness=true. Elapsed: 2.006131021s
Apr 18 09:17:47.754: INFO: Pod "execpod-affinity68thn" satisfied condition "running"
Apr 18 09:17:48.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-9698 exec execpod-affinity68thn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Apr 18 09:17:48.858: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Apr 18 09:17:48.858: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:17:48.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-9698 exec execpod-affinity68thn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.152.145 80'
Apr 18 09:17:48.959: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.152.145 80\nConnection to 10.247.152.145 80 port [tcp/http] succeeded!\n"
Apr 18 09:17:48.959: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:17:48.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-9698 exec execpod-affinity68thn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.247.152.145:80/ ; done'
Apr 18 09:17:49.111: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n"
Apr 18 09:17:49.111: INFO: stdout: "\naffinity-clusterip-transition-cj2bg\naffinity-clusterip-transition-cj2bg\naffinity-clusterip-transition-cnm5x\naffinity-clusterip-transition-cnm5x\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-cj2bg\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-cj2bg\naffinity-clusterip-transition-cnm5x\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-cj2bg\naffinity-clusterip-transition-cnm5x\naffinity-clusterip-transition-cnm5x\naffinity-clusterip-transition-cj2bg\naffinity-clusterip-transition-cnm5x\naffinity-clusterip-transition-bw6cw"
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cj2bg
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cj2bg
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cnm5x
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cnm5x
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cj2bg
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cj2bg
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cnm5x
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cj2bg
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cnm5x
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cnm5x
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cj2bg
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cnm5x
Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-9698 exec execpod-affinity68thn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.247.152.145:80/ ; done'
Apr 18 09:17:49.262: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n"
Apr 18 09:17:49.262: INFO: stdout: "\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw"
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
Apr 18 09:17:49.262: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-9698, will wait for the garbage collector to delete the pods 04/18/23 09:17:49.274
Apr 18 09:17:49.332: INFO: Deleting ReplicationController affinity-clusterip-transition took: 4.572872ms
Apr 18 09:17:49.432: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.385219ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 09:17:51.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9698" for this suite. 04/18/23 09:17:51.46
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":205,"skipped":3902,"failed":0}
------------------------------
• [SLOW TEST] [8.827 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:42.638
    Apr 18 09:17:42.638: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 09:17:42.639
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:42.651
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:42.655
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-9698 04/18/23 09:17:42.658
    STEP: creating service affinity-clusterip-transition in namespace services-9698 04/18/23 09:17:42.658
    STEP: creating replication controller affinity-clusterip-transition in namespace services-9698 04/18/23 09:17:42.668
    I0418 09:17:42.684622      18 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-9698, replica count: 3
    I0418 09:17:45.736102      18 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 09:17:45.742: INFO: Creating new exec pod
    Apr 18 09:17:45.748: INFO: Waiting up to 5m0s for pod "execpod-affinity68thn" in namespace "services-9698" to be "running"
    Apr 18 09:17:45.750: INFO: Pod "execpod-affinity68thn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.627955ms
    Apr 18 09:17:47.754: INFO: Pod "execpod-affinity68thn": Phase="Running", Reason="", readiness=true. Elapsed: 2.006131021s
    Apr 18 09:17:47.754: INFO: Pod "execpod-affinity68thn" satisfied condition "running"
    Apr 18 09:17:48.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-9698 exec execpod-affinity68thn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Apr 18 09:17:48.858: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Apr 18 09:17:48.858: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:17:48.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-9698 exec execpod-affinity68thn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.152.145 80'
    Apr 18 09:17:48.959: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.152.145 80\nConnection to 10.247.152.145 80 port [tcp/http] succeeded!\n"
    Apr 18 09:17:48.959: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:17:48.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-9698 exec execpod-affinity68thn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.247.152.145:80/ ; done'
    Apr 18 09:17:49.111: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n"
    Apr 18 09:17:49.111: INFO: stdout: "\naffinity-clusterip-transition-cj2bg\naffinity-clusterip-transition-cj2bg\naffinity-clusterip-transition-cnm5x\naffinity-clusterip-transition-cnm5x\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-cj2bg\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-cj2bg\naffinity-clusterip-transition-cnm5x\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-cj2bg\naffinity-clusterip-transition-cnm5x\naffinity-clusterip-transition-cnm5x\naffinity-clusterip-transition-cj2bg\naffinity-clusterip-transition-cnm5x\naffinity-clusterip-transition-bw6cw"
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cj2bg
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cj2bg
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cnm5x
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cnm5x
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cj2bg
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cj2bg
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cnm5x
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cj2bg
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cnm5x
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cnm5x
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cj2bg
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-cnm5x
    Apr 18 09:17:49.111: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-9698 exec execpod-affinity68thn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.247.152.145:80/ ; done'
    Apr 18 09:17:49.262: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.152.145:80/\n"
    Apr 18 09:17:49.262: INFO: stdout: "\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw\naffinity-clusterip-transition-bw6cw"
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Received response from host: affinity-clusterip-transition-bw6cw
    Apr 18 09:17:49.262: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-9698, will wait for the garbage collector to delete the pods 04/18/23 09:17:49.274
    Apr 18 09:17:49.332: INFO: Deleting ReplicationController affinity-clusterip-transition took: 4.572872ms
    Apr 18 09:17:49.432: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.385219ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 09:17:51.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9698" for this suite. 04/18/23 09:17:51.46
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:51.466
Apr 18 09:17:51.466: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename security-context 04/18/23 09:17:51.467
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:51.478
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:51.482
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/18/23 09:17:51.486
Apr 18 09:17:51.491: INFO: Waiting up to 5m0s for pod "security-context-b68717b1-43a9-4118-a57f-1facf884b3a1" in namespace "security-context-3245" to be "Succeeded or Failed"
Apr 18 09:17:51.494: INFO: Pod "security-context-b68717b1-43a9-4118-a57f-1facf884b3a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.501771ms
Apr 18 09:17:53.497: INFO: Pod "security-context-b68717b1-43a9-4118-a57f-1facf884b3a1": Phase="Running", Reason="", readiness=false. Elapsed: 2.005639042s
Apr 18 09:17:55.497: INFO: Pod "security-context-b68717b1-43a9-4118-a57f-1facf884b3a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005856934s
STEP: Saw pod success 04/18/23 09:17:55.497
Apr 18 09:17:55.497: INFO: Pod "security-context-b68717b1-43a9-4118-a57f-1facf884b3a1" satisfied condition "Succeeded or Failed"
Apr 18 09:17:55.500: INFO: Trying to get logs from node 192.168.1.152 pod security-context-b68717b1-43a9-4118-a57f-1facf884b3a1 container test-container: <nil>
STEP: delete the pod 04/18/23 09:17:55.507
Apr 18 09:17:55.521: INFO: Waiting for pod security-context-b68717b1-43a9-4118-a57f-1facf884b3a1 to disappear
Apr 18 09:17:55.524: INFO: Pod security-context-b68717b1-43a9-4118-a57f-1facf884b3a1 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 18 09:17:55.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-3245" for this suite. 04/18/23 09:17:55.534
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":206,"skipped":3923,"failed":0}
------------------------------
• [4.072 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:51.466
    Apr 18 09:17:51.466: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename security-context 04/18/23 09:17:51.467
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:51.478
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:51.482
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/18/23 09:17:51.486
    Apr 18 09:17:51.491: INFO: Waiting up to 5m0s for pod "security-context-b68717b1-43a9-4118-a57f-1facf884b3a1" in namespace "security-context-3245" to be "Succeeded or Failed"
    Apr 18 09:17:51.494: INFO: Pod "security-context-b68717b1-43a9-4118-a57f-1facf884b3a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.501771ms
    Apr 18 09:17:53.497: INFO: Pod "security-context-b68717b1-43a9-4118-a57f-1facf884b3a1": Phase="Running", Reason="", readiness=false. Elapsed: 2.005639042s
    Apr 18 09:17:55.497: INFO: Pod "security-context-b68717b1-43a9-4118-a57f-1facf884b3a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005856934s
    STEP: Saw pod success 04/18/23 09:17:55.497
    Apr 18 09:17:55.497: INFO: Pod "security-context-b68717b1-43a9-4118-a57f-1facf884b3a1" satisfied condition "Succeeded or Failed"
    Apr 18 09:17:55.500: INFO: Trying to get logs from node 192.168.1.152 pod security-context-b68717b1-43a9-4118-a57f-1facf884b3a1 container test-container: <nil>
    STEP: delete the pod 04/18/23 09:17:55.507
    Apr 18 09:17:55.521: INFO: Waiting for pod security-context-b68717b1-43a9-4118-a57f-1facf884b3a1 to disappear
    Apr 18 09:17:55.524: INFO: Pod security-context-b68717b1-43a9-4118-a57f-1facf884b3a1 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 18 09:17:55.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-3245" for this suite. 04/18/23 09:17:55.534
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:55.539
Apr 18 09:17:55.539: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename ingress 04/18/23 09:17:55.54
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:55.555
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:55.559
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 04/18/23 09:17:55.563
STEP: getting /apis/networking.k8s.io 04/18/23 09:17:55.567
STEP: getting /apis/networking.k8s.iov1 04/18/23 09:17:55.568
STEP: creating 04/18/23 09:17:55.57
STEP: getting 04/18/23 09:17:55.583
STEP: listing 04/18/23 09:17:55.585
STEP: watching 04/18/23 09:17:55.589
Apr 18 09:17:55.589: INFO: starting watch
STEP: cluster-wide listing 04/18/23 09:17:55.591
STEP: cluster-wide watching 04/18/23 09:17:55.593
Apr 18 09:17:55.594: INFO: starting watch
STEP: patching 04/18/23 09:17:55.595
STEP: updating 04/18/23 09:17:55.6
Apr 18 09:17:55.607: INFO: waiting for watch events with expected annotations
Apr 18 09:17:55.607: INFO: saw patched and updated annotations
STEP: patching /status 04/18/23 09:17:55.607
STEP: updating /status 04/18/23 09:17:55.611
STEP: get /status 04/18/23 09:17:55.618
STEP: deleting 04/18/23 09:17:55.62
STEP: deleting a collection 04/18/23 09:17:55.629
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Apr 18 09:17:55.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-7856" for this suite. 04/18/23 09:17:55.644
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":207,"skipped":3959,"failed":0}
------------------------------
• [0.114 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:55.539
    Apr 18 09:17:55.539: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename ingress 04/18/23 09:17:55.54
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:55.555
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:55.559
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 04/18/23 09:17:55.563
    STEP: getting /apis/networking.k8s.io 04/18/23 09:17:55.567
    STEP: getting /apis/networking.k8s.iov1 04/18/23 09:17:55.568
    STEP: creating 04/18/23 09:17:55.57
    STEP: getting 04/18/23 09:17:55.583
    STEP: listing 04/18/23 09:17:55.585
    STEP: watching 04/18/23 09:17:55.589
    Apr 18 09:17:55.589: INFO: starting watch
    STEP: cluster-wide listing 04/18/23 09:17:55.591
    STEP: cluster-wide watching 04/18/23 09:17:55.593
    Apr 18 09:17:55.594: INFO: starting watch
    STEP: patching 04/18/23 09:17:55.595
    STEP: updating 04/18/23 09:17:55.6
    Apr 18 09:17:55.607: INFO: waiting for watch events with expected annotations
    Apr 18 09:17:55.607: INFO: saw patched and updated annotations
    STEP: patching /status 04/18/23 09:17:55.607
    STEP: updating /status 04/18/23 09:17:55.611
    STEP: get /status 04/18/23 09:17:55.618
    STEP: deleting 04/18/23 09:17:55.62
    STEP: deleting a collection 04/18/23 09:17:55.629
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Apr 18 09:17:55.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-7856" for this suite. 04/18/23 09:17:55.644
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:55.654
Apr 18 09:17:55.654: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir 04/18/23 09:17:55.654
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:55.665
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:55.668
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 04/18/23 09:17:55.672
Apr 18 09:17:55.681: INFO: Waiting up to 5m0s for pod "pod-6ed923a4-c78a-4e25-a401-71dba971fdaf" in namespace "emptydir-665" to be "Succeeded or Failed"
Apr 18 09:17:55.684: INFO: Pod "pod-6ed923a4-c78a-4e25-a401-71dba971fdaf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.60605ms
Apr 18 09:17:57.688: INFO: Pod "pod-6ed923a4-c78a-4e25-a401-71dba971fdaf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006881659s
Apr 18 09:17:59.688: INFO: Pod "pod-6ed923a4-c78a-4e25-a401-71dba971fdaf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006557351s
STEP: Saw pod success 04/18/23 09:17:59.688
Apr 18 09:17:59.688: INFO: Pod "pod-6ed923a4-c78a-4e25-a401-71dba971fdaf" satisfied condition "Succeeded or Failed"
Apr 18 09:17:59.691: INFO: Trying to get logs from node 192.168.1.152 pod pod-6ed923a4-c78a-4e25-a401-71dba971fdaf container test-container: <nil>
STEP: delete the pod 04/18/23 09:17:59.696
Apr 18 09:17:59.714: INFO: Waiting for pod pod-6ed923a4-c78a-4e25-a401-71dba971fdaf to disappear
Apr 18 09:17:59.717: INFO: Pod pod-6ed923a4-c78a-4e25-a401-71dba971fdaf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 09:17:59.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-665" for this suite. 04/18/23 09:17:59.721
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":208,"skipped":3961,"failed":0}
------------------------------
• [4.072 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:55.654
    Apr 18 09:17:55.654: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir 04/18/23 09:17:55.654
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:55.665
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:55.668
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 04/18/23 09:17:55.672
    Apr 18 09:17:55.681: INFO: Waiting up to 5m0s for pod "pod-6ed923a4-c78a-4e25-a401-71dba971fdaf" in namespace "emptydir-665" to be "Succeeded or Failed"
    Apr 18 09:17:55.684: INFO: Pod "pod-6ed923a4-c78a-4e25-a401-71dba971fdaf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.60605ms
    Apr 18 09:17:57.688: INFO: Pod "pod-6ed923a4-c78a-4e25-a401-71dba971fdaf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006881659s
    Apr 18 09:17:59.688: INFO: Pod "pod-6ed923a4-c78a-4e25-a401-71dba971fdaf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006557351s
    STEP: Saw pod success 04/18/23 09:17:59.688
    Apr 18 09:17:59.688: INFO: Pod "pod-6ed923a4-c78a-4e25-a401-71dba971fdaf" satisfied condition "Succeeded or Failed"
    Apr 18 09:17:59.691: INFO: Trying to get logs from node 192.168.1.152 pod pod-6ed923a4-c78a-4e25-a401-71dba971fdaf container test-container: <nil>
    STEP: delete the pod 04/18/23 09:17:59.696
    Apr 18 09:17:59.714: INFO: Waiting for pod pod-6ed923a4-c78a-4e25-a401-71dba971fdaf to disappear
    Apr 18 09:17:59.717: INFO: Pod pod-6ed923a4-c78a-4e25-a401-71dba971fdaf no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 09:17:59.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-665" for this suite. 04/18/23 09:17:59.721
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:17:59.726
Apr 18 09:17:59.726: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename replicaset 04/18/23 09:17:59.727
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:59.737
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:59.741
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Apr 18 09:17:59.756: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 18 09:18:04.759: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/18/23 09:18:04.759
STEP: Scaling up "test-rs" replicaset  04/18/23 09:18:04.759
Apr 18 09:18:04.768: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 04/18/23 09:18:04.768
W0418 09:18:04.775165      18 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 18 09:18:04.777: INFO: observed ReplicaSet test-rs in namespace replicaset-108 with ReadyReplicas 1, AvailableReplicas 1
Apr 18 09:18:04.790: INFO: observed ReplicaSet test-rs in namespace replicaset-108 with ReadyReplicas 1, AvailableReplicas 1
Apr 18 09:18:04.809: INFO: observed ReplicaSet test-rs in namespace replicaset-108 with ReadyReplicas 1, AvailableReplicas 1
Apr 18 09:18:04.815: INFO: observed ReplicaSet test-rs in namespace replicaset-108 with ReadyReplicas 1, AvailableReplicas 1
Apr 18 09:18:06.138: INFO: observed ReplicaSet test-rs in namespace replicaset-108 with ReadyReplicas 2, AvailableReplicas 2
Apr 18 09:18:06.419: INFO: observed Replicaset test-rs in namespace replicaset-108 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 18 09:18:06.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-108" for this suite. 04/18/23 09:18:06.424
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":209,"skipped":3972,"failed":0}
------------------------------
• [SLOW TEST] [6.702 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:17:59.726
    Apr 18 09:17:59.726: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename replicaset 04/18/23 09:17:59.727
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:17:59.737
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:17:59.741
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Apr 18 09:17:59.756: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 18 09:18:04.759: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/18/23 09:18:04.759
    STEP: Scaling up "test-rs" replicaset  04/18/23 09:18:04.759
    Apr 18 09:18:04.768: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 04/18/23 09:18:04.768
    W0418 09:18:04.775165      18 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 18 09:18:04.777: INFO: observed ReplicaSet test-rs in namespace replicaset-108 with ReadyReplicas 1, AvailableReplicas 1
    Apr 18 09:18:04.790: INFO: observed ReplicaSet test-rs in namespace replicaset-108 with ReadyReplicas 1, AvailableReplicas 1
    Apr 18 09:18:04.809: INFO: observed ReplicaSet test-rs in namespace replicaset-108 with ReadyReplicas 1, AvailableReplicas 1
    Apr 18 09:18:04.815: INFO: observed ReplicaSet test-rs in namespace replicaset-108 with ReadyReplicas 1, AvailableReplicas 1
    Apr 18 09:18:06.138: INFO: observed ReplicaSet test-rs in namespace replicaset-108 with ReadyReplicas 2, AvailableReplicas 2
    Apr 18 09:18:06.419: INFO: observed Replicaset test-rs in namespace replicaset-108 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 18 09:18:06.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-108" for this suite. 04/18/23 09:18:06.424
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:18:06.428
Apr 18 09:18:06.428: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 09:18:06.429
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:18:06.438
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:18:06.442
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 04/18/23 09:18:06.446
Apr 18 09:18:06.454: INFO: Waiting up to 5m0s for pod "downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7" in namespace "downward-api-4958" to be "Succeeded or Failed"
Apr 18 09:18:06.458: INFO: Pod "downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05775ms
Apr 18 09:18:08.462: INFO: Pod "downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008300898s
Apr 18 09:18:10.461: INFO: Pod "downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007585341s
STEP: Saw pod success 04/18/23 09:18:10.461
Apr 18 09:18:10.461: INFO: Pod "downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7" satisfied condition "Succeeded or Failed"
Apr 18 09:18:10.464: INFO: Trying to get logs from node 192.168.1.152 pod downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7 container dapi-container: <nil>
STEP: delete the pod 04/18/23 09:18:10.47
Apr 18 09:18:10.481: INFO: Waiting for pod downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7 to disappear
Apr 18 09:18:10.484: INFO: Pod downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 18 09:18:10.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4958" for this suite. 04/18/23 09:18:10.488
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":210,"skipped":3980,"failed":0}
------------------------------
• [4.065 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:18:06.428
    Apr 18 09:18:06.428: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 09:18:06.429
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:18:06.438
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:18:06.442
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 04/18/23 09:18:06.446
    Apr 18 09:18:06.454: INFO: Waiting up to 5m0s for pod "downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7" in namespace "downward-api-4958" to be "Succeeded or Failed"
    Apr 18 09:18:06.458: INFO: Pod "downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05775ms
    Apr 18 09:18:08.462: INFO: Pod "downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008300898s
    Apr 18 09:18:10.461: INFO: Pod "downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007585341s
    STEP: Saw pod success 04/18/23 09:18:10.461
    Apr 18 09:18:10.461: INFO: Pod "downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7" satisfied condition "Succeeded or Failed"
    Apr 18 09:18:10.464: INFO: Trying to get logs from node 192.168.1.152 pod downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7 container dapi-container: <nil>
    STEP: delete the pod 04/18/23 09:18:10.47
    Apr 18 09:18:10.481: INFO: Waiting for pod downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7 to disappear
    Apr 18 09:18:10.484: INFO: Pod downward-api-05a224fb-5750-4aac-8b1e-84d8fecd7ba7 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 18 09:18:10.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4958" for this suite. 04/18/23 09:18:10.488
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:18:10.496
Apr 18 09:18:10.496: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename resourcequota 04/18/23 09:18:10.496
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:18:10.506
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:18:10.51
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 04/18/23 09:18:10.514
STEP: Creating a ResourceQuota 04/18/23 09:18:15.517
STEP: Ensuring resource quota status is calculated 04/18/23 09:18:15.523
STEP: Creating a ReplicationController 04/18/23 09:18:17.527
STEP: Ensuring resource quota status captures replication controller creation 04/18/23 09:18:17.538
STEP: Deleting a ReplicationController 04/18/23 09:18:19.543
STEP: Ensuring resource quota status released usage 04/18/23 09:18:19.548
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 09:18:21.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7222" for this suite. 04/18/23 09:18:21.559
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":211,"skipped":4002,"failed":0}
------------------------------
• [SLOW TEST] [11.071 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:18:10.496
    Apr 18 09:18:10.496: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename resourcequota 04/18/23 09:18:10.496
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:18:10.506
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:18:10.51
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 04/18/23 09:18:10.514
    STEP: Creating a ResourceQuota 04/18/23 09:18:15.517
    STEP: Ensuring resource quota status is calculated 04/18/23 09:18:15.523
    STEP: Creating a ReplicationController 04/18/23 09:18:17.527
    STEP: Ensuring resource quota status captures replication controller creation 04/18/23 09:18:17.538
    STEP: Deleting a ReplicationController 04/18/23 09:18:19.543
    STEP: Ensuring resource quota status released usage 04/18/23 09:18:19.548
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 09:18:21.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7222" for this suite. 04/18/23 09:18:21.559
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:18:21.569
Apr 18 09:18:21.569: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 09:18:21.569
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:18:21.579
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:18:21.583
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 09:18:21.587
Apr 18 09:18:21.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-238 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Apr 18 09:18:21.643: INFO: stderr: ""
Apr 18 09:18:21.643: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 04/18/23 09:18:21.643
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Apr 18 09:18:21.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-238 delete pods e2e-test-httpd-pod'
Apr 18 09:18:24.192: INFO: stderr: ""
Apr 18 09:18:24.192: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 09:18:24.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-238" for this suite. 04/18/23 09:18:24.197
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":212,"skipped":4058,"failed":0}
------------------------------
• [2.638 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:18:21.569
    Apr 18 09:18:21.569: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 09:18:21.569
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:18:21.579
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:18:21.583
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 09:18:21.587
    Apr 18 09:18:21.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-238 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Apr 18 09:18:21.643: INFO: stderr: ""
    Apr 18 09:18:21.643: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 04/18/23 09:18:21.643
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Apr 18 09:18:21.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-238 delete pods e2e-test-httpd-pod'
    Apr 18 09:18:24.192: INFO: stderr: ""
    Apr 18 09:18:24.192: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 09:18:24.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-238" for this suite. 04/18/23 09:18:24.197
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:18:24.207
Apr 18 09:18:24.207: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename daemonsets 04/18/23 09:18:24.207
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:18:24.228
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:18:24.234
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Apr 18 09:18:24.260: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 04/18/23 09:18:24.265
Apr 18 09:18:24.269: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:18:24.269: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 04/18/23 09:18:24.269
Apr 18 09:18:24.296: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:18:24.296: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
Apr 18 09:18:25.300: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:18:25.300: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
Apr 18 09:18:26.300: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 18 09:18:26.300: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 04/18/23 09:18:26.302
Apr 18 09:18:26.317: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 18 09:18:26.317: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Apr 18 09:18:27.322: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:18:27.322: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 04/18/23 09:18:27.322
Apr 18 09:18:27.332: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:18:27.332: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
Apr 18 09:18:28.336: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:18:28.336: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
Apr 18 09:18:29.335: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:18:29.335: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
Apr 18 09:18:30.336: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 18 09:18:30.336: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/18/23 09:18:30.342
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2617, will wait for the garbage collector to delete the pods 04/18/23 09:18:30.342
Apr 18 09:18:30.400: INFO: Deleting DaemonSet.extensions daemon-set took: 4.803651ms
Apr 18 09:18:30.501: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.890842ms
Apr 18 09:18:32.505: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:18:32.505: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 18 09:18:32.508: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4191087"},"items":null}

Apr 18 09:18:32.510: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4191087"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:18:32.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2617" for this suite. 04/18/23 09:18:32.539
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":213,"skipped":4058,"failed":0}
------------------------------
• [SLOW TEST] [8.339 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:18:24.207
    Apr 18 09:18:24.207: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename daemonsets 04/18/23 09:18:24.207
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:18:24.228
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:18:24.234
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Apr 18 09:18:24.260: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 04/18/23 09:18:24.265
    Apr 18 09:18:24.269: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:18:24.269: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 04/18/23 09:18:24.269
    Apr 18 09:18:24.296: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:18:24.296: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
    Apr 18 09:18:25.300: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:18:25.300: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
    Apr 18 09:18:26.300: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 18 09:18:26.300: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 04/18/23 09:18:26.302
    Apr 18 09:18:26.317: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 18 09:18:26.317: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Apr 18 09:18:27.322: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:18:27.322: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 04/18/23 09:18:27.322
    Apr 18 09:18:27.332: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:18:27.332: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
    Apr 18 09:18:28.336: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:18:28.336: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
    Apr 18 09:18:29.335: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:18:29.335: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
    Apr 18 09:18:30.336: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 18 09:18:30.336: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/18/23 09:18:30.342
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2617, will wait for the garbage collector to delete the pods 04/18/23 09:18:30.342
    Apr 18 09:18:30.400: INFO: Deleting DaemonSet.extensions daemon-set took: 4.803651ms
    Apr 18 09:18:30.501: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.890842ms
    Apr 18 09:18:32.505: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:18:32.505: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 18 09:18:32.508: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4191087"},"items":null}

    Apr 18 09:18:32.510: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4191087"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:18:32.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-2617" for this suite. 04/18/23 09:18:32.539
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:18:32.547
Apr 18 09:18:32.547: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename resourcequota 04/18/23 09:18:32.548
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:18:32.565
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:18:32.569
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 04/18/23 09:18:32.573
STEP: Ensuring ResourceQuota status is calculated 04/18/23 09:18:32.578
STEP: Creating a ResourceQuota with not best effort scope 04/18/23 09:18:34.582
STEP: Ensuring ResourceQuota status is calculated 04/18/23 09:18:34.588
STEP: Creating a best-effort pod 04/18/23 09:18:36.592
STEP: Ensuring resource quota with best effort scope captures the pod usage 04/18/23 09:18:36.601
STEP: Ensuring resource quota with not best effort ignored the pod usage 04/18/23 09:18:38.605
STEP: Deleting the pod 04/18/23 09:18:40.61
STEP: Ensuring resource quota status released the pod usage 04/18/23 09:18:40.62
STEP: Creating a not best-effort pod 04/18/23 09:18:42.624
STEP: Ensuring resource quota with not best effort scope captures the pod usage 04/18/23 09:18:42.633
STEP: Ensuring resource quota with best effort scope ignored the pod usage 04/18/23 09:18:44.637
STEP: Deleting the pod 04/18/23 09:18:46.643
STEP: Ensuring resource quota status released the pod usage 04/18/23 09:18:46.651
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 09:18:48.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8983" for this suite. 04/18/23 09:18:48.659
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":214,"skipped":4070,"failed":0}
------------------------------
• [SLOW TEST] [16.116 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:18:32.547
    Apr 18 09:18:32.547: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename resourcequota 04/18/23 09:18:32.548
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:18:32.565
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:18:32.569
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 04/18/23 09:18:32.573
    STEP: Ensuring ResourceQuota status is calculated 04/18/23 09:18:32.578
    STEP: Creating a ResourceQuota with not best effort scope 04/18/23 09:18:34.582
    STEP: Ensuring ResourceQuota status is calculated 04/18/23 09:18:34.588
    STEP: Creating a best-effort pod 04/18/23 09:18:36.592
    STEP: Ensuring resource quota with best effort scope captures the pod usage 04/18/23 09:18:36.601
    STEP: Ensuring resource quota with not best effort ignored the pod usage 04/18/23 09:18:38.605
    STEP: Deleting the pod 04/18/23 09:18:40.61
    STEP: Ensuring resource quota status released the pod usage 04/18/23 09:18:40.62
    STEP: Creating a not best-effort pod 04/18/23 09:18:42.624
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 04/18/23 09:18:42.633
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 04/18/23 09:18:44.637
    STEP: Deleting the pod 04/18/23 09:18:46.643
    STEP: Ensuring resource quota status released the pod usage 04/18/23 09:18:46.651
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 09:18:48.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8983" for this suite. 04/18/23 09:18:48.659
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:18:48.685
Apr 18 09:18:48.686: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename daemonsets 04/18/23 09:18:48.688
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:18:48.698
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:18:48.702
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 04/18/23 09:18:48.721
STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 09:18:48.727
Apr 18 09:18:48.732: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:18:48.732: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
Apr 18 09:18:49.740: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 18 09:18:49.741: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
Apr 18 09:18:50.743: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 09:18:50.743: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 04/18/23 09:18:50.749
Apr 18 09:18:50.769: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 09:18:50.769: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
Apr 18 09:18:51.776: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 09:18:51.776: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
Apr 18 09:18:52.777: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 09:18:52.777: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
Apr 18 09:18:53.811: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 09:18:53.811: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
Apr 18 09:18:54.777: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 09:18:54.777: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/18/23 09:18:54.78
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4746, will wait for the garbage collector to delete the pods 04/18/23 09:18:54.78
Apr 18 09:18:54.837: INFO: Deleting DaemonSet.extensions daemon-set took: 4.692957ms
Apr 18 09:18:54.938: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.90438ms
Apr 18 09:18:57.342: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:18:57.342: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 18 09:18:57.345: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4191280"},"items":null}

Apr 18 09:18:57.347: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4191280"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:18:57.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4746" for this suite. 04/18/23 09:18:57.364
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":215,"skipped":4079,"failed":0}
------------------------------
• [SLOW TEST] [8.683 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:18:48.685
    Apr 18 09:18:48.686: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename daemonsets 04/18/23 09:18:48.688
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:18:48.698
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:18:48.702
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 04/18/23 09:18:48.721
    STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 09:18:48.727
    Apr 18 09:18:48.732: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:18:48.732: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
    Apr 18 09:18:49.740: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 18 09:18:49.741: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
    Apr 18 09:18:50.743: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 09:18:50.743: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 04/18/23 09:18:50.749
    Apr 18 09:18:50.769: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 09:18:50.769: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
    Apr 18 09:18:51.776: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 09:18:51.776: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
    Apr 18 09:18:52.777: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 09:18:52.777: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
    Apr 18 09:18:53.811: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 09:18:53.811: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
    Apr 18 09:18:54.777: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 09:18:54.777: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/18/23 09:18:54.78
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4746, will wait for the garbage collector to delete the pods 04/18/23 09:18:54.78
    Apr 18 09:18:54.837: INFO: Deleting DaemonSet.extensions daemon-set took: 4.692957ms
    Apr 18 09:18:54.938: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.90438ms
    Apr 18 09:18:57.342: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:18:57.342: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 18 09:18:57.345: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4191280"},"items":null}

    Apr 18 09:18:57.347: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4191280"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:18:57.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4746" for this suite. 04/18/23 09:18:57.364
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:18:57.372
Apr 18 09:18:57.372: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename daemonsets 04/18/23 09:18:57.373
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:18:57.383
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:18:57.387
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Apr 18 09:18:57.409: INFO: Create a RollingUpdate DaemonSet
Apr 18 09:18:57.413: INFO: Check that daemon pods launch on every node of the cluster
Apr 18 09:18:57.418: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:18:57.418: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
Apr 18 09:18:58.426: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 09:18:58.426: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
Apr 18 09:18:59.426: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 09:18:59.426: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Apr 18 09:18:59.426: INFO: Update the DaemonSet to trigger a rollout
Apr 18 09:18:59.436: INFO: Updating DaemonSet daemon-set
Apr 18 09:19:02.450: INFO: Roll back the DaemonSet before rollout is complete
Apr 18 09:19:02.459: INFO: Updating DaemonSet daemon-set
Apr 18 09:19:02.459: INFO: Make sure DaemonSet rollback is complete
Apr 18 09:19:02.463: INFO: Wrong image for pod: daemon-set-ltccm. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Apr 18 09:19:02.463: INFO: Pod daemon-set-ltccm is not available
Apr 18 09:19:05.481: INFO: Pod daemon-set-r4j4g is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/18/23 09:19:05.523
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4166, will wait for the garbage collector to delete the pods 04/18/23 09:19:05.523
Apr 18 09:19:05.581: INFO: Deleting DaemonSet.extensions daemon-set took: 5.241264ms
Apr 18 09:19:05.682: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.456691ms
Apr 18 09:19:08.586: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:19:08.586: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 18 09:19:08.588: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4191400"},"items":null}

Apr 18 09:19:08.591: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4191400"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:19:08.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4166" for this suite. 04/18/23 09:19:08.608
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":216,"skipped":4128,"failed":0}
------------------------------
• [SLOW TEST] [11.241 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:18:57.372
    Apr 18 09:18:57.372: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename daemonsets 04/18/23 09:18:57.373
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:18:57.383
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:18:57.387
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Apr 18 09:18:57.409: INFO: Create a RollingUpdate DaemonSet
    Apr 18 09:18:57.413: INFO: Check that daemon pods launch on every node of the cluster
    Apr 18 09:18:57.418: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:18:57.418: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
    Apr 18 09:18:58.426: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 09:18:58.426: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
    Apr 18 09:18:59.426: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 09:18:59.426: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Apr 18 09:18:59.426: INFO: Update the DaemonSet to trigger a rollout
    Apr 18 09:18:59.436: INFO: Updating DaemonSet daemon-set
    Apr 18 09:19:02.450: INFO: Roll back the DaemonSet before rollout is complete
    Apr 18 09:19:02.459: INFO: Updating DaemonSet daemon-set
    Apr 18 09:19:02.459: INFO: Make sure DaemonSet rollback is complete
    Apr 18 09:19:02.463: INFO: Wrong image for pod: daemon-set-ltccm. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Apr 18 09:19:02.463: INFO: Pod daemon-set-ltccm is not available
    Apr 18 09:19:05.481: INFO: Pod daemon-set-r4j4g is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/18/23 09:19:05.523
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4166, will wait for the garbage collector to delete the pods 04/18/23 09:19:05.523
    Apr 18 09:19:05.581: INFO: Deleting DaemonSet.extensions daemon-set took: 5.241264ms
    Apr 18 09:19:05.682: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.456691ms
    Apr 18 09:19:08.586: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:19:08.586: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 18 09:19:08.588: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4191400"},"items":null}

    Apr 18 09:19:08.591: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4191400"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:19:08.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4166" for this suite. 04/18/23 09:19:08.608
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:19:08.613
Apr 18 09:19:08.613: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename pods 04/18/23 09:19:08.614
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:19:08.625
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:19:08.629
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Apr 18 09:19:08.632: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: creating the pod 04/18/23 09:19:08.633
STEP: submitting the pod to kubernetes 04/18/23 09:19:08.633
Apr 18 09:19:08.651: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-6b4b55ca-5f63-447d-b9c9-36995c447230" in namespace "pods-7795" to be "running and ready"
Apr 18 09:19:08.654: INFO: Pod "pod-logs-websocket-6b4b55ca-5f63-447d-b9c9-36995c447230": Phase="Pending", Reason="", readiness=false. Elapsed: 2.74692ms
Apr 18 09:19:08.654: INFO: The phase of Pod pod-logs-websocket-6b4b55ca-5f63-447d-b9c9-36995c447230 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:19:10.658: INFO: Pod "pod-logs-websocket-6b4b55ca-5f63-447d-b9c9-36995c447230": Phase="Running", Reason="", readiness=true. Elapsed: 2.00707476s
Apr 18 09:19:10.658: INFO: The phase of Pod pod-logs-websocket-6b4b55ca-5f63-447d-b9c9-36995c447230 is Running (Ready = true)
Apr 18 09:19:10.658: INFO: Pod "pod-logs-websocket-6b4b55ca-5f63-447d-b9c9-36995c447230" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 09:19:10.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7795" for this suite. 04/18/23 09:19:10.676
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":217,"skipped":4134,"failed":0}
------------------------------
• [2.068 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:19:08.613
    Apr 18 09:19:08.613: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename pods 04/18/23 09:19:08.614
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:19:08.625
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:19:08.629
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Apr 18 09:19:08.632: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: creating the pod 04/18/23 09:19:08.633
    STEP: submitting the pod to kubernetes 04/18/23 09:19:08.633
    Apr 18 09:19:08.651: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-6b4b55ca-5f63-447d-b9c9-36995c447230" in namespace "pods-7795" to be "running and ready"
    Apr 18 09:19:08.654: INFO: Pod "pod-logs-websocket-6b4b55ca-5f63-447d-b9c9-36995c447230": Phase="Pending", Reason="", readiness=false. Elapsed: 2.74692ms
    Apr 18 09:19:08.654: INFO: The phase of Pod pod-logs-websocket-6b4b55ca-5f63-447d-b9c9-36995c447230 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:19:10.658: INFO: Pod "pod-logs-websocket-6b4b55ca-5f63-447d-b9c9-36995c447230": Phase="Running", Reason="", readiness=true. Elapsed: 2.00707476s
    Apr 18 09:19:10.658: INFO: The phase of Pod pod-logs-websocket-6b4b55ca-5f63-447d-b9c9-36995c447230 is Running (Ready = true)
    Apr 18 09:19:10.658: INFO: Pod "pod-logs-websocket-6b4b55ca-5f63-447d-b9c9-36995c447230" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 09:19:10.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7795" for this suite. 04/18/23 09:19:10.676
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:19:10.681
Apr 18 09:19:10.681: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 09:19:10.682
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:19:10.695
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:19:10.699
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-49eefc90-c7bf-483c-8a78-b34c36c4c23b 04/18/23 09:19:10.703
STEP: Creating secret with name secret-projected-all-test-volume-0fc81d7e-e027-4bb2-8275-77c28ac726c1 04/18/23 09:19:10.707
STEP: Creating a pod to test Check all projections for projected volume plugin 04/18/23 09:19:10.711
Apr 18 09:19:10.719: INFO: Waiting up to 5m0s for pod "projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2" in namespace "projected-5940" to be "Succeeded or Failed"
Apr 18 09:19:10.724: INFO: Pod "projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.628443ms
Apr 18 09:19:12.735: INFO: Pod "projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015907193s
Apr 18 09:19:14.728: INFO: Pod "projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008625237s
STEP: Saw pod success 04/18/23 09:19:14.728
Apr 18 09:19:14.728: INFO: Pod "projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2" satisfied condition "Succeeded or Failed"
Apr 18 09:19:14.731: INFO: Trying to get logs from node 192.168.1.152 pod projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2 container projected-all-volume-test: <nil>
STEP: delete the pod 04/18/23 09:19:14.736
Apr 18 09:19:14.753: INFO: Waiting for pod projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2 to disappear
Apr 18 09:19:14.763: INFO: Pod projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Apr 18 09:19:14.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5940" for this suite. 04/18/23 09:19:14.767
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":218,"skipped":4137,"failed":0}
------------------------------
• [4.091 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:19:10.681
    Apr 18 09:19:10.681: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 09:19:10.682
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:19:10.695
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:19:10.699
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-49eefc90-c7bf-483c-8a78-b34c36c4c23b 04/18/23 09:19:10.703
    STEP: Creating secret with name secret-projected-all-test-volume-0fc81d7e-e027-4bb2-8275-77c28ac726c1 04/18/23 09:19:10.707
    STEP: Creating a pod to test Check all projections for projected volume plugin 04/18/23 09:19:10.711
    Apr 18 09:19:10.719: INFO: Waiting up to 5m0s for pod "projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2" in namespace "projected-5940" to be "Succeeded or Failed"
    Apr 18 09:19:10.724: INFO: Pod "projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.628443ms
    Apr 18 09:19:12.735: INFO: Pod "projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015907193s
    Apr 18 09:19:14.728: INFO: Pod "projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008625237s
    STEP: Saw pod success 04/18/23 09:19:14.728
    Apr 18 09:19:14.728: INFO: Pod "projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2" satisfied condition "Succeeded or Failed"
    Apr 18 09:19:14.731: INFO: Trying to get logs from node 192.168.1.152 pod projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2 container projected-all-volume-test: <nil>
    STEP: delete the pod 04/18/23 09:19:14.736
    Apr 18 09:19:14.753: INFO: Waiting for pod projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2 to disappear
    Apr 18 09:19:14.763: INFO: Pod projected-volume-492515cb-3602-42e3-9932-8873fc4f97f2 no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Apr 18 09:19:14.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5940" for this suite. 04/18/23 09:19:14.767
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:19:14.775
Apr 18 09:19:14.775: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename var-expansion 04/18/23 09:19:14.776
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:19:14.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:19:14.794
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Apr 18 09:19:14.803: INFO: Waiting up to 2m0s for pod "var-expansion-072ba1f6-d821-4e45-b10b-22bde21ee856" in namespace "var-expansion-3257" to be "container 0 failed with reason CreateContainerConfigError"
Apr 18 09:19:14.809: INFO: Pod "var-expansion-072ba1f6-d821-4e45-b10b-22bde21ee856": Phase="Pending", Reason="", readiness=false. Elapsed: 5.286671ms
Apr 18 09:19:16.821: INFO: Pod "var-expansion-072ba1f6-d821-4e45-b10b-22bde21ee856": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017185461s
Apr 18 09:19:16.821: INFO: Pod "var-expansion-072ba1f6-d821-4e45-b10b-22bde21ee856" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Apr 18 09:19:16.821: INFO: Deleting pod "var-expansion-072ba1f6-d821-4e45-b10b-22bde21ee856" in namespace "var-expansion-3257"
Apr 18 09:19:16.837: INFO: Wait up to 5m0s for pod "var-expansion-072ba1f6-d821-4e45-b10b-22bde21ee856" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 09:19:18.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3257" for this suite. 04/18/23 09:19:18.858
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":219,"skipped":4193,"failed":0}
------------------------------
• [4.090 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:19:14.775
    Apr 18 09:19:14.775: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename var-expansion 04/18/23 09:19:14.776
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:19:14.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:19:14.794
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Apr 18 09:19:14.803: INFO: Waiting up to 2m0s for pod "var-expansion-072ba1f6-d821-4e45-b10b-22bde21ee856" in namespace "var-expansion-3257" to be "container 0 failed with reason CreateContainerConfigError"
    Apr 18 09:19:14.809: INFO: Pod "var-expansion-072ba1f6-d821-4e45-b10b-22bde21ee856": Phase="Pending", Reason="", readiness=false. Elapsed: 5.286671ms
    Apr 18 09:19:16.821: INFO: Pod "var-expansion-072ba1f6-d821-4e45-b10b-22bde21ee856": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017185461s
    Apr 18 09:19:16.821: INFO: Pod "var-expansion-072ba1f6-d821-4e45-b10b-22bde21ee856" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Apr 18 09:19:16.821: INFO: Deleting pod "var-expansion-072ba1f6-d821-4e45-b10b-22bde21ee856" in namespace "var-expansion-3257"
    Apr 18 09:19:16.837: INFO: Wait up to 5m0s for pod "var-expansion-072ba1f6-d821-4e45-b10b-22bde21ee856" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 09:19:18.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3257" for this suite. 04/18/23 09:19:18.858
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:19:18.865
Apr 18 09:19:18.865: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename secrets 04/18/23 09:19:18.866
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:19:18.876
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:19:18.88
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-2a097905-8d2e-4120-9522-1c738a500f8b 04/18/23 09:19:18.897
STEP: Creating a pod to test consume secrets 04/18/23 09:19:18.902
Apr 18 09:19:18.908: INFO: Waiting up to 5m0s for pod "pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364" in namespace "secrets-960" to be "Succeeded or Failed"
Apr 18 09:19:18.910: INFO: Pod "pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364": Phase="Pending", Reason="", readiness=false. Elapsed: 2.525933ms
Apr 18 09:19:20.921: INFO: Pod "pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013541187s
Apr 18 09:19:22.917: INFO: Pod "pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009320319s
STEP: Saw pod success 04/18/23 09:19:22.917
Apr 18 09:19:22.917: INFO: Pod "pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364" satisfied condition "Succeeded or Failed"
Apr 18 09:19:22.927: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364 container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 09:19:22.933
Apr 18 09:19:22.954: INFO: Waiting for pod pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364 to disappear
Apr 18 09:19:22.959: INFO: Pod pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 09:19:22.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-960" for this suite. 04/18/23 09:19:22.964
STEP: Destroying namespace "secret-namespace-8166" for this suite. 04/18/23 09:19:22.968
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":220,"skipped":4219,"failed":0}
------------------------------
• [4.107 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:19:18.865
    Apr 18 09:19:18.865: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename secrets 04/18/23 09:19:18.866
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:19:18.876
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:19:18.88
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-2a097905-8d2e-4120-9522-1c738a500f8b 04/18/23 09:19:18.897
    STEP: Creating a pod to test consume secrets 04/18/23 09:19:18.902
    Apr 18 09:19:18.908: INFO: Waiting up to 5m0s for pod "pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364" in namespace "secrets-960" to be "Succeeded or Failed"
    Apr 18 09:19:18.910: INFO: Pod "pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364": Phase="Pending", Reason="", readiness=false. Elapsed: 2.525933ms
    Apr 18 09:19:20.921: INFO: Pod "pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013541187s
    Apr 18 09:19:22.917: INFO: Pod "pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009320319s
    STEP: Saw pod success 04/18/23 09:19:22.917
    Apr 18 09:19:22.917: INFO: Pod "pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364" satisfied condition "Succeeded or Failed"
    Apr 18 09:19:22.927: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364 container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 09:19:22.933
    Apr 18 09:19:22.954: INFO: Waiting for pod pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364 to disappear
    Apr 18 09:19:22.959: INFO: Pod pod-secrets-01815d2d-34a0-47b0-bdd6-fb9285b68364 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 09:19:22.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-960" for this suite. 04/18/23 09:19:22.964
    STEP: Destroying namespace "secret-namespace-8166" for this suite. 04/18/23 09:19:22.968
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:19:22.974
Apr 18 09:19:22.974: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubelet-test 04/18/23 09:19:22.974
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:19:22.987
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:19:22.991
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 04/18/23 09:19:23.007
Apr 18 09:19:23.007: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasesc9118fba-cded-4a19-a720-ed61451f0442" in namespace "kubelet-test-6932" to be "completed"
Apr 18 09:19:23.010: INFO: Pod "agnhost-host-aliasesc9118fba-cded-4a19-a720-ed61451f0442": Phase="Pending", Reason="", readiness=false. Elapsed: 3.343761ms
Apr 18 09:19:25.014: INFO: Pod "agnhost-host-aliasesc9118fba-cded-4a19-a720-ed61451f0442": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006800291s
Apr 18 09:19:27.014: INFO: Pod "agnhost-host-aliasesc9118fba-cded-4a19-a720-ed61451f0442": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007226345s
Apr 18 09:19:27.014: INFO: Pod "agnhost-host-aliasesc9118fba-cded-4a19-a720-ed61451f0442" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 18 09:19:27.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6932" for this suite. 04/18/23 09:19:27.023
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":221,"skipped":4244,"failed":0}
------------------------------
• [4.055 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:19:22.974
    Apr 18 09:19:22.974: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubelet-test 04/18/23 09:19:22.974
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:19:22.987
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:19:22.991
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 04/18/23 09:19:23.007
    Apr 18 09:19:23.007: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasesc9118fba-cded-4a19-a720-ed61451f0442" in namespace "kubelet-test-6932" to be "completed"
    Apr 18 09:19:23.010: INFO: Pod "agnhost-host-aliasesc9118fba-cded-4a19-a720-ed61451f0442": Phase="Pending", Reason="", readiness=false. Elapsed: 3.343761ms
    Apr 18 09:19:25.014: INFO: Pod "agnhost-host-aliasesc9118fba-cded-4a19-a720-ed61451f0442": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006800291s
    Apr 18 09:19:27.014: INFO: Pod "agnhost-host-aliasesc9118fba-cded-4a19-a720-ed61451f0442": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007226345s
    Apr 18 09:19:27.014: INFO: Pod "agnhost-host-aliasesc9118fba-cded-4a19-a720-ed61451f0442" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 18 09:19:27.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-6932" for this suite. 04/18/23 09:19:27.023
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:19:27.029
Apr 18 09:19:27.029: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-probe 04/18/23 09:19:27.029
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:19:27.04
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:19:27.044
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 09:20:27.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6701" for this suite. 04/18/23 09:20:27.062
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":222,"skipped":4254,"failed":0}
------------------------------
• [SLOW TEST] [60.040 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:19:27.029
    Apr 18 09:19:27.029: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-probe 04/18/23 09:19:27.029
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:19:27.04
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:19:27.044
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 09:20:27.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6701" for this suite. 04/18/23 09:20:27.062
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:20:27.069
Apr 18 09:20:27.069: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename configmap 04/18/23 09:20:27.07
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:20:27.079
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:20:27.083
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-41b900d9-b1a4-479b-8054-a0a4bf910553 04/18/23 09:20:27.088
STEP: Creating a pod to test consume configMaps 04/18/23 09:20:27.092
Apr 18 09:20:27.099: INFO: Waiting up to 5m0s for pod "pod-configmaps-24131432-6785-43ec-bf39-543e72f38075" in namespace "configmap-9922" to be "Succeeded or Failed"
Apr 18 09:20:27.102: INFO: Pod "pod-configmaps-24131432-6785-43ec-bf39-543e72f38075": Phase="Pending", Reason="", readiness=false. Elapsed: 2.597201ms
Apr 18 09:20:29.106: INFO: Pod "pod-configmaps-24131432-6785-43ec-bf39-543e72f38075": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007250547s
Apr 18 09:20:31.105: INFO: Pod "pod-configmaps-24131432-6785-43ec-bf39-543e72f38075": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006015571s
STEP: Saw pod success 04/18/23 09:20:31.105
Apr 18 09:20:31.105: INFO: Pod "pod-configmaps-24131432-6785-43ec-bf39-543e72f38075" satisfied condition "Succeeded or Failed"
Apr 18 09:20:31.108: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-24131432-6785-43ec-bf39-543e72f38075 container configmap-volume-test: <nil>
STEP: delete the pod 04/18/23 09:20:31.113
Apr 18 09:20:31.121: INFO: Waiting for pod pod-configmaps-24131432-6785-43ec-bf39-543e72f38075 to disappear
Apr 18 09:20:31.125: INFO: Pod pod-configmaps-24131432-6785-43ec-bf39-543e72f38075 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 09:20:31.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9922" for this suite. 04/18/23 09:20:31.129
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":223,"skipped":4264,"failed":0}
------------------------------
• [4.064 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:20:27.069
    Apr 18 09:20:27.069: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename configmap 04/18/23 09:20:27.07
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:20:27.079
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:20:27.083
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-41b900d9-b1a4-479b-8054-a0a4bf910553 04/18/23 09:20:27.088
    STEP: Creating a pod to test consume configMaps 04/18/23 09:20:27.092
    Apr 18 09:20:27.099: INFO: Waiting up to 5m0s for pod "pod-configmaps-24131432-6785-43ec-bf39-543e72f38075" in namespace "configmap-9922" to be "Succeeded or Failed"
    Apr 18 09:20:27.102: INFO: Pod "pod-configmaps-24131432-6785-43ec-bf39-543e72f38075": Phase="Pending", Reason="", readiness=false. Elapsed: 2.597201ms
    Apr 18 09:20:29.106: INFO: Pod "pod-configmaps-24131432-6785-43ec-bf39-543e72f38075": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007250547s
    Apr 18 09:20:31.105: INFO: Pod "pod-configmaps-24131432-6785-43ec-bf39-543e72f38075": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006015571s
    STEP: Saw pod success 04/18/23 09:20:31.105
    Apr 18 09:20:31.105: INFO: Pod "pod-configmaps-24131432-6785-43ec-bf39-543e72f38075" satisfied condition "Succeeded or Failed"
    Apr 18 09:20:31.108: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-24131432-6785-43ec-bf39-543e72f38075 container configmap-volume-test: <nil>
    STEP: delete the pod 04/18/23 09:20:31.113
    Apr 18 09:20:31.121: INFO: Waiting for pod pod-configmaps-24131432-6785-43ec-bf39-543e72f38075 to disappear
    Apr 18 09:20:31.125: INFO: Pod pod-configmaps-24131432-6785-43ec-bf39-543e72f38075 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 09:20:31.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9922" for this suite. 04/18/23 09:20:31.129
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:20:31.134
Apr 18 09:20:31.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-probe 04/18/23 09:20:31.134
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:20:31.146
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:20:31.149
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b in namespace container-probe-6255 04/18/23 09:20:31.153
Apr 18 09:20:31.159: INFO: Waiting up to 5m0s for pod "liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b" in namespace "container-probe-6255" to be "not pending"
Apr 18 09:20:31.162: INFO: Pod "liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.584041ms
Apr 18 09:20:33.166: INFO: Pod "liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b": Phase="Running", Reason="", readiness=true. Elapsed: 2.00668537s
Apr 18 09:20:33.166: INFO: Pod "liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b" satisfied condition "not pending"
Apr 18 09:20:33.166: INFO: Started pod liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b in namespace container-probe-6255
STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 09:20:33.166
Apr 18 09:20:33.169: INFO: Initial restart count of pod liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b is 0
Apr 18 09:20:53.211: INFO: Restart count of pod container-probe-6255/liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b is now 1 (20.042556998s elapsed)
STEP: deleting the pod 04/18/23 09:20:53.211
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 09:20:53.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6255" for this suite. 04/18/23 09:20:53.225
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":224,"skipped":4271,"failed":0}
------------------------------
• [SLOW TEST] [22.097 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:20:31.134
    Apr 18 09:20:31.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-probe 04/18/23 09:20:31.134
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:20:31.146
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:20:31.149
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b in namespace container-probe-6255 04/18/23 09:20:31.153
    Apr 18 09:20:31.159: INFO: Waiting up to 5m0s for pod "liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b" in namespace "container-probe-6255" to be "not pending"
    Apr 18 09:20:31.162: INFO: Pod "liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.584041ms
    Apr 18 09:20:33.166: INFO: Pod "liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b": Phase="Running", Reason="", readiness=true. Elapsed: 2.00668537s
    Apr 18 09:20:33.166: INFO: Pod "liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b" satisfied condition "not pending"
    Apr 18 09:20:33.166: INFO: Started pod liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b in namespace container-probe-6255
    STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 09:20:33.166
    Apr 18 09:20:33.169: INFO: Initial restart count of pod liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b is 0
    Apr 18 09:20:53.211: INFO: Restart count of pod container-probe-6255/liveness-a4a31d2e-9da2-4c1b-83db-9f5b9733a21b is now 1 (20.042556998s elapsed)
    STEP: deleting the pod 04/18/23 09:20:53.211
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 09:20:53.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6255" for this suite. 04/18/23 09:20:53.225
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:20:53.231
Apr 18 09:20:53.231: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 09:20:53.232
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:20:53.241
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:20:53.245
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 04/18/23 09:20:53.248
Apr 18 09:20:53.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5357 create -f -'
Apr 18 09:20:54.219: INFO: stderr: ""
Apr 18 09:20:54.219: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/18/23 09:20:54.219
Apr 18 09:20:55.223: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 09:20:55.223: INFO: Found 0 / 1
Apr 18 09:20:56.222: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 09:20:56.222: INFO: Found 1 / 1
Apr 18 09:20:56.222: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 04/18/23 09:20:56.222
Apr 18 09:20:56.225: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 09:20:56.225: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 18 09:20:56.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5357 patch pod agnhost-primary-gqdrg -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 18 09:20:56.287: INFO: stderr: ""
Apr 18 09:20:56.287: INFO: stdout: "pod/agnhost-primary-gqdrg patched\n"
STEP: checking annotations 04/18/23 09:20:56.287
Apr 18 09:20:56.290: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 09:20:56.290: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 09:20:56.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5357" for this suite. 04/18/23 09:20:56.294
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":225,"skipped":4276,"failed":0}
------------------------------
• [3.068 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:20:53.231
    Apr 18 09:20:53.231: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 09:20:53.232
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:20:53.241
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:20:53.245
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 04/18/23 09:20:53.248
    Apr 18 09:20:53.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5357 create -f -'
    Apr 18 09:20:54.219: INFO: stderr: ""
    Apr 18 09:20:54.219: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/18/23 09:20:54.219
    Apr 18 09:20:55.223: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 09:20:55.223: INFO: Found 0 / 1
    Apr 18 09:20:56.222: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 09:20:56.222: INFO: Found 1 / 1
    Apr 18 09:20:56.222: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 04/18/23 09:20:56.222
    Apr 18 09:20:56.225: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 09:20:56.225: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 18 09:20:56.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5357 patch pod agnhost-primary-gqdrg -p {"metadata":{"annotations":{"x":"y"}}}'
    Apr 18 09:20:56.287: INFO: stderr: ""
    Apr 18 09:20:56.287: INFO: stdout: "pod/agnhost-primary-gqdrg patched\n"
    STEP: checking annotations 04/18/23 09:20:56.287
    Apr 18 09:20:56.290: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 09:20:56.290: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 09:20:56.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5357" for this suite. 04/18/23 09:20:56.294
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:20:56.3
Apr 18 09:20:56.300: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 09:20:56.301
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:20:56.312
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:20:56.316
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Apr 18 09:20:56.320: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:20:59.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1567" for this suite. 04/18/23 09:20:59.468
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":226,"skipped":4305,"failed":0}
------------------------------
• [3.173 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:20:56.3
    Apr 18 09:20:56.300: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 09:20:56.301
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:20:56.312
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:20:56.316
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Apr 18 09:20:56.320: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:20:59.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1567" for this suite. 04/18/23 09:20:59.468
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:20:59.473
Apr 18 09:20:59.473: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename job 04/18/23 09:20:59.474
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:20:59.483
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:20:59.487
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 04/18/23 09:20:59.491
STEP: Ensure pods equal to paralellism count is attached to the job 04/18/23 09:20:59.495
STEP: patching /status 04/18/23 09:21:01.5
STEP: updating /status 04/18/23 09:21:01.508
STEP: get /status 04/18/23 09:21:01.517
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 18 09:21:01.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8469" for this suite. 04/18/23 09:21:01.526
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":227,"skipped":4314,"failed":0}
------------------------------
• [2.059 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:20:59.473
    Apr 18 09:20:59.473: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename job 04/18/23 09:20:59.474
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:20:59.483
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:20:59.487
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 04/18/23 09:20:59.491
    STEP: Ensure pods equal to paralellism count is attached to the job 04/18/23 09:20:59.495
    STEP: patching /status 04/18/23 09:21:01.5
    STEP: updating /status 04/18/23 09:21:01.508
    STEP: get /status 04/18/23 09:21:01.517
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 18 09:21:01.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-8469" for this suite. 04/18/23 09:21:01.526
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:21:01.533
Apr 18 09:21:01.533: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename crd-webhook 04/18/23 09:21:01.534
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:01.544
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:01.548
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 04/18/23 09:21:01.554
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/18/23 09:21:01.991
STEP: Deploying the custom resource conversion webhook pod 04/18/23 09:21:01.997
STEP: Wait for the deployment to be ready 04/18/23 09:21:02.007
Apr 18 09:21:02.013: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 09:21:04.022
STEP: Verifying the service has paired with the endpoint 04/18/23 09:21:04.031
Apr 18 09:21:05.032: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Apr 18 09:21:05.035: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Creating a v1 custom resource 04/18/23 09:21:07.634
STEP: Create a v2 custom resource 04/18/23 09:21:07.651
STEP: List CRs in v1 04/18/23 09:21:07.716
STEP: List CRs in v2 04/18/23 09:21:07.721
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:21:08.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9734" for this suite. 04/18/23 09:21:08.245
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":228,"skipped":4316,"failed":0}
------------------------------
• [SLOW TEST] [6.751 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:21:01.533
    Apr 18 09:21:01.533: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename crd-webhook 04/18/23 09:21:01.534
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:01.544
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:01.548
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 04/18/23 09:21:01.554
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/18/23 09:21:01.991
    STEP: Deploying the custom resource conversion webhook pod 04/18/23 09:21:01.997
    STEP: Wait for the deployment to be ready 04/18/23 09:21:02.007
    Apr 18 09:21:02.013: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 09:21:04.022
    STEP: Verifying the service has paired with the endpoint 04/18/23 09:21:04.031
    Apr 18 09:21:05.032: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Apr 18 09:21:05.035: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Creating a v1 custom resource 04/18/23 09:21:07.634
    STEP: Create a v2 custom resource 04/18/23 09:21:07.651
    STEP: List CRs in v1 04/18/23 09:21:07.716
    STEP: List CRs in v2 04/18/23 09:21:07.721
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:21:08.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-9734" for this suite. 04/18/23 09:21:08.245
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:21:08.284
Apr 18 09:21:08.284: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename podtemplate 04/18/23 09:21:08.285
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:08.311
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:08.315
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 04/18/23 09:21:08.319
Apr 18 09:21:08.324: INFO: created test-podtemplate-1
Apr 18 09:21:08.328: INFO: created test-podtemplate-2
Apr 18 09:21:08.331: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 04/18/23 09:21:08.331
STEP: delete collection of pod templates 04/18/23 09:21:08.336
Apr 18 09:21:08.336: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 04/18/23 09:21:08.347
Apr 18 09:21:08.347: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Apr 18 09:21:08.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-7644" for this suite. 04/18/23 09:21:08.353
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":229,"skipped":4316,"failed":0}
------------------------------
• [0.075 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:21:08.284
    Apr 18 09:21:08.284: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename podtemplate 04/18/23 09:21:08.285
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:08.311
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:08.315
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 04/18/23 09:21:08.319
    Apr 18 09:21:08.324: INFO: created test-podtemplate-1
    Apr 18 09:21:08.328: INFO: created test-podtemplate-2
    Apr 18 09:21:08.331: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 04/18/23 09:21:08.331
    STEP: delete collection of pod templates 04/18/23 09:21:08.336
    Apr 18 09:21:08.336: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 04/18/23 09:21:08.347
    Apr 18 09:21:08.347: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Apr 18 09:21:08.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-7644" for this suite. 04/18/23 09:21:08.353
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:21:08.36
Apr 18 09:21:08.360: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 09:21:08.361
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:08.369
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:08.373
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-41387228-2992-4ce3-801f-b4e9add342ec 04/18/23 09:21:08.378
STEP: Creating a pod to test consume secrets 04/18/23 09:21:08.382
Apr 18 09:21:08.388: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d" in namespace "projected-1756" to be "Succeeded or Failed"
Apr 18 09:21:08.393: INFO: Pod "pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.978788ms
Apr 18 09:21:10.397: INFO: Pod "pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009011394s
Apr 18 09:21:12.396: INFO: Pod "pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008221545s
STEP: Saw pod success 04/18/23 09:21:12.396
Apr 18 09:21:12.396: INFO: Pod "pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d" satisfied condition "Succeeded or Failed"
Apr 18 09:21:12.399: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d container projected-secret-volume-test: <nil>
STEP: delete the pod 04/18/23 09:21:12.404
Apr 18 09:21:12.413: INFO: Waiting for pod pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d to disappear
Apr 18 09:21:12.417: INFO: Pod pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 18 09:21:12.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1756" for this suite. 04/18/23 09:21:12.421
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":230,"skipped":4338,"failed":0}
------------------------------
• [4.066 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:21:08.36
    Apr 18 09:21:08.360: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 09:21:08.361
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:08.369
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:08.373
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-41387228-2992-4ce3-801f-b4e9add342ec 04/18/23 09:21:08.378
    STEP: Creating a pod to test consume secrets 04/18/23 09:21:08.382
    Apr 18 09:21:08.388: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d" in namespace "projected-1756" to be "Succeeded or Failed"
    Apr 18 09:21:08.393: INFO: Pod "pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.978788ms
    Apr 18 09:21:10.397: INFO: Pod "pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009011394s
    Apr 18 09:21:12.396: INFO: Pod "pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008221545s
    STEP: Saw pod success 04/18/23 09:21:12.396
    Apr 18 09:21:12.396: INFO: Pod "pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d" satisfied condition "Succeeded or Failed"
    Apr 18 09:21:12.399: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 09:21:12.404
    Apr 18 09:21:12.413: INFO: Waiting for pod pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d to disappear
    Apr 18 09:21:12.417: INFO: Pod pod-projected-secrets-5af4b8f1-18d6-4173-b39e-bb4febdbfe8d no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 18 09:21:12.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1756" for this suite. 04/18/23 09:21:12.421
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:21:12.427
Apr 18 09:21:12.427: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename daemonsets 04/18/23 09:21:12.427
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:12.437
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:12.44
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 04/18/23 09:21:12.459
STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 09:21:12.464
Apr 18 09:21:12.471: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:21:12.471: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
Apr 18 09:21:13.481: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 09:21:13.481: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
Apr 18 09:21:14.479: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 09:21:14.479: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 04/18/23 09:21:14.482
STEP: DeleteCollection of the DaemonSets 04/18/23 09:21:14.485
STEP: Verify that ReplicaSets have been deleted 04/18/23 09:21:14.49
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Apr 18 09:21:14.504: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4192303"},"items":null}

Apr 18 09:21:14.507: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4192303"},"items":[{"metadata":{"name":"daemon-set-ccdgs","generateName":"daemon-set-","namespace":"daemonsets-2171","uid":"b134101b-eecb-4926-8b65-8193a458dc08","resourceVersion":"4192303","creationTimestamp":"2023-04-18T09:21:12Z","deletionTimestamp":"2023-04-18T09:21:44Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"71be1ce2-7dcb-4ec6-9aa6-e48f72fc70b2","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-18T09:21:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"71be1ce2-7dcb-4ec6-9aa6-e48f72fc70b2\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-18T09:21:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.83\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-k5v8j","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-k5v8j","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"192.168.1.29","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["192.168.1.29"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"dnsConfig":{"options":[{"name":"single-request-reopen","value":""},{"name":"timeout","value":"2"}]},"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:12Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:13Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:13Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:12Z"}],"hostIP":"192.168.1.29","podIP":"172.16.0.83","podIPs":[{"ip":"172.16.0.83"}],"startTime":"2023-04-18T09:21:12Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-18T09:21:13Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://9e3ca4c66be88cb19a6295214d488a0b45e44160ed5b7a9fd633b33ac9055d09","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-vfkxj","generateName":"daemon-set-","namespace":"daemonsets-2171","uid":"d6f72dfe-9f4a-45a1-b3a7-5be927095499","resourceVersion":"4192300","creationTimestamp":"2023-04-18T09:21:12Z","deletionTimestamp":"2023-04-18T09:21:44Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"71be1ce2-7dcb-4ec6-9aa6-e48f72fc70b2","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-18T09:21:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"71be1ce2-7dcb-4ec6-9aa6-e48f72fc70b2\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-18T09:21:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.237\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-6s4hr","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-6s4hr","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"192.168.1.84","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["192.168.1.84"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"dnsConfig":{"options":[{"name":"single-request-reopen","value":""},{"name":"timeout","value":"2"}]},"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:12Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:13Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:13Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:12Z"}],"hostIP":"192.168.1.84","podIP":"172.16.0.237","podIPs":[{"ip":"172.16.0.237"}],"startTime":"2023-04-18T09:21:12Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-18T09:21:13Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://b844239693a98abec8c85e08d136f149aa29c754d3b31b31943de74747a99f87","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-xt9wd","generateName":"daemon-set-","namespace":"daemonsets-2171","uid":"a3a77015-c108-4ae2-9146-6d1669f2f1e2","resourceVersion":"4192301","creationTimestamp":"2023-04-18T09:21:12Z","deletionTimestamp":"2023-04-18T09:21:44Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"71be1ce2-7dcb-4ec6-9aa6-e48f72fc70b2","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-18T09:21:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"71be1ce2-7dcb-4ec6-9aa6-e48f72fc70b2\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-18T09:21:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.125\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-rn7nq","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-rn7nq","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"192.168.1.152","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["192.168.1.152"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"dnsConfig":{"options":[{"name":"single-request-reopen","value":""},{"name":"timeout","value":"2"}]},"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:12Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:13Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:13Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:12Z"}],"hostIP":"192.168.1.152","podIP":"172.16.1.125","podIPs":[{"ip":"172.16.1.125"}],"startTime":"2023-04-18T09:21:12Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-18T09:21:13Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://a90c3213f9fef9d20fc6d0797791c23784b0dcb53c746cd0319c7b0836460c2d","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:21:14.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2171" for this suite. 04/18/23 09:21:14.522
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":231,"skipped":4362,"failed":0}
------------------------------
• [2.100 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:21:12.427
    Apr 18 09:21:12.427: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename daemonsets 04/18/23 09:21:12.427
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:12.437
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:12.44
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 04/18/23 09:21:12.459
    STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 09:21:12.464
    Apr 18 09:21:12.471: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:21:12.471: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
    Apr 18 09:21:13.481: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 09:21:13.481: INFO: Node 192.168.1.29 is running 0 daemon pod, expected 1
    Apr 18 09:21:14.479: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 09:21:14.479: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 04/18/23 09:21:14.482
    STEP: DeleteCollection of the DaemonSets 04/18/23 09:21:14.485
    STEP: Verify that ReplicaSets have been deleted 04/18/23 09:21:14.49
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Apr 18 09:21:14.504: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4192303"},"items":null}

    Apr 18 09:21:14.507: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4192303"},"items":[{"metadata":{"name":"daemon-set-ccdgs","generateName":"daemon-set-","namespace":"daemonsets-2171","uid":"b134101b-eecb-4926-8b65-8193a458dc08","resourceVersion":"4192303","creationTimestamp":"2023-04-18T09:21:12Z","deletionTimestamp":"2023-04-18T09:21:44Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"71be1ce2-7dcb-4ec6-9aa6-e48f72fc70b2","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-18T09:21:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"71be1ce2-7dcb-4ec6-9aa6-e48f72fc70b2\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-18T09:21:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.83\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-k5v8j","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-k5v8j","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"192.168.1.29","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["192.168.1.29"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"dnsConfig":{"options":[{"name":"single-request-reopen","value":""},{"name":"timeout","value":"2"}]},"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:12Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:13Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:13Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:12Z"}],"hostIP":"192.168.1.29","podIP":"172.16.0.83","podIPs":[{"ip":"172.16.0.83"}],"startTime":"2023-04-18T09:21:12Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-18T09:21:13Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://9e3ca4c66be88cb19a6295214d488a0b45e44160ed5b7a9fd633b33ac9055d09","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-vfkxj","generateName":"daemon-set-","namespace":"daemonsets-2171","uid":"d6f72dfe-9f4a-45a1-b3a7-5be927095499","resourceVersion":"4192300","creationTimestamp":"2023-04-18T09:21:12Z","deletionTimestamp":"2023-04-18T09:21:44Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"71be1ce2-7dcb-4ec6-9aa6-e48f72fc70b2","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-18T09:21:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"71be1ce2-7dcb-4ec6-9aa6-e48f72fc70b2\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-18T09:21:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.237\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-6s4hr","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-6s4hr","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"192.168.1.84","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["192.168.1.84"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"dnsConfig":{"options":[{"name":"single-request-reopen","value":""},{"name":"timeout","value":"2"}]},"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:12Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:13Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:13Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:12Z"}],"hostIP":"192.168.1.84","podIP":"172.16.0.237","podIPs":[{"ip":"172.16.0.237"}],"startTime":"2023-04-18T09:21:12Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-18T09:21:13Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://b844239693a98abec8c85e08d136f149aa29c754d3b31b31943de74747a99f87","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-xt9wd","generateName":"daemon-set-","namespace":"daemonsets-2171","uid":"a3a77015-c108-4ae2-9146-6d1669f2f1e2","resourceVersion":"4192301","creationTimestamp":"2023-04-18T09:21:12Z","deletionTimestamp":"2023-04-18T09:21:44Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"71be1ce2-7dcb-4ec6-9aa6-e48f72fc70b2","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-18T09:21:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"71be1ce2-7dcb-4ec6-9aa6-e48f72fc70b2\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-18T09:21:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.125\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-rn7nq","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-rn7nq","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"192.168.1.152","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["192.168.1.152"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"dnsConfig":{"options":[{"name":"single-request-reopen","value":""},{"name":"timeout","value":"2"}]},"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:12Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:13Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:13Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T09:21:12Z"}],"hostIP":"192.168.1.152","podIP":"172.16.1.125","podIPs":[{"ip":"172.16.1.125"}],"startTime":"2023-04-18T09:21:12Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-18T09:21:13Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://a90c3213f9fef9d20fc6d0797791c23784b0dcb53c746cd0319c7b0836460c2d","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:21:14.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-2171" for this suite. 04/18/23 09:21:14.522
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:21:14.527
Apr 18 09:21:14.527: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 09:21:14.528
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:14.539
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:14.542
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 04/18/23 09:21:14.546
Apr 18 09:21:14.554: INFO: Waiting up to 5m0s for pod "annotationupdate36cdd645-2ce1-4523-a2a2-396d46b46627" in namespace "downward-api-7047" to be "running and ready"
Apr 18 09:21:14.559: INFO: Pod "annotationupdate36cdd645-2ce1-4523-a2a2-396d46b46627": Phase="Pending", Reason="", readiness=false. Elapsed: 4.26304ms
Apr 18 09:21:14.559: INFO: The phase of Pod annotationupdate36cdd645-2ce1-4523-a2a2-396d46b46627 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:21:16.562: INFO: Pod "annotationupdate36cdd645-2ce1-4523-a2a2-396d46b46627": Phase="Running", Reason="", readiness=true. Elapsed: 2.007947972s
Apr 18 09:21:16.562: INFO: The phase of Pod annotationupdate36cdd645-2ce1-4523-a2a2-396d46b46627 is Running (Ready = true)
Apr 18 09:21:16.562: INFO: Pod "annotationupdate36cdd645-2ce1-4523-a2a2-396d46b46627" satisfied condition "running and ready"
Apr 18 09:21:17.080: INFO: Successfully updated pod "annotationupdate36cdd645-2ce1-4523-a2a2-396d46b46627"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 09:21:21.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7047" for this suite. 04/18/23 09:21:21.101
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":232,"skipped":4371,"failed":0}
------------------------------
• [SLOW TEST] [6.578 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:21:14.527
    Apr 18 09:21:14.527: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 09:21:14.528
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:14.539
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:14.542
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 04/18/23 09:21:14.546
    Apr 18 09:21:14.554: INFO: Waiting up to 5m0s for pod "annotationupdate36cdd645-2ce1-4523-a2a2-396d46b46627" in namespace "downward-api-7047" to be "running and ready"
    Apr 18 09:21:14.559: INFO: Pod "annotationupdate36cdd645-2ce1-4523-a2a2-396d46b46627": Phase="Pending", Reason="", readiness=false. Elapsed: 4.26304ms
    Apr 18 09:21:14.559: INFO: The phase of Pod annotationupdate36cdd645-2ce1-4523-a2a2-396d46b46627 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:21:16.562: INFO: Pod "annotationupdate36cdd645-2ce1-4523-a2a2-396d46b46627": Phase="Running", Reason="", readiness=true. Elapsed: 2.007947972s
    Apr 18 09:21:16.562: INFO: The phase of Pod annotationupdate36cdd645-2ce1-4523-a2a2-396d46b46627 is Running (Ready = true)
    Apr 18 09:21:16.562: INFO: Pod "annotationupdate36cdd645-2ce1-4523-a2a2-396d46b46627" satisfied condition "running and ready"
    Apr 18 09:21:17.080: INFO: Successfully updated pod "annotationupdate36cdd645-2ce1-4523-a2a2-396d46b46627"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 09:21:21.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7047" for this suite. 04/18/23 09:21:21.101
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:21:21.106
Apr 18 09:21:21.106: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 09:21:21.107
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:21.116
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:21.12
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 09:21:21.133
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:21:21.499
STEP: Deploying the webhook pod 04/18/23 09:21:21.504
STEP: Wait for the deployment to be ready 04/18/23 09:21:21.515
Apr 18 09:21:21.521: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 09:21:23.531
STEP: Verifying the service has paired with the endpoint 04/18/23 09:21:23.54
Apr 18 09:21:24.541: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 04/18/23 09:21:24.545
STEP: Updating a mutating webhook configuration's rules to not include the create operation 04/18/23 09:21:24.565
STEP: Creating a configMap that should not be mutated 04/18/23 09:21:24.571
STEP: Patching a mutating webhook configuration's rules to include the create operation 04/18/23 09:21:24.58
STEP: Creating a configMap that should be mutated 04/18/23 09:21:24.587
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:21:24.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1879" for this suite. 04/18/23 09:21:24.609
STEP: Destroying namespace "webhook-1879-markers" for this suite. 04/18/23 09:21:24.614
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":233,"skipped":4389,"failed":0}
------------------------------
• [3.564 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:21:21.106
    Apr 18 09:21:21.106: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 09:21:21.107
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:21.116
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:21.12
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 09:21:21.133
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:21:21.499
    STEP: Deploying the webhook pod 04/18/23 09:21:21.504
    STEP: Wait for the deployment to be ready 04/18/23 09:21:21.515
    Apr 18 09:21:21.521: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 09:21:23.531
    STEP: Verifying the service has paired with the endpoint 04/18/23 09:21:23.54
    Apr 18 09:21:24.541: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 04/18/23 09:21:24.545
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 04/18/23 09:21:24.565
    STEP: Creating a configMap that should not be mutated 04/18/23 09:21:24.571
    STEP: Patching a mutating webhook configuration's rules to include the create operation 04/18/23 09:21:24.58
    STEP: Creating a configMap that should be mutated 04/18/23 09:21:24.587
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:21:24.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1879" for this suite. 04/18/23 09:21:24.609
    STEP: Destroying namespace "webhook-1879-markers" for this suite. 04/18/23 09:21:24.614
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:21:24.67
Apr 18 09:21:24.671: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename security-context-test 04/18/23 09:21:24.671
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:24.687
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:24.691
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Apr 18 09:21:24.701: INFO: Waiting up to 5m0s for pod "busybox-user-65534-85eb1811-315a-4db6-a1fe-b34fbd0979a7" in namespace "security-context-test-414" to be "Succeeded or Failed"
Apr 18 09:21:24.704: INFO: Pod "busybox-user-65534-85eb1811-315a-4db6-a1fe-b34fbd0979a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.49346ms
Apr 18 09:21:26.708: INFO: Pod "busybox-user-65534-85eb1811-315a-4db6-a1fe-b34fbd0979a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006664418s
Apr 18 09:21:28.707: INFO: Pod "busybox-user-65534-85eb1811-315a-4db6-a1fe-b34fbd0979a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006021375s
Apr 18 09:21:28.707: INFO: Pod "busybox-user-65534-85eb1811-315a-4db6-a1fe-b34fbd0979a7" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 18 09:21:28.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-414" for this suite. 04/18/23 09:21:28.712
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":234,"skipped":4401,"failed":0}
------------------------------
• [4.046 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:21:24.67
    Apr 18 09:21:24.671: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename security-context-test 04/18/23 09:21:24.671
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:24.687
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:24.691
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Apr 18 09:21:24.701: INFO: Waiting up to 5m0s for pod "busybox-user-65534-85eb1811-315a-4db6-a1fe-b34fbd0979a7" in namespace "security-context-test-414" to be "Succeeded or Failed"
    Apr 18 09:21:24.704: INFO: Pod "busybox-user-65534-85eb1811-315a-4db6-a1fe-b34fbd0979a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.49346ms
    Apr 18 09:21:26.708: INFO: Pod "busybox-user-65534-85eb1811-315a-4db6-a1fe-b34fbd0979a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006664418s
    Apr 18 09:21:28.707: INFO: Pod "busybox-user-65534-85eb1811-315a-4db6-a1fe-b34fbd0979a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006021375s
    Apr 18 09:21:28.707: INFO: Pod "busybox-user-65534-85eb1811-315a-4db6-a1fe-b34fbd0979a7" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 18 09:21:28.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-414" for this suite. 04/18/23 09:21:28.712
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:21:28.718
Apr 18 09:21:28.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename svcaccounts 04/18/23 09:21:28.719
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:28.731
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:28.735
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Apr 18 09:21:28.749: INFO: Waiting up to 5m0s for pod "pod-service-account-37981464-6969-4827-8651-d6e4c11e64f9" in namespace "svcaccounts-9583" to be "running"
Apr 18 09:21:28.752: INFO: Pod "pod-service-account-37981464-6969-4827-8651-d6e4c11e64f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.620052ms
Apr 18 09:21:30.757: INFO: Pod "pod-service-account-37981464-6969-4827-8651-d6e4c11e64f9": Phase="Running", Reason="", readiness=true. Elapsed: 2.007912651s
Apr 18 09:21:30.757: INFO: Pod "pod-service-account-37981464-6969-4827-8651-d6e4c11e64f9" satisfied condition "running"
STEP: reading a file in the container 04/18/23 09:21:30.757
Apr 18 09:21:30.757: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9583 pod-service-account-37981464-6969-4827-8651-d6e4c11e64f9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 04/18/23 09:21:30.872
Apr 18 09:21:30.872: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9583 pod-service-account-37981464-6969-4827-8651-d6e4c11e64f9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 04/18/23 09:21:30.972
Apr 18 09:21:30.972: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9583 pod-service-account-37981464-6969-4827-8651-d6e4c11e64f9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Apr 18 09:21:31.076: INFO: Got root ca configmap in namespace "svcaccounts-9583"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 18 09:21:31.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9583" for this suite. 04/18/23 09:21:31.083
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":235,"skipped":4427,"failed":0}
------------------------------
• [2.369 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:21:28.718
    Apr 18 09:21:28.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename svcaccounts 04/18/23 09:21:28.719
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:28.731
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:28.735
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Apr 18 09:21:28.749: INFO: Waiting up to 5m0s for pod "pod-service-account-37981464-6969-4827-8651-d6e4c11e64f9" in namespace "svcaccounts-9583" to be "running"
    Apr 18 09:21:28.752: INFO: Pod "pod-service-account-37981464-6969-4827-8651-d6e4c11e64f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.620052ms
    Apr 18 09:21:30.757: INFO: Pod "pod-service-account-37981464-6969-4827-8651-d6e4c11e64f9": Phase="Running", Reason="", readiness=true. Elapsed: 2.007912651s
    Apr 18 09:21:30.757: INFO: Pod "pod-service-account-37981464-6969-4827-8651-d6e4c11e64f9" satisfied condition "running"
    STEP: reading a file in the container 04/18/23 09:21:30.757
    Apr 18 09:21:30.757: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9583 pod-service-account-37981464-6969-4827-8651-d6e4c11e64f9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 04/18/23 09:21:30.872
    Apr 18 09:21:30.872: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9583 pod-service-account-37981464-6969-4827-8651-d6e4c11e64f9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 04/18/23 09:21:30.972
    Apr 18 09:21:30.972: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9583 pod-service-account-37981464-6969-4827-8651-d6e4c11e64f9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Apr 18 09:21:31.076: INFO: Got root ca configmap in namespace "svcaccounts-9583"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 18 09:21:31.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9583" for this suite. 04/18/23 09:21:31.083
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:21:31.088
Apr 18 09:21:31.088: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir 04/18/23 09:21:31.091
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:31.1
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:31.104
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 04/18/23 09:21:31.108
Apr 18 09:21:31.113: INFO: Waiting up to 5m0s for pod "pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f" in namespace "emptydir-9224" to be "Succeeded or Failed"
Apr 18 09:21:31.116: INFO: Pod "pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.462695ms
Apr 18 09:21:33.119: INFO: Pod "pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006031047s
Apr 18 09:21:35.120: INFO: Pod "pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0070435s
STEP: Saw pod success 04/18/23 09:21:35.12
Apr 18 09:21:35.120: INFO: Pod "pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f" satisfied condition "Succeeded or Failed"
Apr 18 09:21:35.123: INFO: Trying to get logs from node 192.168.1.152 pod pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f container test-container: <nil>
STEP: delete the pod 04/18/23 09:21:35.128
Apr 18 09:21:35.137: INFO: Waiting for pod pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f to disappear
Apr 18 09:21:35.140: INFO: Pod pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 09:21:35.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9224" for this suite. 04/18/23 09:21:35.144
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":236,"skipped":4430,"failed":0}
------------------------------
• [4.061 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:21:31.088
    Apr 18 09:21:31.088: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir 04/18/23 09:21:31.091
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:31.1
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:31.104
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 04/18/23 09:21:31.108
    Apr 18 09:21:31.113: INFO: Waiting up to 5m0s for pod "pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f" in namespace "emptydir-9224" to be "Succeeded or Failed"
    Apr 18 09:21:31.116: INFO: Pod "pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.462695ms
    Apr 18 09:21:33.119: INFO: Pod "pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006031047s
    Apr 18 09:21:35.120: INFO: Pod "pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0070435s
    STEP: Saw pod success 04/18/23 09:21:35.12
    Apr 18 09:21:35.120: INFO: Pod "pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f" satisfied condition "Succeeded or Failed"
    Apr 18 09:21:35.123: INFO: Trying to get logs from node 192.168.1.152 pod pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f container test-container: <nil>
    STEP: delete the pod 04/18/23 09:21:35.128
    Apr 18 09:21:35.137: INFO: Waiting for pod pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f to disappear
    Apr 18 09:21:35.140: INFO: Pod pod-fea838f8-7ca0-4ac8-a359-f49ceac31f0f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 09:21:35.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9224" for this suite. 04/18/23 09:21:35.144
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:21:35.149
Apr 18 09:21:35.149: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir-wrapper 04/18/23 09:21:35.15
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:35.162
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:35.166
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Apr 18 09:21:35.191: INFO: Waiting up to 5m0s for pod "pod-secrets-a1439f71-fbc0-401d-995b-8a6afdd1d7b8" in namespace "emptydir-wrapper-4302" to be "running and ready"
Apr 18 09:21:35.193: INFO: Pod "pod-secrets-a1439f71-fbc0-401d-995b-8a6afdd1d7b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.459139ms
Apr 18 09:21:35.193: INFO: The phase of Pod pod-secrets-a1439f71-fbc0-401d-995b-8a6afdd1d7b8 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:21:37.198: INFO: Pod "pod-secrets-a1439f71-fbc0-401d-995b-8a6afdd1d7b8": Phase="Running", Reason="", readiness=true. Elapsed: 2.00704973s
Apr 18 09:21:37.198: INFO: The phase of Pod pod-secrets-a1439f71-fbc0-401d-995b-8a6afdd1d7b8 is Running (Ready = true)
Apr 18 09:21:37.198: INFO: Pod "pod-secrets-a1439f71-fbc0-401d-995b-8a6afdd1d7b8" satisfied condition "running and ready"
STEP: Cleaning up the secret 04/18/23 09:21:37.201
STEP: Cleaning up the configmap 04/18/23 09:21:37.205
STEP: Cleaning up the pod 04/18/23 09:21:37.209
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Apr 18 09:21:37.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4302" for this suite. 04/18/23 09:21:37.223
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":237,"skipped":4434,"failed":0}
------------------------------
• [2.078 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:21:35.149
    Apr 18 09:21:35.149: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir-wrapper 04/18/23 09:21:35.15
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:35.162
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:35.166
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Apr 18 09:21:35.191: INFO: Waiting up to 5m0s for pod "pod-secrets-a1439f71-fbc0-401d-995b-8a6afdd1d7b8" in namespace "emptydir-wrapper-4302" to be "running and ready"
    Apr 18 09:21:35.193: INFO: Pod "pod-secrets-a1439f71-fbc0-401d-995b-8a6afdd1d7b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.459139ms
    Apr 18 09:21:35.193: INFO: The phase of Pod pod-secrets-a1439f71-fbc0-401d-995b-8a6afdd1d7b8 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:21:37.198: INFO: Pod "pod-secrets-a1439f71-fbc0-401d-995b-8a6afdd1d7b8": Phase="Running", Reason="", readiness=true. Elapsed: 2.00704973s
    Apr 18 09:21:37.198: INFO: The phase of Pod pod-secrets-a1439f71-fbc0-401d-995b-8a6afdd1d7b8 is Running (Ready = true)
    Apr 18 09:21:37.198: INFO: Pod "pod-secrets-a1439f71-fbc0-401d-995b-8a6afdd1d7b8" satisfied condition "running and ready"
    STEP: Cleaning up the secret 04/18/23 09:21:37.201
    STEP: Cleaning up the configmap 04/18/23 09:21:37.205
    STEP: Cleaning up the pod 04/18/23 09:21:37.209
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Apr 18 09:21:37.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-4302" for this suite. 04/18/23 09:21:37.223
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:21:37.234
Apr 18 09:21:37.234: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename lease-test 04/18/23 09:21:37.235
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:37.253
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:37.256
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Apr 18 09:21:37.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-2588" for this suite. 04/18/23 09:21:37.305
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":238,"skipped":4483,"failed":0}
------------------------------
• [0.076 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:21:37.234
    Apr 18 09:21:37.234: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename lease-test 04/18/23 09:21:37.235
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:37.253
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:37.256
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Apr 18 09:21:37.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-2588" for this suite. 04/18/23 09:21:37.305
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:21:37.31
Apr 18 09:21:37.310: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir 04/18/23 09:21:37.311
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:37.32
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:37.324
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 04/18/23 09:21:37.328
Apr 18 09:21:37.333: INFO: Waiting up to 5m0s for pod "pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06" in namespace "emptydir-3955" to be "Succeeded or Failed"
Apr 18 09:21:37.335: INFO: Pod "pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.366442ms
Apr 18 09:21:39.339: INFO: Pod "pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005599891s
Apr 18 09:21:41.339: INFO: Pod "pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006487592s
STEP: Saw pod success 04/18/23 09:21:41.339
Apr 18 09:21:41.340: INFO: Pod "pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06" satisfied condition "Succeeded or Failed"
Apr 18 09:21:41.346: INFO: Trying to get logs from node 192.168.1.152 pod pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06 container test-container: <nil>
STEP: delete the pod 04/18/23 09:21:41.35
Apr 18 09:21:41.363: INFO: Waiting for pod pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06 to disappear
Apr 18 09:21:41.366: INFO: Pod pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 09:21:41.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3955" for this suite. 04/18/23 09:21:41.372
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":239,"skipped":4488,"failed":0}
------------------------------
• [4.066 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:21:37.31
    Apr 18 09:21:37.310: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir 04/18/23 09:21:37.311
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:37.32
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:37.324
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 04/18/23 09:21:37.328
    Apr 18 09:21:37.333: INFO: Waiting up to 5m0s for pod "pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06" in namespace "emptydir-3955" to be "Succeeded or Failed"
    Apr 18 09:21:37.335: INFO: Pod "pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.366442ms
    Apr 18 09:21:39.339: INFO: Pod "pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005599891s
    Apr 18 09:21:41.339: INFO: Pod "pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006487592s
    STEP: Saw pod success 04/18/23 09:21:41.339
    Apr 18 09:21:41.340: INFO: Pod "pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06" satisfied condition "Succeeded or Failed"
    Apr 18 09:21:41.346: INFO: Trying to get logs from node 192.168.1.152 pod pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06 container test-container: <nil>
    STEP: delete the pod 04/18/23 09:21:41.35
    Apr 18 09:21:41.363: INFO: Waiting for pod pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06 to disappear
    Apr 18 09:21:41.366: INFO: Pod pod-4493df7c-ff4c-4e5c-8101-b8f4b758fc06 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 09:21:41.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3955" for this suite. 04/18/23 09:21:41.372
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:21:41.377
Apr 18 09:21:41.377: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename var-expansion 04/18/23 09:21:41.378
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:41.387
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:41.391
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 04/18/23 09:21:41.395
Apr 18 09:21:41.402: INFO: Waiting up to 2m0s for pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7" in namespace "var-expansion-7285" to be "running"
Apr 18 09:21:41.405: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.52612ms
Apr 18 09:21:43.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006511799s
Apr 18 09:21:45.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006166914s
Apr 18 09:21:47.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007360287s
Apr 18 09:21:49.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.007017923s
Apr 18 09:21:51.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.006977474s
Apr 18 09:21:53.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.006002547s
Apr 18 09:21:55.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.007318681s
Apr 18 09:21:57.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.007286136s
Apr 18 09:21:59.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 18.006681168s
Apr 18 09:22:01.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 20.006046493s
Apr 18 09:22:03.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 22.005727569s
Apr 18 09:22:05.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 24.005794338s
Apr 18 09:22:07.407: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 26.005474449s
Apr 18 09:22:09.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 28.007206854s
Apr 18 09:22:11.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 30.007295095s
Apr 18 09:22:13.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 32.006278539s
Apr 18 09:22:15.410: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 34.007741217s
Apr 18 09:22:17.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 36.007031321s
Apr 18 09:22:19.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 38.005863114s
Apr 18 09:22:21.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 40.006519809s
Apr 18 09:22:23.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.006051791s
Apr 18 09:22:25.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 44.006033404s
Apr 18 09:22:27.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 46.006020025s
Apr 18 09:22:29.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 48.007207879s
Apr 18 09:22:31.410: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 50.008044384s
Apr 18 09:22:33.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 52.0058802s
Apr 18 09:22:35.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 54.006139043s
Apr 18 09:22:37.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 56.005915414s
Apr 18 09:22:39.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 58.006410662s
Apr 18 09:22:41.410: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.007726525s
Apr 18 09:22:43.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.006466689s
Apr 18 09:22:45.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.007197659s
Apr 18 09:22:47.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.005833866s
Apr 18 09:22:49.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.006890667s
Apr 18 09:22:51.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.006074241s
Apr 18 09:22:53.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.006309179s
Apr 18 09:22:55.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.006142607s
Apr 18 09:22:57.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.006120672s
Apr 18 09:22:59.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.00735264s
Apr 18 09:23:01.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.007119954s
Apr 18 09:23:03.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.006463111s
Apr 18 09:23:05.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.006504835s
Apr 18 09:23:07.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.006042891s
Apr 18 09:23:09.410: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.007648987s
Apr 18 09:23:11.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.006130612s
Apr 18 09:23:13.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.006077455s
Apr 18 09:23:15.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.005990181s
Apr 18 09:23:17.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.006563604s
Apr 18 09:23:19.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.006947486s
Apr 18 09:23:21.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.006061564s
Apr 18 09:23:23.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.006570866s
Apr 18 09:23:25.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.006024645s
Apr 18 09:23:27.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.006237867s
Apr 18 09:23:29.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.006660998s
Apr 18 09:23:31.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.005956686s
Apr 18 09:23:33.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.006087147s
Apr 18 09:23:35.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.0074959s
Apr 18 09:23:37.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.007422343s
Apr 18 09:23:39.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.006152014s
Apr 18 09:23:41.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.007307375s
Apr 18 09:23:41.412: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.010197167s
STEP: updating the pod 04/18/23 09:23:41.412
Apr 18 09:23:41.924: INFO: Successfully updated pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7"
STEP: waiting for pod running 04/18/23 09:23:41.924
Apr 18 09:23:41.924: INFO: Waiting up to 2m0s for pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7" in namespace "var-expansion-7285" to be "running"
Apr 18 09:23:41.927: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.213525ms
Apr 18 09:23:43.931: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Running", Reason="", readiness=true. Elapsed: 2.006956783s
Apr 18 09:23:43.931: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7" satisfied condition "running"
STEP: deleting the pod gracefully 04/18/23 09:23:43.931
Apr 18 09:23:43.931: INFO: Deleting pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7" in namespace "var-expansion-7285"
Apr 18 09:23:43.940: INFO: Wait up to 5m0s for pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 09:24:15.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7285" for this suite. 04/18/23 09:24:15.951
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":240,"skipped":4523,"failed":0}
------------------------------
• [SLOW TEST] [154.579 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:21:41.377
    Apr 18 09:21:41.377: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename var-expansion 04/18/23 09:21:41.378
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:21:41.387
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:21:41.391
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 04/18/23 09:21:41.395
    Apr 18 09:21:41.402: INFO: Waiting up to 2m0s for pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7" in namespace "var-expansion-7285" to be "running"
    Apr 18 09:21:41.405: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.52612ms
    Apr 18 09:21:43.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006511799s
    Apr 18 09:21:45.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006166914s
    Apr 18 09:21:47.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007360287s
    Apr 18 09:21:49.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.007017923s
    Apr 18 09:21:51.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.006977474s
    Apr 18 09:21:53.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.006002547s
    Apr 18 09:21:55.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.007318681s
    Apr 18 09:21:57.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.007286136s
    Apr 18 09:21:59.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 18.006681168s
    Apr 18 09:22:01.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 20.006046493s
    Apr 18 09:22:03.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 22.005727569s
    Apr 18 09:22:05.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 24.005794338s
    Apr 18 09:22:07.407: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 26.005474449s
    Apr 18 09:22:09.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 28.007206854s
    Apr 18 09:22:11.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 30.007295095s
    Apr 18 09:22:13.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 32.006278539s
    Apr 18 09:22:15.410: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 34.007741217s
    Apr 18 09:22:17.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 36.007031321s
    Apr 18 09:22:19.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 38.005863114s
    Apr 18 09:22:21.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 40.006519809s
    Apr 18 09:22:23.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.006051791s
    Apr 18 09:22:25.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 44.006033404s
    Apr 18 09:22:27.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 46.006020025s
    Apr 18 09:22:29.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 48.007207879s
    Apr 18 09:22:31.410: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 50.008044384s
    Apr 18 09:22:33.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 52.0058802s
    Apr 18 09:22:35.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 54.006139043s
    Apr 18 09:22:37.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 56.005915414s
    Apr 18 09:22:39.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 58.006410662s
    Apr 18 09:22:41.410: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.007726525s
    Apr 18 09:22:43.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.006466689s
    Apr 18 09:22:45.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.007197659s
    Apr 18 09:22:47.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.005833866s
    Apr 18 09:22:49.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.006890667s
    Apr 18 09:22:51.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.006074241s
    Apr 18 09:22:53.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.006309179s
    Apr 18 09:22:55.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.006142607s
    Apr 18 09:22:57.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.006120672s
    Apr 18 09:22:59.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.00735264s
    Apr 18 09:23:01.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.007119954s
    Apr 18 09:23:03.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.006463111s
    Apr 18 09:23:05.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.006504835s
    Apr 18 09:23:07.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.006042891s
    Apr 18 09:23:09.410: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.007648987s
    Apr 18 09:23:11.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.006130612s
    Apr 18 09:23:13.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.006077455s
    Apr 18 09:23:15.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.005990181s
    Apr 18 09:23:17.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.006563604s
    Apr 18 09:23:19.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.006947486s
    Apr 18 09:23:21.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.006061564s
    Apr 18 09:23:23.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.006570866s
    Apr 18 09:23:25.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.006024645s
    Apr 18 09:23:27.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.006237867s
    Apr 18 09:23:29.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.006660998s
    Apr 18 09:23:31.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.005956686s
    Apr 18 09:23:33.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.006087147s
    Apr 18 09:23:35.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.0074959s
    Apr 18 09:23:37.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.007422343s
    Apr 18 09:23:39.408: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.006152014s
    Apr 18 09:23:41.409: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.007307375s
    Apr 18 09:23:41.412: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.010197167s
    STEP: updating the pod 04/18/23 09:23:41.412
    Apr 18 09:23:41.924: INFO: Successfully updated pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7"
    STEP: waiting for pod running 04/18/23 09:23:41.924
    Apr 18 09:23:41.924: INFO: Waiting up to 2m0s for pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7" in namespace "var-expansion-7285" to be "running"
    Apr 18 09:23:41.927: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.213525ms
    Apr 18 09:23:43.931: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7": Phase="Running", Reason="", readiness=true. Elapsed: 2.006956783s
    Apr 18 09:23:43.931: INFO: Pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7" satisfied condition "running"
    STEP: deleting the pod gracefully 04/18/23 09:23:43.931
    Apr 18 09:23:43.931: INFO: Deleting pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7" in namespace "var-expansion-7285"
    Apr 18 09:23:43.940: INFO: Wait up to 5m0s for pod "var-expansion-b9793d46-da7f-46f3-9037-9dcf63831bf7" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 09:24:15.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7285" for this suite. 04/18/23 09:24:15.951
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:24:15.957
Apr 18 09:24:15.957: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename replicaset 04/18/23 09:24:15.958
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:24:15.968
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:24:15.972
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 04/18/23 09:24:15.976
Apr 18 09:24:15.982: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-6129" to be "running and ready"
Apr 18 09:24:15.986: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 3.839012ms
Apr 18 09:24:15.986: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:24:17.990: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.008093625s
Apr 18 09:24:17.991: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Apr 18 09:24:17.991: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 04/18/23 09:24:17.993
STEP: Then the orphan pod is adopted 04/18/23 09:24:17.998
STEP: When the matched label of one of its pods change 04/18/23 09:24:19.004
Apr 18 09:24:19.007: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 04/18/23 09:24:19.019
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 18 09:24:20.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6129" for this suite. 04/18/23 09:24:20.029
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":241,"skipped":4545,"failed":0}
------------------------------
• [4.077 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:24:15.957
    Apr 18 09:24:15.957: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename replicaset 04/18/23 09:24:15.958
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:24:15.968
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:24:15.972
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 04/18/23 09:24:15.976
    Apr 18 09:24:15.982: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-6129" to be "running and ready"
    Apr 18 09:24:15.986: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 3.839012ms
    Apr 18 09:24:15.986: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:24:17.990: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.008093625s
    Apr 18 09:24:17.991: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Apr 18 09:24:17.991: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 04/18/23 09:24:17.993
    STEP: Then the orphan pod is adopted 04/18/23 09:24:17.998
    STEP: When the matched label of one of its pods change 04/18/23 09:24:19.004
    Apr 18 09:24:19.007: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 04/18/23 09:24:19.019
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 18 09:24:20.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-6129" for this suite. 04/18/23 09:24:20.029
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:24:20.035
Apr 18 09:24:20.035: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename namespaces 04/18/23 09:24:20.035
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:24:20.046
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:24:20.05
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 04/18/23 09:24:20.054
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:24:20.062
STEP: Creating a pod in the namespace 04/18/23 09:24:20.066
STEP: Waiting for the pod to have running status 04/18/23 09:24:20.073
Apr 18 09:24:20.073: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-6754" to be "running"
Apr 18 09:24:20.075: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.549927ms
Apr 18 09:24:22.080: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007259567s
Apr 18 09:24:22.080: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 04/18/23 09:24:22.08
STEP: Waiting for the namespace to be removed. 04/18/23 09:24:22.087
STEP: Recreating the namespace 04/18/23 09:24:33.09
STEP: Verifying there are no pods in the namespace 04/18/23 09:24:33.102
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:24:33.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8295" for this suite. 04/18/23 09:24:33.11
STEP: Destroying namespace "nsdeletetest-6754" for this suite. 04/18/23 09:24:33.115
Apr 18 09:24:33.117: INFO: Namespace nsdeletetest-6754 was already deleted
STEP: Destroying namespace "nsdeletetest-3338" for this suite. 04/18/23 09:24:33.117
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":242,"skipped":4565,"failed":0}
------------------------------
• [SLOW TEST] [13.087 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:24:20.035
    Apr 18 09:24:20.035: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename namespaces 04/18/23 09:24:20.035
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:24:20.046
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:24:20.05
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 04/18/23 09:24:20.054
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:24:20.062
    STEP: Creating a pod in the namespace 04/18/23 09:24:20.066
    STEP: Waiting for the pod to have running status 04/18/23 09:24:20.073
    Apr 18 09:24:20.073: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-6754" to be "running"
    Apr 18 09:24:20.075: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.549927ms
    Apr 18 09:24:22.080: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007259567s
    Apr 18 09:24:22.080: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 04/18/23 09:24:22.08
    STEP: Waiting for the namespace to be removed. 04/18/23 09:24:22.087
    STEP: Recreating the namespace 04/18/23 09:24:33.09
    STEP: Verifying there are no pods in the namespace 04/18/23 09:24:33.102
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:24:33.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-8295" for this suite. 04/18/23 09:24:33.11
    STEP: Destroying namespace "nsdeletetest-6754" for this suite. 04/18/23 09:24:33.115
    Apr 18 09:24:33.117: INFO: Namespace nsdeletetest-6754 was already deleted
    STEP: Destroying namespace "nsdeletetest-3338" for this suite. 04/18/23 09:24:33.117
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:24:33.123
Apr 18 09:24:33.123: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 09:24:33.123
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:24:33.135
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:24:33.138
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 04/18/23 09:24:33.142
Apr 18 09:24:33.150: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca" in namespace "downward-api-5418" to be "Succeeded or Failed"
Apr 18 09:24:33.154: INFO: Pod "downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca": Phase="Pending", Reason="", readiness=false. Elapsed: 3.814727ms
Apr 18 09:24:35.160: INFO: Pod "downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009426659s
Apr 18 09:24:37.157: INFO: Pod "downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007044045s
STEP: Saw pod success 04/18/23 09:24:37.157
Apr 18 09:24:37.157: INFO: Pod "downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca" satisfied condition "Succeeded or Failed"
Apr 18 09:24:37.160: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca container client-container: <nil>
STEP: delete the pod 04/18/23 09:24:37.173
Apr 18 09:24:37.181: INFO: Waiting for pod downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca to disappear
Apr 18 09:24:37.184: INFO: Pod downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 09:24:37.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5418" for this suite. 04/18/23 09:24:37.188
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":243,"skipped":4567,"failed":0}
------------------------------
• [4.071 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:24:33.123
    Apr 18 09:24:33.123: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 09:24:33.123
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:24:33.135
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:24:33.138
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 04/18/23 09:24:33.142
    Apr 18 09:24:33.150: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca" in namespace "downward-api-5418" to be "Succeeded or Failed"
    Apr 18 09:24:33.154: INFO: Pod "downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca": Phase="Pending", Reason="", readiness=false. Elapsed: 3.814727ms
    Apr 18 09:24:35.160: INFO: Pod "downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009426659s
    Apr 18 09:24:37.157: INFO: Pod "downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007044045s
    STEP: Saw pod success 04/18/23 09:24:37.157
    Apr 18 09:24:37.157: INFO: Pod "downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca" satisfied condition "Succeeded or Failed"
    Apr 18 09:24:37.160: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca container client-container: <nil>
    STEP: delete the pod 04/18/23 09:24:37.173
    Apr 18 09:24:37.181: INFO: Waiting for pod downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca to disappear
    Apr 18 09:24:37.184: INFO: Pod downwardapi-volume-c4be5b48-a8fa-4b90-b9cb-3ac4fd9954ca no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 09:24:37.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5418" for this suite. 04/18/23 09:24:37.188
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:24:37.196
Apr 18 09:24:37.196: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename subpath 04/18/23 09:24:37.197
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:24:37.207
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:24:37.21
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/18/23 09:24:37.214
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-djfj 04/18/23 09:24:37.223
STEP: Creating a pod to test atomic-volume-subpath 04/18/23 09:24:37.223
Apr 18 09:24:37.228: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-djfj" in namespace "subpath-9652" to be "Succeeded or Failed"
Apr 18 09:24:37.231: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.548258ms
Apr 18 09:24:39.235: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 2.006292344s
Apr 18 09:24:41.236: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 4.007209573s
Apr 18 09:24:43.235: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 6.006785291s
Apr 18 09:24:45.234: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 8.005997827s
Apr 18 09:24:47.235: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 10.006203005s
Apr 18 09:24:49.235: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 12.006431854s
Apr 18 09:24:51.234: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 14.006058441s
Apr 18 09:24:53.235: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 16.007136121s
Apr 18 09:24:55.235: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 18.007138017s
Apr 18 09:24:57.235: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 20.007057092s
Apr 18 09:24:59.236: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=false. Elapsed: 22.007301313s
Apr 18 09:25:01.234: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.005703966s
STEP: Saw pod success 04/18/23 09:25:01.234
Apr 18 09:25:01.234: INFO: Pod "pod-subpath-test-configmap-djfj" satisfied condition "Succeeded or Failed"
Apr 18 09:25:01.237: INFO: Trying to get logs from node 192.168.1.152 pod pod-subpath-test-configmap-djfj container test-container-subpath-configmap-djfj: <nil>
STEP: delete the pod 04/18/23 09:25:01.242
Apr 18 09:25:01.253: INFO: Waiting for pod pod-subpath-test-configmap-djfj to disappear
Apr 18 09:25:01.256: INFO: Pod pod-subpath-test-configmap-djfj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-djfj 04/18/23 09:25:01.256
Apr 18 09:25:01.256: INFO: Deleting pod "pod-subpath-test-configmap-djfj" in namespace "subpath-9652"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 18 09:25:01.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9652" for this suite. 04/18/23 09:25:01.264
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":244,"skipped":4589,"failed":0}
------------------------------
• [SLOW TEST] [24.073 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:24:37.196
    Apr 18 09:24:37.196: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename subpath 04/18/23 09:24:37.197
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:24:37.207
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:24:37.21
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/18/23 09:24:37.214
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-djfj 04/18/23 09:24:37.223
    STEP: Creating a pod to test atomic-volume-subpath 04/18/23 09:24:37.223
    Apr 18 09:24:37.228: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-djfj" in namespace "subpath-9652" to be "Succeeded or Failed"
    Apr 18 09:24:37.231: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.548258ms
    Apr 18 09:24:39.235: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 2.006292344s
    Apr 18 09:24:41.236: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 4.007209573s
    Apr 18 09:24:43.235: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 6.006785291s
    Apr 18 09:24:45.234: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 8.005997827s
    Apr 18 09:24:47.235: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 10.006203005s
    Apr 18 09:24:49.235: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 12.006431854s
    Apr 18 09:24:51.234: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 14.006058441s
    Apr 18 09:24:53.235: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 16.007136121s
    Apr 18 09:24:55.235: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 18.007138017s
    Apr 18 09:24:57.235: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=true. Elapsed: 20.007057092s
    Apr 18 09:24:59.236: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Running", Reason="", readiness=false. Elapsed: 22.007301313s
    Apr 18 09:25:01.234: INFO: Pod "pod-subpath-test-configmap-djfj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.005703966s
    STEP: Saw pod success 04/18/23 09:25:01.234
    Apr 18 09:25:01.234: INFO: Pod "pod-subpath-test-configmap-djfj" satisfied condition "Succeeded or Failed"
    Apr 18 09:25:01.237: INFO: Trying to get logs from node 192.168.1.152 pod pod-subpath-test-configmap-djfj container test-container-subpath-configmap-djfj: <nil>
    STEP: delete the pod 04/18/23 09:25:01.242
    Apr 18 09:25:01.253: INFO: Waiting for pod pod-subpath-test-configmap-djfj to disappear
    Apr 18 09:25:01.256: INFO: Pod pod-subpath-test-configmap-djfj no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-djfj 04/18/23 09:25:01.256
    Apr 18 09:25:01.256: INFO: Deleting pod "pod-subpath-test-configmap-djfj" in namespace "subpath-9652"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 18 09:25:01.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-9652" for this suite. 04/18/23 09:25:01.264
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:25:01.27
Apr 18 09:25:01.270: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename namespaces 04/18/23 09:25:01.27
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:01.279
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:01.283
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 04/18/23 09:25:01.287
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:01.297
STEP: Creating a service in the namespace 04/18/23 09:25:01.301
STEP: Deleting the namespace 04/18/23 09:25:01.308
STEP: Waiting for the namespace to be removed. 04/18/23 09:25:01.314
STEP: Recreating the namespace 04/18/23 09:25:07.318
STEP: Verifying there is no service in the namespace 04/18/23 09:25:07.331
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:25:07.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8127" for this suite. 04/18/23 09:25:07.338
STEP: Destroying namespace "nsdeletetest-6540" for this suite. 04/18/23 09:25:07.342
Apr 18 09:25:07.344: INFO: Namespace nsdeletetest-6540 was already deleted
STEP: Destroying namespace "nsdeletetest-8077" for this suite. 04/18/23 09:25:07.344
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":245,"skipped":4595,"failed":0}
------------------------------
• [SLOW TEST] [6.080 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:25:01.27
    Apr 18 09:25:01.270: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename namespaces 04/18/23 09:25:01.27
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:01.279
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:01.283
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 04/18/23 09:25:01.287
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:01.297
    STEP: Creating a service in the namespace 04/18/23 09:25:01.301
    STEP: Deleting the namespace 04/18/23 09:25:01.308
    STEP: Waiting for the namespace to be removed. 04/18/23 09:25:01.314
    STEP: Recreating the namespace 04/18/23 09:25:07.318
    STEP: Verifying there is no service in the namespace 04/18/23 09:25:07.331
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:25:07.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-8127" for this suite. 04/18/23 09:25:07.338
    STEP: Destroying namespace "nsdeletetest-6540" for this suite. 04/18/23 09:25:07.342
    Apr 18 09:25:07.344: INFO: Namespace nsdeletetest-6540 was already deleted
    STEP: Destroying namespace "nsdeletetest-8077" for this suite. 04/18/23 09:25:07.344
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:25:07.349
Apr 18 09:25:07.349: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename sched-pred 04/18/23 09:25:07.35
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:07.36
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:07.364
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 18 09:25:07.368: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 18 09:25:07.374: INFO: Waiting for terminating namespaces to be deleted...
Apr 18 09:25:07.377: INFO: 
Logging pods the apiserver thinks is on node 192.168.1.152 before test
Apr 18 09:25:07.383: INFO: everest-csi-driver-2sbdm from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:25:07.383: INFO: 	Container everest-csi-driver ready: true, restart count 0
Apr 18 09:25:07.383: INFO: icagent-blm9c from kube-system started at 2023-04-17 15:47:22 +0000 UTC (1 container statuses recorded)
Apr 18 09:25:07.383: INFO: 	Container icagent ready: true, restart count 0
Apr 18 09:25:07.383: INFO: sonobuoy from sonobuoy started at 2023-04-18 08:25:22 +0000 UTC (1 container statuses recorded)
Apr 18 09:25:07.383: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 18 09:25:07.383: INFO: sonobuoy-e2e-job-98a0ff59191d4d9f from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:25:07.383: INFO: 	Container e2e ready: true, restart count 0
Apr 18 09:25:07.383: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:25:07.383: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-brt2v from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:25:07.383: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:25:07.383: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 09:25:07.383: INFO: 
Logging pods the apiserver thinks is on node 192.168.1.29 before test
Apr 18 09:25:07.387: INFO: coredns-67ffcb9db-g9zw5 from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
Apr 18 09:25:07.387: INFO: 	Container coredns ready: true, restart count 0
Apr 18 09:25:07.387: INFO: everest-csi-controller-76f85d46b8-f4ksg from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:25:07.387: INFO: 	Container everest-csi-controller ready: true, restart count 0
Apr 18 09:25:07.387: INFO: everest-csi-driver-j2vqd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:25:07.387: INFO: 	Container everest-csi-driver ready: true, restart count 0
Apr 18 09:25:07.387: INFO: icagent-znmkj from kube-system started at 2023-04-17 15:47:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:25:07.387: INFO: 	Container icagent ready: true, restart count 0
Apr 18 09:25:07.387: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-8kqvb from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:25:07.387: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:25:07.387: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 09:25:07.387: INFO: 
Logging pods the apiserver thinks is on node 192.168.1.84 before test
Apr 18 09:25:07.392: INFO: coredns-67ffcb9db-fc7fx from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
Apr 18 09:25:07.392: INFO: 	Container coredns ready: true, restart count 0
Apr 18 09:25:07.392: INFO: everest-csi-controller-76f85d46b8-vkvbd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:25:07.392: INFO: 	Container everest-csi-controller ready: true, restart count 0
Apr 18 09:25:07.392: INFO: everest-csi-driver-ww79w from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:25:07.392: INFO: 	Container everest-csi-driver ready: true, restart count 0
Apr 18 09:25:07.392: INFO: icagent-9xt4k from kube-system started at 2023-04-07 10:53:39 +0000 UTC (1 container statuses recorded)
Apr 18 09:25:07.392: INFO: 	Container icagent ready: true, restart count 0
Apr 18 09:25:07.392: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-6q6gp from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:25:07.392: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:25:07.392: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node 192.168.1.152 04/18/23 09:25:07.408
STEP: verifying the node has the label node 192.168.1.29 04/18/23 09:25:07.42
STEP: verifying the node has the label node 192.168.1.84 04/18/23 09:25:07.436
Apr 18 09:25:07.446: INFO: Pod coredns-67ffcb9db-fc7fx requesting resource cpu=500m on Node 192.168.1.84
Apr 18 09:25:07.446: INFO: Pod coredns-67ffcb9db-g9zw5 requesting resource cpu=500m on Node 192.168.1.29
Apr 18 09:25:07.446: INFO: Pod everest-csi-controller-76f85d46b8-f4ksg requesting resource cpu=250m on Node 192.168.1.29
Apr 18 09:25:07.446: INFO: Pod everest-csi-controller-76f85d46b8-vkvbd requesting resource cpu=250m on Node 192.168.1.84
Apr 18 09:25:07.446: INFO: Pod everest-csi-driver-2sbdm requesting resource cpu=100m on Node 192.168.1.152
Apr 18 09:25:07.446: INFO: Pod everest-csi-driver-j2vqd requesting resource cpu=100m on Node 192.168.1.29
Apr 18 09:25:07.446: INFO: Pod everest-csi-driver-ww79w requesting resource cpu=100m on Node 192.168.1.84
Apr 18 09:25:07.446: INFO: Pod icagent-9xt4k requesting resource cpu=0m on Node 192.168.1.84
Apr 18 09:25:07.446: INFO: Pod icagent-blm9c requesting resource cpu=0m on Node 192.168.1.152
Apr 18 09:25:07.446: INFO: Pod icagent-znmkj requesting resource cpu=0m on Node 192.168.1.29
Apr 18 09:25:07.446: INFO: Pod sonobuoy requesting resource cpu=0m on Node 192.168.1.152
Apr 18 09:25:07.446: INFO: Pod sonobuoy-e2e-job-98a0ff59191d4d9f requesting resource cpu=0m on Node 192.168.1.152
Apr 18 09:25:07.446: INFO: Pod sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-6q6gp requesting resource cpu=0m on Node 192.168.1.84
Apr 18 09:25:07.446: INFO: Pod sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-8kqvb requesting resource cpu=0m on Node 192.168.1.29
Apr 18 09:25:07.446: INFO: Pod sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-brt2v requesting resource cpu=0m on Node 192.168.1.152
STEP: Starting Pods to consume most of the cluster CPU. 04/18/23 09:25:07.446
Apr 18 09:25:07.446: INFO: Creating a pod which consumes cpu=756m on Node 192.168.1.84
Apr 18 09:25:07.453: INFO: Creating a pod which consumes cpu=1281m on Node 192.168.1.152
Apr 18 09:25:07.461: INFO: Creating a pod which consumes cpu=756m on Node 192.168.1.29
Apr 18 09:25:07.473: INFO: Waiting up to 5m0s for pod "filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582" in namespace "sched-pred-8500" to be "running"
Apr 18 09:25:07.476: INFO: Pod "filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582": Phase="Pending", Reason="", readiness=false. Elapsed: 3.089865ms
Apr 18 09:25:09.481: INFO: Pod "filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582": Phase="Running", Reason="", readiness=true. Elapsed: 2.007427162s
Apr 18 09:25:09.481: INFO: Pod "filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582" satisfied condition "running"
Apr 18 09:25:09.481: INFO: Waiting up to 5m0s for pod "filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e" in namespace "sched-pred-8500" to be "running"
Apr 18 09:25:09.483: INFO: Pod "filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e": Phase="Running", Reason="", readiness=true. Elapsed: 2.852036ms
Apr 18 09:25:09.483: INFO: Pod "filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e" satisfied condition "running"
Apr 18 09:25:09.483: INFO: Waiting up to 5m0s for pod "filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337" in namespace "sched-pred-8500" to be "running"
Apr 18 09:25:09.486: INFO: Pod "filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337": Phase="Running", Reason="", readiness=true. Elapsed: 2.602919ms
Apr 18 09:25:09.486: INFO: Pod "filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 04/18/23 09:25:09.486
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e.1756fd33423e454f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8500/filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e to 192.168.1.152] 04/18/23 09:25:09.49
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e.1756fd33543af085], Reason = [SuccessfulMountVolume], Message = [Successfully mounted volumes for pod "filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e_sched-pred-8500(f53af47f-ffe3-4ebe-aeaa-cca452c7d0c9)"] 04/18/23 09:25:09.49
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e.1756fd335e073f64], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/18/23 09:25:09.49
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e.1756fd335eefeb1f], Reason = [SuccessfulCreate], Message = [Created container filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e] 04/18/23 09:25:09.491
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e.1756fd3363916dab], Reason = [Started], Message = [Started container filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e] 04/18/23 09:25:09.491
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582.1756fd3341c0bd1e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8500/filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582 to 192.168.1.84] 04/18/23 09:25:09.491
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582.1756fd3353d76dc4], Reason = [SuccessfulMountVolume], Message = [Successfully mounted volumes for pod "filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582_sched-pred-8500(04e3f55f-e2b2-409d-ba8a-ed47dc61f80a)"] 04/18/23 09:25:09.491
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582.1756fd335db8a9d8], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/18/23 09:25:09.491
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582.1756fd335edaf690], Reason = [SuccessfulCreate], Message = [Created container filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582] 04/18/23 09:25:09.491
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582.1756fd336351e3e2], Reason = [Started], Message = [Started container filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582] 04/18/23 09:25:09.491
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337.1756fd3342f04d6c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8500/filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337 to 192.168.1.29] 04/18/23 09:25:09.491
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337.1756fd3354ff9c7a], Reason = [SuccessfulMountVolume], Message = [Successfully mounted volumes for pod "filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337_sched-pred-8500(11608667-925e-4d50-8137-d86a06c1609c)"] 04/18/23 09:25:09.491
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337.1756fd335ea96640], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/18/23 09:25:09.491
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337.1756fd335f8d8685], Reason = [SuccessfulCreate], Message = [Created container filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337] 04/18/23 09:25:09.491
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337.1756fd3363c3c7ce], Reason = [Started], Message = [Started container filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337] 04/18/23 09:25:09.491
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1756fd33bb6a6327], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 04/18/23 09:25:09.503
STEP: removing the label node off the node 192.168.1.84 04/18/23 09:25:10.502
STEP: verifying the node doesn't have the label node 04/18/23 09:25:10.518
STEP: removing the label node off the node 192.168.1.152 04/18/23 09:25:10.521
STEP: verifying the node doesn't have the label node 04/18/23 09:25:10.532
STEP: removing the label node off the node 192.168.1.29 04/18/23 09:25:10.536
STEP: verifying the node doesn't have the label node 04/18/23 09:25:10.549
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:25:10.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8500" for this suite. 04/18/23 09:25:10.556
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":246,"skipped":4595,"failed":0}
------------------------------
• [3.211 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:25:07.349
    Apr 18 09:25:07.349: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename sched-pred 04/18/23 09:25:07.35
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:07.36
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:07.364
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 18 09:25:07.368: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 18 09:25:07.374: INFO: Waiting for terminating namespaces to be deleted...
    Apr 18 09:25:07.377: INFO: 
    Logging pods the apiserver thinks is on node 192.168.1.152 before test
    Apr 18 09:25:07.383: INFO: everest-csi-driver-2sbdm from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:25:07.383: INFO: 	Container everest-csi-driver ready: true, restart count 0
    Apr 18 09:25:07.383: INFO: icagent-blm9c from kube-system started at 2023-04-17 15:47:22 +0000 UTC (1 container statuses recorded)
    Apr 18 09:25:07.383: INFO: 	Container icagent ready: true, restart count 0
    Apr 18 09:25:07.383: INFO: sonobuoy from sonobuoy started at 2023-04-18 08:25:22 +0000 UTC (1 container statuses recorded)
    Apr 18 09:25:07.383: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 18 09:25:07.383: INFO: sonobuoy-e2e-job-98a0ff59191d4d9f from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:25:07.383: INFO: 	Container e2e ready: true, restart count 0
    Apr 18 09:25:07.383: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:25:07.383: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-brt2v from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:25:07.383: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:25:07.383: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 09:25:07.383: INFO: 
    Logging pods the apiserver thinks is on node 192.168.1.29 before test
    Apr 18 09:25:07.387: INFO: coredns-67ffcb9db-g9zw5 from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
    Apr 18 09:25:07.387: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 09:25:07.387: INFO: everest-csi-controller-76f85d46b8-f4ksg from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:25:07.387: INFO: 	Container everest-csi-controller ready: true, restart count 0
    Apr 18 09:25:07.387: INFO: everest-csi-driver-j2vqd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:25:07.387: INFO: 	Container everest-csi-driver ready: true, restart count 0
    Apr 18 09:25:07.387: INFO: icagent-znmkj from kube-system started at 2023-04-17 15:47:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:25:07.387: INFO: 	Container icagent ready: true, restart count 0
    Apr 18 09:25:07.387: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-8kqvb from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:25:07.387: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:25:07.387: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 09:25:07.387: INFO: 
    Logging pods the apiserver thinks is on node 192.168.1.84 before test
    Apr 18 09:25:07.392: INFO: coredns-67ffcb9db-fc7fx from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
    Apr 18 09:25:07.392: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 09:25:07.392: INFO: everest-csi-controller-76f85d46b8-vkvbd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:25:07.392: INFO: 	Container everest-csi-controller ready: true, restart count 0
    Apr 18 09:25:07.392: INFO: everest-csi-driver-ww79w from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:25:07.392: INFO: 	Container everest-csi-driver ready: true, restart count 0
    Apr 18 09:25:07.392: INFO: icagent-9xt4k from kube-system started at 2023-04-07 10:53:39 +0000 UTC (1 container statuses recorded)
    Apr 18 09:25:07.392: INFO: 	Container icagent ready: true, restart count 0
    Apr 18 09:25:07.392: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-6q6gp from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:25:07.392: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:25:07.392: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node 192.168.1.152 04/18/23 09:25:07.408
    STEP: verifying the node has the label node 192.168.1.29 04/18/23 09:25:07.42
    STEP: verifying the node has the label node 192.168.1.84 04/18/23 09:25:07.436
    Apr 18 09:25:07.446: INFO: Pod coredns-67ffcb9db-fc7fx requesting resource cpu=500m on Node 192.168.1.84
    Apr 18 09:25:07.446: INFO: Pod coredns-67ffcb9db-g9zw5 requesting resource cpu=500m on Node 192.168.1.29
    Apr 18 09:25:07.446: INFO: Pod everest-csi-controller-76f85d46b8-f4ksg requesting resource cpu=250m on Node 192.168.1.29
    Apr 18 09:25:07.446: INFO: Pod everest-csi-controller-76f85d46b8-vkvbd requesting resource cpu=250m on Node 192.168.1.84
    Apr 18 09:25:07.446: INFO: Pod everest-csi-driver-2sbdm requesting resource cpu=100m on Node 192.168.1.152
    Apr 18 09:25:07.446: INFO: Pod everest-csi-driver-j2vqd requesting resource cpu=100m on Node 192.168.1.29
    Apr 18 09:25:07.446: INFO: Pod everest-csi-driver-ww79w requesting resource cpu=100m on Node 192.168.1.84
    Apr 18 09:25:07.446: INFO: Pod icagent-9xt4k requesting resource cpu=0m on Node 192.168.1.84
    Apr 18 09:25:07.446: INFO: Pod icagent-blm9c requesting resource cpu=0m on Node 192.168.1.152
    Apr 18 09:25:07.446: INFO: Pod icagent-znmkj requesting resource cpu=0m on Node 192.168.1.29
    Apr 18 09:25:07.446: INFO: Pod sonobuoy requesting resource cpu=0m on Node 192.168.1.152
    Apr 18 09:25:07.446: INFO: Pod sonobuoy-e2e-job-98a0ff59191d4d9f requesting resource cpu=0m on Node 192.168.1.152
    Apr 18 09:25:07.446: INFO: Pod sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-6q6gp requesting resource cpu=0m on Node 192.168.1.84
    Apr 18 09:25:07.446: INFO: Pod sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-8kqvb requesting resource cpu=0m on Node 192.168.1.29
    Apr 18 09:25:07.446: INFO: Pod sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-brt2v requesting resource cpu=0m on Node 192.168.1.152
    STEP: Starting Pods to consume most of the cluster CPU. 04/18/23 09:25:07.446
    Apr 18 09:25:07.446: INFO: Creating a pod which consumes cpu=756m on Node 192.168.1.84
    Apr 18 09:25:07.453: INFO: Creating a pod which consumes cpu=1281m on Node 192.168.1.152
    Apr 18 09:25:07.461: INFO: Creating a pod which consumes cpu=756m on Node 192.168.1.29
    Apr 18 09:25:07.473: INFO: Waiting up to 5m0s for pod "filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582" in namespace "sched-pred-8500" to be "running"
    Apr 18 09:25:07.476: INFO: Pod "filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582": Phase="Pending", Reason="", readiness=false. Elapsed: 3.089865ms
    Apr 18 09:25:09.481: INFO: Pod "filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582": Phase="Running", Reason="", readiness=true. Elapsed: 2.007427162s
    Apr 18 09:25:09.481: INFO: Pod "filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582" satisfied condition "running"
    Apr 18 09:25:09.481: INFO: Waiting up to 5m0s for pod "filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e" in namespace "sched-pred-8500" to be "running"
    Apr 18 09:25:09.483: INFO: Pod "filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e": Phase="Running", Reason="", readiness=true. Elapsed: 2.852036ms
    Apr 18 09:25:09.483: INFO: Pod "filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e" satisfied condition "running"
    Apr 18 09:25:09.483: INFO: Waiting up to 5m0s for pod "filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337" in namespace "sched-pred-8500" to be "running"
    Apr 18 09:25:09.486: INFO: Pod "filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337": Phase="Running", Reason="", readiness=true. Elapsed: 2.602919ms
    Apr 18 09:25:09.486: INFO: Pod "filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 04/18/23 09:25:09.486
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e.1756fd33423e454f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8500/filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e to 192.168.1.152] 04/18/23 09:25:09.49
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e.1756fd33543af085], Reason = [SuccessfulMountVolume], Message = [Successfully mounted volumes for pod "filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e_sched-pred-8500(f53af47f-ffe3-4ebe-aeaa-cca452c7d0c9)"] 04/18/23 09:25:09.49
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e.1756fd335e073f64], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/18/23 09:25:09.49
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e.1756fd335eefeb1f], Reason = [SuccessfulCreate], Message = [Created container filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e] 04/18/23 09:25:09.491
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e.1756fd3363916dab], Reason = [Started], Message = [Started container filler-pod-940f779a-b065-46e0-80ba-dfc0f94b918e] 04/18/23 09:25:09.491
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582.1756fd3341c0bd1e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8500/filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582 to 192.168.1.84] 04/18/23 09:25:09.491
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582.1756fd3353d76dc4], Reason = [SuccessfulMountVolume], Message = [Successfully mounted volumes for pod "filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582_sched-pred-8500(04e3f55f-e2b2-409d-ba8a-ed47dc61f80a)"] 04/18/23 09:25:09.491
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582.1756fd335db8a9d8], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/18/23 09:25:09.491
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582.1756fd335edaf690], Reason = [SuccessfulCreate], Message = [Created container filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582] 04/18/23 09:25:09.491
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582.1756fd336351e3e2], Reason = [Started], Message = [Started container filler-pod-a0c8dd47-a05b-4c6d-9740-f977a46f1582] 04/18/23 09:25:09.491
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337.1756fd3342f04d6c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8500/filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337 to 192.168.1.29] 04/18/23 09:25:09.491
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337.1756fd3354ff9c7a], Reason = [SuccessfulMountVolume], Message = [Successfully mounted volumes for pod "filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337_sched-pred-8500(11608667-925e-4d50-8137-d86a06c1609c)"] 04/18/23 09:25:09.491
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337.1756fd335ea96640], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/18/23 09:25:09.491
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337.1756fd335f8d8685], Reason = [SuccessfulCreate], Message = [Created container filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337] 04/18/23 09:25:09.491
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337.1756fd3363c3c7ce], Reason = [Started], Message = [Started container filler-pod-f4b95cbb-499d-4ec4-b2fc-a68e9a777337] 04/18/23 09:25:09.491
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.1756fd33bb6a6327], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 04/18/23 09:25:09.503
    STEP: removing the label node off the node 192.168.1.84 04/18/23 09:25:10.502
    STEP: verifying the node doesn't have the label node 04/18/23 09:25:10.518
    STEP: removing the label node off the node 192.168.1.152 04/18/23 09:25:10.521
    STEP: verifying the node doesn't have the label node 04/18/23 09:25:10.532
    STEP: removing the label node off the node 192.168.1.29 04/18/23 09:25:10.536
    STEP: verifying the node doesn't have the label node 04/18/23 09:25:10.549
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:25:10.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8500" for this suite. 04/18/23 09:25:10.556
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:25:10.562
Apr 18 09:25:10.562: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename disruption 04/18/23 09:25:10.563
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:10.573
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:10.576
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 04/18/23 09:25:10.58
STEP: Waiting for the pdb to be processed 04/18/23 09:25:10.584
STEP: First trying to evict a pod which shouldn't be evictable 04/18/23 09:25:12.595
STEP: Waiting for all pods to be running 04/18/23 09:25:12.595
Apr 18 09:25:12.598: INFO: pods: 0 < 3
STEP: locating a running pod 04/18/23 09:25:14.603
STEP: Updating the pdb to allow a pod to be evicted 04/18/23 09:25:14.611
STEP: Waiting for the pdb to be processed 04/18/23 09:25:14.618
STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/18/23 09:25:14.622
STEP: Waiting for all pods to be running 04/18/23 09:25:14.623
STEP: Waiting for the pdb to observed all healthy pods 04/18/23 09:25:14.626
STEP: Patching the pdb to disallow a pod to be evicted 04/18/23 09:25:14.642
STEP: Waiting for the pdb to be processed 04/18/23 09:25:14.668
STEP: Waiting for all pods to be running 04/18/23 09:25:16.674
STEP: locating a running pod 04/18/23 09:25:16.677
STEP: Deleting the pdb to allow a pod to be evicted 04/18/23 09:25:16.685
STEP: Waiting for the pdb to be deleted 04/18/23 09:25:16.689
STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/18/23 09:25:16.693
STEP: Waiting for all pods to be running 04/18/23 09:25:16.693
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 18 09:25:16.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-7009" for this suite. 04/18/23 09:25:16.711
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":247,"skipped":4597,"failed":0}
------------------------------
• [SLOW TEST] [6.157 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:25:10.562
    Apr 18 09:25:10.562: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename disruption 04/18/23 09:25:10.563
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:10.573
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:10.576
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 04/18/23 09:25:10.58
    STEP: Waiting for the pdb to be processed 04/18/23 09:25:10.584
    STEP: First trying to evict a pod which shouldn't be evictable 04/18/23 09:25:12.595
    STEP: Waiting for all pods to be running 04/18/23 09:25:12.595
    Apr 18 09:25:12.598: INFO: pods: 0 < 3
    STEP: locating a running pod 04/18/23 09:25:14.603
    STEP: Updating the pdb to allow a pod to be evicted 04/18/23 09:25:14.611
    STEP: Waiting for the pdb to be processed 04/18/23 09:25:14.618
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/18/23 09:25:14.622
    STEP: Waiting for all pods to be running 04/18/23 09:25:14.623
    STEP: Waiting for the pdb to observed all healthy pods 04/18/23 09:25:14.626
    STEP: Patching the pdb to disallow a pod to be evicted 04/18/23 09:25:14.642
    STEP: Waiting for the pdb to be processed 04/18/23 09:25:14.668
    STEP: Waiting for all pods to be running 04/18/23 09:25:16.674
    STEP: locating a running pod 04/18/23 09:25:16.677
    STEP: Deleting the pdb to allow a pod to be evicted 04/18/23 09:25:16.685
    STEP: Waiting for the pdb to be deleted 04/18/23 09:25:16.689
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/18/23 09:25:16.693
    STEP: Waiting for all pods to be running 04/18/23 09:25:16.693
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 18 09:25:16.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-7009" for this suite. 04/18/23 09:25:16.711
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:25:16.72
Apr 18 09:25:16.720: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename server-version 04/18/23 09:25:16.72
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:16.732
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:16.736
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 04/18/23 09:25:16.739
STEP: Confirm major version 04/18/23 09:25:16.742
Apr 18 09:25:16.742: INFO: Major version: 1
STEP: Confirm minor version 04/18/23 09:25:16.742
Apr 18 09:25:16.742: INFO: cleanMinorVersion: 25
Apr 18 09:25:16.742: INFO: Minor version: 25+
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Apr 18 09:25:16.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-1727" for this suite. 04/18/23 09:25:16.753
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":248,"skipped":4597,"failed":0}
------------------------------
• [0.041 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:25:16.72
    Apr 18 09:25:16.720: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename server-version 04/18/23 09:25:16.72
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:16.732
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:16.736
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 04/18/23 09:25:16.739
    STEP: Confirm major version 04/18/23 09:25:16.742
    Apr 18 09:25:16.742: INFO: Major version: 1
    STEP: Confirm minor version 04/18/23 09:25:16.742
    Apr 18 09:25:16.742: INFO: cleanMinorVersion: 25
    Apr 18 09:25:16.742: INFO: Minor version: 25+
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Apr 18 09:25:16.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-1727" for this suite. 04/18/23 09:25:16.753
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:25:16.762
Apr 18 09:25:16.762: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename dns 04/18/23 09:25:16.763
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:16.78
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:16.783
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 04/18/23 09:25:16.788
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5158 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5158;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5158 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5158;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5158.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5158.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5158.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5158.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5158.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5158.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5158.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5158.svc;check="$$(dig +notcp +noall +answer +search 47.168.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.168.47_udp@PTR;check="$$(dig +tcp +noall +answer +search 47.168.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.168.47_tcp@PTR;sleep 1; done
 04/18/23 09:25:16.804
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5158 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5158;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5158 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5158;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5158.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5158.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5158.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5158.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5158.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5158.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5158.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5158.svc;check="$$(dig +notcp +noall +answer +search 47.168.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.168.47_udp@PTR;check="$$(dig +tcp +noall +answer +search 47.168.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.168.47_tcp@PTR;sleep 1; done
 04/18/23 09:25:16.804
STEP: creating a pod to probe DNS 04/18/23 09:25:16.804
STEP: submitting the pod to kubernetes 04/18/23 09:25:16.804
Apr 18 09:25:16.814: INFO: Waiting up to 15m0s for pod "dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227" in namespace "dns-5158" to be "running"
Apr 18 09:25:16.818: INFO: Pod "dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227": Phase="Pending", Reason="", readiness=false. Elapsed: 3.677186ms
Apr 18 09:25:18.823: INFO: Pod "dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227": Phase="Running", Reason="", readiness=true. Elapsed: 2.008285209s
Apr 18 09:25:18.823: INFO: Pod "dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227" satisfied condition "running"
STEP: retrieving the pod 04/18/23 09:25:18.823
STEP: looking for the results for each expected name from probers 04/18/23 09:25:18.827
Apr 18 09:25:18.832: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.836: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.840: INFO: Unable to read wheezy_udp@dns-test-service.dns-5158 from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.844: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5158 from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.848: INFO: Unable to read wheezy_udp@dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.851: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.855: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.859: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.878: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.882: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.885: INFO: Unable to read jessie_udp@dns-test-service.dns-5158 from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.889: INFO: Unable to read jessie_tcp@dns-test-service.dns-5158 from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.893: INFO: Unable to read jessie_udp@dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.896: INFO: Unable to read jessie_tcp@dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.900: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.904: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
Apr 18 09:25:18.919: INFO: Lookups using dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5158 wheezy_tcp@dns-test-service.dns-5158 wheezy_udp@dns-test-service.dns-5158.svc wheezy_tcp@dns-test-service.dns-5158.svc wheezy_udp@_http._tcp.dns-test-service.dns-5158.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5158.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5158 jessie_tcp@dns-test-service.dns-5158 jessie_udp@dns-test-service.dns-5158.svc jessie_tcp@dns-test-service.dns-5158.svc jessie_udp@_http._tcp.dns-test-service.dns-5158.svc jessie_tcp@_http._tcp.dns-test-service.dns-5158.svc]

Apr 18 09:25:24.015: INFO: DNS probes using dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227 succeeded

STEP: deleting the pod 04/18/23 09:25:24.015
STEP: deleting the test service 04/18/23 09:25:24.028
STEP: deleting the test headless service 04/18/23 09:25:24.063
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 09:25:24.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5158" for this suite. 04/18/23 09:25:24.09
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":249,"skipped":4630,"failed":0}
------------------------------
• [SLOW TEST] [7.353 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:25:16.762
    Apr 18 09:25:16.762: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename dns 04/18/23 09:25:16.763
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:16.78
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:16.783
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 04/18/23 09:25:16.788
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5158 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5158;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5158 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5158;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5158.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5158.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5158.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5158.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5158.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5158.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5158.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5158.svc;check="$$(dig +notcp +noall +answer +search 47.168.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.168.47_udp@PTR;check="$$(dig +tcp +noall +answer +search 47.168.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.168.47_tcp@PTR;sleep 1; done
     04/18/23 09:25:16.804
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5158 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5158;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5158 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5158;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5158.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5158.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5158.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5158.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5158.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5158.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5158.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5158.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5158.svc;check="$$(dig +notcp +noall +answer +search 47.168.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.168.47_udp@PTR;check="$$(dig +tcp +noall +answer +search 47.168.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.168.47_tcp@PTR;sleep 1; done
     04/18/23 09:25:16.804
    STEP: creating a pod to probe DNS 04/18/23 09:25:16.804
    STEP: submitting the pod to kubernetes 04/18/23 09:25:16.804
    Apr 18 09:25:16.814: INFO: Waiting up to 15m0s for pod "dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227" in namespace "dns-5158" to be "running"
    Apr 18 09:25:16.818: INFO: Pod "dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227": Phase="Pending", Reason="", readiness=false. Elapsed: 3.677186ms
    Apr 18 09:25:18.823: INFO: Pod "dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227": Phase="Running", Reason="", readiness=true. Elapsed: 2.008285209s
    Apr 18 09:25:18.823: INFO: Pod "dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 09:25:18.823
    STEP: looking for the results for each expected name from probers 04/18/23 09:25:18.827
    Apr 18 09:25:18.832: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.836: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.840: INFO: Unable to read wheezy_udp@dns-test-service.dns-5158 from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.844: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5158 from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.848: INFO: Unable to read wheezy_udp@dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.851: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.855: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.859: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.878: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.882: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.885: INFO: Unable to read jessie_udp@dns-test-service.dns-5158 from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.889: INFO: Unable to read jessie_tcp@dns-test-service.dns-5158 from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.893: INFO: Unable to read jessie_udp@dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.896: INFO: Unable to read jessie_tcp@dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.900: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.904: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5158.svc from pod dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227: the server could not find the requested resource (get pods dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227)
    Apr 18 09:25:18.919: INFO: Lookups using dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5158 wheezy_tcp@dns-test-service.dns-5158 wheezy_udp@dns-test-service.dns-5158.svc wheezy_tcp@dns-test-service.dns-5158.svc wheezy_udp@_http._tcp.dns-test-service.dns-5158.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5158.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5158 jessie_tcp@dns-test-service.dns-5158 jessie_udp@dns-test-service.dns-5158.svc jessie_tcp@dns-test-service.dns-5158.svc jessie_udp@_http._tcp.dns-test-service.dns-5158.svc jessie_tcp@_http._tcp.dns-test-service.dns-5158.svc]

    Apr 18 09:25:24.015: INFO: DNS probes using dns-5158/dns-test-0cd1ea62-1178-4eb8-9216-6eb918562227 succeeded

    STEP: deleting the pod 04/18/23 09:25:24.015
    STEP: deleting the test service 04/18/23 09:25:24.028
    STEP: deleting the test headless service 04/18/23 09:25:24.063
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 09:25:24.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-5158" for this suite. 04/18/23 09:25:24.09
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:25:24.116
Apr 18 09:25:24.116: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubelet-test 04/18/23 09:25:24.118
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:24.155
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:24.16
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Apr 18 09:25:24.195: INFO: Waiting up to 5m0s for pod "busybox-scheduling-070019c0-1903-4ec2-bb55-2fc4b86c12c6" in namespace "kubelet-test-3024" to be "running and ready"
Apr 18 09:25:24.200: INFO: Pod "busybox-scheduling-070019c0-1903-4ec2-bb55-2fc4b86c12c6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.909541ms
Apr 18 09:25:24.201: INFO: The phase of Pod busybox-scheduling-070019c0-1903-4ec2-bb55-2fc4b86c12c6 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:25:26.205: INFO: Pod "busybox-scheduling-070019c0-1903-4ec2-bb55-2fc4b86c12c6": Phase="Running", Reason="", readiness=true. Elapsed: 2.010530266s
Apr 18 09:25:26.205: INFO: The phase of Pod busybox-scheduling-070019c0-1903-4ec2-bb55-2fc4b86c12c6 is Running (Ready = true)
Apr 18 09:25:26.205: INFO: Pod "busybox-scheduling-070019c0-1903-4ec2-bb55-2fc4b86c12c6" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 18 09:25:26.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3024" for this suite. 04/18/23 09:25:26.228
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":250,"skipped":4641,"failed":0}
------------------------------
• [2.116 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:25:24.116
    Apr 18 09:25:24.116: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubelet-test 04/18/23 09:25:24.118
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:24.155
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:24.16
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Apr 18 09:25:24.195: INFO: Waiting up to 5m0s for pod "busybox-scheduling-070019c0-1903-4ec2-bb55-2fc4b86c12c6" in namespace "kubelet-test-3024" to be "running and ready"
    Apr 18 09:25:24.200: INFO: Pod "busybox-scheduling-070019c0-1903-4ec2-bb55-2fc4b86c12c6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.909541ms
    Apr 18 09:25:24.201: INFO: The phase of Pod busybox-scheduling-070019c0-1903-4ec2-bb55-2fc4b86c12c6 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:25:26.205: INFO: Pod "busybox-scheduling-070019c0-1903-4ec2-bb55-2fc4b86c12c6": Phase="Running", Reason="", readiness=true. Elapsed: 2.010530266s
    Apr 18 09:25:26.205: INFO: The phase of Pod busybox-scheduling-070019c0-1903-4ec2-bb55-2fc4b86c12c6 is Running (Ready = true)
    Apr 18 09:25:26.205: INFO: Pod "busybox-scheduling-070019c0-1903-4ec2-bb55-2fc4b86c12c6" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 18 09:25:26.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-3024" for this suite. 04/18/23 09:25:26.228
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:25:26.233
Apr 18 09:25:26.233: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 09:25:26.233
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:26.244
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:26.248
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-133 04/18/23 09:25:26.251
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-133 to expose endpoints map[] 04/18/23 09:25:26.261
Apr 18 09:25:26.263: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Apr 18 09:25:27.272: INFO: successfully validated that service multi-endpoint-test in namespace services-133 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-133 04/18/23 09:25:27.272
Apr 18 09:25:27.278: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-133" to be "running and ready"
Apr 18 09:25:27.281: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.593584ms
Apr 18 09:25:27.281: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:25:29.284: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.005556568s
Apr 18 09:25:29.284: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 18 09:25:29.284: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-133 to expose endpoints map[pod1:[100]] 04/18/23 09:25:29.287
Apr 18 09:25:29.296: INFO: successfully validated that service multi-endpoint-test in namespace services-133 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-133 04/18/23 09:25:29.296
Apr 18 09:25:29.300: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-133" to be "running and ready"
Apr 18 09:25:29.306: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.359005ms
Apr 18 09:25:29.306: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:25:31.309: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.009390211s
Apr 18 09:25:31.309: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 18 09:25:31.309: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-133 to expose endpoints map[pod1:[100] pod2:[101]] 04/18/23 09:25:31.312
Apr 18 09:25:31.323: INFO: successfully validated that service multi-endpoint-test in namespace services-133 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 04/18/23 09:25:31.323
Apr 18 09:25:31.323: INFO: Creating new exec pod
Apr 18 09:25:31.327: INFO: Waiting up to 5m0s for pod "execpodglpxq" in namespace "services-133" to be "running"
Apr 18 09:25:31.330: INFO: Pod "execpodglpxq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.373733ms
Apr 18 09:25:33.334: INFO: Pod "execpodglpxq": Phase="Running", Reason="", readiness=true. Elapsed: 2.006448083s
Apr 18 09:25:33.334: INFO: Pod "execpodglpxq" satisfied condition "running"
Apr 18 09:25:34.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-133 exec execpodglpxq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Apr 18 09:25:34.435: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Apr 18 09:25:34.435: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:25:34.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-133 exec execpodglpxq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.130.150 80'
Apr 18 09:25:34.538: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.130.150 80\nConnection to 10.247.130.150 80 port [tcp/http] succeeded!\n"
Apr 18 09:25:34.539: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:25:34.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-133 exec execpodglpxq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Apr 18 09:25:34.639: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Apr 18 09:25:34.639: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:25:34.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-133 exec execpodglpxq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.130.150 81'
Apr 18 09:25:34.739: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.130.150 81\nConnection to 10.247.130.150 81 port [tcp/*] succeeded!\n"
Apr 18 09:25:34.739: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-133 04/18/23 09:25:34.739
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-133 to expose endpoints map[pod2:[101]] 04/18/23 09:25:34.751
Apr 18 09:25:35.769: INFO: successfully validated that service multi-endpoint-test in namespace services-133 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-133 04/18/23 09:25:35.769
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-133 to expose endpoints map[] 04/18/23 09:25:35.789
Apr 18 09:25:36.808: INFO: successfully validated that service multi-endpoint-test in namespace services-133 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 09:25:36.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-133" for this suite. 04/18/23 09:25:36.823
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":251,"skipped":4660,"failed":0}
------------------------------
• [SLOW TEST] [10.595 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:25:26.233
    Apr 18 09:25:26.233: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 09:25:26.233
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:26.244
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:26.248
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-133 04/18/23 09:25:26.251
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-133 to expose endpoints map[] 04/18/23 09:25:26.261
    Apr 18 09:25:26.263: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
    Apr 18 09:25:27.272: INFO: successfully validated that service multi-endpoint-test in namespace services-133 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-133 04/18/23 09:25:27.272
    Apr 18 09:25:27.278: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-133" to be "running and ready"
    Apr 18 09:25:27.281: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.593584ms
    Apr 18 09:25:27.281: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:25:29.284: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.005556568s
    Apr 18 09:25:29.284: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 18 09:25:29.284: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-133 to expose endpoints map[pod1:[100]] 04/18/23 09:25:29.287
    Apr 18 09:25:29.296: INFO: successfully validated that service multi-endpoint-test in namespace services-133 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-133 04/18/23 09:25:29.296
    Apr 18 09:25:29.300: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-133" to be "running and ready"
    Apr 18 09:25:29.306: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.359005ms
    Apr 18 09:25:29.306: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:25:31.309: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.009390211s
    Apr 18 09:25:31.309: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 18 09:25:31.309: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-133 to expose endpoints map[pod1:[100] pod2:[101]] 04/18/23 09:25:31.312
    Apr 18 09:25:31.323: INFO: successfully validated that service multi-endpoint-test in namespace services-133 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 04/18/23 09:25:31.323
    Apr 18 09:25:31.323: INFO: Creating new exec pod
    Apr 18 09:25:31.327: INFO: Waiting up to 5m0s for pod "execpodglpxq" in namespace "services-133" to be "running"
    Apr 18 09:25:31.330: INFO: Pod "execpodglpxq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.373733ms
    Apr 18 09:25:33.334: INFO: Pod "execpodglpxq": Phase="Running", Reason="", readiness=true. Elapsed: 2.006448083s
    Apr 18 09:25:33.334: INFO: Pod "execpodglpxq" satisfied condition "running"
    Apr 18 09:25:34.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-133 exec execpodglpxq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Apr 18 09:25:34.435: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Apr 18 09:25:34.435: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:25:34.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-133 exec execpodglpxq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.130.150 80'
    Apr 18 09:25:34.538: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.130.150 80\nConnection to 10.247.130.150 80 port [tcp/http] succeeded!\n"
    Apr 18 09:25:34.539: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:25:34.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-133 exec execpodglpxq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Apr 18 09:25:34.639: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Apr 18 09:25:34.639: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:25:34.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-133 exec execpodglpxq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.130.150 81'
    Apr 18 09:25:34.739: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.130.150 81\nConnection to 10.247.130.150 81 port [tcp/*] succeeded!\n"
    Apr 18 09:25:34.739: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-133 04/18/23 09:25:34.739
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-133 to expose endpoints map[pod2:[101]] 04/18/23 09:25:34.751
    Apr 18 09:25:35.769: INFO: successfully validated that service multi-endpoint-test in namespace services-133 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-133 04/18/23 09:25:35.769
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-133 to expose endpoints map[] 04/18/23 09:25:35.789
    Apr 18 09:25:36.808: INFO: successfully validated that service multi-endpoint-test in namespace services-133 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 09:25:36.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-133" for this suite. 04/18/23 09:25:36.823
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:25:36.828
Apr 18 09:25:36.828: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename resourcequota 04/18/23 09:25:36.829
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:36.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:36.843
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 04/18/23 09:25:36.847
STEP: Counting existing ResourceQuota 04/18/23 09:25:41.849
STEP: Creating a ResourceQuota 04/18/23 09:25:46.854
STEP: Ensuring resource quota status is calculated 04/18/23 09:25:46.858
STEP: Creating a Secret 04/18/23 09:25:48.862
STEP: Ensuring resource quota status captures secret creation 04/18/23 09:25:48.873
STEP: Deleting a secret 04/18/23 09:25:50.876
STEP: Ensuring resource quota status released usage 04/18/23 09:25:50.882
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 09:25:52.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8616" for this suite. 04/18/23 09:25:52.89
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":252,"skipped":4667,"failed":0}
------------------------------
• [SLOW TEST] [16.067 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:25:36.828
    Apr 18 09:25:36.828: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename resourcequota 04/18/23 09:25:36.829
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:36.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:36.843
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 04/18/23 09:25:36.847
    STEP: Counting existing ResourceQuota 04/18/23 09:25:41.849
    STEP: Creating a ResourceQuota 04/18/23 09:25:46.854
    STEP: Ensuring resource quota status is calculated 04/18/23 09:25:46.858
    STEP: Creating a Secret 04/18/23 09:25:48.862
    STEP: Ensuring resource quota status captures secret creation 04/18/23 09:25:48.873
    STEP: Deleting a secret 04/18/23 09:25:50.876
    STEP: Ensuring resource quota status released usage 04/18/23 09:25:50.882
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 09:25:52.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8616" for this suite. 04/18/23 09:25:52.89
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:25:52.896
Apr 18 09:25:52.896: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 09:25:52.896
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:52.909
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:52.913
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-8cf5db68-c3b8-4f8b-8c10-bd40a313b8b9 04/18/23 09:25:52.921
STEP: Creating a pod to test consume secrets 04/18/23 09:25:52.945
Apr 18 09:25:52.985: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3" in namespace "projected-2145" to be "Succeeded or Failed"
Apr 18 09:25:52.999: INFO: Pod "pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3": Phase="Pending", Reason="", readiness=false. Elapsed: 13.245631ms
Apr 18 09:25:55.003: INFO: Pod "pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017127792s
Apr 18 09:25:57.004: INFO: Pod "pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018179414s
STEP: Saw pod success 04/18/23 09:25:57.004
Apr 18 09:25:57.004: INFO: Pod "pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3" satisfied condition "Succeeded or Failed"
Apr 18 09:25:57.007: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/18/23 09:25:57.012
Apr 18 09:25:57.022: INFO: Waiting for pod pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3 to disappear
Apr 18 09:25:57.024: INFO: Pod pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 18 09:25:57.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2145" for this suite. 04/18/23 09:25:57.029
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":253,"skipped":4682,"failed":0}
------------------------------
• [4.138 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:25:52.896
    Apr 18 09:25:52.896: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 09:25:52.896
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:52.909
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:52.913
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-8cf5db68-c3b8-4f8b-8c10-bd40a313b8b9 04/18/23 09:25:52.921
    STEP: Creating a pod to test consume secrets 04/18/23 09:25:52.945
    Apr 18 09:25:52.985: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3" in namespace "projected-2145" to be "Succeeded or Failed"
    Apr 18 09:25:52.999: INFO: Pod "pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3": Phase="Pending", Reason="", readiness=false. Elapsed: 13.245631ms
    Apr 18 09:25:55.003: INFO: Pod "pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017127792s
    Apr 18 09:25:57.004: INFO: Pod "pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018179414s
    STEP: Saw pod success 04/18/23 09:25:57.004
    Apr 18 09:25:57.004: INFO: Pod "pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3" satisfied condition "Succeeded or Failed"
    Apr 18 09:25:57.007: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 09:25:57.012
    Apr 18 09:25:57.022: INFO: Waiting for pod pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3 to disappear
    Apr 18 09:25:57.024: INFO: Pod pod-projected-secrets-271bda88-7e81-47a3-b281-cfd7712a13d3 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 18 09:25:57.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2145" for this suite. 04/18/23 09:25:57.029
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:25:57.035
Apr 18 09:25:57.035: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 09:25:57.035
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:57.047
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:57.051
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 04/18/23 09:25:57.055
Apr 18 09:25:57.061: INFO: Waiting up to 5m0s for pod "downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2" in namespace "projected-3144" to be "Succeeded or Failed"
Apr 18 09:25:57.064: INFO: Pod "downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.614687ms
Apr 18 09:25:59.067: INFO: Pod "downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006195017s
Apr 18 09:26:01.068: INFO: Pod "downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007126492s
STEP: Saw pod success 04/18/23 09:26:01.068
Apr 18 09:26:01.068: INFO: Pod "downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2" satisfied condition "Succeeded or Failed"
Apr 18 09:26:01.071: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2 container client-container: <nil>
STEP: delete the pod 04/18/23 09:26:01.076
Apr 18 09:26:01.084: INFO: Waiting for pod downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2 to disappear
Apr 18 09:26:01.087: INFO: Pod downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 09:26:01.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3144" for this suite. 04/18/23 09:26:01.091
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":254,"skipped":4711,"failed":0}
------------------------------
• [4.061 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:25:57.035
    Apr 18 09:25:57.035: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 09:25:57.035
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:25:57.047
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:25:57.051
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 04/18/23 09:25:57.055
    Apr 18 09:25:57.061: INFO: Waiting up to 5m0s for pod "downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2" in namespace "projected-3144" to be "Succeeded or Failed"
    Apr 18 09:25:57.064: INFO: Pod "downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.614687ms
    Apr 18 09:25:59.067: INFO: Pod "downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006195017s
    Apr 18 09:26:01.068: INFO: Pod "downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007126492s
    STEP: Saw pod success 04/18/23 09:26:01.068
    Apr 18 09:26:01.068: INFO: Pod "downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2" satisfied condition "Succeeded or Failed"
    Apr 18 09:26:01.071: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2 container client-container: <nil>
    STEP: delete the pod 04/18/23 09:26:01.076
    Apr 18 09:26:01.084: INFO: Waiting for pod downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2 to disappear
    Apr 18 09:26:01.087: INFO: Pod downwardapi-volume-acbdcdb5-469e-455a-9457-2915582a19c2 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 09:26:01.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3144" for this suite. 04/18/23 09:26:01.091
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:26:01.096
Apr 18 09:26:01.096: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 09:26:01.097
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:01.107
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:01.112
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 04/18/23 09:26:01.115
Apr 18 09:26:01.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7671 api-versions'
Apr 18 09:26:01.173: INFO: stderr: ""
Apr 18 09:26:01.173: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\nconfig.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncrd.yangtse.cni/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nk8s.cni.cncf.io/v1\nlocalvolume.everest.io/v1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nproxy.exporter.k8s.io/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.cce.io/v1beta1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\nversion.cce.io/v1beta1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 09:26:01.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7671" for this suite. 04/18/23 09:26:01.177
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":255,"skipped":4711,"failed":0}
------------------------------
• [0.086 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:26:01.096
    Apr 18 09:26:01.096: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 09:26:01.097
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:01.107
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:01.112
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 04/18/23 09:26:01.115
    Apr 18 09:26:01.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7671 api-versions'
    Apr 18 09:26:01.173: INFO: stderr: ""
    Apr 18 09:26:01.173: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\nconfig.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncrd.yangtse.cni/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nk8s.cni.cncf.io/v1\nlocalvolume.everest.io/v1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nproxy.exporter.k8s.io/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.cce.io/v1beta1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\nversion.cce.io/v1beta1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 09:26:01.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7671" for this suite. 04/18/23 09:26:01.177
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:26:01.182
Apr 18 09:26:01.182: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename replicaset 04/18/23 09:26:01.183
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:01.193
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:01.197
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 04/18/23 09:26:01.204
STEP: Verify that the required pods have come up. 04/18/23 09:26:01.208
Apr 18 09:26:01.211: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 18 09:26:06.218: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/18/23 09:26:06.218
STEP: Getting /status 04/18/23 09:26:06.218
Apr 18 09:26:06.221: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 04/18/23 09:26:06.221
Apr 18 09:26:06.235: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 04/18/23 09:26:06.235
Apr 18 09:26:06.237: INFO: Observed &ReplicaSet event: ADDED
Apr 18 09:26:06.237: INFO: Observed &ReplicaSet event: MODIFIED
Apr 18 09:26:06.238: INFO: Observed &ReplicaSet event: MODIFIED
Apr 18 09:26:06.238: INFO: Observed &ReplicaSet event: MODIFIED
Apr 18 09:26:06.238: INFO: Found replicaset test-rs in namespace replicaset-7032 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 18 09:26:06.238: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 04/18/23 09:26:06.238
Apr 18 09:26:06.238: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 18 09:26:06.243: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 04/18/23 09:26:06.243
Apr 18 09:26:06.246: INFO: Observed &ReplicaSet event: ADDED
Apr 18 09:26:06.246: INFO: Observed &ReplicaSet event: MODIFIED
Apr 18 09:26:06.246: INFO: Observed &ReplicaSet event: MODIFIED
Apr 18 09:26:06.246: INFO: Observed &ReplicaSet event: MODIFIED
Apr 18 09:26:06.246: INFO: Observed replicaset test-rs in namespace replicaset-7032 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 18 09:26:06.246: INFO: Observed &ReplicaSet event: MODIFIED
Apr 18 09:26:06.247: INFO: Found replicaset test-rs in namespace replicaset-7032 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Apr 18 09:26:06.247: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 18 09:26:06.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7032" for this suite. 04/18/23 09:26:06.251
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":256,"skipped":4719,"failed":0}
------------------------------
• [SLOW TEST] [5.075 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:26:01.182
    Apr 18 09:26:01.182: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename replicaset 04/18/23 09:26:01.183
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:01.193
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:01.197
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 04/18/23 09:26:01.204
    STEP: Verify that the required pods have come up. 04/18/23 09:26:01.208
    Apr 18 09:26:01.211: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 18 09:26:06.218: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/18/23 09:26:06.218
    STEP: Getting /status 04/18/23 09:26:06.218
    Apr 18 09:26:06.221: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 04/18/23 09:26:06.221
    Apr 18 09:26:06.235: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 04/18/23 09:26:06.235
    Apr 18 09:26:06.237: INFO: Observed &ReplicaSet event: ADDED
    Apr 18 09:26:06.237: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 18 09:26:06.238: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 18 09:26:06.238: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 18 09:26:06.238: INFO: Found replicaset test-rs in namespace replicaset-7032 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 18 09:26:06.238: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 04/18/23 09:26:06.238
    Apr 18 09:26:06.238: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 18 09:26:06.243: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 04/18/23 09:26:06.243
    Apr 18 09:26:06.246: INFO: Observed &ReplicaSet event: ADDED
    Apr 18 09:26:06.246: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 18 09:26:06.246: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 18 09:26:06.246: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 18 09:26:06.246: INFO: Observed replicaset test-rs in namespace replicaset-7032 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 18 09:26:06.246: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 18 09:26:06.247: INFO: Found replicaset test-rs in namespace replicaset-7032 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Apr 18 09:26:06.247: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 18 09:26:06.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-7032" for this suite. 04/18/23 09:26:06.251
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:26:06.258
Apr 18 09:26:06.258: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename var-expansion 04/18/23 09:26:06.259
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:06.27
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:06.273
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 04/18/23 09:26:06.277
Apr 18 09:26:06.284: INFO: Waiting up to 5m0s for pod "var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594" in namespace "var-expansion-1809" to be "Succeeded or Failed"
Apr 18 09:26:06.289: INFO: Pod "var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594": Phase="Pending", Reason="", readiness=false. Elapsed: 4.458906ms
Apr 18 09:26:08.293: INFO: Pod "var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008643807s
Apr 18 09:26:10.292: INFO: Pod "var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008045467s
STEP: Saw pod success 04/18/23 09:26:10.292
Apr 18 09:26:10.292: INFO: Pod "var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594" satisfied condition "Succeeded or Failed"
Apr 18 09:26:10.296: INFO: Trying to get logs from node 192.168.1.152 pod var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594 container dapi-container: <nil>
STEP: delete the pod 04/18/23 09:26:10.301
Apr 18 09:26:10.307: INFO: Waiting for pod var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594 to disappear
Apr 18 09:26:10.310: INFO: Pod var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 09:26:10.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1809" for this suite. 04/18/23 09:26:10.314
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":257,"skipped":4733,"failed":0}
------------------------------
• [4.062 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:26:06.258
    Apr 18 09:26:06.258: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename var-expansion 04/18/23 09:26:06.259
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:06.27
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:06.273
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 04/18/23 09:26:06.277
    Apr 18 09:26:06.284: INFO: Waiting up to 5m0s for pod "var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594" in namespace "var-expansion-1809" to be "Succeeded or Failed"
    Apr 18 09:26:06.289: INFO: Pod "var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594": Phase="Pending", Reason="", readiness=false. Elapsed: 4.458906ms
    Apr 18 09:26:08.293: INFO: Pod "var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008643807s
    Apr 18 09:26:10.292: INFO: Pod "var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008045467s
    STEP: Saw pod success 04/18/23 09:26:10.292
    Apr 18 09:26:10.292: INFO: Pod "var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594" satisfied condition "Succeeded or Failed"
    Apr 18 09:26:10.296: INFO: Trying to get logs from node 192.168.1.152 pod var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594 container dapi-container: <nil>
    STEP: delete the pod 04/18/23 09:26:10.301
    Apr 18 09:26:10.307: INFO: Waiting for pod var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594 to disappear
    Apr 18 09:26:10.310: INFO: Pod var-expansion-61797288-70c0-4ae1-b1e3-478f41bbc594 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 09:26:10.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1809" for this suite. 04/18/23 09:26:10.314
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:26:10.322
Apr 18 09:26:10.322: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 09:26:10.323
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:10.332
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:10.336
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 04/18/23 09:26:10.34
Apr 18 09:26:10.348: INFO: Waiting up to 5m0s for pod "downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5" in namespace "downward-api-6655" to be "Succeeded or Failed"
Apr 18 09:26:10.353: INFO: Pod "downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.401385ms
Apr 18 09:26:12.357: INFO: Pod "downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008893432s
Apr 18 09:26:14.360: INFO: Pod "downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012152364s
STEP: Saw pod success 04/18/23 09:26:14.36
Apr 18 09:26:14.360: INFO: Pod "downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5" satisfied condition "Succeeded or Failed"
Apr 18 09:26:14.363: INFO: Trying to get logs from node 192.168.1.152 pod downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5 container dapi-container: <nil>
STEP: delete the pod 04/18/23 09:26:14.369
Apr 18 09:26:14.380: INFO: Waiting for pod downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5 to disappear
Apr 18 09:26:14.383: INFO: Pod downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 18 09:26:14.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6655" for this suite. 04/18/23 09:26:14.39
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":258,"skipped":4769,"failed":0}
------------------------------
• [4.072 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:26:10.322
    Apr 18 09:26:10.322: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 09:26:10.323
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:10.332
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:10.336
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 04/18/23 09:26:10.34
    Apr 18 09:26:10.348: INFO: Waiting up to 5m0s for pod "downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5" in namespace "downward-api-6655" to be "Succeeded or Failed"
    Apr 18 09:26:10.353: INFO: Pod "downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.401385ms
    Apr 18 09:26:12.357: INFO: Pod "downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008893432s
    Apr 18 09:26:14.360: INFO: Pod "downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012152364s
    STEP: Saw pod success 04/18/23 09:26:14.36
    Apr 18 09:26:14.360: INFO: Pod "downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5" satisfied condition "Succeeded or Failed"
    Apr 18 09:26:14.363: INFO: Trying to get logs from node 192.168.1.152 pod downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5 container dapi-container: <nil>
    STEP: delete the pod 04/18/23 09:26:14.369
    Apr 18 09:26:14.380: INFO: Waiting for pod downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5 to disappear
    Apr 18 09:26:14.383: INFO: Pod downward-api-b183d652-3126-4e6e-8816-f8845d7c77d5 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 18 09:26:14.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6655" for this suite. 04/18/23 09:26:14.39
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:26:14.395
Apr 18 09:26:14.395: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 09:26:14.395
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:14.405
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:14.408
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 09:26:14.422
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:26:14.668
STEP: Deploying the webhook pod 04/18/23 09:26:14.674
STEP: Wait for the deployment to be ready 04/18/23 09:26:14.688
Apr 18 09:26:14.694: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 09:26:16.704
STEP: Verifying the service has paired with the endpoint 04/18/23 09:26:16.712
Apr 18 09:26:17.713: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 04/18/23 09:26:17.716
STEP: create a pod that should be denied by the webhook 04/18/23 09:26:17.732
STEP: create a pod that causes the webhook to hang 04/18/23 09:26:17.744
STEP: create a configmap that should be denied by the webhook 04/18/23 09:26:27.75
STEP: create a configmap that should be admitted by the webhook 04/18/23 09:26:27.761
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 04/18/23 09:26:27.77
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 04/18/23 09:26:27.777
STEP: create a namespace that bypass the webhook 04/18/23 09:26:27.781
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 04/18/23 09:26:27.786
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:26:27.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8580" for this suite. 04/18/23 09:26:27.809
STEP: Destroying namespace "webhook-8580-markers" for this suite. 04/18/23 09:26:27.818
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":259,"skipped":4772,"failed":0}
------------------------------
• [SLOW TEST] [13.515 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:26:14.395
    Apr 18 09:26:14.395: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 09:26:14.395
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:14.405
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:14.408
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 09:26:14.422
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:26:14.668
    STEP: Deploying the webhook pod 04/18/23 09:26:14.674
    STEP: Wait for the deployment to be ready 04/18/23 09:26:14.688
    Apr 18 09:26:14.694: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 09:26:16.704
    STEP: Verifying the service has paired with the endpoint 04/18/23 09:26:16.712
    Apr 18 09:26:17.713: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 04/18/23 09:26:17.716
    STEP: create a pod that should be denied by the webhook 04/18/23 09:26:17.732
    STEP: create a pod that causes the webhook to hang 04/18/23 09:26:17.744
    STEP: create a configmap that should be denied by the webhook 04/18/23 09:26:27.75
    STEP: create a configmap that should be admitted by the webhook 04/18/23 09:26:27.761
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 04/18/23 09:26:27.77
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 04/18/23 09:26:27.777
    STEP: create a namespace that bypass the webhook 04/18/23 09:26:27.781
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 04/18/23 09:26:27.786
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:26:27.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8580" for this suite. 04/18/23 09:26:27.809
    STEP: Destroying namespace "webhook-8580-markers" for this suite. 04/18/23 09:26:27.818
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:26:27.91
Apr 18 09:26:27.911: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir 04/18/23 09:26:27.911
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:27.931
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:27.935
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 04/18/23 09:26:27.939
Apr 18 09:26:27.946: INFO: Waiting up to 5m0s for pod "pod-a864b770-752a-4766-8e23-03f883fce97c" in namespace "emptydir-7907" to be "Succeeded or Failed"
Apr 18 09:26:27.952: INFO: Pod "pod-a864b770-752a-4766-8e23-03f883fce97c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.489935ms
Apr 18 09:26:29.956: INFO: Pod "pod-a864b770-752a-4766-8e23-03f883fce97c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009346808s
Apr 18 09:26:31.955: INFO: Pod "pod-a864b770-752a-4766-8e23-03f883fce97c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009066066s
STEP: Saw pod success 04/18/23 09:26:31.955
Apr 18 09:26:31.956: INFO: Pod "pod-a864b770-752a-4766-8e23-03f883fce97c" satisfied condition "Succeeded or Failed"
Apr 18 09:26:31.958: INFO: Trying to get logs from node 192.168.1.152 pod pod-a864b770-752a-4766-8e23-03f883fce97c container test-container: <nil>
STEP: delete the pod 04/18/23 09:26:31.964
Apr 18 09:26:31.973: INFO: Waiting for pod pod-a864b770-752a-4766-8e23-03f883fce97c to disappear
Apr 18 09:26:31.975: INFO: Pod pod-a864b770-752a-4766-8e23-03f883fce97c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 09:26:31.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7907" for this suite. 04/18/23 09:26:31.98
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":260,"skipped":4778,"failed":0}
------------------------------
• [4.074 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:26:27.91
    Apr 18 09:26:27.911: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir 04/18/23 09:26:27.911
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:27.931
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:27.935
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 04/18/23 09:26:27.939
    Apr 18 09:26:27.946: INFO: Waiting up to 5m0s for pod "pod-a864b770-752a-4766-8e23-03f883fce97c" in namespace "emptydir-7907" to be "Succeeded or Failed"
    Apr 18 09:26:27.952: INFO: Pod "pod-a864b770-752a-4766-8e23-03f883fce97c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.489935ms
    Apr 18 09:26:29.956: INFO: Pod "pod-a864b770-752a-4766-8e23-03f883fce97c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009346808s
    Apr 18 09:26:31.955: INFO: Pod "pod-a864b770-752a-4766-8e23-03f883fce97c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009066066s
    STEP: Saw pod success 04/18/23 09:26:31.955
    Apr 18 09:26:31.956: INFO: Pod "pod-a864b770-752a-4766-8e23-03f883fce97c" satisfied condition "Succeeded or Failed"
    Apr 18 09:26:31.958: INFO: Trying to get logs from node 192.168.1.152 pod pod-a864b770-752a-4766-8e23-03f883fce97c container test-container: <nil>
    STEP: delete the pod 04/18/23 09:26:31.964
    Apr 18 09:26:31.973: INFO: Waiting for pod pod-a864b770-752a-4766-8e23-03f883fce97c to disappear
    Apr 18 09:26:31.975: INFO: Pod pod-a864b770-752a-4766-8e23-03f883fce97c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 09:26:31.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7907" for this suite. 04/18/23 09:26:31.98
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:26:31.986
Apr 18 09:26:31.986: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename configmap 04/18/23 09:26:31.987
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:31.997
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:32.001
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-97a53ba2-5ff2-4d09-bb83-8f85c4d14b62 04/18/23 09:26:32.005
STEP: Creating a pod to test consume configMaps 04/18/23 09:26:32.008
Apr 18 09:26:32.015: INFO: Waiting up to 5m0s for pod "pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb" in namespace "configmap-6161" to be "Succeeded or Failed"
Apr 18 09:26:32.018: INFO: Pod "pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.535289ms
Apr 18 09:26:34.022: INFO: Pod "pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006381266s
Apr 18 09:26:36.022: INFO: Pod "pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006870331s
STEP: Saw pod success 04/18/23 09:26:36.022
Apr 18 09:26:36.022: INFO: Pod "pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb" satisfied condition "Succeeded or Failed"
Apr 18 09:26:36.025: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb container agnhost-container: <nil>
STEP: delete the pod 04/18/23 09:26:36.03
Apr 18 09:26:36.041: INFO: Waiting for pod pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb to disappear
Apr 18 09:26:36.045: INFO: Pod pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 09:26:36.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6161" for this suite. 04/18/23 09:26:36.05
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":261,"skipped":4875,"failed":0}
------------------------------
• [4.068 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:26:31.986
    Apr 18 09:26:31.986: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename configmap 04/18/23 09:26:31.987
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:31.997
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:32.001
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-97a53ba2-5ff2-4d09-bb83-8f85c4d14b62 04/18/23 09:26:32.005
    STEP: Creating a pod to test consume configMaps 04/18/23 09:26:32.008
    Apr 18 09:26:32.015: INFO: Waiting up to 5m0s for pod "pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb" in namespace "configmap-6161" to be "Succeeded or Failed"
    Apr 18 09:26:32.018: INFO: Pod "pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.535289ms
    Apr 18 09:26:34.022: INFO: Pod "pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006381266s
    Apr 18 09:26:36.022: INFO: Pod "pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006870331s
    STEP: Saw pod success 04/18/23 09:26:36.022
    Apr 18 09:26:36.022: INFO: Pod "pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb" satisfied condition "Succeeded or Failed"
    Apr 18 09:26:36.025: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 09:26:36.03
    Apr 18 09:26:36.041: INFO: Waiting for pod pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb to disappear
    Apr 18 09:26:36.045: INFO: Pod pod-configmaps-0325c2f5-48da-4b97-99cf-b41d67899feb no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 09:26:36.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6161" for this suite. 04/18/23 09:26:36.05
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:26:36.055
Apr 18 09:26:36.055: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename sched-pred 04/18/23 09:26:36.056
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:36.066
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:36.07
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 18 09:26:36.074: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 18 09:26:36.080: INFO: Waiting for terminating namespaces to be deleted...
Apr 18 09:26:36.083: INFO: 
Logging pods the apiserver thinks is on node 192.168.1.152 before test
Apr 18 09:26:36.089: INFO: everest-csi-driver-2sbdm from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:26:36.089: INFO: 	Container everest-csi-driver ready: true, restart count 0
Apr 18 09:26:36.089: INFO: icagent-blm9c from kube-system started at 2023-04-17 15:47:22 +0000 UTC (1 container statuses recorded)
Apr 18 09:26:36.089: INFO: 	Container icagent ready: true, restart count 0
Apr 18 09:26:36.089: INFO: sonobuoy from sonobuoy started at 2023-04-18 08:25:22 +0000 UTC (1 container statuses recorded)
Apr 18 09:26:36.089: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 18 09:26:36.089: INFO: sonobuoy-e2e-job-98a0ff59191d4d9f from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:26:36.089: INFO: 	Container e2e ready: true, restart count 0
Apr 18 09:26:36.089: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:26:36.089: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-brt2v from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:26:36.089: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:26:36.089: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 09:26:36.089: INFO: 
Logging pods the apiserver thinks is on node 192.168.1.29 before test
Apr 18 09:26:36.094: INFO: coredns-67ffcb9db-g9zw5 from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
Apr 18 09:26:36.094: INFO: 	Container coredns ready: true, restart count 0
Apr 18 09:26:36.094: INFO: everest-csi-controller-76f85d46b8-f4ksg from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:26:36.094: INFO: 	Container everest-csi-controller ready: true, restart count 0
Apr 18 09:26:36.094: INFO: everest-csi-driver-j2vqd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:26:36.094: INFO: 	Container everest-csi-driver ready: true, restart count 0
Apr 18 09:26:36.094: INFO: icagent-znmkj from kube-system started at 2023-04-17 15:47:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:26:36.094: INFO: 	Container icagent ready: true, restart count 0
Apr 18 09:26:36.094: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-8kqvb from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:26:36.094: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:26:36.094: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 09:26:36.094: INFO: 
Logging pods the apiserver thinks is on node 192.168.1.84 before test
Apr 18 09:26:36.098: INFO: coredns-67ffcb9db-fc7fx from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
Apr 18 09:26:36.098: INFO: 	Container coredns ready: true, restart count 0
Apr 18 09:26:36.098: INFO: everest-csi-controller-76f85d46b8-vkvbd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:26:36.098: INFO: 	Container everest-csi-controller ready: true, restart count 0
Apr 18 09:26:36.098: INFO: everest-csi-driver-ww79w from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:26:36.098: INFO: 	Container everest-csi-driver ready: true, restart count 0
Apr 18 09:26:36.098: INFO: icagent-9xt4k from kube-system started at 2023-04-07 10:53:39 +0000 UTC (1 container statuses recorded)
Apr 18 09:26:36.098: INFO: 	Container icagent ready: true, restart count 0
Apr 18 09:26:36.098: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-6q6gp from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:26:36.099: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:26:36.099: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/18/23 09:26:36.099
Apr 18 09:26:36.106: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-6180" to be "running"
Apr 18 09:26:36.111: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 5.720264ms
Apr 18 09:26:38.116: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.009948181s
Apr 18 09:26:38.116: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/18/23 09:26:38.119
STEP: Trying to apply a random label on the found node. 04/18/23 09:26:38.131
STEP: verifying the node has the label kubernetes.io/e2e-9935c11b-74d2-4bcb-944a-0aa2249e8c2b 95 04/18/23 09:26:38.143
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 04/18/23 09:26:38.148
Apr 18 09:26:38.156: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-6180" to be "not pending"
Apr 18 09:26:38.159: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.660519ms
Apr 18 09:26:40.162: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006543299s
Apr 18 09:26:40.162: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.1.152 on the node which pod4 resides and expect not scheduled 04/18/23 09:26:40.162
Apr 18 09:26:40.167: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-6180" to be "not pending"
Apr 18 09:26:40.170: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.765371ms
Apr 18 09:26:42.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005951617s
Apr 18 09:26:44.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006581581s
Apr 18 09:26:46.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006377619s
Apr 18 09:26:48.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.006372589s
Apr 18 09:26:50.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007263881s
Apr 18 09:26:52.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.005901413s
Apr 18 09:26:54.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.007545265s
Apr 18 09:26:56.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.006354185s
Apr 18 09:26:58.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.00664256s
Apr 18 09:27:00.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.007006856s
Apr 18 09:27:02.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.006482707s
Apr 18 09:27:04.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.006611252s
Apr 18 09:27:06.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.007398648s
Apr 18 09:27:08.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.006217031s
Apr 18 09:27:10.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.006195472s
Apr 18 09:27:12.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.006358659s
Apr 18 09:27:14.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.007499232s
Apr 18 09:27:16.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.005933911s
Apr 18 09:27:18.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.006721709s
Apr 18 09:27:20.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.006228692s
Apr 18 09:27:22.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.006122552s
Apr 18 09:27:24.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.006320312s
Apr 18 09:27:26.179: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.011257624s
Apr 18 09:27:28.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.006509919s
Apr 18 09:27:30.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.006408694s
Apr 18 09:27:32.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.007301877s
Apr 18 09:27:34.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.006483429s
Apr 18 09:27:36.177: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.009291541s
Apr 18 09:27:38.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.007241097s
Apr 18 09:27:40.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.006584936s
Apr 18 09:27:42.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.007386615s
Apr 18 09:27:44.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.007592876s
Apr 18 09:27:46.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.006981828s
Apr 18 09:27:48.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.006243249s
Apr 18 09:27:50.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.007938689s
Apr 18 09:27:52.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.005994343s
Apr 18 09:27:54.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.007301608s
Apr 18 09:27:56.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.006163572s
Apr 18 09:27:58.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.00700572s
Apr 18 09:28:00.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.006114903s
Apr 18 09:28:02.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.006371818s
Apr 18 09:28:04.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.008530846s
Apr 18 09:28:06.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.00609146s
Apr 18 09:28:08.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.006069575s
Apr 18 09:28:10.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.008278752s
Apr 18 09:28:12.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.007521966s
Apr 18 09:28:14.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.007217258s
Apr 18 09:28:16.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.006409123s
Apr 18 09:28:18.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.006243124s
Apr 18 09:28:20.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.00615715s
Apr 18 09:28:22.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.007480509s
Apr 18 09:28:24.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.006447283s
Apr 18 09:28:26.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.006937711s
Apr 18 09:28:28.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.006026224s
Apr 18 09:28:30.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.006202491s
Apr 18 09:28:32.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.006003031s
Apr 18 09:28:34.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.006396943s
Apr 18 09:28:36.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.00716648s
Apr 18 09:28:38.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.006373395s
Apr 18 09:28:40.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.007382563s
Apr 18 09:28:42.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.006604104s
Apr 18 09:28:44.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.007180279s
Apr 18 09:28:46.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.007546448s
Apr 18 09:28:48.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.0060057s
Apr 18 09:28:50.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.00663098s
Apr 18 09:28:52.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.006097259s
Apr 18 09:28:54.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.006580901s
Apr 18 09:28:56.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.007299769s
Apr 18 09:28:58.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.007074619s
Apr 18 09:29:00.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.006686776s
Apr 18 09:29:02.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.007252122s
Apr 18 09:29:04.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.007728509s
Apr 18 09:29:06.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.007379377s
Apr 18 09:29:08.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.006412323s
Apr 18 09:29:10.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.007440867s
Apr 18 09:29:12.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.00686652s
Apr 18 09:29:14.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.007496474s
Apr 18 09:29:16.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.006688911s
Apr 18 09:29:18.182: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.014326769s
Apr 18 09:29:20.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.008805787s
Apr 18 09:29:22.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.006286671s
Apr 18 09:29:24.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.007914021s
Apr 18 09:29:26.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.006614813s
Apr 18 09:29:28.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.006282932s
Apr 18 09:29:30.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.006123014s
Apr 18 09:29:32.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.006887572s
Apr 18 09:29:34.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.006949689s
Apr 18 09:29:36.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.008065102s
Apr 18 09:29:38.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.007340498s
Apr 18 09:29:40.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.008648053s
Apr 18 09:29:42.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.006104343s
Apr 18 09:29:44.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.007466329s
Apr 18 09:29:46.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.007067545s
Apr 18 09:29:48.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.00605963s
Apr 18 09:29:50.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.006396471s
Apr 18 09:29:52.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.007376224s
Apr 18 09:29:54.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.006437565s
Apr 18 09:29:56.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.006645342s
Apr 18 09:29:58.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.006888774s
Apr 18 09:30:00.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.006281634s
Apr 18 09:30:02.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.008186135s
Apr 18 09:30:04.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.006224065s
Apr 18 09:30:06.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.007261441s
Apr 18 09:30:08.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.005987886s
Apr 18 09:30:10.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.006660978s
Apr 18 09:30:12.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.006491128s
Apr 18 09:30:14.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.007654143s
Apr 18 09:30:16.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.007530074s
Apr 18 09:30:18.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.006404898s
Apr 18 09:30:20.177: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.009165252s
Apr 18 09:30:22.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.006365873s
Apr 18 09:30:24.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.007674236s
Apr 18 09:30:26.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.007971878s
Apr 18 09:30:28.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.006287405s
Apr 18 09:30:30.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.006598804s
Apr 18 09:30:32.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.006366698s
Apr 18 09:30:34.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.007062338s
Apr 18 09:30:36.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.007568584s
Apr 18 09:30:38.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.006729946s
Apr 18 09:30:40.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.006717639s
Apr 18 09:30:42.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.007396539s
Apr 18 09:30:44.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.00723581s
Apr 18 09:30:46.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.008474616s
Apr 18 09:30:48.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.006706938s
Apr 18 09:30:50.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.00724539s
Apr 18 09:30:52.182: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.014305311s
Apr 18 09:30:54.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.007985488s
Apr 18 09:30:56.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.007199876s
Apr 18 09:30:58.181: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.013973423s
Apr 18 09:31:00.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.006627071s
Apr 18 09:31:02.187: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.019398604s
Apr 18 09:31:04.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.007858246s
Apr 18 09:31:06.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.007987443s
Apr 18 09:31:08.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.006547272s
Apr 18 09:31:10.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.006526048s
Apr 18 09:31:12.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.006246735s
Apr 18 09:31:14.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.00754218s
Apr 18 09:31:16.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.006343705s
Apr 18 09:31:18.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.008231266s
Apr 18 09:31:20.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.007093452s
Apr 18 09:31:22.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.006666081s
Apr 18 09:31:24.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.007052965s
Apr 18 09:31:26.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.007103158s
Apr 18 09:31:28.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.007125527s
Apr 18 09:31:30.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.006461712s
Apr 18 09:31:32.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.00608629s
Apr 18 09:31:34.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.006241268s
Apr 18 09:31:36.177: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.009999751s
Apr 18 09:31:38.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.006755666s
Apr 18 09:31:40.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.006260724s
Apr 18 09:31:40.177: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.009497353s
STEP: removing the label kubernetes.io/e2e-9935c11b-74d2-4bcb-944a-0aa2249e8c2b off the node 192.168.1.152 04/18/23 09:31:40.177
STEP: verifying the node doesn't have the label kubernetes.io/e2e-9935c11b-74d2-4bcb-944a-0aa2249e8c2b 04/18/23 09:31:40.225
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:31:40.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6180" for this suite. 04/18/23 09:31:40.288
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":262,"skipped":4881,"failed":0}
------------------------------
• [SLOW TEST] [304.239 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:26:36.055
    Apr 18 09:26:36.055: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename sched-pred 04/18/23 09:26:36.056
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:26:36.066
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:26:36.07
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 18 09:26:36.074: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 18 09:26:36.080: INFO: Waiting for terminating namespaces to be deleted...
    Apr 18 09:26:36.083: INFO: 
    Logging pods the apiserver thinks is on node 192.168.1.152 before test
    Apr 18 09:26:36.089: INFO: everest-csi-driver-2sbdm from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:26:36.089: INFO: 	Container everest-csi-driver ready: true, restart count 0
    Apr 18 09:26:36.089: INFO: icagent-blm9c from kube-system started at 2023-04-17 15:47:22 +0000 UTC (1 container statuses recorded)
    Apr 18 09:26:36.089: INFO: 	Container icagent ready: true, restart count 0
    Apr 18 09:26:36.089: INFO: sonobuoy from sonobuoy started at 2023-04-18 08:25:22 +0000 UTC (1 container statuses recorded)
    Apr 18 09:26:36.089: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 18 09:26:36.089: INFO: sonobuoy-e2e-job-98a0ff59191d4d9f from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:26:36.089: INFO: 	Container e2e ready: true, restart count 0
    Apr 18 09:26:36.089: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:26:36.089: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-brt2v from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:26:36.089: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:26:36.089: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 09:26:36.089: INFO: 
    Logging pods the apiserver thinks is on node 192.168.1.29 before test
    Apr 18 09:26:36.094: INFO: coredns-67ffcb9db-g9zw5 from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
    Apr 18 09:26:36.094: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 09:26:36.094: INFO: everest-csi-controller-76f85d46b8-f4ksg from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:26:36.094: INFO: 	Container everest-csi-controller ready: true, restart count 0
    Apr 18 09:26:36.094: INFO: everest-csi-driver-j2vqd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:26:36.094: INFO: 	Container everest-csi-driver ready: true, restart count 0
    Apr 18 09:26:36.094: INFO: icagent-znmkj from kube-system started at 2023-04-17 15:47:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:26:36.094: INFO: 	Container icagent ready: true, restart count 0
    Apr 18 09:26:36.094: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-8kqvb from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:26:36.094: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:26:36.094: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 09:26:36.094: INFO: 
    Logging pods the apiserver thinks is on node 192.168.1.84 before test
    Apr 18 09:26:36.098: INFO: coredns-67ffcb9db-fc7fx from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
    Apr 18 09:26:36.098: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 09:26:36.098: INFO: everest-csi-controller-76f85d46b8-vkvbd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:26:36.098: INFO: 	Container everest-csi-controller ready: true, restart count 0
    Apr 18 09:26:36.098: INFO: everest-csi-driver-ww79w from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:26:36.098: INFO: 	Container everest-csi-driver ready: true, restart count 0
    Apr 18 09:26:36.098: INFO: icagent-9xt4k from kube-system started at 2023-04-07 10:53:39 +0000 UTC (1 container statuses recorded)
    Apr 18 09:26:36.098: INFO: 	Container icagent ready: true, restart count 0
    Apr 18 09:26:36.098: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-6q6gp from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:26:36.099: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:26:36.099: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/18/23 09:26:36.099
    Apr 18 09:26:36.106: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-6180" to be "running"
    Apr 18 09:26:36.111: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 5.720264ms
    Apr 18 09:26:38.116: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.009948181s
    Apr 18 09:26:38.116: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/18/23 09:26:38.119
    STEP: Trying to apply a random label on the found node. 04/18/23 09:26:38.131
    STEP: verifying the node has the label kubernetes.io/e2e-9935c11b-74d2-4bcb-944a-0aa2249e8c2b 95 04/18/23 09:26:38.143
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 04/18/23 09:26:38.148
    Apr 18 09:26:38.156: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-6180" to be "not pending"
    Apr 18 09:26:38.159: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.660519ms
    Apr 18 09:26:40.162: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006543299s
    Apr 18 09:26:40.162: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.1.152 on the node which pod4 resides and expect not scheduled 04/18/23 09:26:40.162
    Apr 18 09:26:40.167: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-6180" to be "not pending"
    Apr 18 09:26:40.170: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.765371ms
    Apr 18 09:26:42.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005951617s
    Apr 18 09:26:44.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006581581s
    Apr 18 09:26:46.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006377619s
    Apr 18 09:26:48.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.006372589s
    Apr 18 09:26:50.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007263881s
    Apr 18 09:26:52.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.005901413s
    Apr 18 09:26:54.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.007545265s
    Apr 18 09:26:56.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.006354185s
    Apr 18 09:26:58.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.00664256s
    Apr 18 09:27:00.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.007006856s
    Apr 18 09:27:02.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.006482707s
    Apr 18 09:27:04.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.006611252s
    Apr 18 09:27:06.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.007398648s
    Apr 18 09:27:08.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.006217031s
    Apr 18 09:27:10.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.006195472s
    Apr 18 09:27:12.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.006358659s
    Apr 18 09:27:14.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.007499232s
    Apr 18 09:27:16.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.005933911s
    Apr 18 09:27:18.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.006721709s
    Apr 18 09:27:20.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.006228692s
    Apr 18 09:27:22.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.006122552s
    Apr 18 09:27:24.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.006320312s
    Apr 18 09:27:26.179: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.011257624s
    Apr 18 09:27:28.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.006509919s
    Apr 18 09:27:30.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.006408694s
    Apr 18 09:27:32.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.007301877s
    Apr 18 09:27:34.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.006483429s
    Apr 18 09:27:36.177: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.009291541s
    Apr 18 09:27:38.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.007241097s
    Apr 18 09:27:40.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.006584936s
    Apr 18 09:27:42.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.007386615s
    Apr 18 09:27:44.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.007592876s
    Apr 18 09:27:46.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.006981828s
    Apr 18 09:27:48.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.006243249s
    Apr 18 09:27:50.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.007938689s
    Apr 18 09:27:52.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.005994343s
    Apr 18 09:27:54.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.007301608s
    Apr 18 09:27:56.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.006163572s
    Apr 18 09:27:58.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.00700572s
    Apr 18 09:28:00.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.006114903s
    Apr 18 09:28:02.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.006371818s
    Apr 18 09:28:04.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.008530846s
    Apr 18 09:28:06.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.00609146s
    Apr 18 09:28:08.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.006069575s
    Apr 18 09:28:10.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.008278752s
    Apr 18 09:28:12.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.007521966s
    Apr 18 09:28:14.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.007217258s
    Apr 18 09:28:16.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.006409123s
    Apr 18 09:28:18.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.006243124s
    Apr 18 09:28:20.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.00615715s
    Apr 18 09:28:22.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.007480509s
    Apr 18 09:28:24.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.006447283s
    Apr 18 09:28:26.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.006937711s
    Apr 18 09:28:28.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.006026224s
    Apr 18 09:28:30.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.006202491s
    Apr 18 09:28:32.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.006003031s
    Apr 18 09:28:34.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.006396943s
    Apr 18 09:28:36.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.00716648s
    Apr 18 09:28:38.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.006373395s
    Apr 18 09:28:40.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.007382563s
    Apr 18 09:28:42.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.006604104s
    Apr 18 09:28:44.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.007180279s
    Apr 18 09:28:46.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.007546448s
    Apr 18 09:28:48.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.0060057s
    Apr 18 09:28:50.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.00663098s
    Apr 18 09:28:52.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.006097259s
    Apr 18 09:28:54.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.006580901s
    Apr 18 09:28:56.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.007299769s
    Apr 18 09:28:58.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.007074619s
    Apr 18 09:29:00.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.006686776s
    Apr 18 09:29:02.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.007252122s
    Apr 18 09:29:04.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.007728509s
    Apr 18 09:29:06.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.007379377s
    Apr 18 09:29:08.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.006412323s
    Apr 18 09:29:10.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.007440867s
    Apr 18 09:29:12.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.00686652s
    Apr 18 09:29:14.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.007496474s
    Apr 18 09:29:16.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.006688911s
    Apr 18 09:29:18.182: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.014326769s
    Apr 18 09:29:20.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.008805787s
    Apr 18 09:29:22.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.006286671s
    Apr 18 09:29:24.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.007914021s
    Apr 18 09:29:26.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.006614813s
    Apr 18 09:29:28.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.006282932s
    Apr 18 09:29:30.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.006123014s
    Apr 18 09:29:32.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.006887572s
    Apr 18 09:29:34.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.006949689s
    Apr 18 09:29:36.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.008065102s
    Apr 18 09:29:38.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.007340498s
    Apr 18 09:29:40.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.008648053s
    Apr 18 09:29:42.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.006104343s
    Apr 18 09:29:44.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.007466329s
    Apr 18 09:29:46.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.007067545s
    Apr 18 09:29:48.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.00605963s
    Apr 18 09:29:50.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.006396471s
    Apr 18 09:29:52.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.007376224s
    Apr 18 09:29:54.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.006437565s
    Apr 18 09:29:56.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.006645342s
    Apr 18 09:29:58.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.006888774s
    Apr 18 09:30:00.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.006281634s
    Apr 18 09:30:02.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.008186135s
    Apr 18 09:30:04.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.006224065s
    Apr 18 09:30:06.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.007261441s
    Apr 18 09:30:08.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.005987886s
    Apr 18 09:30:10.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.006660978s
    Apr 18 09:30:12.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.006491128s
    Apr 18 09:30:14.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.007654143s
    Apr 18 09:30:16.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.007530074s
    Apr 18 09:30:18.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.006404898s
    Apr 18 09:30:20.177: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.009165252s
    Apr 18 09:30:22.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.006365873s
    Apr 18 09:30:24.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.007674236s
    Apr 18 09:30:26.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.007971878s
    Apr 18 09:30:28.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.006287405s
    Apr 18 09:30:30.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.006598804s
    Apr 18 09:30:32.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.006366698s
    Apr 18 09:30:34.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.007062338s
    Apr 18 09:30:36.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.007568584s
    Apr 18 09:30:38.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.006729946s
    Apr 18 09:30:40.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.006717639s
    Apr 18 09:30:42.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.007396539s
    Apr 18 09:30:44.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.00723581s
    Apr 18 09:30:46.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.008474616s
    Apr 18 09:30:48.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.006706938s
    Apr 18 09:30:50.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.00724539s
    Apr 18 09:30:52.182: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.014305311s
    Apr 18 09:30:54.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.007985488s
    Apr 18 09:30:56.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.007199876s
    Apr 18 09:30:58.181: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.013973423s
    Apr 18 09:31:00.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.006627071s
    Apr 18 09:31:02.187: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.019398604s
    Apr 18 09:31:04.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.007858246s
    Apr 18 09:31:06.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.007987443s
    Apr 18 09:31:08.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.006547272s
    Apr 18 09:31:10.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.006526048s
    Apr 18 09:31:12.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.006246735s
    Apr 18 09:31:14.175: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.00754218s
    Apr 18 09:31:16.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.006343705s
    Apr 18 09:31:18.176: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.008231266s
    Apr 18 09:31:20.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.007093452s
    Apr 18 09:31:22.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.006666081s
    Apr 18 09:31:24.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.007052965s
    Apr 18 09:31:26.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.007103158s
    Apr 18 09:31:28.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.007125527s
    Apr 18 09:31:30.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.006461712s
    Apr 18 09:31:32.173: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.00608629s
    Apr 18 09:31:34.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.006241268s
    Apr 18 09:31:36.177: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.009999751s
    Apr 18 09:31:38.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.006755666s
    Apr 18 09:31:40.174: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.006260724s
    Apr 18 09:31:40.177: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.009497353s
    STEP: removing the label kubernetes.io/e2e-9935c11b-74d2-4bcb-944a-0aa2249e8c2b off the node 192.168.1.152 04/18/23 09:31:40.177
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-9935c11b-74d2-4bcb-944a-0aa2249e8c2b 04/18/23 09:31:40.225
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:31:40.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-6180" for this suite. 04/18/23 09:31:40.288
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:31:40.294
Apr 18 09:31:40.295: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 09:31:40.295
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:31:40.305
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:31:40.311
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Apr 18 09:31:40.317: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:31:41.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1886" for this suite. 04/18/23 09:31:41.349
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":263,"skipped":4883,"failed":0}
------------------------------
• [1.061 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:31:40.294
    Apr 18 09:31:40.295: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 09:31:40.295
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:31:40.305
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:31:40.311
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Apr 18 09:31:40.317: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:31:41.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1886" for this suite. 04/18/23 09:31:41.349
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:31:41.356
Apr 18 09:31:41.356: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename job 04/18/23 09:31:41.356
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:31:41.366
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:31:41.37
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 04/18/23 09:31:41.374
STEP: Ensuring job reaches completions 04/18/23 09:31:41.38
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 18 09:31:51.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5253" for this suite. 04/18/23 09:31:51.388
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":264,"skipped":4887,"failed":0}
------------------------------
• [SLOW TEST] [10.037 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:31:41.356
    Apr 18 09:31:41.356: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename job 04/18/23 09:31:41.356
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:31:41.366
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:31:41.37
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 04/18/23 09:31:41.374
    STEP: Ensuring job reaches completions 04/18/23 09:31:41.38
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 18 09:31:51.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-5253" for this suite. 04/18/23 09:31:51.388
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:31:51.393
Apr 18 09:31:51.393: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir 04/18/23 09:31:51.394
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:31:51.403
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:31:51.407
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 04/18/23 09:31:51.411
Apr 18 09:31:51.417: INFO: Waiting up to 5m0s for pod "pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b" in namespace "emptydir-7107" to be "Succeeded or Failed"
Apr 18 09:31:51.421: INFO: Pod "pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.813123ms
Apr 18 09:31:53.425: INFO: Pod "pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008337299s
Apr 18 09:31:55.425: INFO: Pod "pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008471097s
STEP: Saw pod success 04/18/23 09:31:55.425
Apr 18 09:31:55.425: INFO: Pod "pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b" satisfied condition "Succeeded or Failed"
Apr 18 09:31:55.428: INFO: Trying to get logs from node 192.168.1.152 pod pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b container test-container: <nil>
STEP: delete the pod 04/18/23 09:31:55.442
Apr 18 09:31:55.456: INFO: Waiting for pod pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b to disappear
Apr 18 09:31:55.459: INFO: Pod pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 09:31:55.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7107" for this suite. 04/18/23 09:31:55.463
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":265,"skipped":4898,"failed":0}
------------------------------
• [4.074 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:31:51.393
    Apr 18 09:31:51.393: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir 04/18/23 09:31:51.394
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:31:51.403
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:31:51.407
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 04/18/23 09:31:51.411
    Apr 18 09:31:51.417: INFO: Waiting up to 5m0s for pod "pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b" in namespace "emptydir-7107" to be "Succeeded or Failed"
    Apr 18 09:31:51.421: INFO: Pod "pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.813123ms
    Apr 18 09:31:53.425: INFO: Pod "pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008337299s
    Apr 18 09:31:55.425: INFO: Pod "pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008471097s
    STEP: Saw pod success 04/18/23 09:31:55.425
    Apr 18 09:31:55.425: INFO: Pod "pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b" satisfied condition "Succeeded or Failed"
    Apr 18 09:31:55.428: INFO: Trying to get logs from node 192.168.1.152 pod pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b container test-container: <nil>
    STEP: delete the pod 04/18/23 09:31:55.442
    Apr 18 09:31:55.456: INFO: Waiting for pod pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b to disappear
    Apr 18 09:31:55.459: INFO: Pod pod-bd6eb00d-8d48-40cb-aea7-53d905a74e7b no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 09:31:55.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7107" for this suite. 04/18/23 09:31:55.463
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:31:55.468
Apr 18 09:31:55.468: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename aggregator 04/18/23 09:31:55.469
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:31:55.481
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:31:55.484
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Apr 18 09:31:55.488: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 04/18/23 09:31:55.489
Apr 18 09:31:55.865: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr 18 09:31:57.897: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 09:31:59.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 09:32:01.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 09:32:03.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 09:32:05.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 09:32:07.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 09:32:09.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 09:32:11.900: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 09:32:13.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 09:32:15.902: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 09:32:17.900: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 09:32:19.902: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 09:32:22.027: INFO: Waited 120.587727ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 04/18/23 09:32:22.075
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 04/18/23 09:32:22.078
STEP: List APIServices 04/18/23 09:32:22.085
Apr 18 09:32:22.091: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Apr 18 09:32:22.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1411" for this suite. 04/18/23 09:32:22.614
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":266,"skipped":4937,"failed":0}
------------------------------
• [SLOW TEST] [27.198 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:31:55.468
    Apr 18 09:31:55.468: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename aggregator 04/18/23 09:31:55.469
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:31:55.481
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:31:55.484
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Apr 18 09:31:55.488: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 04/18/23 09:31:55.489
    Apr 18 09:31:55.865: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Apr 18 09:31:57.897: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 09:31:59.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 09:32:01.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 09:32:03.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 09:32:05.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 09:32:07.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 09:32:09.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 09:32:11.900: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 09:32:13.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 09:32:15.902: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 09:32:17.900: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 09:32:19.902: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 9, 31, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7896d48456\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 09:32:22.027: INFO: Waited 120.587727ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 04/18/23 09:32:22.075
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 04/18/23 09:32:22.078
    STEP: List APIServices 04/18/23 09:32:22.085
    Apr 18 09:32:22.091: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Apr 18 09:32:22.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-1411" for this suite. 04/18/23 09:32:22.614
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:32:22.667
Apr 18 09:32:22.667: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename sched-pred 04/18/23 09:32:22.668
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:32:22.678
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:32:22.682
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 18 09:32:22.686: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 18 09:32:22.692: INFO: Waiting for terminating namespaces to be deleted...
Apr 18 09:32:22.695: INFO: 
Logging pods the apiserver thinks is on node 192.168.1.152 before test
Apr 18 09:32:22.700: INFO: everest-csi-driver-2sbdm from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:32:22.700: INFO: 	Container everest-csi-driver ready: true, restart count 0
Apr 18 09:32:22.700: INFO: icagent-blm9c from kube-system started at 2023-04-17 15:47:22 +0000 UTC (1 container statuses recorded)
Apr 18 09:32:22.700: INFO: 	Container icagent ready: true, restart count 0
Apr 18 09:32:22.700: INFO: sonobuoy from sonobuoy started at 2023-04-18 08:25:22 +0000 UTC (1 container statuses recorded)
Apr 18 09:32:22.701: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 18 09:32:22.701: INFO: sonobuoy-e2e-job-98a0ff59191d4d9f from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:32:22.701: INFO: 	Container e2e ready: true, restart count 0
Apr 18 09:32:22.701: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:32:22.701: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-brt2v from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:32:22.701: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:32:22.701: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 09:32:22.701: INFO: 
Logging pods the apiserver thinks is on node 192.168.1.29 before test
Apr 18 09:32:22.706: INFO: coredns-67ffcb9db-g9zw5 from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
Apr 18 09:32:22.706: INFO: 	Container coredns ready: true, restart count 0
Apr 18 09:32:22.706: INFO: everest-csi-controller-76f85d46b8-f4ksg from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:32:22.706: INFO: 	Container everest-csi-controller ready: true, restart count 0
Apr 18 09:32:22.706: INFO: everest-csi-driver-j2vqd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:32:22.706: INFO: 	Container everest-csi-driver ready: true, restart count 0
Apr 18 09:32:22.706: INFO: icagent-znmkj from kube-system started at 2023-04-17 15:47:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:32:22.706: INFO: 	Container icagent ready: true, restart count 0
Apr 18 09:32:22.706: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-8kqvb from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:32:22.706: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:32:22.706: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 09:32:22.706: INFO: 
Logging pods the apiserver thinks is on node 192.168.1.84 before test
Apr 18 09:32:22.711: INFO: coredns-67ffcb9db-fc7fx from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
Apr 18 09:32:22.711: INFO: 	Container coredns ready: true, restart count 0
Apr 18 09:32:22.711: INFO: everest-csi-controller-76f85d46b8-vkvbd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:32:22.711: INFO: 	Container everest-csi-controller ready: true, restart count 0
Apr 18 09:32:22.711: INFO: everest-csi-driver-ww79w from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:32:22.711: INFO: 	Container everest-csi-driver ready: true, restart count 0
Apr 18 09:32:22.711: INFO: icagent-9xt4k from kube-system started at 2023-04-07 10:53:39 +0000 UTC (1 container statuses recorded)
Apr 18 09:32:22.711: INFO: 	Container icagent ready: true, restart count 0
Apr 18 09:32:22.711: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-6q6gp from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:32:22.711: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:32:22.711: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 04/18/23 09:32:22.711
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1756fd989a12aba8], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 04/18/23 09:32:22.737
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:32:23.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6060" for this suite. 04/18/23 09:32:23.741
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":267,"skipped":4944,"failed":0}
------------------------------
• [1.087 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:32:22.667
    Apr 18 09:32:22.667: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename sched-pred 04/18/23 09:32:22.668
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:32:22.678
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:32:22.682
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 18 09:32:22.686: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 18 09:32:22.692: INFO: Waiting for terminating namespaces to be deleted...
    Apr 18 09:32:22.695: INFO: 
    Logging pods the apiserver thinks is on node 192.168.1.152 before test
    Apr 18 09:32:22.700: INFO: everest-csi-driver-2sbdm from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:32:22.700: INFO: 	Container everest-csi-driver ready: true, restart count 0
    Apr 18 09:32:22.700: INFO: icagent-blm9c from kube-system started at 2023-04-17 15:47:22 +0000 UTC (1 container statuses recorded)
    Apr 18 09:32:22.700: INFO: 	Container icagent ready: true, restart count 0
    Apr 18 09:32:22.700: INFO: sonobuoy from sonobuoy started at 2023-04-18 08:25:22 +0000 UTC (1 container statuses recorded)
    Apr 18 09:32:22.701: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 18 09:32:22.701: INFO: sonobuoy-e2e-job-98a0ff59191d4d9f from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:32:22.701: INFO: 	Container e2e ready: true, restart count 0
    Apr 18 09:32:22.701: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:32:22.701: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-brt2v from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:32:22.701: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:32:22.701: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 09:32:22.701: INFO: 
    Logging pods the apiserver thinks is on node 192.168.1.29 before test
    Apr 18 09:32:22.706: INFO: coredns-67ffcb9db-g9zw5 from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
    Apr 18 09:32:22.706: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 09:32:22.706: INFO: everest-csi-controller-76f85d46b8-f4ksg from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:32:22.706: INFO: 	Container everest-csi-controller ready: true, restart count 0
    Apr 18 09:32:22.706: INFO: everest-csi-driver-j2vqd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:32:22.706: INFO: 	Container everest-csi-driver ready: true, restart count 0
    Apr 18 09:32:22.706: INFO: icagent-znmkj from kube-system started at 2023-04-17 15:47:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:32:22.706: INFO: 	Container icagent ready: true, restart count 0
    Apr 18 09:32:22.706: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-8kqvb from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:32:22.706: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:32:22.706: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 09:32:22.706: INFO: 
    Logging pods the apiserver thinks is on node 192.168.1.84 before test
    Apr 18 09:32:22.711: INFO: coredns-67ffcb9db-fc7fx from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
    Apr 18 09:32:22.711: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 09:32:22.711: INFO: everest-csi-controller-76f85d46b8-vkvbd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:32:22.711: INFO: 	Container everest-csi-controller ready: true, restart count 0
    Apr 18 09:32:22.711: INFO: everest-csi-driver-ww79w from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:32:22.711: INFO: 	Container everest-csi-driver ready: true, restart count 0
    Apr 18 09:32:22.711: INFO: icagent-9xt4k from kube-system started at 2023-04-07 10:53:39 +0000 UTC (1 container statuses recorded)
    Apr 18 09:32:22.711: INFO: 	Container icagent ready: true, restart count 0
    Apr 18 09:32:22.711: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-6q6gp from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:32:22.711: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:32:22.711: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 04/18/23 09:32:22.711
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.1756fd989a12aba8], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 04/18/23 09:32:22.737
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:32:23.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-6060" for this suite. 04/18/23 09:32:23.741
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:32:23.754
Apr 18 09:32:23.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 09:32:23.755
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:32:23.765
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:32:23.771
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-a4ef911a-39d2-4afb-b77e-38b8d8961e6d 04/18/23 09:32:23.778
STEP: Creating secret with name s-test-opt-upd-638112d0-64eb-46a7-8806-972c8f76f2f8 04/18/23 09:32:23.786
STEP: Creating the pod 04/18/23 09:32:23.79
Apr 18 09:32:23.802: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e48ab164-4314-4c45-9e33-7458f9d87fd0" in namespace "projected-1260" to be "running and ready"
Apr 18 09:32:23.805: INFO: Pod "pod-projected-secrets-e48ab164-4314-4c45-9e33-7458f9d87fd0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.983336ms
Apr 18 09:32:23.805: INFO: The phase of Pod pod-projected-secrets-e48ab164-4314-4c45-9e33-7458f9d87fd0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:32:25.809: INFO: Pod "pod-projected-secrets-e48ab164-4314-4c45-9e33-7458f9d87fd0": Phase="Running", Reason="", readiness=true. Elapsed: 2.006516501s
Apr 18 09:32:25.809: INFO: The phase of Pod pod-projected-secrets-e48ab164-4314-4c45-9e33-7458f9d87fd0 is Running (Ready = true)
Apr 18 09:32:25.809: INFO: Pod "pod-projected-secrets-e48ab164-4314-4c45-9e33-7458f9d87fd0" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-a4ef911a-39d2-4afb-b77e-38b8d8961e6d 04/18/23 09:32:25.828
STEP: Updating secret s-test-opt-upd-638112d0-64eb-46a7-8806-972c8f76f2f8 04/18/23 09:32:25.833
STEP: Creating secret with name s-test-opt-create-b74352d3-684a-4ca1-8a15-6854efb547d9 04/18/23 09:32:25.838
STEP: waiting to observe update in volume 04/18/23 09:32:25.843
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 18 09:33:46.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1260" for this suite. 04/18/23 09:33:46.162
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":268,"skipped":4958,"failed":0}
------------------------------
• [SLOW TEST] [82.413 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:32:23.754
    Apr 18 09:32:23.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 09:32:23.755
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:32:23.765
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:32:23.771
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-a4ef911a-39d2-4afb-b77e-38b8d8961e6d 04/18/23 09:32:23.778
    STEP: Creating secret with name s-test-opt-upd-638112d0-64eb-46a7-8806-972c8f76f2f8 04/18/23 09:32:23.786
    STEP: Creating the pod 04/18/23 09:32:23.79
    Apr 18 09:32:23.802: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e48ab164-4314-4c45-9e33-7458f9d87fd0" in namespace "projected-1260" to be "running and ready"
    Apr 18 09:32:23.805: INFO: Pod "pod-projected-secrets-e48ab164-4314-4c45-9e33-7458f9d87fd0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.983336ms
    Apr 18 09:32:23.805: INFO: The phase of Pod pod-projected-secrets-e48ab164-4314-4c45-9e33-7458f9d87fd0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:32:25.809: INFO: Pod "pod-projected-secrets-e48ab164-4314-4c45-9e33-7458f9d87fd0": Phase="Running", Reason="", readiness=true. Elapsed: 2.006516501s
    Apr 18 09:32:25.809: INFO: The phase of Pod pod-projected-secrets-e48ab164-4314-4c45-9e33-7458f9d87fd0 is Running (Ready = true)
    Apr 18 09:32:25.809: INFO: Pod "pod-projected-secrets-e48ab164-4314-4c45-9e33-7458f9d87fd0" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-a4ef911a-39d2-4afb-b77e-38b8d8961e6d 04/18/23 09:32:25.828
    STEP: Updating secret s-test-opt-upd-638112d0-64eb-46a7-8806-972c8f76f2f8 04/18/23 09:32:25.833
    STEP: Creating secret with name s-test-opt-create-b74352d3-684a-4ca1-8a15-6854efb547d9 04/18/23 09:32:25.838
    STEP: waiting to observe update in volume 04/18/23 09:32:25.843
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 18 09:33:46.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1260" for this suite. 04/18/23 09:33:46.162
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:33:46.168
Apr 18 09:33:46.168: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 09:33:46.168
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:33:46.182
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:33:46.186
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 09:33:46.19
Apr 18 09:33:46.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1290 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr 18 09:33:46.246: INFO: stderr: ""
Apr 18 09:33:46.246: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 04/18/23 09:33:46.246
STEP: verifying the pod e2e-test-httpd-pod was created 04/18/23 09:33:51.299
Apr 18 09:33:51.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1290 get pod e2e-test-httpd-pod -o json'
Apr 18 09:33:51.361: INFO: stderr: ""
Apr 18 09:33:51.361: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-04-18T09:33:46Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-1290\",\n        \"resourceVersion\": \"4196653\",\n        \"uid\": \"1086149d-e5f8-44df-aa92-d6df37700477\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-w2rk6\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsConfig\": {\n            \"options\": [\n                {\n                    \"name\": \"single-request-reopen\",\n                    \"value\": \"\"\n                },\n                {\n                    \"name\": \"timeout\",\n                    \"value\": \"2\"\n                }\n            ]\n        },\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"192.168.1.152\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-w2rk6\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T09:33:46Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T09:33:47Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T09:33:47Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T09:33:46Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://9710d65a2494ec289556da2845c65baae5508f7f2acf68c0575bcedc7902fe78\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-04-18T09:33:46Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.1.152\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.16.1.39\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.16.1.39\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-04-18T09:33:46Z\"\n    }\n}\n"
STEP: replace the image in the pod 04/18/23 09:33:51.361
Apr 18 09:33:51.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1290 replace -f -'
Apr 18 09:33:52.219: INFO: stderr: ""
Apr 18 09:33:52.219: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 04/18/23 09:33:52.219
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Apr 18 09:33:52.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1290 delete pods e2e-test-httpd-pod'
Apr 18 09:33:53.736: INFO: stderr: ""
Apr 18 09:33:53.736: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 09:33:53.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1290" for this suite. 04/18/23 09:33:53.741
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":269,"skipped":4962,"failed":0}
------------------------------
• [SLOW TEST] [7.579 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:33:46.168
    Apr 18 09:33:46.168: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 09:33:46.168
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:33:46.182
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:33:46.186
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 09:33:46.19
    Apr 18 09:33:46.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1290 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Apr 18 09:33:46.246: INFO: stderr: ""
    Apr 18 09:33:46.246: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 04/18/23 09:33:46.246
    STEP: verifying the pod e2e-test-httpd-pod was created 04/18/23 09:33:51.299
    Apr 18 09:33:51.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1290 get pod e2e-test-httpd-pod -o json'
    Apr 18 09:33:51.361: INFO: stderr: ""
    Apr 18 09:33:51.361: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-04-18T09:33:46Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-1290\",\n        \"resourceVersion\": \"4196653\",\n        \"uid\": \"1086149d-e5f8-44df-aa92-d6df37700477\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-w2rk6\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsConfig\": {\n            \"options\": [\n                {\n                    \"name\": \"single-request-reopen\",\n                    \"value\": \"\"\n                },\n                {\n                    \"name\": \"timeout\",\n                    \"value\": \"2\"\n                }\n            ]\n        },\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"192.168.1.152\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-w2rk6\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T09:33:46Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T09:33:47Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T09:33:47Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T09:33:46Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://9710d65a2494ec289556da2845c65baae5508f7f2acf68c0575bcedc7902fe78\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-04-18T09:33:46Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.1.152\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.16.1.39\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.16.1.39\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-04-18T09:33:46Z\"\n    }\n}\n"
    STEP: replace the image in the pod 04/18/23 09:33:51.361
    Apr 18 09:33:51.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1290 replace -f -'
    Apr 18 09:33:52.219: INFO: stderr: ""
    Apr 18 09:33:52.219: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 04/18/23 09:33:52.219
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Apr 18 09:33:52.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1290 delete pods e2e-test-httpd-pod'
    Apr 18 09:33:53.736: INFO: stderr: ""
    Apr 18 09:33:53.736: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 09:33:53.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1290" for this suite. 04/18/23 09:33:53.741
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:33:53.746
Apr 18 09:33:53.747: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 09:33:53.747
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:33:53.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:33:53.762
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 04/18/23 09:33:53.766
Apr 18 09:33:53.766: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 09:33:55.925: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:34:07.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1509" for this suite. 04/18/23 09:34:07.33
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":270,"skipped":4965,"failed":0}
------------------------------
• [SLOW TEST] [13.588 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:33:53.746
    Apr 18 09:33:53.747: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 09:33:53.747
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:33:53.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:33:53.762
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 04/18/23 09:33:53.766
    Apr 18 09:33:53.766: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 09:33:55.925: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:34:07.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1509" for this suite. 04/18/23 09:34:07.33
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:34:07.336
Apr 18 09:34:07.336: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename job 04/18/23 09:34:07.337
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:34:07.352
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:34:07.356
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 04/18/23 09:34:07.359
STEP: Ensuring active pods == parallelism 04/18/23 09:34:07.363
STEP: delete a job 04/18/23 09:34:09.367
STEP: deleting Job.batch foo in namespace job-5041, will wait for the garbage collector to delete the pods 04/18/23 09:34:09.367
Apr 18 09:34:09.425: INFO: Deleting Job.batch foo took: 4.677477ms
Apr 18 09:34:09.526: INFO: Terminating Job.batch foo pods took: 100.730782ms
STEP: Ensuring job was deleted 04/18/23 09:34:41.926
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 18 09:34:41.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5041" for this suite. 04/18/23 09:34:41.934
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":271,"skipped":4983,"failed":0}
------------------------------
• [SLOW TEST] [34.602 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:34:07.336
    Apr 18 09:34:07.336: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename job 04/18/23 09:34:07.337
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:34:07.352
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:34:07.356
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 04/18/23 09:34:07.359
    STEP: Ensuring active pods == parallelism 04/18/23 09:34:07.363
    STEP: delete a job 04/18/23 09:34:09.367
    STEP: deleting Job.batch foo in namespace job-5041, will wait for the garbage collector to delete the pods 04/18/23 09:34:09.367
    Apr 18 09:34:09.425: INFO: Deleting Job.batch foo took: 4.677477ms
    Apr 18 09:34:09.526: INFO: Terminating Job.batch foo pods took: 100.730782ms
    STEP: Ensuring job was deleted 04/18/23 09:34:41.926
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 18 09:34:41.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-5041" for this suite. 04/18/23 09:34:41.934
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:34:41.941
Apr 18 09:34:41.942: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename svcaccounts 04/18/23 09:34:41.942
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:34:41.953
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:34:41.956
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Apr 18 09:34:41.962: INFO: Got root ca configmap in namespace "svcaccounts-4365"
Apr 18 09:34:41.966: INFO: Deleted root ca configmap in namespace "svcaccounts-4365"
STEP: waiting for a new root ca configmap created 04/18/23 09:34:42.467
Apr 18 09:34:42.470: INFO: Recreated root ca configmap in namespace "svcaccounts-4365"
Apr 18 09:34:42.475: INFO: Updated root ca configmap in namespace "svcaccounts-4365"
STEP: waiting for the root ca configmap reconciled 04/18/23 09:34:42.976
Apr 18 09:34:42.979: INFO: Reconciled root ca configmap in namespace "svcaccounts-4365"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 18 09:34:42.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4365" for this suite. 04/18/23 09:34:42.985
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":272,"skipped":5002,"failed":0}
------------------------------
• [1.050 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:34:41.941
    Apr 18 09:34:41.942: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename svcaccounts 04/18/23 09:34:41.942
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:34:41.953
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:34:41.956
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Apr 18 09:34:41.962: INFO: Got root ca configmap in namespace "svcaccounts-4365"
    Apr 18 09:34:41.966: INFO: Deleted root ca configmap in namespace "svcaccounts-4365"
    STEP: waiting for a new root ca configmap created 04/18/23 09:34:42.467
    Apr 18 09:34:42.470: INFO: Recreated root ca configmap in namespace "svcaccounts-4365"
    Apr 18 09:34:42.475: INFO: Updated root ca configmap in namespace "svcaccounts-4365"
    STEP: waiting for the root ca configmap reconciled 04/18/23 09:34:42.976
    Apr 18 09:34:42.979: INFO: Reconciled root ca configmap in namespace "svcaccounts-4365"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 18 09:34:42.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4365" for this suite. 04/18/23 09:34:42.985
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:34:42.997
Apr 18 09:34:42.997: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename secrets 04/18/23 09:34:42.998
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:34:43.008
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:34:43.011
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-f730ba52-9ee9-49bc-8da2-333425ea0cdd 04/18/23 09:34:43.015
STEP: Creating a pod to test consume secrets 04/18/23 09:34:43.02
Apr 18 09:34:43.025: INFO: Waiting up to 5m0s for pod "pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350" in namespace "secrets-1564" to be "Succeeded or Failed"
Apr 18 09:34:43.028: INFO: Pod "pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350": Phase="Pending", Reason="", readiness=false. Elapsed: 2.861833ms
Apr 18 09:34:45.032: INFO: Pod "pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006115509s
Apr 18 09:34:47.031: INFO: Pod "pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005749305s
STEP: Saw pod success 04/18/23 09:34:47.031
Apr 18 09:34:47.032: INFO: Pod "pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350" satisfied condition "Succeeded or Failed"
Apr 18 09:34:47.034: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350 container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 09:34:47.041
Apr 18 09:34:47.052: INFO: Waiting for pod pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350 to disappear
Apr 18 09:34:47.054: INFO: Pod pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 09:34:47.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1564" for this suite. 04/18/23 09:34:47.058
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":273,"skipped":5023,"failed":0}
------------------------------
• [4.065 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:34:42.997
    Apr 18 09:34:42.997: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename secrets 04/18/23 09:34:42.998
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:34:43.008
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:34:43.011
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-f730ba52-9ee9-49bc-8da2-333425ea0cdd 04/18/23 09:34:43.015
    STEP: Creating a pod to test consume secrets 04/18/23 09:34:43.02
    Apr 18 09:34:43.025: INFO: Waiting up to 5m0s for pod "pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350" in namespace "secrets-1564" to be "Succeeded or Failed"
    Apr 18 09:34:43.028: INFO: Pod "pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350": Phase="Pending", Reason="", readiness=false. Elapsed: 2.861833ms
    Apr 18 09:34:45.032: INFO: Pod "pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006115509s
    Apr 18 09:34:47.031: INFO: Pod "pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005749305s
    STEP: Saw pod success 04/18/23 09:34:47.031
    Apr 18 09:34:47.032: INFO: Pod "pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350" satisfied condition "Succeeded or Failed"
    Apr 18 09:34:47.034: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350 container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 09:34:47.041
    Apr 18 09:34:47.052: INFO: Waiting for pod pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350 to disappear
    Apr 18 09:34:47.054: INFO: Pod pod-secrets-963825a9-8f79-42f0-9431-cc094a2d3350 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 09:34:47.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1564" for this suite. 04/18/23 09:34:47.058
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:34:47.063
Apr 18 09:34:47.063: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename replication-controller 04/18/23 09:34:47.063
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:34:47.073
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:34:47.076
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 04/18/23 09:34:47.079
STEP: When the matched label of one of its pods change 04/18/23 09:34:47.083
Apr 18 09:34:47.085: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 18 09:34:52.089: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 04/18/23 09:34:52.098
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 18 09:34:53.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2801" for this suite. 04/18/23 09:34:53.109
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":274,"skipped":5024,"failed":0}
------------------------------
• [SLOW TEST] [6.052 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:34:47.063
    Apr 18 09:34:47.063: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename replication-controller 04/18/23 09:34:47.063
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:34:47.073
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:34:47.076
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 04/18/23 09:34:47.079
    STEP: When the matched label of one of its pods change 04/18/23 09:34:47.083
    Apr 18 09:34:47.085: INFO: Pod name pod-release: Found 0 pods out of 1
    Apr 18 09:34:52.089: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 04/18/23 09:34:52.098
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 18 09:34:53.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-2801" for this suite. 04/18/23 09:34:53.109
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:34:53.115
Apr 18 09:34:53.115: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename init-container 04/18/23 09:34:53.115
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:34:53.125
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:34:53.128
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 04/18/23 09:34:53.132
Apr 18 09:34:53.132: INFO: PodSpec: initContainers in spec.initContainers
Apr 18 09:35:35.899: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-7d3fca51-15c2-4878-bdaf-0967568e311c", GenerateName:"", Namespace:"init-container-9197", SelfLink:"", UID:"34040f3d-a277-4116-aae4-cf383262d759", ResourceVersion:"4197294", Generation:0, CreationTimestamp:time.Date(2023, time.April, 18, 9, 34, 53, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"132537722"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 18, 9, 34, 53, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc006b21b48), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 18, 9, 35, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc006b21b78), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-kpflc", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0051b6600), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kpflc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kpflc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kpflc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc006c1e870), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"192.168.1.152", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc007f00a80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006c1e920)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006c1e940)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc006c1e948), DNSConfig:(*v1.PodDNSConfig)(0xc003131b30), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc006c1e957), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc006b648c0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 9, 34, 53, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 9, 34, 53, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 9, 34, 53, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 9, 34, 53, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.1.152", PodIP:"172.16.1.45", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.16.1.45"}}, StartTime:time.Date(2023, time.April, 18, 9, 34, 53, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc007f00b60)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc007f00bd0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://f79a9aa86398f64bb523b09f8edd41d2b80ebfda827aca05865d3fbcc6b8c5f3", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0051b6680), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0051b6660), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc006c1e9ef)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 18 09:35:35.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9197" for this suite. 04/18/23 09:35:35.906
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":275,"skipped":5025,"failed":0}
------------------------------
• [SLOW TEST] [42.796 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:34:53.115
    Apr 18 09:34:53.115: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename init-container 04/18/23 09:34:53.115
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:34:53.125
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:34:53.128
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 04/18/23 09:34:53.132
    Apr 18 09:34:53.132: INFO: PodSpec: initContainers in spec.initContainers
    Apr 18 09:35:35.899: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-7d3fca51-15c2-4878-bdaf-0967568e311c", GenerateName:"", Namespace:"init-container-9197", SelfLink:"", UID:"34040f3d-a277-4116-aae4-cf383262d759", ResourceVersion:"4197294", Generation:0, CreationTimestamp:time.Date(2023, time.April, 18, 9, 34, 53, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"132537722"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 18, 9, 34, 53, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc006b21b48), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 18, 9, 35, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc006b21b78), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-kpflc", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0051b6600), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kpflc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kpflc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kpflc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc006c1e870), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"192.168.1.152", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc007f00a80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006c1e920)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006c1e940)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc006c1e948), DNSConfig:(*v1.PodDNSConfig)(0xc003131b30), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc006c1e957), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc006b648c0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 9, 34, 53, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 9, 34, 53, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 9, 34, 53, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 9, 34, 53, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.1.152", PodIP:"172.16.1.45", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.16.1.45"}}, StartTime:time.Date(2023, time.April, 18, 9, 34, 53, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc007f00b60)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc007f00bd0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://f79a9aa86398f64bb523b09f8edd41d2b80ebfda827aca05865d3fbcc6b8c5f3", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0051b6680), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0051b6660), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc006c1e9ef)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 18 09:35:35.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-9197" for this suite. 04/18/23 09:35:35.906
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:35:35.912
Apr 18 09:35:35.912: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 09:35:35.912
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:35:35.921
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:35:35.925
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-0dfbcd99-e212-40af-9bfc-ff66d9a20a99 04/18/23 09:35:35.928
STEP: Creating a pod to test consume configMaps 04/18/23 09:35:35.935
Apr 18 09:35:35.943: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631" in namespace "projected-6433" to be "Succeeded or Failed"
Apr 18 09:35:35.946: INFO: Pod "pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631": Phase="Pending", Reason="", readiness=false. Elapsed: 2.809904ms
Apr 18 09:35:37.949: INFO: Pod "pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006454887s
Apr 18 09:35:39.950: INFO: Pod "pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007275244s
STEP: Saw pod success 04/18/23 09:35:39.95
Apr 18 09:35:39.950: INFO: Pod "pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631" satisfied condition "Succeeded or Failed"
Apr 18 09:35:39.953: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 09:35:39.958
Apr 18 09:35:39.967: INFO: Waiting for pod pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631 to disappear
Apr 18 09:35:39.969: INFO: Pod pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 09:35:39.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6433" for this suite. 04/18/23 09:35:39.973
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":276,"skipped":5026,"failed":0}
------------------------------
• [4.066 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:35:35.912
    Apr 18 09:35:35.912: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 09:35:35.912
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:35:35.921
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:35:35.925
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-0dfbcd99-e212-40af-9bfc-ff66d9a20a99 04/18/23 09:35:35.928
    STEP: Creating a pod to test consume configMaps 04/18/23 09:35:35.935
    Apr 18 09:35:35.943: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631" in namespace "projected-6433" to be "Succeeded or Failed"
    Apr 18 09:35:35.946: INFO: Pod "pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631": Phase="Pending", Reason="", readiness=false. Elapsed: 2.809904ms
    Apr 18 09:35:37.949: INFO: Pod "pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006454887s
    Apr 18 09:35:39.950: INFO: Pod "pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007275244s
    STEP: Saw pod success 04/18/23 09:35:39.95
    Apr 18 09:35:39.950: INFO: Pod "pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631" satisfied condition "Succeeded or Failed"
    Apr 18 09:35:39.953: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 09:35:39.958
    Apr 18 09:35:39.967: INFO: Waiting for pod pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631 to disappear
    Apr 18 09:35:39.969: INFO: Pod pod-projected-configmaps-5d271dff-4883-4bf2-ab6f-c91e0ff99631 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 09:35:39.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6433" for this suite. 04/18/23 09:35:39.973
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:35:39.98
Apr 18 09:35:39.980: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 09:35:39.982
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:35:39.992
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:35:39.995
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 04/18/23 09:35:39.999
Apr 18 09:35:39.999: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 04/18/23 09:35:50.003
Apr 18 09:35:50.003: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 09:35:53.157: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:36:03.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6234" for this suite. 04/18/23 09:36:03.504
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":277,"skipped":5075,"failed":0}
------------------------------
• [SLOW TEST] [23.529 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:35:39.98
    Apr 18 09:35:39.980: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 09:35:39.982
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:35:39.992
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:35:39.995
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 04/18/23 09:35:39.999
    Apr 18 09:35:39.999: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 04/18/23 09:35:50.003
    Apr 18 09:35:50.003: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 09:35:53.157: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:36:03.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6234" for this suite. 04/18/23 09:36:03.504
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:36:03.51
Apr 18 09:36:03.510: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename secrets 04/18/23 09:36:03.511
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:36:03.522
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:36:03.525
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-98058ff5-e4ff-4d38-9c95-164b9bd60505 04/18/23 09:36:03.528
STEP: Creating a pod to test consume secrets 04/18/23 09:36:03.532
Apr 18 09:36:03.538: INFO: Waiting up to 5m0s for pod "pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064" in namespace "secrets-5386" to be "Succeeded or Failed"
Apr 18 09:36:03.540: INFO: Pod "pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064": Phase="Pending", Reason="", readiness=false. Elapsed: 2.126918ms
Apr 18 09:36:05.544: INFO: Pod "pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005818543s
Apr 18 09:36:07.544: INFO: Pod "pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005642694s
STEP: Saw pod success 04/18/23 09:36:07.544
Apr 18 09:36:07.544: INFO: Pod "pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064" satisfied condition "Succeeded or Failed"
Apr 18 09:36:07.546: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064 container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 09:36:07.551
Apr 18 09:36:07.560: INFO: Waiting for pod pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064 to disappear
Apr 18 09:36:07.562: INFO: Pod pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 09:36:07.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5386" for this suite. 04/18/23 09:36:07.566
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":278,"skipped":5100,"failed":0}
------------------------------
• [4.060 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:36:03.51
    Apr 18 09:36:03.510: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename secrets 04/18/23 09:36:03.511
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:36:03.522
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:36:03.525
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-98058ff5-e4ff-4d38-9c95-164b9bd60505 04/18/23 09:36:03.528
    STEP: Creating a pod to test consume secrets 04/18/23 09:36:03.532
    Apr 18 09:36:03.538: INFO: Waiting up to 5m0s for pod "pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064" in namespace "secrets-5386" to be "Succeeded or Failed"
    Apr 18 09:36:03.540: INFO: Pod "pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064": Phase="Pending", Reason="", readiness=false. Elapsed: 2.126918ms
    Apr 18 09:36:05.544: INFO: Pod "pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005818543s
    Apr 18 09:36:07.544: INFO: Pod "pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005642694s
    STEP: Saw pod success 04/18/23 09:36:07.544
    Apr 18 09:36:07.544: INFO: Pod "pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064" satisfied condition "Succeeded or Failed"
    Apr 18 09:36:07.546: INFO: Trying to get logs from node 192.168.1.152 pod pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064 container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 09:36:07.551
    Apr 18 09:36:07.560: INFO: Waiting for pod pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064 to disappear
    Apr 18 09:36:07.562: INFO: Pod pod-secrets-cf75af5b-a027-4469-bb2c-02be22f2f064 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 09:36:07.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5386" for this suite. 04/18/23 09:36:07.566
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:36:07.574
Apr 18 09:36:07.574: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 09:36:07.574
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:36:07.583
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:36:07.586
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 04/18/23 09:36:07.59
Apr 18 09:36:07.590: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 09:36:09.856: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:36:19.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7090" for this suite. 04/18/23 09:36:19.152
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":279,"skipped":5127,"failed":0}
------------------------------
• [SLOW TEST] [11.583 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:36:07.574
    Apr 18 09:36:07.574: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 09:36:07.574
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:36:07.583
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:36:07.586
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 04/18/23 09:36:07.59
    Apr 18 09:36:07.590: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 09:36:09.856: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:36:19.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7090" for this suite. 04/18/23 09:36:19.152
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:36:19.157
Apr 18 09:36:19.157: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename watch 04/18/23 09:36:19.158
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:36:19.166
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:36:19.169
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 04/18/23 09:36:19.172
STEP: creating a new configmap 04/18/23 09:36:19.174
STEP: modifying the configmap once 04/18/23 09:36:19.177
STEP: changing the label value of the configmap 04/18/23 09:36:19.183
STEP: Expecting to observe a delete notification for the watched object 04/18/23 09:36:19.189
Apr 18 09:36:19.189: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1263  3d16d7c1-9ce4-428d-a969-03ddfea44a5b 4197598 0 2023-04-18 09:36:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 09:36:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 09:36:19.189: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1263  3d16d7c1-9ce4-428d-a969-03ddfea44a5b 4197599 0 2023-04-18 09:36:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 09:36:19 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 09:36:19.189: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1263  3d16d7c1-9ce4-428d-a969-03ddfea44a5b 4197600 0 2023-04-18 09:36:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 09:36:19 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 04/18/23 09:36:19.189
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 04/18/23 09:36:19.196
STEP: changing the label value of the configmap back 04/18/23 09:36:29.196
STEP: modifying the configmap a third time 04/18/23 09:36:29.203
STEP: deleting the configmap 04/18/23 09:36:29.21
STEP: Expecting to observe an add notification for the watched object when the label value was restored 04/18/23 09:36:29.215
Apr 18 09:36:29.215: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1263  3d16d7c1-9ce4-428d-a969-03ddfea44a5b 4197655 0 2023-04-18 09:36:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 09:36:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 09:36:29.216: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1263  3d16d7c1-9ce4-428d-a969-03ddfea44a5b 4197656 0 2023-04-18 09:36:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 09:36:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 09:36:29.216: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1263  3d16d7c1-9ce4-428d-a969-03ddfea44a5b 4197657 0 2023-04-18 09:36:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 09:36:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 18 09:36:29.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1263" for this suite. 04/18/23 09:36:29.219
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":280,"skipped":5144,"failed":0}
------------------------------
• [SLOW TEST] [10.066 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:36:19.157
    Apr 18 09:36:19.157: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename watch 04/18/23 09:36:19.158
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:36:19.166
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:36:19.169
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 04/18/23 09:36:19.172
    STEP: creating a new configmap 04/18/23 09:36:19.174
    STEP: modifying the configmap once 04/18/23 09:36:19.177
    STEP: changing the label value of the configmap 04/18/23 09:36:19.183
    STEP: Expecting to observe a delete notification for the watched object 04/18/23 09:36:19.189
    Apr 18 09:36:19.189: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1263  3d16d7c1-9ce4-428d-a969-03ddfea44a5b 4197598 0 2023-04-18 09:36:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 09:36:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 09:36:19.189: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1263  3d16d7c1-9ce4-428d-a969-03ddfea44a5b 4197599 0 2023-04-18 09:36:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 09:36:19 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 09:36:19.189: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1263  3d16d7c1-9ce4-428d-a969-03ddfea44a5b 4197600 0 2023-04-18 09:36:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 09:36:19 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 04/18/23 09:36:19.189
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 04/18/23 09:36:19.196
    STEP: changing the label value of the configmap back 04/18/23 09:36:29.196
    STEP: modifying the configmap a third time 04/18/23 09:36:29.203
    STEP: deleting the configmap 04/18/23 09:36:29.21
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 04/18/23 09:36:29.215
    Apr 18 09:36:29.215: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1263  3d16d7c1-9ce4-428d-a969-03ddfea44a5b 4197655 0 2023-04-18 09:36:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 09:36:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 09:36:29.216: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1263  3d16d7c1-9ce4-428d-a969-03ddfea44a5b 4197656 0 2023-04-18 09:36:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 09:36:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 09:36:29.216: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1263  3d16d7c1-9ce4-428d-a969-03ddfea44a5b 4197657 0 2023-04-18 09:36:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 09:36:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 18 09:36:29.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-1263" for this suite. 04/18/23 09:36:29.219
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:36:29.225
Apr 18 09:36:29.225: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename init-container 04/18/23 09:36:29.226
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:36:29.235
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:36:29.238
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 04/18/23 09:36:29.241
Apr 18 09:36:29.242: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 18 09:36:33.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9039" for this suite. 04/18/23 09:36:33.999
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":281,"skipped":5242,"failed":0}
------------------------------
• [4.779 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:36:29.225
    Apr 18 09:36:29.225: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename init-container 04/18/23 09:36:29.226
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:36:29.235
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:36:29.238
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 04/18/23 09:36:29.241
    Apr 18 09:36:29.242: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 18 09:36:33.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-9039" for this suite. 04/18/23 09:36:33.999
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:36:34.012
Apr 18 09:36:34.012: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename configmap 04/18/23 09:36:34.013
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:36:34.024
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:36:34.027
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-2649/configmap-test-afabc351-a3b2-4b9d-a7d5-40fc4a1fe75b 04/18/23 09:36:34.031
STEP: Creating a pod to test consume configMaps 04/18/23 09:36:34.034
Apr 18 09:36:34.045: INFO: Waiting up to 5m0s for pod "pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9" in namespace "configmap-2649" to be "Succeeded or Failed"
Apr 18 09:36:34.047: INFO: Pod "pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.104024ms
Apr 18 09:36:36.052: INFO: Pod "pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00628037s
Apr 18 09:36:38.050: INFO: Pod "pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005040386s
STEP: Saw pod success 04/18/23 09:36:38.05
Apr 18 09:36:38.050: INFO: Pod "pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9" satisfied condition "Succeeded or Failed"
Apr 18 09:36:38.053: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9 container env-test: <nil>
STEP: delete the pod 04/18/23 09:36:38.058
Apr 18 09:36:38.066: INFO: Waiting for pod pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9 to disappear
Apr 18 09:36:38.068: INFO: Pod pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 09:36:38.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2649" for this suite. 04/18/23 09:36:38.072
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":282,"skipped":5341,"failed":0}
------------------------------
• [4.064 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:36:34.012
    Apr 18 09:36:34.012: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename configmap 04/18/23 09:36:34.013
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:36:34.024
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:36:34.027
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-2649/configmap-test-afabc351-a3b2-4b9d-a7d5-40fc4a1fe75b 04/18/23 09:36:34.031
    STEP: Creating a pod to test consume configMaps 04/18/23 09:36:34.034
    Apr 18 09:36:34.045: INFO: Waiting up to 5m0s for pod "pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9" in namespace "configmap-2649" to be "Succeeded or Failed"
    Apr 18 09:36:34.047: INFO: Pod "pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.104024ms
    Apr 18 09:36:36.052: INFO: Pod "pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00628037s
    Apr 18 09:36:38.050: INFO: Pod "pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005040386s
    STEP: Saw pod success 04/18/23 09:36:38.05
    Apr 18 09:36:38.050: INFO: Pod "pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9" satisfied condition "Succeeded or Failed"
    Apr 18 09:36:38.053: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9 container env-test: <nil>
    STEP: delete the pod 04/18/23 09:36:38.058
    Apr 18 09:36:38.066: INFO: Waiting for pod pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9 to disappear
    Apr 18 09:36:38.068: INFO: Pod pod-configmaps-bdc4b59a-0f00-46c6-b97d-e7af07ea95a9 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 09:36:38.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2649" for this suite. 04/18/23 09:36:38.072
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:36:38.077
Apr 18 09:36:38.077: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 09:36:38.078
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:36:38.086
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:36:38.089
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-bd7bc1b9-db38-4c2f-b2a7-7ebee6dc8cc1 04/18/23 09:36:38.092
STEP: Creating a pod to test consume configMaps 04/18/23 09:36:38.096
Apr 18 09:36:38.101: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad" in namespace "projected-2764" to be "Succeeded or Failed"
Apr 18 09:36:38.103: INFO: Pod "pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087863ms
Apr 18 09:36:40.107: INFO: Pod "pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005603517s
Apr 18 09:36:42.107: INFO: Pod "pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005918548s
STEP: Saw pod success 04/18/23 09:36:42.107
Apr 18 09:36:42.107: INFO: Pod "pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad" satisfied condition "Succeeded or Failed"
Apr 18 09:36:42.109: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad container agnhost-container: <nil>
STEP: delete the pod 04/18/23 09:36:42.113
Apr 18 09:36:42.123: INFO: Waiting for pod pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad to disappear
Apr 18 09:36:42.126: INFO: Pod pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 09:36:42.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2764" for this suite. 04/18/23 09:36:42.13
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":283,"skipped":5348,"failed":0}
------------------------------
• [4.056 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:36:38.077
    Apr 18 09:36:38.077: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 09:36:38.078
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:36:38.086
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:36:38.089
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-bd7bc1b9-db38-4c2f-b2a7-7ebee6dc8cc1 04/18/23 09:36:38.092
    STEP: Creating a pod to test consume configMaps 04/18/23 09:36:38.096
    Apr 18 09:36:38.101: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad" in namespace "projected-2764" to be "Succeeded or Failed"
    Apr 18 09:36:38.103: INFO: Pod "pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087863ms
    Apr 18 09:36:40.107: INFO: Pod "pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005603517s
    Apr 18 09:36:42.107: INFO: Pod "pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005918548s
    STEP: Saw pod success 04/18/23 09:36:42.107
    Apr 18 09:36:42.107: INFO: Pod "pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad" satisfied condition "Succeeded or Failed"
    Apr 18 09:36:42.109: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 09:36:42.113
    Apr 18 09:36:42.123: INFO: Waiting for pod pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad to disappear
    Apr 18 09:36:42.126: INFO: Pod pod-projected-configmaps-c9ed41fe-15f0-4a54-97e1-22ae479676ad no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 09:36:42.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2764" for this suite. 04/18/23 09:36:42.13
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:36:42.134
Apr 18 09:36:42.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-probe 04/18/23 09:36:42.135
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:36:42.149
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:36:42.154
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-589a55a5-6c0d-48a2-93bd-2a39a78246e4 in namespace container-probe-8738 04/18/23 09:36:42.157
Apr 18 09:36:42.162: INFO: Waiting up to 5m0s for pod "test-webserver-589a55a5-6c0d-48a2-93bd-2a39a78246e4" in namespace "container-probe-8738" to be "not pending"
Apr 18 09:36:42.164: INFO: Pod "test-webserver-589a55a5-6c0d-48a2-93bd-2a39a78246e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080804ms
Apr 18 09:36:44.169: INFO: Pod "test-webserver-589a55a5-6c0d-48a2-93bd-2a39a78246e4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006491156s
Apr 18 09:36:44.169: INFO: Pod "test-webserver-589a55a5-6c0d-48a2-93bd-2a39a78246e4" satisfied condition "not pending"
Apr 18 09:36:44.169: INFO: Started pod test-webserver-589a55a5-6c0d-48a2-93bd-2a39a78246e4 in namespace container-probe-8738
STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 09:36:44.169
Apr 18 09:36:44.171: INFO: Initial restart count of pod test-webserver-589a55a5-6c0d-48a2-93bd-2a39a78246e4 is 0
STEP: deleting the pod 04/18/23 09:40:44.653
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 09:40:44.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8738" for this suite. 04/18/23 09:40:44.668
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":284,"skipped":5353,"failed":0}
------------------------------
• [SLOW TEST] [242.537 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:36:42.134
    Apr 18 09:36:42.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-probe 04/18/23 09:36:42.135
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:36:42.149
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:36:42.154
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-589a55a5-6c0d-48a2-93bd-2a39a78246e4 in namespace container-probe-8738 04/18/23 09:36:42.157
    Apr 18 09:36:42.162: INFO: Waiting up to 5m0s for pod "test-webserver-589a55a5-6c0d-48a2-93bd-2a39a78246e4" in namespace "container-probe-8738" to be "not pending"
    Apr 18 09:36:42.164: INFO: Pod "test-webserver-589a55a5-6c0d-48a2-93bd-2a39a78246e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080804ms
    Apr 18 09:36:44.169: INFO: Pod "test-webserver-589a55a5-6c0d-48a2-93bd-2a39a78246e4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006491156s
    Apr 18 09:36:44.169: INFO: Pod "test-webserver-589a55a5-6c0d-48a2-93bd-2a39a78246e4" satisfied condition "not pending"
    Apr 18 09:36:44.169: INFO: Started pod test-webserver-589a55a5-6c0d-48a2-93bd-2a39a78246e4 in namespace container-probe-8738
    STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 09:36:44.169
    Apr 18 09:36:44.171: INFO: Initial restart count of pod test-webserver-589a55a5-6c0d-48a2-93bd-2a39a78246e4 is 0
    STEP: deleting the pod 04/18/23 09:40:44.653
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 09:40:44.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8738" for this suite. 04/18/23 09:40:44.668
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:40:44.673
Apr 18 09:40:44.673: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename pods 04/18/23 09:40:44.678
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:40:44.687
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:40:44.691
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 04/18/23 09:40:44.696
STEP: submitting the pod to kubernetes 04/18/23 09:40:44.696
Apr 18 09:40:44.701: INFO: Waiting up to 5m0s for pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9" in namespace "pods-704" to be "running and ready"
Apr 18 09:40:44.711: INFO: Pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.438612ms
Apr 18 09:40:44.711: INFO: The phase of Pod pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:40:46.714: INFO: Pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9": Phase="Running", Reason="", readiness=true. Elapsed: 2.012513377s
Apr 18 09:40:46.714: INFO: The phase of Pod pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9 is Running (Ready = true)
Apr 18 09:40:46.714: INFO: Pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 04/18/23 09:40:46.716
STEP: updating the pod 04/18/23 09:40:46.719
Apr 18 09:40:47.228: INFO: Successfully updated pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9"
Apr 18 09:40:47.228: INFO: Waiting up to 5m0s for pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9" in namespace "pods-704" to be "running"
Apr 18 09:40:47.231: INFO: Pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9": Phase="Running", Reason="", readiness=true. Elapsed: 2.488684ms
Apr 18 09:40:47.231: INFO: Pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 04/18/23 09:40:47.231
Apr 18 09:40:47.233: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 09:40:47.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-704" for this suite. 04/18/23 09:40:47.237
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":285,"skipped":5370,"failed":0}
------------------------------
• [2.568 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:40:44.673
    Apr 18 09:40:44.673: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename pods 04/18/23 09:40:44.678
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:40:44.687
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:40:44.691
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 04/18/23 09:40:44.696
    STEP: submitting the pod to kubernetes 04/18/23 09:40:44.696
    Apr 18 09:40:44.701: INFO: Waiting up to 5m0s for pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9" in namespace "pods-704" to be "running and ready"
    Apr 18 09:40:44.711: INFO: Pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.438612ms
    Apr 18 09:40:44.711: INFO: The phase of Pod pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:40:46.714: INFO: Pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9": Phase="Running", Reason="", readiness=true. Elapsed: 2.012513377s
    Apr 18 09:40:46.714: INFO: The phase of Pod pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9 is Running (Ready = true)
    Apr 18 09:40:46.714: INFO: Pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 04/18/23 09:40:46.716
    STEP: updating the pod 04/18/23 09:40:46.719
    Apr 18 09:40:47.228: INFO: Successfully updated pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9"
    Apr 18 09:40:47.228: INFO: Waiting up to 5m0s for pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9" in namespace "pods-704" to be "running"
    Apr 18 09:40:47.231: INFO: Pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9": Phase="Running", Reason="", readiness=true. Elapsed: 2.488684ms
    Apr 18 09:40:47.231: INFO: Pod "pod-update-dc4be8e3-14ed-4d07-a231-bc1fc38d04d9" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 04/18/23 09:40:47.231
    Apr 18 09:40:47.233: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 09:40:47.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-704" for this suite. 04/18/23 09:40:47.237
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:40:47.244
Apr 18 09:40:47.244: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-runtime 04/18/23 09:40:47.244
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:40:47.253
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:40:47.256
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 04/18/23 09:40:47.264
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 04/18/23 09:41:05.334
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 04/18/23 09:41:05.337
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 04/18/23 09:41:05.341
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 04/18/23 09:41:05.341
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 04/18/23 09:41:05.361
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 04/18/23 09:41:08.373
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 04/18/23 09:41:10.382
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 04/18/23 09:41:10.387
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 04/18/23 09:41:10.387
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 04/18/23 09:41:10.402
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 04/18/23 09:41:11.411
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 04/18/23 09:41:13.422
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 04/18/23 09:41:13.427
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 04/18/23 09:41:13.427
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 18 09:41:13.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8917" for this suite. 04/18/23 09:41:13.449
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":286,"skipped":5373,"failed":0}
------------------------------
• [SLOW TEST] [26.210 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:40:47.244
    Apr 18 09:40:47.244: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-runtime 04/18/23 09:40:47.244
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:40:47.253
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:40:47.256
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 04/18/23 09:40:47.264
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 04/18/23 09:41:05.334
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 04/18/23 09:41:05.337
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 04/18/23 09:41:05.341
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 04/18/23 09:41:05.341
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 04/18/23 09:41:05.361
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 04/18/23 09:41:08.373
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 04/18/23 09:41:10.382
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 04/18/23 09:41:10.387
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 04/18/23 09:41:10.387
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 04/18/23 09:41:10.402
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 04/18/23 09:41:11.411
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 04/18/23 09:41:13.422
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 04/18/23 09:41:13.427
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 04/18/23 09:41:13.427
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 18 09:41:13.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-8917" for this suite. 04/18/23 09:41:13.449
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:41:13.454
Apr 18 09:41:13.454: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename statefulset 04/18/23 09:41:13.455
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:13.465
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:13.47
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3789 04/18/23 09:41:13.473
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Apr 18 09:41:13.485: INFO: Found 0 stateful pods, waiting for 1
Apr 18 09:41:23.489: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 04/18/23 09:41:23.494
W0418 09:41:23.504111      18 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 18 09:41:23.508: INFO: Found 1 stateful pods, waiting for 2
Apr 18 09:41:33.513: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 09:41:33.513: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 04/18/23 09:41:33.518
STEP: Delete all of the StatefulSets 04/18/23 09:41:33.52
STEP: Verify that StatefulSets have been deleted 04/18/23 09:41:33.525
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 09:41:33.527: INFO: Deleting all statefulset in ns statefulset-3789
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 09:41:33.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3789" for this suite. 04/18/23 09:41:33.545
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":287,"skipped":5390,"failed":0}
------------------------------
• [SLOW TEST] [20.101 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:41:13.454
    Apr 18 09:41:13.454: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename statefulset 04/18/23 09:41:13.455
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:13.465
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:13.47
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3789 04/18/23 09:41:13.473
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Apr 18 09:41:13.485: INFO: Found 0 stateful pods, waiting for 1
    Apr 18 09:41:23.489: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 04/18/23 09:41:23.494
    W0418 09:41:23.504111      18 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 18 09:41:23.508: INFO: Found 1 stateful pods, waiting for 2
    Apr 18 09:41:33.513: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 09:41:33.513: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 04/18/23 09:41:33.518
    STEP: Delete all of the StatefulSets 04/18/23 09:41:33.52
    STEP: Verify that StatefulSets have been deleted 04/18/23 09:41:33.525
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 09:41:33.527: INFO: Deleting all statefulset in ns statefulset-3789
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 09:41:33.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3789" for this suite. 04/18/23 09:41:33.545
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:41:33.557
Apr 18 09:41:33.557: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename configmap 04/18/23 09:41:33.558
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:33.568
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:33.571
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-49e60664-24ab-489e-9ca7-83efce7fbf83 04/18/23 09:41:33.575
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 09:41:33.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4412" for this suite. 04/18/23 09:41:33.582
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":288,"skipped":5414,"failed":0}
------------------------------
• [0.029 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:41:33.557
    Apr 18 09:41:33.557: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename configmap 04/18/23 09:41:33.558
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:33.568
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:33.571
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-49e60664-24ab-489e-9ca7-83efce7fbf83 04/18/23 09:41:33.575
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 09:41:33.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4412" for this suite. 04/18/23 09:41:33.582
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:41:33.586
Apr 18 09:41:33.586: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename pods 04/18/23 09:41:33.587
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:33.596
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:33.599
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 04/18/23 09:41:33.603
Apr 18 09:41:33.608: INFO: Waiting up to 5m0s for pod "pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e" in namespace "pods-8012" to be "running and ready"
Apr 18 09:41:33.610: INFO: Pod "pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.102883ms
Apr 18 09:41:33.610: INFO: The phase of Pod pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:41:35.613: INFO: Pod "pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e": Phase="Running", Reason="", readiness=true. Elapsed: 2.005646497s
Apr 18 09:41:35.613: INFO: The phase of Pod pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e is Running (Ready = true)
Apr 18 09:41:35.613: INFO: Pod "pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e" satisfied condition "running and ready"
Apr 18 09:41:35.619: INFO: Pod pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e has hostIP: 192.168.1.152
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 09:41:35.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8012" for this suite. 04/18/23 09:41:35.622
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":289,"skipped":5417,"failed":0}
------------------------------
• [2.041 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:41:33.586
    Apr 18 09:41:33.586: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename pods 04/18/23 09:41:33.587
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:33.596
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:33.599
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 04/18/23 09:41:33.603
    Apr 18 09:41:33.608: INFO: Waiting up to 5m0s for pod "pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e" in namespace "pods-8012" to be "running and ready"
    Apr 18 09:41:33.610: INFO: Pod "pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.102883ms
    Apr 18 09:41:33.610: INFO: The phase of Pod pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:41:35.613: INFO: Pod "pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e": Phase="Running", Reason="", readiness=true. Elapsed: 2.005646497s
    Apr 18 09:41:35.613: INFO: The phase of Pod pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e is Running (Ready = true)
    Apr 18 09:41:35.613: INFO: Pod "pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e" satisfied condition "running and ready"
    Apr 18 09:41:35.619: INFO: Pod pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e has hostIP: 192.168.1.152
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 09:41:35.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8012" for this suite. 04/18/23 09:41:35.622
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:41:35.628
Apr 18 09:41:35.628: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename sched-pred 04/18/23 09:41:35.629
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:35.638
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:35.643
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 18 09:41:35.646: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 18 09:41:35.657: INFO: Waiting for terminating namespaces to be deleted...
Apr 18 09:41:35.659: INFO: 
Logging pods the apiserver thinks is on node 192.168.1.152 before test
Apr 18 09:41:35.664: INFO: everest-csi-driver-2sbdm from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:41:35.664: INFO: 	Container everest-csi-driver ready: true, restart count 0
Apr 18 09:41:35.664: INFO: icagent-blm9c from kube-system started at 2023-04-17 15:47:22 +0000 UTC (1 container statuses recorded)
Apr 18 09:41:35.664: INFO: 	Container icagent ready: true, restart count 0
Apr 18 09:41:35.664: INFO: pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e from pods-8012 started at 2023-04-18 09:41:33 +0000 UTC (1 container statuses recorded)
Apr 18 09:41:35.664: INFO: 	Container test ready: true, restart count 0
Apr 18 09:41:35.664: INFO: sonobuoy from sonobuoy started at 2023-04-18 08:25:22 +0000 UTC (1 container statuses recorded)
Apr 18 09:41:35.664: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 18 09:41:35.664: INFO: sonobuoy-e2e-job-98a0ff59191d4d9f from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:41:35.664: INFO: 	Container e2e ready: true, restart count 0
Apr 18 09:41:35.664: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:41:35.664: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-brt2v from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:41:35.664: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:41:35.664: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 09:41:35.664: INFO: 
Logging pods the apiserver thinks is on node 192.168.1.29 before test
Apr 18 09:41:35.669: INFO: coredns-67ffcb9db-g9zw5 from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
Apr 18 09:41:35.669: INFO: 	Container coredns ready: true, restart count 0
Apr 18 09:41:35.669: INFO: everest-csi-controller-76f85d46b8-f4ksg from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:41:35.669: INFO: 	Container everest-csi-controller ready: true, restart count 0
Apr 18 09:41:35.669: INFO: everest-csi-driver-j2vqd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:41:35.669: INFO: 	Container everest-csi-driver ready: true, restart count 0
Apr 18 09:41:35.669: INFO: icagent-znmkj from kube-system started at 2023-04-17 15:47:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:41:35.669: INFO: 	Container icagent ready: true, restart count 0
Apr 18 09:41:35.669: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-8kqvb from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:41:35.669: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:41:35.669: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 09:41:35.669: INFO: 
Logging pods the apiserver thinks is on node 192.168.1.84 before test
Apr 18 09:41:35.674: INFO: coredns-67ffcb9db-fc7fx from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
Apr 18 09:41:35.674: INFO: 	Container coredns ready: true, restart count 0
Apr 18 09:41:35.674: INFO: everest-csi-controller-76f85d46b8-vkvbd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:41:35.674: INFO: 	Container everest-csi-controller ready: true, restart count 0
Apr 18 09:41:35.674: INFO: everest-csi-driver-ww79w from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
Apr 18 09:41:35.674: INFO: 	Container everest-csi-driver ready: true, restart count 0
Apr 18 09:41:35.674: INFO: icagent-9xt4k from kube-system started at 2023-04-07 10:53:39 +0000 UTC (1 container statuses recorded)
Apr 18 09:41:35.675: INFO: 	Container icagent ready: true, restart count 0
Apr 18 09:41:35.675: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-6q6gp from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
Apr 18 09:41:35.675: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 09:41:35.675: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/18/23 09:41:35.675
Apr 18 09:41:35.680: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-7846" to be "running"
Apr 18 09:41:35.694: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 13.321339ms
Apr 18 09:41:37.698: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.017136367s
Apr 18 09:41:37.698: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/18/23 09:41:37.7
STEP: Trying to apply a random label on the found node. 04/18/23 09:41:37.705
STEP: verifying the node has the label kubernetes.io/e2e-8bb6813d-70de-4683-9358-324c4152f740 42 04/18/23 09:41:37.718
STEP: Trying to relaunch the pod, now with labels. 04/18/23 09:41:37.72
Apr 18 09:41:37.725: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-7846" to be "not pending"
Apr 18 09:41:37.728: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 3.305048ms
Apr 18 09:41:39.734: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.008870113s
Apr 18 09:41:39.734: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-8bb6813d-70de-4683-9358-324c4152f740 off the node 192.168.1.152 04/18/23 09:41:39.736
STEP: verifying the node doesn't have the label kubernetes.io/e2e-8bb6813d-70de-4683-9358-324c4152f740 04/18/23 09:41:39.75
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:41:39.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7846" for this suite. 04/18/23 09:41:39.757
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":290,"skipped":5427,"failed":0}
------------------------------
• [4.133 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:41:35.628
    Apr 18 09:41:35.628: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename sched-pred 04/18/23 09:41:35.629
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:35.638
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:35.643
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 18 09:41:35.646: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 18 09:41:35.657: INFO: Waiting for terminating namespaces to be deleted...
    Apr 18 09:41:35.659: INFO: 
    Logging pods the apiserver thinks is on node 192.168.1.152 before test
    Apr 18 09:41:35.664: INFO: everest-csi-driver-2sbdm from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:41:35.664: INFO: 	Container everest-csi-driver ready: true, restart count 0
    Apr 18 09:41:35.664: INFO: icagent-blm9c from kube-system started at 2023-04-17 15:47:22 +0000 UTC (1 container statuses recorded)
    Apr 18 09:41:35.664: INFO: 	Container icagent ready: true, restart count 0
    Apr 18 09:41:35.664: INFO: pod-hostip-95f03c87-c72f-4fbf-b012-17701ba5cc8e from pods-8012 started at 2023-04-18 09:41:33 +0000 UTC (1 container statuses recorded)
    Apr 18 09:41:35.664: INFO: 	Container test ready: true, restart count 0
    Apr 18 09:41:35.664: INFO: sonobuoy from sonobuoy started at 2023-04-18 08:25:22 +0000 UTC (1 container statuses recorded)
    Apr 18 09:41:35.664: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 18 09:41:35.664: INFO: sonobuoy-e2e-job-98a0ff59191d4d9f from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:41:35.664: INFO: 	Container e2e ready: true, restart count 0
    Apr 18 09:41:35.664: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:41:35.664: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-brt2v from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:41:35.664: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:41:35.664: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 09:41:35.664: INFO: 
    Logging pods the apiserver thinks is on node 192.168.1.29 before test
    Apr 18 09:41:35.669: INFO: coredns-67ffcb9db-g9zw5 from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
    Apr 18 09:41:35.669: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 09:41:35.669: INFO: everest-csi-controller-76f85d46b8-f4ksg from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:41:35.669: INFO: 	Container everest-csi-controller ready: true, restart count 0
    Apr 18 09:41:35.669: INFO: everest-csi-driver-j2vqd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:41:35.669: INFO: 	Container everest-csi-driver ready: true, restart count 0
    Apr 18 09:41:35.669: INFO: icagent-znmkj from kube-system started at 2023-04-17 15:47:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:41:35.669: INFO: 	Container icagent ready: true, restart count 0
    Apr 18 09:41:35.669: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-8kqvb from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:41:35.669: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:41:35.669: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 09:41:35.669: INFO: 
    Logging pods the apiserver thinks is on node 192.168.1.84 before test
    Apr 18 09:41:35.674: INFO: coredns-67ffcb9db-fc7fx from kube-system started at 2023-04-17 15:51:18 +0000 UTC (1 container statuses recorded)
    Apr 18 09:41:35.674: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 09:41:35.674: INFO: everest-csi-controller-76f85d46b8-vkvbd from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:41:35.674: INFO: 	Container everest-csi-controller ready: true, restart count 0
    Apr 18 09:41:35.674: INFO: everest-csi-driver-ww79w from kube-system started at 2023-04-17 15:51:24 +0000 UTC (1 container statuses recorded)
    Apr 18 09:41:35.674: INFO: 	Container everest-csi-driver ready: true, restart count 0
    Apr 18 09:41:35.674: INFO: icagent-9xt4k from kube-system started at 2023-04-07 10:53:39 +0000 UTC (1 container statuses recorded)
    Apr 18 09:41:35.675: INFO: 	Container icagent ready: true, restart count 0
    Apr 18 09:41:35.675: INFO: sonobuoy-systemd-logs-daemon-set-7ab0767e5342416a-6q6gp from sonobuoy started at 2023-04-18 08:25:30 +0000 UTC (2 container statuses recorded)
    Apr 18 09:41:35.675: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 09:41:35.675: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/18/23 09:41:35.675
    Apr 18 09:41:35.680: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-7846" to be "running"
    Apr 18 09:41:35.694: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 13.321339ms
    Apr 18 09:41:37.698: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.017136367s
    Apr 18 09:41:37.698: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/18/23 09:41:37.7
    STEP: Trying to apply a random label on the found node. 04/18/23 09:41:37.705
    STEP: verifying the node has the label kubernetes.io/e2e-8bb6813d-70de-4683-9358-324c4152f740 42 04/18/23 09:41:37.718
    STEP: Trying to relaunch the pod, now with labels. 04/18/23 09:41:37.72
    Apr 18 09:41:37.725: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-7846" to be "not pending"
    Apr 18 09:41:37.728: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 3.305048ms
    Apr 18 09:41:39.734: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.008870113s
    Apr 18 09:41:39.734: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-8bb6813d-70de-4683-9358-324c4152f740 off the node 192.168.1.152 04/18/23 09:41:39.736
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-8bb6813d-70de-4683-9358-324c4152f740 04/18/23 09:41:39.75
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:41:39.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-7846" for this suite. 04/18/23 09:41:39.757
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:41:39.761
Apr 18 09:41:39.762: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 09:41:39.762
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:39.77
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:39.774
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 04/18/23 09:41:39.777
Apr 18 09:41:39.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5288 create -f -'
Apr 18 09:41:40.286: INFO: stderr: ""
Apr 18 09:41:40.286: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 04/18/23 09:41:40.286
Apr 18 09:41:40.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5288 diff -f -'
Apr 18 09:41:40.450: INFO: rc: 1
Apr 18 09:41:40.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5288 delete -f -'
Apr 18 09:41:40.503: INFO: stderr: ""
Apr 18 09:41:40.503: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 09:41:40.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5288" for this suite. 04/18/23 09:41:40.507
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":291,"skipped":5454,"failed":0}
------------------------------
• [0.751 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:41:39.761
    Apr 18 09:41:39.762: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 09:41:39.762
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:39.77
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:39.774
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 04/18/23 09:41:39.777
    Apr 18 09:41:39.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5288 create -f -'
    Apr 18 09:41:40.286: INFO: stderr: ""
    Apr 18 09:41:40.286: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 04/18/23 09:41:40.286
    Apr 18 09:41:40.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5288 diff -f -'
    Apr 18 09:41:40.450: INFO: rc: 1
    Apr 18 09:41:40.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5288 delete -f -'
    Apr 18 09:41:40.503: INFO: stderr: ""
    Apr 18 09:41:40.503: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 09:41:40.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5288" for this suite. 04/18/23 09:41:40.507
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:41:40.514
Apr 18 09:41:40.514: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 09:41:40.514
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:40.523
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:40.526
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 09:41:40.538
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:41:40.886
STEP: Deploying the webhook pod 04/18/23 09:41:40.892
STEP: Wait for the deployment to be ready 04/18/23 09:41:40.91
Apr 18 09:41:40.916: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 09:41:42.924
STEP: Verifying the service has paired with the endpoint 04/18/23 09:41:42.941
Apr 18 09:41:43.941: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/18/23 09:41:43.945
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/18/23 09:41:43.962
STEP: Creating a dummy validating-webhook-configuration object 04/18/23 09:41:43.982
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 04/18/23 09:41:44.013
STEP: Creating a dummy mutating-webhook-configuration object 04/18/23 09:41:44.02
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 04/18/23 09:41:44.027
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:41:44.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-531" for this suite. 04/18/23 09:41:44.055
STEP: Destroying namespace "webhook-531-markers" for this suite. 04/18/23 09:41:44.059
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":292,"skipped":5469,"failed":0}
------------------------------
• [3.587 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:41:40.514
    Apr 18 09:41:40.514: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 09:41:40.514
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:40.523
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:40.526
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 09:41:40.538
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:41:40.886
    STEP: Deploying the webhook pod 04/18/23 09:41:40.892
    STEP: Wait for the deployment to be ready 04/18/23 09:41:40.91
    Apr 18 09:41:40.916: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 09:41:42.924
    STEP: Verifying the service has paired with the endpoint 04/18/23 09:41:42.941
    Apr 18 09:41:43.941: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/18/23 09:41:43.945
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/18/23 09:41:43.962
    STEP: Creating a dummy validating-webhook-configuration object 04/18/23 09:41:43.982
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 04/18/23 09:41:44.013
    STEP: Creating a dummy mutating-webhook-configuration object 04/18/23 09:41:44.02
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 04/18/23 09:41:44.027
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:41:44.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-531" for this suite. 04/18/23 09:41:44.055
    STEP: Destroying namespace "webhook-531-markers" for this suite. 04/18/23 09:41:44.059
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:41:44.103
Apr 18 09:41:44.103: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename emptydir 04/18/23 09:41:44.103
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:44.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:44.122
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 04/18/23 09:41:44.126
Apr 18 09:41:44.132: INFO: Waiting up to 5m0s for pod "pod-5b171b91-8ca5-4378-a719-b835ca069269" in namespace "emptydir-8091" to be "Succeeded or Failed"
Apr 18 09:41:44.134: INFO: Pod "pod-5b171b91-8ca5-4378-a719-b835ca069269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.360862ms
Apr 18 09:41:46.142: INFO: Pod "pod-5b171b91-8ca5-4378-a719-b835ca069269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010063479s
Apr 18 09:41:48.137: INFO: Pod "pod-5b171b91-8ca5-4378-a719-b835ca069269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005272913s
STEP: Saw pod success 04/18/23 09:41:48.137
Apr 18 09:41:48.137: INFO: Pod "pod-5b171b91-8ca5-4378-a719-b835ca069269" satisfied condition "Succeeded or Failed"
Apr 18 09:41:48.140: INFO: Trying to get logs from node 192.168.1.152 pod pod-5b171b91-8ca5-4378-a719-b835ca069269 container test-container: <nil>
STEP: delete the pod 04/18/23 09:41:48.158
Apr 18 09:41:48.169: INFO: Waiting for pod pod-5b171b91-8ca5-4378-a719-b835ca069269 to disappear
Apr 18 09:41:48.171: INFO: Pod pod-5b171b91-8ca5-4378-a719-b835ca069269 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 09:41:48.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8091" for this suite. 04/18/23 09:41:48.175
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":293,"skipped":5487,"failed":0}
------------------------------
• [4.078 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:41:44.103
    Apr 18 09:41:44.103: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename emptydir 04/18/23 09:41:44.103
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:44.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:44.122
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 04/18/23 09:41:44.126
    Apr 18 09:41:44.132: INFO: Waiting up to 5m0s for pod "pod-5b171b91-8ca5-4378-a719-b835ca069269" in namespace "emptydir-8091" to be "Succeeded or Failed"
    Apr 18 09:41:44.134: INFO: Pod "pod-5b171b91-8ca5-4378-a719-b835ca069269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.360862ms
    Apr 18 09:41:46.142: INFO: Pod "pod-5b171b91-8ca5-4378-a719-b835ca069269": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010063479s
    Apr 18 09:41:48.137: INFO: Pod "pod-5b171b91-8ca5-4378-a719-b835ca069269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005272913s
    STEP: Saw pod success 04/18/23 09:41:48.137
    Apr 18 09:41:48.137: INFO: Pod "pod-5b171b91-8ca5-4378-a719-b835ca069269" satisfied condition "Succeeded or Failed"
    Apr 18 09:41:48.140: INFO: Trying to get logs from node 192.168.1.152 pod pod-5b171b91-8ca5-4378-a719-b835ca069269 container test-container: <nil>
    STEP: delete the pod 04/18/23 09:41:48.158
    Apr 18 09:41:48.169: INFO: Waiting for pod pod-5b171b91-8ca5-4378-a719-b835ca069269 to disappear
    Apr 18 09:41:48.171: INFO: Pod pod-5b171b91-8ca5-4378-a719-b835ca069269 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 09:41:48.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8091" for this suite. 04/18/23 09:41:48.175
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:41:48.18
Apr 18 09:41:48.180: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 09:41:48.181
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:48.193
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:48.196
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-5902 04/18/23 09:41:48.199
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5902 to expose endpoints map[] 04/18/23 09:41:48.206
Apr 18 09:41:48.217: INFO: successfully validated that service endpoint-test2 in namespace services-5902 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-5902 04/18/23 09:41:48.217
Apr 18 09:41:48.222: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5902" to be "running and ready"
Apr 18 09:41:48.227: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.932268ms
Apr 18 09:41:48.227: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:41:50.230: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.008035843s
Apr 18 09:41:50.230: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 18 09:41:50.230: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5902 to expose endpoints map[pod1:[80]] 04/18/23 09:41:50.233
Apr 18 09:41:50.242: INFO: successfully validated that service endpoint-test2 in namespace services-5902 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 04/18/23 09:41:50.242
Apr 18 09:41:50.242: INFO: Creating new exec pod
Apr 18 09:41:50.245: INFO: Waiting up to 5m0s for pod "execpodqs8jd" in namespace "services-5902" to be "running"
Apr 18 09:41:50.248: INFO: Pod "execpodqs8jd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.113846ms
Apr 18 09:41:52.252: INFO: Pod "execpodqs8jd": Phase="Running", Reason="", readiness=true. Elapsed: 2.006313327s
Apr 18 09:41:52.252: INFO: Pod "execpodqs8jd" satisfied condition "running"
Apr 18 09:41:53.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-5902 exec execpodqs8jd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 18 09:41:53.356: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 18 09:41:53.356: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:41:53.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-5902 exec execpodqs8jd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.59.232 80'
Apr 18 09:41:53.457: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.59.232 80\nConnection to 10.247.59.232 80 port [tcp/http] succeeded!\n"
Apr 18 09:41:53.457: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-5902 04/18/23 09:41:53.457
Apr 18 09:41:53.461: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5902" to be "running and ready"
Apr 18 09:41:53.464: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.337382ms
Apr 18 09:41:53.464: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:41:55.467: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.005736878s
Apr 18 09:41:55.467: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 18 09:41:55.467: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5902 to expose endpoints map[pod1:[80] pod2:[80]] 04/18/23 09:41:55.47
Apr 18 09:41:55.482: INFO: successfully validated that service endpoint-test2 in namespace services-5902 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 04/18/23 09:41:55.482
Apr 18 09:41:56.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-5902 exec execpodqs8jd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 18 09:41:56.582: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 18 09:41:56.582: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:41:56.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-5902 exec execpodqs8jd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.59.232 80'
Apr 18 09:41:56.682: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.59.232 80\nConnection to 10.247.59.232 80 port [tcp/http] succeeded!\n"
Apr 18 09:41:56.682: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-5902 04/18/23 09:41:56.682
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5902 to expose endpoints map[pod2:[80]] 04/18/23 09:41:56.705
Apr 18 09:41:56.718: INFO: successfully validated that service endpoint-test2 in namespace services-5902 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 04/18/23 09:41:56.718
Apr 18 09:41:57.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-5902 exec execpodqs8jd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 18 09:41:57.834: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 18 09:41:57.834: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:41:57.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-5902 exec execpodqs8jd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.59.232 80'
Apr 18 09:41:57.936: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.59.232 80\nConnection to 10.247.59.232 80 port [tcp/http] succeeded!\n"
Apr 18 09:41:57.936: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-5902 04/18/23 09:41:57.936
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5902 to expose endpoints map[] 04/18/23 09:41:57.951
Apr 18 09:41:57.958: INFO: successfully validated that service endpoint-test2 in namespace services-5902 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 09:41:57.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5902" for this suite. 04/18/23 09:41:57.979
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":294,"skipped":5487,"failed":0}
------------------------------
• [SLOW TEST] [9.803 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:41:48.18
    Apr 18 09:41:48.180: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 09:41:48.181
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:48.193
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:48.196
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-5902 04/18/23 09:41:48.199
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5902 to expose endpoints map[] 04/18/23 09:41:48.206
    Apr 18 09:41:48.217: INFO: successfully validated that service endpoint-test2 in namespace services-5902 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-5902 04/18/23 09:41:48.217
    Apr 18 09:41:48.222: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5902" to be "running and ready"
    Apr 18 09:41:48.227: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.932268ms
    Apr 18 09:41:48.227: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:41:50.230: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.008035843s
    Apr 18 09:41:50.230: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 18 09:41:50.230: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5902 to expose endpoints map[pod1:[80]] 04/18/23 09:41:50.233
    Apr 18 09:41:50.242: INFO: successfully validated that service endpoint-test2 in namespace services-5902 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 04/18/23 09:41:50.242
    Apr 18 09:41:50.242: INFO: Creating new exec pod
    Apr 18 09:41:50.245: INFO: Waiting up to 5m0s for pod "execpodqs8jd" in namespace "services-5902" to be "running"
    Apr 18 09:41:50.248: INFO: Pod "execpodqs8jd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.113846ms
    Apr 18 09:41:52.252: INFO: Pod "execpodqs8jd": Phase="Running", Reason="", readiness=true. Elapsed: 2.006313327s
    Apr 18 09:41:52.252: INFO: Pod "execpodqs8jd" satisfied condition "running"
    Apr 18 09:41:53.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-5902 exec execpodqs8jd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Apr 18 09:41:53.356: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 18 09:41:53.356: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:41:53.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-5902 exec execpodqs8jd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.59.232 80'
    Apr 18 09:41:53.457: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.59.232 80\nConnection to 10.247.59.232 80 port [tcp/http] succeeded!\n"
    Apr 18 09:41:53.457: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-5902 04/18/23 09:41:53.457
    Apr 18 09:41:53.461: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5902" to be "running and ready"
    Apr 18 09:41:53.464: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.337382ms
    Apr 18 09:41:53.464: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:41:55.467: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.005736878s
    Apr 18 09:41:55.467: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 18 09:41:55.467: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5902 to expose endpoints map[pod1:[80] pod2:[80]] 04/18/23 09:41:55.47
    Apr 18 09:41:55.482: INFO: successfully validated that service endpoint-test2 in namespace services-5902 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 04/18/23 09:41:55.482
    Apr 18 09:41:56.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-5902 exec execpodqs8jd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Apr 18 09:41:56.582: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 18 09:41:56.582: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:41:56.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-5902 exec execpodqs8jd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.59.232 80'
    Apr 18 09:41:56.682: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.59.232 80\nConnection to 10.247.59.232 80 port [tcp/http] succeeded!\n"
    Apr 18 09:41:56.682: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-5902 04/18/23 09:41:56.682
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5902 to expose endpoints map[pod2:[80]] 04/18/23 09:41:56.705
    Apr 18 09:41:56.718: INFO: successfully validated that service endpoint-test2 in namespace services-5902 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 04/18/23 09:41:56.718
    Apr 18 09:41:57.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-5902 exec execpodqs8jd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Apr 18 09:41:57.834: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 18 09:41:57.834: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:41:57.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-5902 exec execpodqs8jd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.59.232 80'
    Apr 18 09:41:57.936: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.59.232 80\nConnection to 10.247.59.232 80 port [tcp/http] succeeded!\n"
    Apr 18 09:41:57.936: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-5902 04/18/23 09:41:57.936
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5902 to expose endpoints map[] 04/18/23 09:41:57.951
    Apr 18 09:41:57.958: INFO: successfully validated that service endpoint-test2 in namespace services-5902 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 09:41:57.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5902" for this suite. 04/18/23 09:41:57.979
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:41:57.984
Apr 18 09:41:57.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename disruption 04/18/23 09:41:57.984
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:57.993
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:57.996
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:41:57.999
Apr 18 09:41:57.999: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename disruption-2 04/18/23 09:41:58
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:58.01
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:58.014
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 04/18/23 09:41:58.022
STEP: Waiting for the pdb to be processed 04/18/23 09:41:58.028
STEP: Waiting for the pdb to be processed 04/18/23 09:42:00.038
STEP: listing a collection of PDBs across all namespaces 04/18/23 09:42:02.044
STEP: listing a collection of PDBs in namespace disruption-5191 04/18/23 09:42:02.047
STEP: deleting a collection of PDBs 04/18/23 09:42:02.05
STEP: Waiting for the PDB collection to be deleted 04/18/23 09:42:02.057
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Apr 18 09:42:02.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-2786" for this suite. 04/18/23 09:42:02.063
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 18 09:42:02.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-5191" for this suite. 04/18/23 09:42:02.071
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":295,"skipped":5494,"failed":0}
------------------------------
• [4.092 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:41:57.984
    Apr 18 09:41:57.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename disruption 04/18/23 09:41:57.984
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:57.993
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:57.996
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:41:57.999
    Apr 18 09:41:57.999: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename disruption-2 04/18/23 09:41:58
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:41:58.01
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:41:58.014
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 04/18/23 09:41:58.022
    STEP: Waiting for the pdb to be processed 04/18/23 09:41:58.028
    STEP: Waiting for the pdb to be processed 04/18/23 09:42:00.038
    STEP: listing a collection of PDBs across all namespaces 04/18/23 09:42:02.044
    STEP: listing a collection of PDBs in namespace disruption-5191 04/18/23 09:42:02.047
    STEP: deleting a collection of PDBs 04/18/23 09:42:02.05
    STEP: Waiting for the PDB collection to be deleted 04/18/23 09:42:02.057
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Apr 18 09:42:02.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-2786" for this suite. 04/18/23 09:42:02.063
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 18 09:42:02.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-5191" for this suite. 04/18/23 09:42:02.071
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:42:02.076
Apr 18 09:42:02.076: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename var-expansion 04/18/23 09:42:02.076
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:02.087
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:02.091
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 04/18/23 09:42:02.094
Apr 18 09:42:02.101: INFO: Waiting up to 5m0s for pod "var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b" in namespace "var-expansion-1899" to be "Succeeded or Failed"
Apr 18 09:42:02.104: INFO: Pod "var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.332188ms
Apr 18 09:42:04.109: INFO: Pod "var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007635493s
Apr 18 09:42:06.107: INFO: Pod "var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005938061s
STEP: Saw pod success 04/18/23 09:42:06.107
Apr 18 09:42:06.107: INFO: Pod "var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b" satisfied condition "Succeeded or Failed"
Apr 18 09:42:06.110: INFO: Trying to get logs from node 192.168.1.152 pod var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b container dapi-container: <nil>
STEP: delete the pod 04/18/23 09:42:06.115
Apr 18 09:42:06.124: INFO: Waiting for pod var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b to disappear
Apr 18 09:42:06.126: INFO: Pod var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 09:42:06.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1899" for this suite. 04/18/23 09:42:06.13
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":296,"skipped":5499,"failed":0}
------------------------------
• [4.058 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:42:02.076
    Apr 18 09:42:02.076: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename var-expansion 04/18/23 09:42:02.076
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:02.087
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:02.091
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 04/18/23 09:42:02.094
    Apr 18 09:42:02.101: INFO: Waiting up to 5m0s for pod "var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b" in namespace "var-expansion-1899" to be "Succeeded or Failed"
    Apr 18 09:42:02.104: INFO: Pod "var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.332188ms
    Apr 18 09:42:04.109: INFO: Pod "var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007635493s
    Apr 18 09:42:06.107: INFO: Pod "var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005938061s
    STEP: Saw pod success 04/18/23 09:42:06.107
    Apr 18 09:42:06.107: INFO: Pod "var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b" satisfied condition "Succeeded or Failed"
    Apr 18 09:42:06.110: INFO: Trying to get logs from node 192.168.1.152 pod var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b container dapi-container: <nil>
    STEP: delete the pod 04/18/23 09:42:06.115
    Apr 18 09:42:06.124: INFO: Waiting for pod var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b to disappear
    Apr 18 09:42:06.126: INFO: Pod var-expansion-d6c5d0f0-9198-401f-b9ab-8cc93f8d0e7b no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 09:42:06.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1899" for this suite. 04/18/23 09:42:06.13
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:42:06.137
Apr 18 09:42:06.137: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename gc 04/18/23 09:42:06.137
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:06.149
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:06.152
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 04/18/23 09:42:06.156
STEP: delete the rc 04/18/23 09:42:11.164
STEP: wait for all pods to be garbage collected 04/18/23 09:42:11.168
STEP: Gathering metrics 04/18/23 09:42:16.174
W0418 09:42:16.184353      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 18 09:42:16.184: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 18 09:42:16.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7312" for this suite. 04/18/23 09:42:16.187
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":297,"skipped":5568,"failed":0}
------------------------------
• [SLOW TEST] [10.055 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:42:06.137
    Apr 18 09:42:06.137: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename gc 04/18/23 09:42:06.137
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:06.149
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:06.152
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 04/18/23 09:42:06.156
    STEP: delete the rc 04/18/23 09:42:11.164
    STEP: wait for all pods to be garbage collected 04/18/23 09:42:11.168
    STEP: Gathering metrics 04/18/23 09:42:16.174
    W0418 09:42:16.184353      18 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 18 09:42:16.184: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 18 09:42:16.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7312" for this suite. 04/18/23 09:42:16.187
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:42:16.193
Apr 18 09:42:16.193: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename pod-network-test 04/18/23 09:42:16.194
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:16.202
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:16.206
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-9116 04/18/23 09:42:16.209
STEP: creating a selector 04/18/23 09:42:16.209
STEP: Creating the service pods in kubernetes 04/18/23 09:42:16.209
Apr 18 09:42:16.209: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 18 09:42:16.236: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9116" to be "running and ready"
Apr 18 09:42:16.245: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.560799ms
Apr 18 09:42:16.245: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:42:18.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.013375526s
Apr 18 09:42:18.249: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:42:20.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.013334322s
Apr 18 09:42:20.249: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:42:22.250: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.014614384s
Apr 18 09:42:22.250: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:42:24.250: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.014021667s
Apr 18 09:42:24.250: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:42:26.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.013433677s
Apr 18 09:42:26.249: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:42:28.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.013284336s
Apr 18 09:42:28.249: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 18 09:42:28.249: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 18 09:42:28.252: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9116" to be "running and ready"
Apr 18 09:42:28.254: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.385896ms
Apr 18 09:42:28.254: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 18 09:42:28.254: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 18 09:42:28.256: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9116" to be "running and ready"
Apr 18 09:42:28.260: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.253039ms
Apr 18 09:42:28.260: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 18 09:42:28.260: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/18/23 09:42:28.262
Apr 18 09:42:28.273: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9116" to be "running"
Apr 18 09:42:28.275: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073282ms
Apr 18 09:42:30.278: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.00519772s
Apr 18 09:42:30.278: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 18 09:42:30.280: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-9116" to be "running"
Apr 18 09:42:30.283: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.930254ms
Apr 18 09:42:30.283: INFO: Pod "host-test-container-pod" satisfied condition "running"
Apr 18 09:42:30.286: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 18 09:42:30.286: INFO: Going to poll 172.16.1.68 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Apr 18 09:42:30.288: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.1.68:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9116 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 09:42:30.288: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 09:42:30.288: INFO: ExecWithOptions: Clientset creation
Apr 18 09:42:30.288: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-9116/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.1.68%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 18 09:42:30.337: INFO: Found all 1 expected endpoints: [netserver-0]
Apr 18 09:42:30.337: INFO: Going to poll 172.16.0.90 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Apr 18 09:42:30.340: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.0.90:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9116 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 09:42:30.340: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 09:42:30.340: INFO: ExecWithOptions: Clientset creation
Apr 18 09:42:30.340: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-9116/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.0.90%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 18 09:42:30.387: INFO: Found all 1 expected endpoints: [netserver-1]
Apr 18 09:42:30.387: INFO: Going to poll 172.16.0.241 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Apr 18 09:42:30.390: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.0.241:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9116 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 09:42:30.390: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 09:42:30.391: INFO: ExecWithOptions: Clientset creation
Apr 18 09:42:30.391: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-9116/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.0.241%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 18 09:42:30.438: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 18 09:42:30.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9116" for this suite. 04/18/23 09:42:30.446
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":298,"skipped":5586,"failed":0}
------------------------------
• [SLOW TEST] [14.260 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:42:16.193
    Apr 18 09:42:16.193: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename pod-network-test 04/18/23 09:42:16.194
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:16.202
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:16.206
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-9116 04/18/23 09:42:16.209
    STEP: creating a selector 04/18/23 09:42:16.209
    STEP: Creating the service pods in kubernetes 04/18/23 09:42:16.209
    Apr 18 09:42:16.209: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 18 09:42:16.236: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9116" to be "running and ready"
    Apr 18 09:42:16.245: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.560799ms
    Apr 18 09:42:16.245: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:42:18.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.013375526s
    Apr 18 09:42:18.249: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:42:20.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.013334322s
    Apr 18 09:42:20.249: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:42:22.250: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.014614384s
    Apr 18 09:42:22.250: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:42:24.250: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.014021667s
    Apr 18 09:42:24.250: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:42:26.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.013433677s
    Apr 18 09:42:26.249: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:42:28.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.013284336s
    Apr 18 09:42:28.249: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 18 09:42:28.249: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 18 09:42:28.252: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9116" to be "running and ready"
    Apr 18 09:42:28.254: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.385896ms
    Apr 18 09:42:28.254: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 18 09:42:28.254: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 18 09:42:28.256: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9116" to be "running and ready"
    Apr 18 09:42:28.260: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.253039ms
    Apr 18 09:42:28.260: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 18 09:42:28.260: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/18/23 09:42:28.262
    Apr 18 09:42:28.273: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9116" to be "running"
    Apr 18 09:42:28.275: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073282ms
    Apr 18 09:42:30.278: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.00519772s
    Apr 18 09:42:30.278: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 18 09:42:30.280: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-9116" to be "running"
    Apr 18 09:42:30.283: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.930254ms
    Apr 18 09:42:30.283: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Apr 18 09:42:30.286: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 18 09:42:30.286: INFO: Going to poll 172.16.1.68 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Apr 18 09:42:30.288: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.1.68:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9116 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 09:42:30.288: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 09:42:30.288: INFO: ExecWithOptions: Clientset creation
    Apr 18 09:42:30.288: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-9116/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.1.68%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 18 09:42:30.337: INFO: Found all 1 expected endpoints: [netserver-0]
    Apr 18 09:42:30.337: INFO: Going to poll 172.16.0.90 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Apr 18 09:42:30.340: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.0.90:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9116 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 09:42:30.340: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 09:42:30.340: INFO: ExecWithOptions: Clientset creation
    Apr 18 09:42:30.340: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-9116/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.0.90%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 18 09:42:30.387: INFO: Found all 1 expected endpoints: [netserver-1]
    Apr 18 09:42:30.387: INFO: Going to poll 172.16.0.241 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Apr 18 09:42:30.390: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.0.241:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9116 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 09:42:30.390: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 09:42:30.391: INFO: ExecWithOptions: Clientset creation
    Apr 18 09:42:30.391: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-9116/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.0.241%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 18 09:42:30.438: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 18 09:42:30.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-9116" for this suite. 04/18/23 09:42:30.446
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:42:30.455
Apr 18 09:42:30.455: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename certificates 04/18/23 09:42:30.455
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:30.464
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:30.467
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 04/18/23 09:42:30.828
STEP: getting /apis/certificates.k8s.io 04/18/23 09:42:30.833
STEP: getting /apis/certificates.k8s.io/v1 04/18/23 09:42:30.835
STEP: creating 04/18/23 09:42:30.836
STEP: getting 04/18/23 09:42:30.854
STEP: listing 04/18/23 09:42:30.862
STEP: watching 04/18/23 09:42:30.864
Apr 18 09:42:30.864: INFO: starting watch
STEP: patching 04/18/23 09:42:30.866
STEP: updating 04/18/23 09:42:30.881
Apr 18 09:42:30.888: INFO: waiting for watch events with expected annotations
Apr 18 09:42:30.888: INFO: saw patched and updated annotations
STEP: getting /approval 04/18/23 09:42:30.888
STEP: patching /approval 04/18/23 09:42:30.89
STEP: updating /approval 04/18/23 09:42:30.9
STEP: getting /status 04/18/23 09:42:30.905
STEP: patching /status 04/18/23 09:42:30.908
STEP: updating /status 04/18/23 09:42:30.917
STEP: deleting 04/18/23 09:42:30.923
STEP: deleting a collection 04/18/23 09:42:30.934
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:42:30.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-532" for this suite. 04/18/23 09:42:30.953
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":299,"skipped":5618,"failed":0}
------------------------------
• [0.502 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:42:30.455
    Apr 18 09:42:30.455: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename certificates 04/18/23 09:42:30.455
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:30.464
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:30.467
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 04/18/23 09:42:30.828
    STEP: getting /apis/certificates.k8s.io 04/18/23 09:42:30.833
    STEP: getting /apis/certificates.k8s.io/v1 04/18/23 09:42:30.835
    STEP: creating 04/18/23 09:42:30.836
    STEP: getting 04/18/23 09:42:30.854
    STEP: listing 04/18/23 09:42:30.862
    STEP: watching 04/18/23 09:42:30.864
    Apr 18 09:42:30.864: INFO: starting watch
    STEP: patching 04/18/23 09:42:30.866
    STEP: updating 04/18/23 09:42:30.881
    Apr 18 09:42:30.888: INFO: waiting for watch events with expected annotations
    Apr 18 09:42:30.888: INFO: saw patched and updated annotations
    STEP: getting /approval 04/18/23 09:42:30.888
    STEP: patching /approval 04/18/23 09:42:30.89
    STEP: updating /approval 04/18/23 09:42:30.9
    STEP: getting /status 04/18/23 09:42:30.905
    STEP: patching /status 04/18/23 09:42:30.908
    STEP: updating /status 04/18/23 09:42:30.917
    STEP: deleting 04/18/23 09:42:30.923
    STEP: deleting a collection 04/18/23 09:42:30.934
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:42:30.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-532" for this suite. 04/18/23 09:42:30.953
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:42:30.957
Apr 18 09:42:30.957: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 09:42:30.958
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:30.969
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:30.973
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 09:42:30.984
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:42:31.48
STEP: Deploying the webhook pod 04/18/23 09:42:31.487
STEP: Wait for the deployment to be ready 04/18/23 09:42:31.498
Apr 18 09:42:31.504: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 09:42:33.512
STEP: Verifying the service has paired with the endpoint 04/18/23 09:42:33.52
Apr 18 09:42:34.520: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 04/18/23 09:42:34.523
STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 09:42:34.539
STEP: Updating a validating webhook configuration's rules to not include the create operation 04/18/23 09:42:34.549
STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 09:42:34.594
STEP: Patching a validating webhook configuration's rules to include the create operation 04/18/23 09:42:34.601
STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 09:42:34.615
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:42:34.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5773" for this suite. 04/18/23 09:42:34.627
STEP: Destroying namespace "webhook-5773-markers" for this suite. 04/18/23 09:42:34.631
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":300,"skipped":5637,"failed":0}
------------------------------
• [3.719 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:42:30.957
    Apr 18 09:42:30.957: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 09:42:30.958
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:30.969
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:30.973
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 09:42:30.984
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:42:31.48
    STEP: Deploying the webhook pod 04/18/23 09:42:31.487
    STEP: Wait for the deployment to be ready 04/18/23 09:42:31.498
    Apr 18 09:42:31.504: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 09:42:33.512
    STEP: Verifying the service has paired with the endpoint 04/18/23 09:42:33.52
    Apr 18 09:42:34.520: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 04/18/23 09:42:34.523
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 09:42:34.539
    STEP: Updating a validating webhook configuration's rules to not include the create operation 04/18/23 09:42:34.549
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 09:42:34.594
    STEP: Patching a validating webhook configuration's rules to include the create operation 04/18/23 09:42:34.601
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 09:42:34.615
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:42:34.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5773" for this suite. 04/18/23 09:42:34.627
    STEP: Destroying namespace "webhook-5773-markers" for this suite. 04/18/23 09:42:34.631
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:42:34.677
Apr 18 09:42:34.677: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 09:42:34.678
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:34.696
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:34.699
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 04/18/23 09:42:34.702
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 04/18/23 09:42:34.704
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 04/18/23 09:42:34.704
STEP: fetching the /apis/apiextensions.k8s.io discovery document 04/18/23 09:42:34.704
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 04/18/23 09:42:34.705
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 04/18/23 09:42:34.705
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 04/18/23 09:42:34.707
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:42:34.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-711" for this suite. 04/18/23 09:42:34.71
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":301,"skipped":5651,"failed":0}
------------------------------
• [0.039 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:42:34.677
    Apr 18 09:42:34.677: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 09:42:34.678
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:34.696
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:34.699
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 04/18/23 09:42:34.702
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 04/18/23 09:42:34.704
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 04/18/23 09:42:34.704
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 04/18/23 09:42:34.704
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 04/18/23 09:42:34.705
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 04/18/23 09:42:34.705
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 04/18/23 09:42:34.707
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:42:34.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-711" for this suite. 04/18/23 09:42:34.71
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:42:34.717
Apr 18 09:42:34.717: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubelet-test 04/18/23 09:42:34.717
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:34.726
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:34.729
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 18 09:42:38.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1340" for this suite. 04/18/23 09:42:38.755
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":302,"skipped":5657,"failed":0}
------------------------------
• [4.043 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:42:34.717
    Apr 18 09:42:34.717: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubelet-test 04/18/23 09:42:34.717
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:34.726
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:34.729
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 18 09:42:38.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-1340" for this suite. 04/18/23 09:42:38.755
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:42:38.76
Apr 18 09:42:38.760: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 09:42:38.761
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:38.772
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:38.776
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 04/18/23 09:42:38.779
Apr 18 09:42:38.787: INFO: Waiting up to 5m0s for pod "downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353" in namespace "projected-908" to be "Succeeded or Failed"
Apr 18 09:42:38.789: INFO: Pod "downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353": Phase="Pending", Reason="", readiness=false. Elapsed: 2.814361ms
Apr 18 09:42:40.792: INFO: Pod "downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005443733s
Apr 18 09:42:42.793: INFO: Pod "downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006604923s
STEP: Saw pod success 04/18/23 09:42:42.793
Apr 18 09:42:42.793: INFO: Pod "downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353" satisfied condition "Succeeded or Failed"
Apr 18 09:42:42.796: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353 container client-container: <nil>
STEP: delete the pod 04/18/23 09:42:42.801
Apr 18 09:42:42.811: INFO: Waiting for pod downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353 to disappear
Apr 18 09:42:42.813: INFO: Pod downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 09:42:42.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-908" for this suite. 04/18/23 09:42:42.817
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":303,"skipped":5663,"failed":0}
------------------------------
• [4.061 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:42:38.76
    Apr 18 09:42:38.760: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 09:42:38.761
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:38.772
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:38.776
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 04/18/23 09:42:38.779
    Apr 18 09:42:38.787: INFO: Waiting up to 5m0s for pod "downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353" in namespace "projected-908" to be "Succeeded or Failed"
    Apr 18 09:42:38.789: INFO: Pod "downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353": Phase="Pending", Reason="", readiness=false. Elapsed: 2.814361ms
    Apr 18 09:42:40.792: INFO: Pod "downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005443733s
    Apr 18 09:42:42.793: INFO: Pod "downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006604923s
    STEP: Saw pod success 04/18/23 09:42:42.793
    Apr 18 09:42:42.793: INFO: Pod "downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353" satisfied condition "Succeeded or Failed"
    Apr 18 09:42:42.796: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353 container client-container: <nil>
    STEP: delete the pod 04/18/23 09:42:42.801
    Apr 18 09:42:42.811: INFO: Waiting for pod downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353 to disappear
    Apr 18 09:42:42.813: INFO: Pod downwardapi-volume-025df1bb-6305-40fa-a4b7-4b1ef8c76353 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 09:42:42.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-908" for this suite. 04/18/23 09:42:42.817
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:42:42.824
Apr 18 09:42:42.824: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename svcaccounts 04/18/23 09:42:42.825
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:42.835
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:42.838
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  04/18/23 09:42:42.842
Apr 18 09:42:42.855: INFO: Waiting up to 5m0s for pod "test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656" in namespace "svcaccounts-5752" to be "Succeeded or Failed"
Apr 18 09:42:42.858: INFO: Pod "test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656": Phase="Pending", Reason="", readiness=false. Elapsed: 3.205671ms
Apr 18 09:42:44.862: INFO: Pod "test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006383463s
Apr 18 09:42:46.862: INFO: Pod "test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006804797s
STEP: Saw pod success 04/18/23 09:42:46.862
Apr 18 09:42:46.862: INFO: Pod "test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656" satisfied condition "Succeeded or Failed"
Apr 18 09:42:46.865: INFO: Trying to get logs from node 192.168.1.152 pod test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 09:42:46.87
Apr 18 09:42:46.879: INFO: Waiting for pod test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656 to disappear
Apr 18 09:42:46.881: INFO: Pod test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 18 09:42:46.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5752" for this suite. 04/18/23 09:42:46.884
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":304,"skipped":5692,"failed":0}
------------------------------
• [4.065 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:42:42.824
    Apr 18 09:42:42.824: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename svcaccounts 04/18/23 09:42:42.825
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:42.835
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:42.838
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  04/18/23 09:42:42.842
    Apr 18 09:42:42.855: INFO: Waiting up to 5m0s for pod "test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656" in namespace "svcaccounts-5752" to be "Succeeded or Failed"
    Apr 18 09:42:42.858: INFO: Pod "test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656": Phase="Pending", Reason="", readiness=false. Elapsed: 3.205671ms
    Apr 18 09:42:44.862: INFO: Pod "test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006383463s
    Apr 18 09:42:46.862: INFO: Pod "test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006804797s
    STEP: Saw pod success 04/18/23 09:42:46.862
    Apr 18 09:42:46.862: INFO: Pod "test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656" satisfied condition "Succeeded or Failed"
    Apr 18 09:42:46.865: INFO: Trying to get logs from node 192.168.1.152 pod test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 09:42:46.87
    Apr 18 09:42:46.879: INFO: Waiting for pod test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656 to disappear
    Apr 18 09:42:46.881: INFO: Pod test-pod-08d5ce1f-7b86-402f-81d2-a9ad2f793656 no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 18 09:42:46.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-5752" for this suite. 04/18/23 09:42:46.884
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:42:46.889
Apr 18 09:42:46.890: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 09:42:46.89
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:46.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:46.903
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Apr 18 09:42:46.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7289 version'
Apr 18 09:42:46.948: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Apr 18 09:42:46.948: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.0\", GitCommit:\"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2\", GitTreeState:\"clean\", BuildDate:\"2022-08-23T17:44:59Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25+\", GitVersion:\"v1.25.2-r0-CCE22.12.1\", GitCommit:\"2cd913b89d365cdb5fd7f73f04b062ecb0b01a41\", GitTreeState:\"clean\", BuildDate:\"2022-12-30T12:08:50Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 09:42:46.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7289" for this suite. 04/18/23 09:42:46.952
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":305,"skipped":5703,"failed":0}
------------------------------
• [0.068 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:42:46.889
    Apr 18 09:42:46.890: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 09:42:46.89
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:46.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:46.903
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Apr 18 09:42:46.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-7289 version'
    Apr 18 09:42:46.948: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Apr 18 09:42:46.948: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.0\", GitCommit:\"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2\", GitTreeState:\"clean\", BuildDate:\"2022-08-23T17:44:59Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25+\", GitVersion:\"v1.25.2-r0-CCE22.12.1\", GitCommit:\"2cd913b89d365cdb5fd7f73f04b062ecb0b01a41\", GitTreeState:\"clean\", BuildDate:\"2022-12-30T12:08:50Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 09:42:46.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7289" for this suite. 04/18/23 09:42:46.952
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:42:46.958
Apr 18 09:42:46.958: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename configmap 04/18/23 09:42:46.959
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:46.969
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:46.972
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-10f11568-d74a-4478-94be-38e2521a2ac3 04/18/23 09:42:46.976
STEP: Creating a pod to test consume configMaps 04/18/23 09:42:46.979
Apr 18 09:42:46.985: INFO: Waiting up to 5m0s for pod "pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41" in namespace "configmap-4904" to be "Succeeded or Failed"
Apr 18 09:42:46.987: INFO: Pod "pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41": Phase="Pending", Reason="", readiness=false. Elapsed: 2.119157ms
Apr 18 09:42:48.992: INFO: Pod "pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006386732s
Apr 18 09:42:50.990: INFO: Pod "pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005134721s
STEP: Saw pod success 04/18/23 09:42:50.99
Apr 18 09:42:50.990: INFO: Pod "pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41" satisfied condition "Succeeded or Failed"
Apr 18 09:42:50.993: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 09:42:50.998
Apr 18 09:42:51.007: INFO: Waiting for pod pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41 to disappear
Apr 18 09:42:51.011: INFO: Pod pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 09:42:51.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4904" for this suite. 04/18/23 09:42:51.014
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":306,"skipped":5704,"failed":0}
------------------------------
• [4.062 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:42:46.958
    Apr 18 09:42:46.958: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename configmap 04/18/23 09:42:46.959
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:46.969
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:46.972
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-10f11568-d74a-4478-94be-38e2521a2ac3 04/18/23 09:42:46.976
    STEP: Creating a pod to test consume configMaps 04/18/23 09:42:46.979
    Apr 18 09:42:46.985: INFO: Waiting up to 5m0s for pod "pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41" in namespace "configmap-4904" to be "Succeeded or Failed"
    Apr 18 09:42:46.987: INFO: Pod "pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41": Phase="Pending", Reason="", readiness=false. Elapsed: 2.119157ms
    Apr 18 09:42:48.992: INFO: Pod "pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006386732s
    Apr 18 09:42:50.990: INFO: Pod "pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005134721s
    STEP: Saw pod success 04/18/23 09:42:50.99
    Apr 18 09:42:50.990: INFO: Pod "pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41" satisfied condition "Succeeded or Failed"
    Apr 18 09:42:50.993: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 09:42:50.998
    Apr 18 09:42:51.007: INFO: Waiting for pod pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41 to disappear
    Apr 18 09:42:51.011: INFO: Pod pod-configmaps-9142f419-e733-42b8-9d0b-02ad2ba94f41 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 09:42:51.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4904" for this suite. 04/18/23 09:42:51.014
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:42:51.02
Apr 18 09:42:51.020: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 09:42:51.02
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:51.028
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:51.031
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-937 04/18/23 09:42:51.034
STEP: creating service affinity-nodeport-transition in namespace services-937 04/18/23 09:42:51.034
STEP: creating replication controller affinity-nodeport-transition in namespace services-937 04/18/23 09:42:51.044
I0418 09:42:51.054577      18 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-937, replica count: 3
I0418 09:42:54.105734      18 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 09:42:54.114: INFO: Creating new exec pod
Apr 18 09:42:54.124: INFO: Waiting up to 5m0s for pod "execpod-affinityvzswg" in namespace "services-937" to be "running"
Apr 18 09:42:54.131: INFO: Pod "execpod-affinityvzswg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.983325ms
Apr 18 09:42:56.135: INFO: Pod "execpod-affinityvzswg": Phase="Running", Reason="", readiness=true. Elapsed: 2.010501861s
Apr 18 09:42:56.135: INFO: Pod "execpod-affinityvzswg" satisfied condition "running"
Apr 18 09:42:57.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-937 exec execpod-affinityvzswg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Apr 18 09:42:57.238: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Apr 18 09:42:57.238: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:42:57.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-937 exec execpod-affinityvzswg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.94.35 80'
Apr 18 09:42:57.339: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.94.35 80\nConnection to 10.247.94.35 80 port [tcp/http] succeeded!\n"
Apr 18 09:42:57.339: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:42:57.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-937 exec execpod-affinityvzswg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.29 31988'
Apr 18 09:42:57.440: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.29 31988\nConnection to 192.168.1.29 31988 port [tcp/*] succeeded!\n"
Apr 18 09:42:57.441: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:42:57.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-937 exec execpod-affinityvzswg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.84 31988'
Apr 18 09:42:57.542: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.84 31988\nConnection to 192.168.1.84 31988 port [tcp/*] succeeded!\n"
Apr 18 09:42:57.542: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:42:57.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-937 exec execpod-affinityvzswg -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.152:31988/ ; done'
Apr 18 09:42:57.723: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n"
Apr 18 09:42:57.723: INFO: stdout: "\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-kfft5\naffinity-nodeport-transition-kfft5\naffinity-nodeport-transition-bpm6h\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-bpm6h\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-kfft5\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-kfft5\naffinity-nodeport-transition-kfft5\naffinity-nodeport-transition-vm82w"
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-kfft5
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-kfft5
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-bpm6h
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-bpm6h
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-kfft5
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-kfft5
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-kfft5
Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-937 exec execpod-affinityvzswg -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.152:31988/ ; done'
Apr 18 09:42:57.890: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n"
Apr 18 09:42:57.890: INFO: stdout: "\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w"
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
Apr 18 09:42:57.890: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-937, will wait for the garbage collector to delete the pods 04/18/23 09:42:57.902
Apr 18 09:42:57.960: INFO: Deleting ReplicationController affinity-nodeport-transition took: 4.178913ms
Apr 18 09:42:58.060: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.49809ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 09:42:59.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-937" for this suite. 04/18/23 09:42:59.783
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":307,"skipped":5705,"failed":0}
------------------------------
• [SLOW TEST] [8.767 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:42:51.02
    Apr 18 09:42:51.020: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 09:42:51.02
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:51.028
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:51.031
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-937 04/18/23 09:42:51.034
    STEP: creating service affinity-nodeport-transition in namespace services-937 04/18/23 09:42:51.034
    STEP: creating replication controller affinity-nodeport-transition in namespace services-937 04/18/23 09:42:51.044
    I0418 09:42:51.054577      18 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-937, replica count: 3
    I0418 09:42:54.105734      18 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 09:42:54.114: INFO: Creating new exec pod
    Apr 18 09:42:54.124: INFO: Waiting up to 5m0s for pod "execpod-affinityvzswg" in namespace "services-937" to be "running"
    Apr 18 09:42:54.131: INFO: Pod "execpod-affinityvzswg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.983325ms
    Apr 18 09:42:56.135: INFO: Pod "execpod-affinityvzswg": Phase="Running", Reason="", readiness=true. Elapsed: 2.010501861s
    Apr 18 09:42:56.135: INFO: Pod "execpod-affinityvzswg" satisfied condition "running"
    Apr 18 09:42:57.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-937 exec execpod-affinityvzswg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Apr 18 09:42:57.238: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Apr 18 09:42:57.238: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:42:57.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-937 exec execpod-affinityvzswg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.94.35 80'
    Apr 18 09:42:57.339: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.94.35 80\nConnection to 10.247.94.35 80 port [tcp/http] succeeded!\n"
    Apr 18 09:42:57.339: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:42:57.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-937 exec execpod-affinityvzswg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.29 31988'
    Apr 18 09:42:57.440: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.29 31988\nConnection to 192.168.1.29 31988 port [tcp/*] succeeded!\n"
    Apr 18 09:42:57.441: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:42:57.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-937 exec execpod-affinityvzswg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.84 31988'
    Apr 18 09:42:57.542: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.84 31988\nConnection to 192.168.1.84 31988 port [tcp/*] succeeded!\n"
    Apr 18 09:42:57.542: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:42:57.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-937 exec execpod-affinityvzswg -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.152:31988/ ; done'
    Apr 18 09:42:57.723: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n"
    Apr 18 09:42:57.723: INFO: stdout: "\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-kfft5\naffinity-nodeport-transition-kfft5\naffinity-nodeport-transition-bpm6h\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-bpm6h\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-kfft5\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-kfft5\naffinity-nodeport-transition-kfft5\naffinity-nodeport-transition-vm82w"
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-kfft5
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-kfft5
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-bpm6h
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-bpm6h
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-kfft5
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-kfft5
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-kfft5
    Apr 18 09:42:57.723: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-937 exec execpod-affinityvzswg -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.152:31988/ ; done'
    Apr 18 09:42:57.890: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:31988/\n"
    Apr 18 09:42:57.890: INFO: stdout: "\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w\naffinity-nodeport-transition-vm82w"
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Received response from host: affinity-nodeport-transition-vm82w
    Apr 18 09:42:57.890: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-937, will wait for the garbage collector to delete the pods 04/18/23 09:42:57.902
    Apr 18 09:42:57.960: INFO: Deleting ReplicationController affinity-nodeport-transition took: 4.178913ms
    Apr 18 09:42:58.060: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.49809ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 09:42:59.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-937" for this suite. 04/18/23 09:42:59.783
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:42:59.788
Apr 18 09:42:59.788: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename cronjob 04/18/23 09:42:59.789
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:59.8
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:59.803
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 04/18/23 09:42:59.806
STEP: creating 04/18/23 09:42:59.806
STEP: getting 04/18/23 09:42:59.811
STEP: listing 04/18/23 09:42:59.813
STEP: watching 04/18/23 09:42:59.815
Apr 18 09:42:59.815: INFO: starting watch
STEP: cluster-wide listing 04/18/23 09:42:59.817
STEP: cluster-wide watching 04/18/23 09:42:59.82
Apr 18 09:42:59.820: INFO: starting watch
STEP: patching 04/18/23 09:42:59.822
STEP: updating 04/18/23 09:42:59.832
Apr 18 09:42:59.839: INFO: waiting for watch events with expected annotations
Apr 18 09:42:59.839: INFO: saw patched and updated annotations
STEP: patching /status 04/18/23 09:42:59.839
STEP: updating /status 04/18/23 09:42:59.846
STEP: get /status 04/18/23 09:42:59.851
STEP: deleting 04/18/23 09:42:59.854
STEP: deleting a collection 04/18/23 09:42:59.864
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 18 09:42:59.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6740" for this suite. 04/18/23 09:42:59.873
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":308,"skipped":5775,"failed":0}
------------------------------
• [0.089 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:42:59.788
    Apr 18 09:42:59.788: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename cronjob 04/18/23 09:42:59.789
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:59.8
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:59.803
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 04/18/23 09:42:59.806
    STEP: creating 04/18/23 09:42:59.806
    STEP: getting 04/18/23 09:42:59.811
    STEP: listing 04/18/23 09:42:59.813
    STEP: watching 04/18/23 09:42:59.815
    Apr 18 09:42:59.815: INFO: starting watch
    STEP: cluster-wide listing 04/18/23 09:42:59.817
    STEP: cluster-wide watching 04/18/23 09:42:59.82
    Apr 18 09:42:59.820: INFO: starting watch
    STEP: patching 04/18/23 09:42:59.822
    STEP: updating 04/18/23 09:42:59.832
    Apr 18 09:42:59.839: INFO: waiting for watch events with expected annotations
    Apr 18 09:42:59.839: INFO: saw patched and updated annotations
    STEP: patching /status 04/18/23 09:42:59.839
    STEP: updating /status 04/18/23 09:42:59.846
    STEP: get /status 04/18/23 09:42:59.851
    STEP: deleting 04/18/23 09:42:59.854
    STEP: deleting a collection 04/18/23 09:42:59.864
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 18 09:42:59.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-6740" for this suite. 04/18/23 09:42:59.873
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:42:59.88
Apr 18 09:42:59.880: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename pods 04/18/23 09:42:59.88
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:59.895
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:59.899
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 04/18/23 09:42:59.903
STEP: setting up watch 04/18/23 09:42:59.903
STEP: submitting the pod to kubernetes 04/18/23 09:43:00.005
STEP: verifying the pod is in kubernetes 04/18/23 09:43:00.023
STEP: verifying pod creation was observed 04/18/23 09:43:00.036
Apr 18 09:43:00.036: INFO: Waiting up to 5m0s for pod "pod-submit-remove-a4f8a534-ec2e-4e3f-b7c0-ff1d84b4991c" in namespace "pods-6961" to be "running"
Apr 18 09:43:00.051: INFO: Pod "pod-submit-remove-a4f8a534-ec2e-4e3f-b7c0-ff1d84b4991c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.06064ms
Apr 18 09:43:02.055: INFO: Pod "pod-submit-remove-a4f8a534-ec2e-4e3f-b7c0-ff1d84b4991c": Phase="Running", Reason="", readiness=true. Elapsed: 2.01850576s
Apr 18 09:43:02.055: INFO: Pod "pod-submit-remove-a4f8a534-ec2e-4e3f-b7c0-ff1d84b4991c" satisfied condition "running"
STEP: deleting the pod gracefully 04/18/23 09:43:02.057
STEP: verifying pod deletion was observed 04/18/23 09:43:02.063
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 09:43:03.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6961" for this suite. 04/18/23 09:43:03.71
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":309,"skipped":5810,"failed":0}
------------------------------
• [3.835 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:42:59.88
    Apr 18 09:42:59.880: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename pods 04/18/23 09:42:59.88
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:42:59.895
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:42:59.899
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 04/18/23 09:42:59.903
    STEP: setting up watch 04/18/23 09:42:59.903
    STEP: submitting the pod to kubernetes 04/18/23 09:43:00.005
    STEP: verifying the pod is in kubernetes 04/18/23 09:43:00.023
    STEP: verifying pod creation was observed 04/18/23 09:43:00.036
    Apr 18 09:43:00.036: INFO: Waiting up to 5m0s for pod "pod-submit-remove-a4f8a534-ec2e-4e3f-b7c0-ff1d84b4991c" in namespace "pods-6961" to be "running"
    Apr 18 09:43:00.051: INFO: Pod "pod-submit-remove-a4f8a534-ec2e-4e3f-b7c0-ff1d84b4991c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.06064ms
    Apr 18 09:43:02.055: INFO: Pod "pod-submit-remove-a4f8a534-ec2e-4e3f-b7c0-ff1d84b4991c": Phase="Running", Reason="", readiness=true. Elapsed: 2.01850576s
    Apr 18 09:43:02.055: INFO: Pod "pod-submit-remove-a4f8a534-ec2e-4e3f-b7c0-ff1d84b4991c" satisfied condition "running"
    STEP: deleting the pod gracefully 04/18/23 09:43:02.057
    STEP: verifying pod deletion was observed 04/18/23 09:43:02.063
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 09:43:03.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6961" for this suite. 04/18/23 09:43:03.71
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:43:03.716
Apr 18 09:43:03.716: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 09:43:03.716
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:43:03.725
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:43:03.731
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 04/18/23 09:43:03.734
Apr 18 09:43:03.734: INFO: namespace kubectl-1021
Apr 18 09:43:03.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1021 create -f -'
Apr 18 09:43:03.894: INFO: stderr: ""
Apr 18 09:43:03.894: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/18/23 09:43:03.894
Apr 18 09:43:04.898: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 09:43:04.898: INFO: Found 1 / 1
Apr 18 09:43:04.898: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 18 09:43:04.900: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 09:43:04.900: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 18 09:43:04.900: INFO: wait on agnhost-primary startup in kubectl-1021 
Apr 18 09:43:04.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1021 logs agnhost-primary-rtd29 agnhost-primary'
Apr 18 09:43:04.960: INFO: stderr: ""
Apr 18 09:43:04.960: INFO: stdout: "Paused\n"
STEP: exposing RC 04/18/23 09:43:04.96
Apr 18 09:43:04.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1021 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Apr 18 09:43:05.026: INFO: stderr: ""
Apr 18 09:43:05.026: INFO: stdout: "service/rm2 exposed\n"
Apr 18 09:43:05.039: INFO: Service rm2 in namespace kubectl-1021 found.
STEP: exposing service 04/18/23 09:43:07.045
Apr 18 09:43:07.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1021 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Apr 18 09:43:07.116: INFO: stderr: ""
Apr 18 09:43:07.116: INFO: stdout: "service/rm3 exposed\n"
Apr 18 09:43:07.120: INFO: Service rm3 in namespace kubectl-1021 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 09:43:09.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1021" for this suite. 04/18/23 09:43:09.13
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":310,"skipped":5828,"failed":0}
------------------------------
• [SLOW TEST] [5.418 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:43:03.716
    Apr 18 09:43:03.716: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 09:43:03.716
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:43:03.725
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:43:03.731
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 04/18/23 09:43:03.734
    Apr 18 09:43:03.734: INFO: namespace kubectl-1021
    Apr 18 09:43:03.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1021 create -f -'
    Apr 18 09:43:03.894: INFO: stderr: ""
    Apr 18 09:43:03.894: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/18/23 09:43:03.894
    Apr 18 09:43:04.898: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 09:43:04.898: INFO: Found 1 / 1
    Apr 18 09:43:04.898: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Apr 18 09:43:04.900: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 09:43:04.900: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 18 09:43:04.900: INFO: wait on agnhost-primary startup in kubectl-1021 
    Apr 18 09:43:04.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1021 logs agnhost-primary-rtd29 agnhost-primary'
    Apr 18 09:43:04.960: INFO: stderr: ""
    Apr 18 09:43:04.960: INFO: stdout: "Paused\n"
    STEP: exposing RC 04/18/23 09:43:04.96
    Apr 18 09:43:04.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1021 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Apr 18 09:43:05.026: INFO: stderr: ""
    Apr 18 09:43:05.026: INFO: stdout: "service/rm2 exposed\n"
    Apr 18 09:43:05.039: INFO: Service rm2 in namespace kubectl-1021 found.
    STEP: exposing service 04/18/23 09:43:07.045
    Apr 18 09:43:07.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-1021 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Apr 18 09:43:07.116: INFO: stderr: ""
    Apr 18 09:43:07.116: INFO: stdout: "service/rm3 exposed\n"
    Apr 18 09:43:07.120: INFO: Service rm3 in namespace kubectl-1021 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 09:43:09.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1021" for this suite. 04/18/23 09:43:09.13
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:43:09.135
Apr 18 09:43:09.135: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 09:43:09.135
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:43:09.151
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:43:09.154
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 04/18/23 09:43:09.158
Apr 18 09:43:09.158: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3678 proxy --unix-socket=/tmp/kubectl-proxy-unix1978929097/test'
STEP: retrieving proxy /api/ output 04/18/23 09:43:09.197
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 09:43:09.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3678" for this suite. 04/18/23 09:43:09.221
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":311,"skipped":5831,"failed":0}
------------------------------
• [0.103 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:43:09.135
    Apr 18 09:43:09.135: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 09:43:09.135
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:43:09.151
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:43:09.154
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 04/18/23 09:43:09.158
    Apr 18 09:43:09.158: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3678 proxy --unix-socket=/tmp/kubectl-proxy-unix1978929097/test'
    STEP: retrieving proxy /api/ output 04/18/23 09:43:09.197
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 09:43:09.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3678" for this suite. 04/18/23 09:43:09.221
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:43:09.238
Apr 18 09:43:09.239: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename daemonsets 04/18/23 09:43:09.239
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:43:09.28
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:43:09.296
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 04/18/23 09:43:09.316
STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 09:43:09.32
Apr 18 09:43:09.331: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:43:09.331: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
Apr 18 09:43:10.338: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 18 09:43:10.338: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
Apr 18 09:43:11.338: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 09:43:11.338: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 04/18/23 09:43:11.341
Apr 18 09:43:11.356: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 09:43:11.356: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 04/18/23 09:43:11.356
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/18/23 09:43:12.364
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5111, will wait for the garbage collector to delete the pods 04/18/23 09:43:12.364
Apr 18 09:43:12.423: INFO: Deleting DaemonSet.extensions daemon-set took: 5.721361ms
Apr 18 09:43:12.523: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.219748ms
Apr 18 09:43:13.827: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 09:43:13.827: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 18 09:43:13.829: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4200288"},"items":null}

Apr 18 09:43:13.833: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4200288"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:43:13.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5111" for this suite. 04/18/23 09:43:13.85
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":312,"skipped":5856,"failed":0}
------------------------------
• [4.615 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:43:09.238
    Apr 18 09:43:09.239: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename daemonsets 04/18/23 09:43:09.239
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:43:09.28
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:43:09.296
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 04/18/23 09:43:09.316
    STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 09:43:09.32
    Apr 18 09:43:09.331: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:43:09.331: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
    Apr 18 09:43:10.338: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 18 09:43:10.338: INFO: Node 192.168.1.152 is running 0 daemon pod, expected 1
    Apr 18 09:43:11.338: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 09:43:11.338: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 04/18/23 09:43:11.341
    Apr 18 09:43:11.356: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 09:43:11.356: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 04/18/23 09:43:11.356
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/18/23 09:43:12.364
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5111, will wait for the garbage collector to delete the pods 04/18/23 09:43:12.364
    Apr 18 09:43:12.423: INFO: Deleting DaemonSet.extensions daemon-set took: 5.721361ms
    Apr 18 09:43:12.523: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.219748ms
    Apr 18 09:43:13.827: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 09:43:13.827: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 18 09:43:13.829: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4200288"},"items":null}

    Apr 18 09:43:13.833: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4200288"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:43:13.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-5111" for this suite. 04/18/23 09:43:13.85
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:43:13.855
Apr 18 09:43:13.855: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename sched-preemption 04/18/23 09:43:13.855
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:43:13.869
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:43:13.872
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 18 09:43:13.887: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 18 09:44:13.916: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:44:13.919
Apr 18 09:44:13.919: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename sched-preemption-path 04/18/23 09:44:13.919
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:44:13.93
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:44:13.933
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Apr 18 09:44:13.957: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Apr 18 09:44:13.960: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Apr 18 09:44:13.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-1521" for this suite. 04/18/23 09:44:13.976
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:44:13.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7684" for this suite. 04/18/23 09:44:13.988
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":313,"skipped":5878,"failed":0}
------------------------------
• [SLOW TEST] [60.182 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:43:13.855
    Apr 18 09:43:13.855: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename sched-preemption 04/18/23 09:43:13.855
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:43:13.869
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:43:13.872
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 18 09:43:13.887: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 18 09:44:13.916: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:44:13.919
    Apr 18 09:44:13.919: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename sched-preemption-path 04/18/23 09:44:13.919
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:44:13.93
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:44:13.933
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Apr 18 09:44:13.957: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Apr 18 09:44:13.960: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Apr 18 09:44:13.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-1521" for this suite. 04/18/23 09:44:13.976
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:44:13.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-7684" for this suite. 04/18/23 09:44:13.988
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:44:14.037
Apr 18 09:44:14.037: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 09:44:14.038
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:44:14.051
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:44:14.054
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-272 04/18/23 09:44:14.057
STEP: creating service affinity-clusterip in namespace services-272 04/18/23 09:44:14.057
STEP: creating replication controller affinity-clusterip in namespace services-272 04/18/23 09:44:14.065
I0418 09:44:14.073726      18 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-272, replica count: 3
I0418 09:44:17.124965      18 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 09:44:17.130: INFO: Creating new exec pod
Apr 18 09:44:17.134: INFO: Waiting up to 5m0s for pod "execpod-affinitydrsh4" in namespace "services-272" to be "running"
Apr 18 09:44:17.136: INFO: Pod "execpod-affinitydrsh4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.311362ms
Apr 18 09:44:19.139: INFO: Pod "execpod-affinitydrsh4": Phase="Running", Reason="", readiness=true. Elapsed: 2.005552577s
Apr 18 09:44:19.139: INFO: Pod "execpod-affinitydrsh4" satisfied condition "running"
Apr 18 09:44:20.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-272 exec execpod-affinitydrsh4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Apr 18 09:44:20.239: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Apr 18 09:44:20.239: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:44:20.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-272 exec execpod-affinitydrsh4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.242.141 80'
Apr 18 09:44:20.340: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.242.141 80\nConnection to 10.247.242.141 80 port [tcp/http] succeeded!\n"
Apr 18 09:44:20.340: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:44:20.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-272 exec execpod-affinitydrsh4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.247.242.141:80/ ; done'
Apr 18 09:44:20.481: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n"
Apr 18 09:44:20.481: INFO: stdout: "\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4"
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
Apr 18 09:44:20.481: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-272, will wait for the garbage collector to delete the pods 04/18/23 09:44:20.491
Apr 18 09:44:20.550: INFO: Deleting ReplicationController affinity-clusterip took: 5.536095ms
Apr 18 09:44:20.650: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.512805ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 09:44:22.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-272" for this suite. 04/18/23 09:44:22.666
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":314,"skipped":5891,"failed":0}
------------------------------
• [SLOW TEST] [8.632 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:44:14.037
    Apr 18 09:44:14.037: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 09:44:14.038
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:44:14.051
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:44:14.054
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-272 04/18/23 09:44:14.057
    STEP: creating service affinity-clusterip in namespace services-272 04/18/23 09:44:14.057
    STEP: creating replication controller affinity-clusterip in namespace services-272 04/18/23 09:44:14.065
    I0418 09:44:14.073726      18 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-272, replica count: 3
    I0418 09:44:17.124965      18 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 09:44:17.130: INFO: Creating new exec pod
    Apr 18 09:44:17.134: INFO: Waiting up to 5m0s for pod "execpod-affinitydrsh4" in namespace "services-272" to be "running"
    Apr 18 09:44:17.136: INFO: Pod "execpod-affinitydrsh4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.311362ms
    Apr 18 09:44:19.139: INFO: Pod "execpod-affinitydrsh4": Phase="Running", Reason="", readiness=true. Elapsed: 2.005552577s
    Apr 18 09:44:19.139: INFO: Pod "execpod-affinitydrsh4" satisfied condition "running"
    Apr 18 09:44:20.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-272 exec execpod-affinitydrsh4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Apr 18 09:44:20.239: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Apr 18 09:44:20.239: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:44:20.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-272 exec execpod-affinitydrsh4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.242.141 80'
    Apr 18 09:44:20.340: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.242.141 80\nConnection to 10.247.242.141 80 port [tcp/http] succeeded!\n"
    Apr 18 09:44:20.340: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:44:20.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-272 exec execpod-affinitydrsh4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.247.242.141:80/ ; done'
    Apr 18 09:44:20.481: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.242.141:80/\n"
    Apr 18 09:44:20.481: INFO: stdout: "\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4\naffinity-clusterip-88kf4"
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Received response from host: affinity-clusterip-88kf4
    Apr 18 09:44:20.481: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-272, will wait for the garbage collector to delete the pods 04/18/23 09:44:20.491
    Apr 18 09:44:20.550: INFO: Deleting ReplicationController affinity-clusterip took: 5.536095ms
    Apr 18 09:44:20.650: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.512805ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 09:44:22.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-272" for this suite. 04/18/23 09:44:22.666
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:44:22.671
Apr 18 09:44:22.671: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename taint-multiple-pods 04/18/23 09:44:22.671
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:44:22.681
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:44:22.684
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Apr 18 09:44:22.687: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 18 09:45:22.710: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Apr 18 09:45:22.713: INFO: Starting informer...
STEP: Starting pods... 04/18/23 09:45:22.713
Apr 18 09:45:22.929: INFO: Pod1 is running on 192.168.1.152. Tainting Node
Apr 18 09:45:23.139: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-7118" to be "running"
Apr 18 09:45:23.142: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.366116ms
Apr 18 09:45:25.145: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.005664373s
Apr 18 09:45:25.145: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Apr 18 09:45:25.145: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-7118" to be "running"
Apr 18 09:45:25.147: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 2.427557ms
Apr 18 09:45:25.147: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Apr 18 09:45:25.147: INFO: Pod2 is running on 192.168.1.152. Tainting Node
STEP: Trying to apply a taint on the Node 04/18/23 09:45:25.147
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 09:45:25.158
STEP: Waiting for Pod1 and Pod2 to be deleted 04/18/23 09:45:25.162
Apr 18 09:45:30.941: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Apr 18 09:45:50.977: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 09:45:50.988
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:45:50.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-7118" for this suite. 04/18/23 09:45:50.993
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":315,"skipped":5916,"failed":0}
------------------------------
• [SLOW TEST] [88.327 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:44:22.671
    Apr 18 09:44:22.671: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename taint-multiple-pods 04/18/23 09:44:22.671
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:44:22.681
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:44:22.684
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Apr 18 09:44:22.687: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 18 09:45:22.710: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Apr 18 09:45:22.713: INFO: Starting informer...
    STEP: Starting pods... 04/18/23 09:45:22.713
    Apr 18 09:45:22.929: INFO: Pod1 is running on 192.168.1.152. Tainting Node
    Apr 18 09:45:23.139: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-7118" to be "running"
    Apr 18 09:45:23.142: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.366116ms
    Apr 18 09:45:25.145: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.005664373s
    Apr 18 09:45:25.145: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Apr 18 09:45:25.145: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-7118" to be "running"
    Apr 18 09:45:25.147: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 2.427557ms
    Apr 18 09:45:25.147: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Apr 18 09:45:25.147: INFO: Pod2 is running on 192.168.1.152. Tainting Node
    STEP: Trying to apply a taint on the Node 04/18/23 09:45:25.147
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 09:45:25.158
    STEP: Waiting for Pod1 and Pod2 to be deleted 04/18/23 09:45:25.162
    Apr 18 09:45:30.941: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Apr 18 09:45:50.977: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 09:45:50.988
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:45:50.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-7118" for this suite. 04/18/23 09:45:50.993
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:45:50.998
Apr 18 09:45:50.998: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename prestop 04/18/23 09:45:50.999
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:45:51.008
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:45:51.011
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-3065 04/18/23 09:45:51.015
STEP: Waiting for pods to come up. 04/18/23 09:45:51.02
Apr 18 09:45:51.020: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-3065" to be "running"
Apr 18 09:45:51.023: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 3.14329ms
Apr 18 09:45:53.027: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.006688385s
Apr 18 09:45:53.027: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-3065 04/18/23 09:45:53.029
Apr 18 09:45:53.033: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-3065" to be "running"
Apr 18 09:45:53.036: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.823029ms
Apr 18 09:45:55.040: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.007006085s
Apr 18 09:45:55.040: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 04/18/23 09:45:55.04
Apr 18 09:46:00.061: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 04/18/23 09:46:00.061
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Apr 18 09:46:00.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3065" for this suite. 04/18/23 09:46:00.075
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":316,"skipped":5924,"failed":0}
------------------------------
• [SLOW TEST] [9.083 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:45:50.998
    Apr 18 09:45:50.998: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename prestop 04/18/23 09:45:50.999
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:45:51.008
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:45:51.011
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-3065 04/18/23 09:45:51.015
    STEP: Waiting for pods to come up. 04/18/23 09:45:51.02
    Apr 18 09:45:51.020: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-3065" to be "running"
    Apr 18 09:45:51.023: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 3.14329ms
    Apr 18 09:45:53.027: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.006688385s
    Apr 18 09:45:53.027: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-3065 04/18/23 09:45:53.029
    Apr 18 09:45:53.033: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-3065" to be "running"
    Apr 18 09:45:53.036: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.823029ms
    Apr 18 09:45:55.040: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.007006085s
    Apr 18 09:45:55.040: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 04/18/23 09:45:55.04
    Apr 18 09:46:00.061: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 04/18/23 09:46:00.061
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Apr 18 09:46:00.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-3065" for this suite. 04/18/23 09:46:00.075
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:46:00.082
Apr 18 09:46:00.082: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename dns 04/18/23 09:46:00.084
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:00.094
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:00.098
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 04/18/23 09:46:00.101
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6394.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-6394.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 04/18/23 09:46:00.105
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6394.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-6394.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 04/18/23 09:46:00.105
STEP: creating a pod to probe DNS 04/18/23 09:46:00.105
STEP: submitting the pod to kubernetes 04/18/23 09:46:00.105
Apr 18 09:46:00.113: INFO: Waiting up to 15m0s for pod "dns-test-08401ca2-e7f3-4028-aa98-3d1f6400bb3e" in namespace "dns-6394" to be "running"
Apr 18 09:46:00.115: INFO: Pod "dns-test-08401ca2-e7f3-4028-aa98-3d1f6400bb3e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.256878ms
Apr 18 09:46:02.120: INFO: Pod "dns-test-08401ca2-e7f3-4028-aa98-3d1f6400bb3e": Phase="Running", Reason="", readiness=true. Elapsed: 2.006482023s
Apr 18 09:46:02.120: INFO: Pod "dns-test-08401ca2-e7f3-4028-aa98-3d1f6400bb3e" satisfied condition "running"
STEP: retrieving the pod 04/18/23 09:46:02.12
STEP: looking for the results for each expected name from probers 04/18/23 09:46:02.122
Apr 18 09:46:02.139: INFO: DNS probes using dns-6394/dns-test-08401ca2-e7f3-4028-aa98-3d1f6400bb3e succeeded

STEP: deleting the pod 04/18/23 09:46:02.139
STEP: deleting the test headless service 04/18/23 09:46:02.153
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 09:46:02.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6394" for this suite. 04/18/23 09:46:02.174
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":317,"skipped":5937,"failed":0}
------------------------------
• [2.096 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:46:00.082
    Apr 18 09:46:00.082: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename dns 04/18/23 09:46:00.084
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:00.094
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:00.098
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 04/18/23 09:46:00.101
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6394.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-6394.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     04/18/23 09:46:00.105
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6394.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-6394.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     04/18/23 09:46:00.105
    STEP: creating a pod to probe DNS 04/18/23 09:46:00.105
    STEP: submitting the pod to kubernetes 04/18/23 09:46:00.105
    Apr 18 09:46:00.113: INFO: Waiting up to 15m0s for pod "dns-test-08401ca2-e7f3-4028-aa98-3d1f6400bb3e" in namespace "dns-6394" to be "running"
    Apr 18 09:46:00.115: INFO: Pod "dns-test-08401ca2-e7f3-4028-aa98-3d1f6400bb3e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.256878ms
    Apr 18 09:46:02.120: INFO: Pod "dns-test-08401ca2-e7f3-4028-aa98-3d1f6400bb3e": Phase="Running", Reason="", readiness=true. Elapsed: 2.006482023s
    Apr 18 09:46:02.120: INFO: Pod "dns-test-08401ca2-e7f3-4028-aa98-3d1f6400bb3e" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 09:46:02.12
    STEP: looking for the results for each expected name from probers 04/18/23 09:46:02.122
    Apr 18 09:46:02.139: INFO: DNS probes using dns-6394/dns-test-08401ca2-e7f3-4028-aa98-3d1f6400bb3e succeeded

    STEP: deleting the pod 04/18/23 09:46:02.139
    STEP: deleting the test headless service 04/18/23 09:46:02.153
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 09:46:02.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6394" for this suite. 04/18/23 09:46:02.174
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:46:02.181
Apr 18 09:46:02.181: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 09:46:02.182
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:02.19
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:02.194
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 09:46:02.207
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:46:02.489
STEP: Deploying the webhook pod 04/18/23 09:46:02.494
STEP: Wait for the deployment to be ready 04/18/23 09:46:02.505
Apr 18 09:46:02.511: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/18/23 09:46:04.519
STEP: Verifying the service has paired with the endpoint 04/18/23 09:46:04.527
Apr 18 09:46:05.527: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 04/18/23 09:46:05.53
STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 09:46:05.53
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 04/18/23 09:46:05.544
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 04/18/23 09:46:06.553
STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 09:46:06.553
STEP: Having no error when timeout is longer than webhook latency 04/18/23 09:46:07.574
STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 09:46:07.574
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 04/18/23 09:46:12.601
STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 09:46:12.601
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:46:17.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6390" for this suite. 04/18/23 09:46:17.629
STEP: Destroying namespace "webhook-6390-markers" for this suite. 04/18/23 09:46:17.634
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":318,"skipped":5949,"failed":0}
------------------------------
• [SLOW TEST] [15.493 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:46:02.181
    Apr 18 09:46:02.181: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 09:46:02.182
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:02.19
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:02.194
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 09:46:02.207
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:46:02.489
    STEP: Deploying the webhook pod 04/18/23 09:46:02.494
    STEP: Wait for the deployment to be ready 04/18/23 09:46:02.505
    Apr 18 09:46:02.511: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/18/23 09:46:04.519
    STEP: Verifying the service has paired with the endpoint 04/18/23 09:46:04.527
    Apr 18 09:46:05.527: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 04/18/23 09:46:05.53
    STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 09:46:05.53
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 04/18/23 09:46:05.544
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 04/18/23 09:46:06.553
    STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 09:46:06.553
    STEP: Having no error when timeout is longer than webhook latency 04/18/23 09:46:07.574
    STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 09:46:07.574
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 04/18/23 09:46:12.601
    STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 09:46:12.601
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:46:17.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6390" for this suite. 04/18/23 09:46:17.629
    STEP: Destroying namespace "webhook-6390-markers" for this suite. 04/18/23 09:46:17.634
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:46:17.674
Apr 18 09:46:17.674: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename job 04/18/23 09:46:17.675
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:17.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:17.693
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 04/18/23 09:46:17.697
STEP: Ensuring active pods == parallelism 04/18/23 09:46:17.701
STEP: Orphaning one of the Job's Pods 04/18/23 09:46:19.705
Apr 18 09:46:20.220: INFO: Successfully updated pod "adopt-release-6vfh4"
STEP: Checking that the Job readopts the Pod 04/18/23 09:46:20.22
Apr 18 09:46:20.220: INFO: Waiting up to 15m0s for pod "adopt-release-6vfh4" in namespace "job-8321" to be "adopted"
Apr 18 09:46:20.223: INFO: Pod "adopt-release-6vfh4": Phase="Running", Reason="", readiness=true. Elapsed: 2.376859ms
Apr 18 09:46:22.226: INFO: Pod "adopt-release-6vfh4": Phase="Running", Reason="", readiness=true. Elapsed: 2.005434268s
Apr 18 09:46:22.226: INFO: Pod "adopt-release-6vfh4" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 04/18/23 09:46:22.226
Apr 18 09:46:22.737: INFO: Successfully updated pod "adopt-release-6vfh4"
STEP: Checking that the Job releases the Pod 04/18/23 09:46:22.737
Apr 18 09:46:22.737: INFO: Waiting up to 15m0s for pod "adopt-release-6vfh4" in namespace "job-8321" to be "released"
Apr 18 09:46:22.740: INFO: Pod "adopt-release-6vfh4": Phase="Running", Reason="", readiness=true. Elapsed: 3.206467ms
Apr 18 09:46:24.744: INFO: Pod "adopt-release-6vfh4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006661982s
Apr 18 09:46:24.744: INFO: Pod "adopt-release-6vfh4" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 18 09:46:24.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8321" for this suite. 04/18/23 09:46:24.748
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":319,"skipped":5953,"failed":0}
------------------------------
• [SLOW TEST] [7.078 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:46:17.674
    Apr 18 09:46:17.674: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename job 04/18/23 09:46:17.675
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:17.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:17.693
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 04/18/23 09:46:17.697
    STEP: Ensuring active pods == parallelism 04/18/23 09:46:17.701
    STEP: Orphaning one of the Job's Pods 04/18/23 09:46:19.705
    Apr 18 09:46:20.220: INFO: Successfully updated pod "adopt-release-6vfh4"
    STEP: Checking that the Job readopts the Pod 04/18/23 09:46:20.22
    Apr 18 09:46:20.220: INFO: Waiting up to 15m0s for pod "adopt-release-6vfh4" in namespace "job-8321" to be "adopted"
    Apr 18 09:46:20.223: INFO: Pod "adopt-release-6vfh4": Phase="Running", Reason="", readiness=true. Elapsed: 2.376859ms
    Apr 18 09:46:22.226: INFO: Pod "adopt-release-6vfh4": Phase="Running", Reason="", readiness=true. Elapsed: 2.005434268s
    Apr 18 09:46:22.226: INFO: Pod "adopt-release-6vfh4" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 04/18/23 09:46:22.226
    Apr 18 09:46:22.737: INFO: Successfully updated pod "adopt-release-6vfh4"
    STEP: Checking that the Job releases the Pod 04/18/23 09:46:22.737
    Apr 18 09:46:22.737: INFO: Waiting up to 15m0s for pod "adopt-release-6vfh4" in namespace "job-8321" to be "released"
    Apr 18 09:46:22.740: INFO: Pod "adopt-release-6vfh4": Phase="Running", Reason="", readiness=true. Elapsed: 3.206467ms
    Apr 18 09:46:24.744: INFO: Pod "adopt-release-6vfh4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006661982s
    Apr 18 09:46:24.744: INFO: Pod "adopt-release-6vfh4" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 18 09:46:24.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-8321" for this suite. 04/18/23 09:46:24.748
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:46:24.753
Apr 18 09:46:24.753: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename deployment 04/18/23 09:46:24.753
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:24.762
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:24.765
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Apr 18 09:46:24.768: INFO: Creating deployment "webserver-deployment"
Apr 18 09:46:24.773: INFO: Waiting for observed generation 1
Apr 18 09:46:26.779: INFO: Waiting for all required pods to come up
Apr 18 09:46:26.783: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 04/18/23 09:46:26.783
Apr 18 09:46:26.783: INFO: Waiting for deployment "webserver-deployment" to complete
Apr 18 09:46:26.788: INFO: Updating deployment "webserver-deployment" with a non-existent image
Apr 18 09:46:26.797: INFO: Updating deployment webserver-deployment
Apr 18 09:46:26.797: INFO: Waiting for observed generation 2
Apr 18 09:46:28.802: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 18 09:46:28.804: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 18 09:46:28.807: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 18 09:46:28.813: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 18 09:46:28.814: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 18 09:46:28.816: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 18 09:46:28.820: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Apr 18 09:46:28.820: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Apr 18 09:46:28.828: INFO: Updating deployment webserver-deployment
Apr 18 09:46:28.828: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Apr 18 09:46:28.835: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 18 09:46:28.838: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 09:46:28.873: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-1664  ce8eceb5-c133-424a-8d3e-252a1b9736c1 4201569 3 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{kube-controller-manager Update apps/v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status} {e2e.test Update apps/v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0041e8aa8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-18 09:46:26 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-04-18 09:46:26 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Apr 18 09:46:28.892: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-1664  96014463-d619-44eb-bbd8-8f70be2844d6 4201572 3 2023-04-18 09:46:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment ce8eceb5-c133-424a-8d3e-252a1b9736c1 0xc0041e8ee7 0xc0041e8ee8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce8eceb5-c133-424a-8d3e-252a1b9736c1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0041e8f88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 18 09:46:28.892: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Apr 18 09:46:28.892: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-1664  ec40492b-7884-4428-bba1-2d07b12f8163 4201570 3 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment ce8eceb5-c133-424a-8d3e-252a1b9736c1 0xc0041e8fe7 0xc0041e8fe8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce8eceb5-c133-424a-8d3e-252a1b9736c1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0041e9078 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Apr 18 09:46:28.902: INFO: Pod "webserver-deployment-69b7448995-8xj5x" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-8xj5x webserver-deployment-69b7448995- deployment-1664  d0cf6a24-a0fd-4b39-9c9b-747a3dfe90fe 4201584 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0041e9547 0xc0041e9548}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-swfqg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-swfqg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.902: INFO: Pod "webserver-deployment-69b7448995-cj827" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-cj827 webserver-deployment-69b7448995- deployment-1664  fe47f197-fec9-4a49-afcb-ab49ef83e709 4201566 0 2023-04-18 09:46:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0041e96c7 0xc0041e96c8}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.248\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6qm45,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6qm45,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.84,PodIP:172.16.0.248,StartTime:2023-04-18 09:46:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve reference "docker.io/library/webserver:404": failed to authorize: failed to fetch anonymous token: unexpected status: 401 Unauthorized,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.248,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.902: INFO: Pod "webserver-deployment-69b7448995-drw8c" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-drw8c webserver-deployment-69b7448995- deployment-1664  effaec9b-025f-4909-986d-02096bc6e7a1 4201551 0 2023-04-18 09:46:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0041e98e7 0xc0041e98e8}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w85sn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w85sn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.29,PodIP:,StartTime:2023-04-18 09:46:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.902: INFO: Pod "webserver-deployment-69b7448995-md4ww" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-md4ww webserver-deployment-69b7448995- deployment-1664  086e460f-727a-4344-bb03-35079c2cf4e5 4201586 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0041e9ad7 0xc0041e9ad8}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9j94d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9j94d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.902: INFO: Pod "webserver-deployment-69b7448995-pmxf8" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-pmxf8 webserver-deployment-69b7448995- deployment-1664  6f68d6f4-e794-4077-9935-9b83fa292893 4201552 0 2023-04-18 09:46:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0041e9c37 0xc0041e9c38}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pv762,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pv762,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:,StartTime:2023-04-18 09:46:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.902: INFO: Pod "webserver-deployment-69b7448995-prqgc" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-prqgc webserver-deployment-69b7448995- deployment-1664  92652af9-bd52-4a05-9b94-d3086d882011 4201534 0 2023-04-18 09:46:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0041e9e27 0xc0041e9e28}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6xkl6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6xkl6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:,StartTime:2023-04-18 09:46:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.903: INFO: Pod "webserver-deployment-69b7448995-xkg2l" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-xkg2l webserver-deployment-69b7448995- deployment-1664  3ac3a877-5f07-420a-acd5-dcd604a66f36 4201585 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0051fc117 0xc0051fc118}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ckskp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ckskp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.903: INFO: Pod "webserver-deployment-69b7448995-zxjxh" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-zxjxh webserver-deployment-69b7448995- deployment-1664  c69b0bd9-9e96-47d7-8643-84b48db59c3b 4201568 0 2023-04-18 09:46:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0051fc727 0xc0051fc728}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.98\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h95wd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h95wd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:timeout,Value:*2,},PodDNSConfigOption{Name:single-request-reopen,Value:*,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.29,PodIP:172.16.0.98,StartTime:2023-04-18 09:46:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve reference "docker.io/library/webserver:404": failed to authorize: failed to fetch anonymous token: unexpected status: 401 Unauthorized,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.98,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.903: INFO: Pod "webserver-deployment-845c8977d9-2m6z8" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-2m6z8 webserver-deployment-845c8977d9- deployment-1664  f8a91102-34a7-46a9-9e3c-09d29642416a 4201494 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fce87 0xc0051fce88}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.96\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m6bqm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m6bqm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.29,PodIP:172.16.0.96,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://d4d58b8223989e144c321a7624310525a71ebf805afa77cad688156904f2d8e4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.96,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.903: INFO: Pod "webserver-deployment-845c8977d9-2svtv" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-2svtv webserver-deployment-845c8977d9- deployment-1664  3bbeed7a-60f5-4a2a-87a2-1663e26c131b 4201587 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fd077 0xc0051fd078}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gxr9x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gxr9x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:,StartTime:2023-04-18 09:46:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.903: INFO: Pod "webserver-deployment-845c8977d9-67rwb" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-67rwb webserver-deployment-845c8977d9- deployment-1664  b4aee51a-886c-4280-8a10-91d05d822c53 4201480 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fd247 0xc0051fd248}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.246\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hq24q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hq24q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.84,PodIP:172.16.0.246,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://554d231b0fdce5c04a3971a2d84a16a02aa3cc6f372f5b3d6ab0cc7a615ed77c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.246,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.903: INFO: Pod "webserver-deployment-845c8977d9-8hxb2" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-8hxb2 webserver-deployment-845c8977d9- deployment-1664  df5edba9-eb95-43b3-b204-8b5ccfd36711 4201491 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fd437 0xc0051fd438}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.95\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4fkg4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4fkg4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.29,PodIP:172.16.0.95,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://02da80e79dda8076e35f92f0c8420249ed907f32ffe0a9b67f20cd1e0cd168b4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.95,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.903: INFO: Pod "webserver-deployment-845c8977d9-bhmdd" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-bhmdd webserver-deployment-845c8977d9- deployment-1664  da4c8560-972a-4386-bb27-04a6ccf4f7cc 4201482 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fd627 0xc0051fd628}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.247\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mwtlg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mwtlg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.84,PodIP:172.16.0.247,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://a6f3f90572ac28c63edd306f857308e25d2b6fea0970e6307d86bdf49d7d36c9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.247,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.904: INFO: Pod "webserver-deployment-845c8977d9-bqnbp" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-bqnbp webserver-deployment-845c8977d9- deployment-1664  eea9e7b8-ab91-4f95-ac18-2c797b8dd9f6 4201500 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fd817 0xc0051fd818}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.92\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qdxgl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qdxgl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.92,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://023861bd002b12c5b5c0ff8a1441d5df9ce56acd20731676e409b6fafdaaf22e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.92,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.904: INFO: Pod "webserver-deployment-845c8977d9-cs9rl" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-cs9rl webserver-deployment-845c8977d9- deployment-1664  4353c0ef-5061-4c6c-a52e-771df4eec308 4201580 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fda07 0xc0051fda08}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cm5px,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cm5px,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.904: INFO: Pod "webserver-deployment-845c8977d9-kjprs" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-kjprs webserver-deployment-845c8977d9- deployment-1664  69054938-94b3-416e-96cf-b2cdf19e36fb 4201578 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fdb57 0xc0051fdb58}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xj46r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xj46r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.904: INFO: Pod "webserver-deployment-845c8977d9-kpdhg" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-kpdhg webserver-deployment-845c8977d9- deployment-1664  d6bd762d-94a9-4705-b3a6-02bd597a74e5 4201510 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fdcc7 0xc0051fdcc8}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.93\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s2r6p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s2r6p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:timeout,Value:*2,},PodDNSConfigOption{Name:single-request-reopen,Value:*,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.93,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e6f0c0c51f637324ffa915b124dff84a7e78f2fc701e051bbb0598f47bf4e537,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.93,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.904: INFO: Pod "webserver-deployment-845c8977d9-ln7dd" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ln7dd webserver-deployment-845c8977d9- deployment-1664  059548c6-fd9f-4059-a4f1-d51789c8cc9c 4201581 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fdeb7 0xc0051fdeb8}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2547z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2547z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.904: INFO: Pod "webserver-deployment-845c8977d9-n2hk8" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-n2hk8 webserver-deployment-845c8977d9- deployment-1664  958265c2-7abe-451d-afa7-73b67b36a4c4 4201486 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0017ff297 0xc0017ff298}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.245\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jggcm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jggcm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.84,PodIP:172.16.0.245,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://5585676c75d3ea9d1148ee021d19749fa4d13fb4ca5c666409f0dee3ca02dde4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.245,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.904: INFO: Pod "webserver-deployment-845c8977d9-qlb89" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-qlb89 webserver-deployment-845c8977d9- deployment-1664  79bdc328-7271-42a0-8f39-4ee36ae22ada 4201489 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0017ff487 0xc0017ff488}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.97\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2kdvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2kdvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:timeout,Value:*2,},PodDNSConfigOption{Name:single-request-reopen,Value:*,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.29,PodIP:172.16.0.97,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://5a1a0500066628a064f04cfc7c9350d9bba25999fa906159d1be563bfbbd9591,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.97,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.905: INFO: Pod "webserver-deployment-845c8977d9-r7j6c" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-r7j6c webserver-deployment-845c8977d9- deployment-1664  ad3768f3-f289-43bb-a1ac-90f0f2cd4740 4201583 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0017ff6a7 0xc0017ff6a8}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-52tlx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-52tlx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.905: INFO: Pod "webserver-deployment-845c8977d9-vzlhp" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-vzlhp webserver-deployment-845c8977d9- deployment-1664  0c85728f-bd61-422a-95e7-d08306375be0 4201579 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0017ff7f7 0xc0017ff7f8}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dbjnj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dbjnj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 09:46:28.905: INFO: Pod "webserver-deployment-845c8977d9-z8p7r" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-z8p7r webserver-deployment-845c8977d9- deployment-1664  3e7565ef-5eb3-4ad4-bd26-322cd032ead3 4201582 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0017ff967 0xc0017ff968}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dfbpt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dfbpt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:timeout,Value:*2,},PodDNSConfigOption{Name:single-request-reopen,Value:*,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 09:46:28.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1664" for this suite. 04/18/23 09:46:28.924
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":320,"skipped":5959,"failed":0}
------------------------------
• [4.192 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:46:24.753
    Apr 18 09:46:24.753: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename deployment 04/18/23 09:46:24.753
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:24.762
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:24.765
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Apr 18 09:46:24.768: INFO: Creating deployment "webserver-deployment"
    Apr 18 09:46:24.773: INFO: Waiting for observed generation 1
    Apr 18 09:46:26.779: INFO: Waiting for all required pods to come up
    Apr 18 09:46:26.783: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 04/18/23 09:46:26.783
    Apr 18 09:46:26.783: INFO: Waiting for deployment "webserver-deployment" to complete
    Apr 18 09:46:26.788: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Apr 18 09:46:26.797: INFO: Updating deployment webserver-deployment
    Apr 18 09:46:26.797: INFO: Waiting for observed generation 2
    Apr 18 09:46:28.802: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Apr 18 09:46:28.804: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Apr 18 09:46:28.807: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Apr 18 09:46:28.813: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Apr 18 09:46:28.814: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Apr 18 09:46:28.816: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Apr 18 09:46:28.820: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Apr 18 09:46:28.820: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Apr 18 09:46:28.828: INFO: Updating deployment webserver-deployment
    Apr 18 09:46:28.828: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Apr 18 09:46:28.835: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Apr 18 09:46:28.838: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 09:46:28.873: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-1664  ce8eceb5-c133-424a-8d3e-252a1b9736c1 4201569 3 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{kube-controller-manager Update apps/v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status} {e2e.test Update apps/v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0041e8aa8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-18 09:46:26 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-04-18 09:46:26 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Apr 18 09:46:28.892: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-1664  96014463-d619-44eb-bbd8-8f70be2844d6 4201572 3 2023-04-18 09:46:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment ce8eceb5-c133-424a-8d3e-252a1b9736c1 0xc0041e8ee7 0xc0041e8ee8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce8eceb5-c133-424a-8d3e-252a1b9736c1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0041e8f88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 09:46:28.892: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Apr 18 09:46:28.892: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-1664  ec40492b-7884-4428-bba1-2d07b12f8163 4201570 3 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment ce8eceb5-c133-424a-8d3e-252a1b9736c1 0xc0041e8fe7 0xc0041e8fe8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce8eceb5-c133-424a-8d3e-252a1b9736c1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0041e9078 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 09:46:28.902: INFO: Pod "webserver-deployment-69b7448995-8xj5x" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-8xj5x webserver-deployment-69b7448995- deployment-1664  d0cf6a24-a0fd-4b39-9c9b-747a3dfe90fe 4201584 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0041e9547 0xc0041e9548}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-swfqg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-swfqg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.902: INFO: Pod "webserver-deployment-69b7448995-cj827" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-cj827 webserver-deployment-69b7448995- deployment-1664  fe47f197-fec9-4a49-afcb-ab49ef83e709 4201566 0 2023-04-18 09:46:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0041e96c7 0xc0041e96c8}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.248\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6qm45,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6qm45,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.84,PodIP:172.16.0.248,StartTime:2023-04-18 09:46:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve reference "docker.io/library/webserver:404": failed to authorize: failed to fetch anonymous token: unexpected status: 401 Unauthorized,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.248,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.902: INFO: Pod "webserver-deployment-69b7448995-drw8c" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-drw8c webserver-deployment-69b7448995- deployment-1664  effaec9b-025f-4909-986d-02096bc6e7a1 4201551 0 2023-04-18 09:46:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0041e98e7 0xc0041e98e8}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w85sn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w85sn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.29,PodIP:,StartTime:2023-04-18 09:46:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.902: INFO: Pod "webserver-deployment-69b7448995-md4ww" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-md4ww webserver-deployment-69b7448995- deployment-1664  086e460f-727a-4344-bb03-35079c2cf4e5 4201586 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0041e9ad7 0xc0041e9ad8}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9j94d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9j94d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.902: INFO: Pod "webserver-deployment-69b7448995-pmxf8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-pmxf8 webserver-deployment-69b7448995- deployment-1664  6f68d6f4-e794-4077-9935-9b83fa292893 4201552 0 2023-04-18 09:46:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0041e9c37 0xc0041e9c38}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pv762,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pv762,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:,StartTime:2023-04-18 09:46:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.902: INFO: Pod "webserver-deployment-69b7448995-prqgc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-prqgc webserver-deployment-69b7448995- deployment-1664  92652af9-bd52-4a05-9b94-d3086d882011 4201534 0 2023-04-18 09:46:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0041e9e27 0xc0041e9e28}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6xkl6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6xkl6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:,StartTime:2023-04-18 09:46:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.903: INFO: Pod "webserver-deployment-69b7448995-xkg2l" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-xkg2l webserver-deployment-69b7448995- deployment-1664  3ac3a877-5f07-420a-acd5-dcd604a66f36 4201585 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0051fc117 0xc0051fc118}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ckskp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ckskp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.903: INFO: Pod "webserver-deployment-69b7448995-zxjxh" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-zxjxh webserver-deployment-69b7448995- deployment-1664  c69b0bd9-9e96-47d7-8643-84b48db59c3b 4201568 0 2023-04-18 09:46:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 96014463-d619-44eb-bbd8-8f70be2844d6 0xc0051fc727 0xc0051fc728}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"96014463-d619-44eb-bbd8-8f70be2844d6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.98\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h95wd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h95wd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:timeout,Value:*2,},PodDNSConfigOption{Name:single-request-reopen,Value:*,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.29,PodIP:172.16.0.98,StartTime:2023-04-18 09:46:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve reference "docker.io/library/webserver:404": failed to authorize: failed to fetch anonymous token: unexpected status: 401 Unauthorized,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.98,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.903: INFO: Pod "webserver-deployment-845c8977d9-2m6z8" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-2m6z8 webserver-deployment-845c8977d9- deployment-1664  f8a91102-34a7-46a9-9e3c-09d29642416a 4201494 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fce87 0xc0051fce88}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.96\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m6bqm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m6bqm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.29,PodIP:172.16.0.96,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://d4d58b8223989e144c321a7624310525a71ebf805afa77cad688156904f2d8e4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.96,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.903: INFO: Pod "webserver-deployment-845c8977d9-2svtv" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-2svtv webserver-deployment-845c8977d9- deployment-1664  3bbeed7a-60f5-4a2a-87a2-1663e26c131b 4201587 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fd077 0xc0051fd078}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gxr9x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gxr9x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:,StartTime:2023-04-18 09:46:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.903: INFO: Pod "webserver-deployment-845c8977d9-67rwb" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-67rwb webserver-deployment-845c8977d9- deployment-1664  b4aee51a-886c-4280-8a10-91d05d822c53 4201480 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fd247 0xc0051fd248}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.246\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hq24q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hq24q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.84,PodIP:172.16.0.246,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://554d231b0fdce5c04a3971a2d84a16a02aa3cc6f372f5b3d6ab0cc7a615ed77c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.246,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.903: INFO: Pod "webserver-deployment-845c8977d9-8hxb2" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-8hxb2 webserver-deployment-845c8977d9- deployment-1664  df5edba9-eb95-43b3-b204-8b5ccfd36711 4201491 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fd437 0xc0051fd438}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.95\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4fkg4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4fkg4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.29,PodIP:172.16.0.95,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://02da80e79dda8076e35f92f0c8420249ed907f32ffe0a9b67f20cd1e0cd168b4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.95,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.903: INFO: Pod "webserver-deployment-845c8977d9-bhmdd" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-bhmdd webserver-deployment-845c8977d9- deployment-1664  da4c8560-972a-4386-bb27-04a6ccf4f7cc 4201482 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fd627 0xc0051fd628}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.247\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mwtlg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mwtlg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.84,PodIP:172.16.0.247,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://a6f3f90572ac28c63edd306f857308e25d2b6fea0970e6307d86bdf49d7d36c9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.247,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.904: INFO: Pod "webserver-deployment-845c8977d9-bqnbp" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-bqnbp webserver-deployment-845c8977d9- deployment-1664  eea9e7b8-ab91-4f95-ac18-2c797b8dd9f6 4201500 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fd817 0xc0051fd818}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.92\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qdxgl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qdxgl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.92,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://023861bd002b12c5b5c0ff8a1441d5df9ce56acd20731676e409b6fafdaaf22e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.92,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.904: INFO: Pod "webserver-deployment-845c8977d9-cs9rl" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-cs9rl webserver-deployment-845c8977d9- deployment-1664  4353c0ef-5061-4c6c-a52e-771df4eec308 4201580 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fda07 0xc0051fda08}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cm5px,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cm5px,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.904: INFO: Pod "webserver-deployment-845c8977d9-kjprs" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-kjprs webserver-deployment-845c8977d9- deployment-1664  69054938-94b3-416e-96cf-b2cdf19e36fb 4201578 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fdb57 0xc0051fdb58}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xj46r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xj46r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.904: INFO: Pod "webserver-deployment-845c8977d9-kpdhg" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-kpdhg webserver-deployment-845c8977d9- deployment-1664  d6bd762d-94a9-4705-b3a6-02bd597a74e5 4201510 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fdcc7 0xc0051fdcc8}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.93\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s2r6p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s2r6p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:timeout,Value:*2,},PodDNSConfigOption{Name:single-request-reopen,Value:*,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.93,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e6f0c0c51f637324ffa915b124dff84a7e78f2fc701e051bbb0598f47bf4e537,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.93,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.904: INFO: Pod "webserver-deployment-845c8977d9-ln7dd" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ln7dd webserver-deployment-845c8977d9- deployment-1664  059548c6-fd9f-4059-a4f1-d51789c8cc9c 4201581 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0051fdeb7 0xc0051fdeb8}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2547z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2547z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.904: INFO: Pod "webserver-deployment-845c8977d9-n2hk8" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-n2hk8 webserver-deployment-845c8977d9- deployment-1664  958265c2-7abe-451d-afa7-73b67b36a4c4 4201486 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0017ff297 0xc0017ff298}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.245\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jggcm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jggcm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.84,PodIP:172.16.0.245,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://5585676c75d3ea9d1148ee021d19749fa4d13fb4ca5c666409f0dee3ca02dde4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.245,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.904: INFO: Pod "webserver-deployment-845c8977d9-qlb89" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-qlb89 webserver-deployment-845c8977d9- deployment-1664  79bdc328-7271-42a0-8f39-4ee36ae22ada 4201489 0 2023-04-18 09:46:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0017ff487 0xc0017ff488}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:46:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.97\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2kdvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2kdvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.29,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:timeout,Value:*2,},PodDNSConfigOption{Name:single-request-reopen,Value:*,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.29,PodIP:172.16.0.97,StartTime:2023-04-18 09:46:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:46:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://5a1a0500066628a064f04cfc7c9350d9bba25999fa906159d1be563bfbbd9591,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.97,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.905: INFO: Pod "webserver-deployment-845c8977d9-r7j6c" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-r7j6c webserver-deployment-845c8977d9- deployment-1664  ad3768f3-f289-43bb-a1ac-90f0f2cd4740 4201583 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0017ff6a7 0xc0017ff6a8}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-52tlx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-52tlx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.905: INFO: Pod "webserver-deployment-845c8977d9-vzlhp" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-vzlhp webserver-deployment-845c8977d9- deployment-1664  0c85728f-bd61-422a-95e7-d08306375be0 4201579 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0017ff7f7 0xc0017ff7f8}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dbjnj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dbjnj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.84,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:46:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 09:46:28.905: INFO: Pod "webserver-deployment-845c8977d9-z8p7r" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-z8p7r webserver-deployment-845c8977d9- deployment-1664  3e7565ef-5eb3-4ad4-bd26-322cd032ead3 4201582 0 2023-04-18 09:46:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ec40492b-7884-4428-bba1-2d07b12f8163 0xc0017ff967 0xc0017ff968}] [] [{kube-controller-manager Update v1 2023-04-18 09:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ec40492b-7884-4428-bba1-2d07b12f8163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dfbpt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dfbpt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:timeout,Value:*2,},PodDNSConfigOption{Name:single-request-reopen,Value:*,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 09:46:28.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-1664" for this suite. 04/18/23 09:46:28.924
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:46:28.946
Apr 18 09:46:28.946: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename events 04/18/23 09:46:28.947
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:28.996
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:28.999
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 04/18/23 09:46:29.002
STEP: listing events in all namespaces 04/18/23 09:46:29.012
STEP: listing events in test namespace 04/18/23 09:46:29.017
STEP: listing events with field selection filtering on source 04/18/23 09:46:29.022
STEP: listing events with field selection filtering on reportingController 04/18/23 09:46:29.025
STEP: getting the test event 04/18/23 09:46:29.027
STEP: patching the test event 04/18/23 09:46:29.032
STEP: getting the test event 04/18/23 09:46:29.048
STEP: updating the test event 04/18/23 09:46:29.051
STEP: getting the test event 04/18/23 09:46:29.056
STEP: deleting the test event 04/18/23 09:46:29.059
STEP: listing events in all namespaces 04/18/23 09:46:29.063
STEP: listing events in test namespace 04/18/23 09:46:29.068
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Apr 18 09:46:29.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8837" for this suite. 04/18/23 09:46:29.073
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":321,"skipped":5973,"failed":0}
------------------------------
• [0.132 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:46:28.946
    Apr 18 09:46:28.946: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename events 04/18/23 09:46:28.947
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:28.996
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:28.999
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 04/18/23 09:46:29.002
    STEP: listing events in all namespaces 04/18/23 09:46:29.012
    STEP: listing events in test namespace 04/18/23 09:46:29.017
    STEP: listing events with field selection filtering on source 04/18/23 09:46:29.022
    STEP: listing events with field selection filtering on reportingController 04/18/23 09:46:29.025
    STEP: getting the test event 04/18/23 09:46:29.027
    STEP: patching the test event 04/18/23 09:46:29.032
    STEP: getting the test event 04/18/23 09:46:29.048
    STEP: updating the test event 04/18/23 09:46:29.051
    STEP: getting the test event 04/18/23 09:46:29.056
    STEP: deleting the test event 04/18/23 09:46:29.059
    STEP: listing events in all namespaces 04/18/23 09:46:29.063
    STEP: listing events in test namespace 04/18/23 09:46:29.068
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Apr 18 09:46:29.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-8837" for this suite. 04/18/23 09:46:29.073
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:46:29.079
Apr 18 09:46:29.079: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename security-context-test 04/18/23 09:46:29.08
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:29.087
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:29.091
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Apr 18 09:46:29.100: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-c7f8090c-8643-4ba8-8270-2f0e7e4439fd" in namespace "security-context-test-7436" to be "Succeeded or Failed"
Apr 18 09:46:29.105: INFO: Pod "busybox-readonly-false-c7f8090c-8643-4ba8-8270-2f0e7e4439fd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.912634ms
Apr 18 09:46:31.109: INFO: Pod "busybox-readonly-false-c7f8090c-8643-4ba8-8270-2f0e7e4439fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00853773s
Apr 18 09:46:33.108: INFO: Pod "busybox-readonly-false-c7f8090c-8643-4ba8-8270-2f0e7e4439fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007959197s
Apr 18 09:46:33.108: INFO: Pod "busybox-readonly-false-c7f8090c-8643-4ba8-8270-2f0e7e4439fd" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 18 09:46:33.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7436" for this suite. 04/18/23 09:46:33.112
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":322,"skipped":5989,"failed":0}
------------------------------
• [4.037 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:46:29.079
    Apr 18 09:46:29.079: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename security-context-test 04/18/23 09:46:29.08
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:29.087
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:29.091
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Apr 18 09:46:29.100: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-c7f8090c-8643-4ba8-8270-2f0e7e4439fd" in namespace "security-context-test-7436" to be "Succeeded or Failed"
    Apr 18 09:46:29.105: INFO: Pod "busybox-readonly-false-c7f8090c-8643-4ba8-8270-2f0e7e4439fd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.912634ms
    Apr 18 09:46:31.109: INFO: Pod "busybox-readonly-false-c7f8090c-8643-4ba8-8270-2f0e7e4439fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00853773s
    Apr 18 09:46:33.108: INFO: Pod "busybox-readonly-false-c7f8090c-8643-4ba8-8270-2f0e7e4439fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007959197s
    Apr 18 09:46:33.108: INFO: Pod "busybox-readonly-false-c7f8090c-8643-4ba8-8270-2f0e7e4439fd" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 18 09:46:33.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-7436" for this suite. 04/18/23 09:46:33.112
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:46:33.117
Apr 18 09:46:33.117: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename init-container 04/18/23 09:46:33.117
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:33.128
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:33.131
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 04/18/23 09:46:33.134
Apr 18 09:46:33.135: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 18 09:46:37.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-485" for this suite. 04/18/23 09:46:37.085
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":323,"skipped":5989,"failed":0}
------------------------------
• [3.973 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:46:33.117
    Apr 18 09:46:33.117: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename init-container 04/18/23 09:46:33.117
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:33.128
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:33.131
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 04/18/23 09:46:33.134
    Apr 18 09:46:33.135: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 18 09:46:37.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-485" for this suite. 04/18/23 09:46:37.085
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:46:37.09
Apr 18 09:46:37.090: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename events 04/18/23 09:46:37.091
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:37.102
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:37.105
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 04/18/23 09:46:37.109
STEP: get a list of Events with a label in the current namespace 04/18/23 09:46:37.12
STEP: delete a list of events 04/18/23 09:46:37.123
Apr 18 09:46:37.123: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 04/18/23 09:46:37.133
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Apr 18 09:46:37.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3095" for this suite. 04/18/23 09:46:37.139
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":324,"skipped":5990,"failed":0}
------------------------------
• [0.053 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:46:37.09
    Apr 18 09:46:37.090: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename events 04/18/23 09:46:37.091
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:37.102
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:37.105
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 04/18/23 09:46:37.109
    STEP: get a list of Events with a label in the current namespace 04/18/23 09:46:37.12
    STEP: delete a list of events 04/18/23 09:46:37.123
    Apr 18 09:46:37.123: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 04/18/23 09:46:37.133
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Apr 18 09:46:37.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-3095" for this suite. 04/18/23 09:46:37.139
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:46:37.151
Apr 18 09:46:37.152: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename runtimeclass 04/18/23 09:46:37.152
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:37.162
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:37.165
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Apr 18 09:46:37.177: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-9136 to be scheduled
Apr 18 09:46:37.180: INFO: 1 pods are not scheduled: [runtimeclass-9136/test-runtimeclass-runtimeclass-9136-preconfigured-handler-knqtq(6b3d9e32-8776-4d35-9876-9204d383cf68)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 18 09:46:39.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-9136" for this suite. 04/18/23 09:46:39.191
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":325,"skipped":6048,"failed":0}
------------------------------
• [2.043 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:46:37.151
    Apr 18 09:46:37.152: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename runtimeclass 04/18/23 09:46:37.152
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:37.162
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:37.165
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Apr 18 09:46:37.177: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-9136 to be scheduled
    Apr 18 09:46:37.180: INFO: 1 pods are not scheduled: [runtimeclass-9136/test-runtimeclass-runtimeclass-9136-preconfigured-handler-knqtq(6b3d9e32-8776-4d35-9876-9204d383cf68)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 18 09:46:39.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-9136" for this suite. 04/18/23 09:46:39.191
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:46:39.195
Apr 18 09:46:39.195: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 09:46:39.196
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:39.204
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:39.207
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 09:46:39.21
Apr 18 09:46:39.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5048 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr 18 09:46:39.267: INFO: stderr: ""
Apr 18 09:46:39.267: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 04/18/23 09:46:39.267
Apr 18 09:46:39.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5048 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Apr 18 09:46:39.419: INFO: stderr: ""
Apr 18 09:46:39.419: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 09:46:39.419
Apr 18 09:46:39.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5048 delete pods e2e-test-httpd-pod'
Apr 18 09:46:41.834: INFO: stderr: ""
Apr 18 09:46:41.834: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 09:46:41.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5048" for this suite. 04/18/23 09:46:41.838
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":326,"skipped":6060,"failed":0}
------------------------------
• [2.646 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:46:39.195
    Apr 18 09:46:39.195: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 09:46:39.196
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:39.204
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:39.207
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 09:46:39.21
    Apr 18 09:46:39.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5048 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Apr 18 09:46:39.267: INFO: stderr: ""
    Apr 18 09:46:39.267: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 04/18/23 09:46:39.267
    Apr 18 09:46:39.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5048 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Apr 18 09:46:39.419: INFO: stderr: ""
    Apr 18 09:46:39.419: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 09:46:39.419
    Apr 18 09:46:39.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-5048 delete pods e2e-test-httpd-pod'
    Apr 18 09:46:41.834: INFO: stderr: ""
    Apr 18 09:46:41.834: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 09:46:41.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5048" for this suite. 04/18/23 09:46:41.838
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:46:41.842
Apr 18 09:46:41.842: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename watch 04/18/23 09:46:41.843
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:41.853
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:41.856
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 04/18/23 09:46:41.859
STEP: creating a new configmap 04/18/23 09:46:41.861
STEP: modifying the configmap once 04/18/23 09:46:41.864
STEP: closing the watch once it receives two notifications 04/18/23 09:46:41.869
Apr 18 09:46:41.869: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1835  11231f53-5e22-4526-9db4-778f3eff1a50 4201896 0 2023-04-18 09:46:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 09:46:41 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 09:46:41.870: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1835  11231f53-5e22-4526-9db4-778f3eff1a50 4201897 0 2023-04-18 09:46:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 09:46:41 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 04/18/23 09:46:41.87
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 04/18/23 09:46:41.876
STEP: deleting the configmap 04/18/23 09:46:41.878
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 04/18/23 09:46:41.882
Apr 18 09:46:41.882: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1835  11231f53-5e22-4526-9db4-778f3eff1a50 4201898 0 2023-04-18 09:46:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 09:46:41 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 09:46:41.883: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1835  11231f53-5e22-4526-9db4-778f3eff1a50 4201899 0 2023-04-18 09:46:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 09:46:41 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 18 09:46:41.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1835" for this suite. 04/18/23 09:46:41.886
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":327,"skipped":6083,"failed":0}
------------------------------
• [0.049 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:46:41.842
    Apr 18 09:46:41.842: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename watch 04/18/23 09:46:41.843
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:41.853
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:41.856
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 04/18/23 09:46:41.859
    STEP: creating a new configmap 04/18/23 09:46:41.861
    STEP: modifying the configmap once 04/18/23 09:46:41.864
    STEP: closing the watch once it receives two notifications 04/18/23 09:46:41.869
    Apr 18 09:46:41.869: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1835  11231f53-5e22-4526-9db4-778f3eff1a50 4201896 0 2023-04-18 09:46:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 09:46:41 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 09:46:41.870: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1835  11231f53-5e22-4526-9db4-778f3eff1a50 4201897 0 2023-04-18 09:46:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 09:46:41 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 04/18/23 09:46:41.87
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 04/18/23 09:46:41.876
    STEP: deleting the configmap 04/18/23 09:46:41.878
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 04/18/23 09:46:41.882
    Apr 18 09:46:41.882: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1835  11231f53-5e22-4526-9db4-778f3eff1a50 4201898 0 2023-04-18 09:46:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 09:46:41 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 09:46:41.883: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1835  11231f53-5e22-4526-9db4-778f3eff1a50 4201899 0 2023-04-18 09:46:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 09:46:41 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 18 09:46:41.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-1835" for this suite. 04/18/23 09:46:41.886
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:46:41.894
Apr 18 09:46:41.894: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 09:46:41.895
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:41.906
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:41.909
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 04/18/23 09:46:41.912
Apr 18 09:46:41.917: INFO: Waiting up to 5m0s for pod "downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081" in namespace "downward-api-4958" to be "Succeeded or Failed"
Apr 18 09:46:41.920: INFO: Pod "downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081": Phase="Pending", Reason="", readiness=false. Elapsed: 2.943363ms
Apr 18 09:46:43.924: INFO: Pod "downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006743537s
Apr 18 09:46:45.926: INFO: Pod "downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008120317s
STEP: Saw pod success 04/18/23 09:46:45.926
Apr 18 09:46:45.926: INFO: Pod "downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081" satisfied condition "Succeeded or Failed"
Apr 18 09:46:45.928: INFO: Trying to get logs from node 192.168.1.29 pod downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081 container client-container: <nil>
STEP: delete the pod 04/18/23 09:46:45.941
Apr 18 09:46:45.955: INFO: Waiting for pod downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081 to disappear
Apr 18 09:46:45.957: INFO: Pod downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 09:46:45.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4958" for this suite. 04/18/23 09:46:45.961
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":328,"skipped":6083,"failed":0}
------------------------------
• [4.073 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:46:41.894
    Apr 18 09:46:41.894: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 09:46:41.895
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:41.906
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:41.909
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 04/18/23 09:46:41.912
    Apr 18 09:46:41.917: INFO: Waiting up to 5m0s for pod "downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081" in namespace "downward-api-4958" to be "Succeeded or Failed"
    Apr 18 09:46:41.920: INFO: Pod "downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081": Phase="Pending", Reason="", readiness=false. Elapsed: 2.943363ms
    Apr 18 09:46:43.924: INFO: Pod "downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006743537s
    Apr 18 09:46:45.926: INFO: Pod "downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008120317s
    STEP: Saw pod success 04/18/23 09:46:45.926
    Apr 18 09:46:45.926: INFO: Pod "downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081" satisfied condition "Succeeded or Failed"
    Apr 18 09:46:45.928: INFO: Trying to get logs from node 192.168.1.29 pod downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081 container client-container: <nil>
    STEP: delete the pod 04/18/23 09:46:45.941
    Apr 18 09:46:45.955: INFO: Waiting for pod downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081 to disappear
    Apr 18 09:46:45.957: INFO: Pod downwardapi-volume-00879351-e0cc-4444-9e73-a039cd15b081 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 09:46:45.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4958" for this suite. 04/18/23 09:46:45.961
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:46:45.966
Apr 18 09:46:45.967: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename statefulset 04/18/23 09:46:45.967
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:45.975
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:45.979
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-439 04/18/23 09:46:45.982
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 04/18/23 09:46:45.986
STEP: Creating stateful set ss in namespace statefulset-439 04/18/23 09:46:45.99
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-439 04/18/23 09:46:45.994
Apr 18 09:46:45.996: INFO: Found 0 stateful pods, waiting for 1
Apr 18 09:46:56.000: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 04/18/23 09:46:56
Apr 18 09:46:56.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 09:46:56.111: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 09:46:56.111: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 09:46:56.111: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 09:46:56.114: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 18 09:47:06.119: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 09:47:06.119: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 09:47:06.132: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999837s
Apr 18 09:47:07.135: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997526139s
Apr 18 09:47:08.138: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994373981s
Apr 18 09:47:09.141: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.991201789s
Apr 18 09:47:10.145: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.988053442s
Apr 18 09:47:11.148: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.984801274s
Apr 18 09:47:12.152: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.981143261s
Apr 18 09:47:13.156: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.977062541s
Apr 18 09:47:14.160: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.972966961s
Apr 18 09:47:15.163: INFO: Verifying statefulset ss doesn't scale past 1 for another 969.774877ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-439 04/18/23 09:47:16.163
Apr 18 09:47:16.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 09:47:16.284: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 18 09:47:16.284: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 09:47:16.284: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 18 09:47:16.286: INFO: Found 1 stateful pods, waiting for 3
Apr 18 09:47:26.290: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 09:47:26.290: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 09:47:26.290: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 04/18/23 09:47:26.29
STEP: Scale down will halt with unhealthy stateful pod 04/18/23 09:47:26.29
Apr 18 09:47:26.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 09:47:26.401: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 09:47:26.401: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 09:47:26.401: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 09:47:26.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 09:47:26.512: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 09:47:26.512: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 09:47:26.512: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 09:47:26.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 09:47:26.610: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 09:47:26.610: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 09:47:26.610: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 09:47:26.610: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 09:47:26.612: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Apr 18 09:47:36.619: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 09:47:36.619: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 09:47:36.619: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 09:47:36.629: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999809s
Apr 18 09:47:37.632: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997291313s
Apr 18 09:47:38.636: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992961068s
Apr 18 09:47:39.639: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989621547s
Apr 18 09:47:40.643: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986365756s
Apr 18 09:47:41.648: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.982679892s
Apr 18 09:47:42.653: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.976620487s
Apr 18 09:47:43.656: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.973000535s
Apr 18 09:47:44.660: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.969600844s
Apr 18 09:47:45.663: INFO: Verifying statefulset ss doesn't scale past 3 for another 966.33788ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-439 04/18/23 09:47:46.663
Apr 18 09:47:46.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 09:47:46.775: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 18 09:47:46.775: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 09:47:46.775: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 18 09:47:46.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 09:47:46.881: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 18 09:47:46.881: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 09:47:46.881: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 18 09:47:46.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 09:47:46.982: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 18 09:47:46.982: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 09:47:46.982: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 18 09:47:46.982: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 04/18/23 09:47:56.999
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 09:47:56.999: INFO: Deleting all statefulset in ns statefulset-439
Apr 18 09:47:57.001: INFO: Scaling statefulset ss to 0
Apr 18 09:47:57.010: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 09:47:57.012: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 09:47:57.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-439" for this suite. 04/18/23 09:47:57.028
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":329,"skipped":6101,"failed":0}
------------------------------
• [SLOW TEST] [71.067 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:46:45.966
    Apr 18 09:46:45.967: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename statefulset 04/18/23 09:46:45.967
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:46:45.975
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:46:45.979
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-439 04/18/23 09:46:45.982
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 04/18/23 09:46:45.986
    STEP: Creating stateful set ss in namespace statefulset-439 04/18/23 09:46:45.99
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-439 04/18/23 09:46:45.994
    Apr 18 09:46:45.996: INFO: Found 0 stateful pods, waiting for 1
    Apr 18 09:46:56.000: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 04/18/23 09:46:56
    Apr 18 09:46:56.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 09:46:56.111: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 09:46:56.111: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 09:46:56.111: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 09:46:56.114: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Apr 18 09:47:06.119: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 09:47:06.119: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 09:47:06.132: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999837s
    Apr 18 09:47:07.135: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997526139s
    Apr 18 09:47:08.138: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994373981s
    Apr 18 09:47:09.141: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.991201789s
    Apr 18 09:47:10.145: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.988053442s
    Apr 18 09:47:11.148: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.984801274s
    Apr 18 09:47:12.152: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.981143261s
    Apr 18 09:47:13.156: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.977062541s
    Apr 18 09:47:14.160: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.972966961s
    Apr 18 09:47:15.163: INFO: Verifying statefulset ss doesn't scale past 1 for another 969.774877ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-439 04/18/23 09:47:16.163
    Apr 18 09:47:16.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 09:47:16.284: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 18 09:47:16.284: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 09:47:16.284: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 18 09:47:16.286: INFO: Found 1 stateful pods, waiting for 3
    Apr 18 09:47:26.290: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 09:47:26.290: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 09:47:26.290: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 04/18/23 09:47:26.29
    STEP: Scale down will halt with unhealthy stateful pod 04/18/23 09:47:26.29
    Apr 18 09:47:26.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 09:47:26.401: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 09:47:26.401: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 09:47:26.401: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 09:47:26.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 09:47:26.512: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 09:47:26.512: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 09:47:26.512: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 09:47:26.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 09:47:26.610: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 09:47:26.610: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 09:47:26.610: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 09:47:26.610: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 09:47:26.612: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Apr 18 09:47:36.619: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 09:47:36.619: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 09:47:36.619: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 09:47:36.629: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999809s
    Apr 18 09:47:37.632: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997291313s
    Apr 18 09:47:38.636: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992961068s
    Apr 18 09:47:39.639: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989621547s
    Apr 18 09:47:40.643: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986365756s
    Apr 18 09:47:41.648: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.982679892s
    Apr 18 09:47:42.653: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.976620487s
    Apr 18 09:47:43.656: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.973000535s
    Apr 18 09:47:44.660: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.969600844s
    Apr 18 09:47:45.663: INFO: Verifying statefulset ss doesn't scale past 3 for another 966.33788ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-439 04/18/23 09:47:46.663
    Apr 18 09:47:46.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 09:47:46.775: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 18 09:47:46.775: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 09:47:46.775: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 18 09:47:46.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 09:47:46.881: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 18 09:47:46.881: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 09:47:46.881: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 18 09:47:46.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=statefulset-439 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 09:47:46.982: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 18 09:47:46.982: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 09:47:46.982: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 18 09:47:46.982: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 04/18/23 09:47:56.999
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 09:47:56.999: INFO: Deleting all statefulset in ns statefulset-439
    Apr 18 09:47:57.001: INFO: Scaling statefulset ss to 0
    Apr 18 09:47:57.010: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 09:47:57.012: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 09:47:57.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-439" for this suite. 04/18/23 09:47:57.028
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:47:57.034
Apr 18 09:47:57.034: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename runtimeclass 04/18/23 09:47:57.035
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:47:57.05
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:47:57.053
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 18 09:47:57.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7553" for this suite. 04/18/23 09:47:57.065
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":330,"skipped":6102,"failed":0}
------------------------------
• [0.037 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:47:57.034
    Apr 18 09:47:57.034: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename runtimeclass 04/18/23 09:47:57.035
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:47:57.05
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:47:57.053
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 18 09:47:57.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-7553" for this suite. 04/18/23 09:47:57.065
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:47:57.072
Apr 18 09:47:57.072: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 09:47:57.072
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:47:57.081
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:47:57.09
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-3743 04/18/23 09:47:57.093
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/18/23 09:47:57.103
STEP: creating service externalsvc in namespace services-3743 04/18/23 09:47:57.103
STEP: creating replication controller externalsvc in namespace services-3743 04/18/23 09:47:57.113
I0418 09:47:57.120102      18 runners.go:193] Created replication controller with name: externalsvc, namespace: services-3743, replica count: 2
I0418 09:48:00.170511      18 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 04/18/23 09:48:00.173
Apr 18 09:48:00.186: INFO: Creating new exec pod
Apr 18 09:48:00.191: INFO: Waiting up to 5m0s for pod "execpodjshfx" in namespace "services-3743" to be "running"
Apr 18 09:48:00.196: INFO: Pod "execpodjshfx": Phase="Pending", Reason="", readiness=false. Elapsed: 5.574683ms
Apr 18 09:48:02.199: INFO: Pod "execpodjshfx": Phase="Running", Reason="", readiness=true. Elapsed: 2.008503285s
Apr 18 09:48:02.199: INFO: Pod "execpodjshfx" satisfied condition "running"
Apr 18 09:48:02.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-3743 exec execpodjshfx -- /bin/sh -x -c nslookup nodeport-service.services-3743.svc.cluster.local'
Apr 18 09:48:02.383: INFO: stderr: "+ nslookup nodeport-service.services-3743.svc.cluster.local\n"
Apr 18 09:48:02.383: INFO: stdout: "Server:\t\t10.247.3.10\nAddress:\t10.247.3.10#53\n\nnodeport-service.services-3743.svc.cluster.local\tcanonical name = externalsvc.services-3743.svc.cluster.local.\nName:\texternalsvc.services-3743.svc.cluster.local\nAddress: 10.247.200.109\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3743, will wait for the garbage collector to delete the pods 04/18/23 09:48:02.383
Apr 18 09:48:02.439: INFO: Deleting ReplicationController externalsvc took: 4.008496ms
Apr 18 09:48:02.540: INFO: Terminating ReplicationController externalsvc pods took: 100.38853ms
Apr 18 09:48:04.366: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 09:48:04.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3743" for this suite. 04/18/23 09:48:04.381
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":331,"skipped":6130,"failed":0}
------------------------------
• [SLOW TEST] [7.314 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:47:57.072
    Apr 18 09:47:57.072: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 09:47:57.072
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:47:57.081
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:47:57.09
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-3743 04/18/23 09:47:57.093
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/18/23 09:47:57.103
    STEP: creating service externalsvc in namespace services-3743 04/18/23 09:47:57.103
    STEP: creating replication controller externalsvc in namespace services-3743 04/18/23 09:47:57.113
    I0418 09:47:57.120102      18 runners.go:193] Created replication controller with name: externalsvc, namespace: services-3743, replica count: 2
    I0418 09:48:00.170511      18 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 04/18/23 09:48:00.173
    Apr 18 09:48:00.186: INFO: Creating new exec pod
    Apr 18 09:48:00.191: INFO: Waiting up to 5m0s for pod "execpodjshfx" in namespace "services-3743" to be "running"
    Apr 18 09:48:00.196: INFO: Pod "execpodjshfx": Phase="Pending", Reason="", readiness=false. Elapsed: 5.574683ms
    Apr 18 09:48:02.199: INFO: Pod "execpodjshfx": Phase="Running", Reason="", readiness=true. Elapsed: 2.008503285s
    Apr 18 09:48:02.199: INFO: Pod "execpodjshfx" satisfied condition "running"
    Apr 18 09:48:02.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-3743 exec execpodjshfx -- /bin/sh -x -c nslookup nodeport-service.services-3743.svc.cluster.local'
    Apr 18 09:48:02.383: INFO: stderr: "+ nslookup nodeport-service.services-3743.svc.cluster.local\n"
    Apr 18 09:48:02.383: INFO: stdout: "Server:\t\t10.247.3.10\nAddress:\t10.247.3.10#53\n\nnodeport-service.services-3743.svc.cluster.local\tcanonical name = externalsvc.services-3743.svc.cluster.local.\nName:\texternalsvc.services-3743.svc.cluster.local\nAddress: 10.247.200.109\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-3743, will wait for the garbage collector to delete the pods 04/18/23 09:48:02.383
    Apr 18 09:48:02.439: INFO: Deleting ReplicationController externalsvc took: 4.008496ms
    Apr 18 09:48:02.540: INFO: Terminating ReplicationController externalsvc pods took: 100.38853ms
    Apr 18 09:48:04.366: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 09:48:04.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3743" for this suite. 04/18/23 09:48:04.381
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:48:04.387
Apr 18 09:48:04.387: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 09:48:04.387
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:48:04.397
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:48:04.4
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 04/18/23 09:48:04.403
Apr 18 09:48:04.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-2327 cluster-info'
Apr 18 09:48:04.458: INFO: stderr: ""
Apr 18 09:48:04.458: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.247.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 09:48:04.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2327" for this suite. 04/18/23 09:48:04.461
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":332,"skipped":6156,"failed":0}
------------------------------
• [0.079 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:48:04.387
    Apr 18 09:48:04.387: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 09:48:04.387
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:48:04.397
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:48:04.4
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 04/18/23 09:48:04.403
    Apr 18 09:48:04.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-2327 cluster-info'
    Apr 18 09:48:04.458: INFO: stderr: ""
    Apr 18 09:48:04.458: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.247.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 09:48:04.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2327" for this suite. 04/18/23 09:48:04.461
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:48:04.466
Apr 18 09:48:04.466: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename endpointslice 04/18/23 09:48:04.467
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:48:04.476
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:48:04.479
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 04/18/23 09:48:09.533
STEP: referencing matching pods with named port 04/18/23 09:48:14.539
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 04/18/23 09:48:19.545
STEP: recreating EndpointSlices after they've been deleted 04/18/23 09:48:24.551
Apr 18 09:48:24.563: INFO: EndpointSlice for Service endpointslice-6173/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 18 09:48:34.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-6173" for this suite. 04/18/23 09:48:34.574
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":333,"skipped":6185,"failed":0}
------------------------------
• [SLOW TEST] [30.112 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:48:04.466
    Apr 18 09:48:04.466: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename endpointslice 04/18/23 09:48:04.467
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:48:04.476
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:48:04.479
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 04/18/23 09:48:09.533
    STEP: referencing matching pods with named port 04/18/23 09:48:14.539
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 04/18/23 09:48:19.545
    STEP: recreating EndpointSlices after they've been deleted 04/18/23 09:48:24.551
    Apr 18 09:48:24.563: INFO: EndpointSlice for Service endpointslice-6173/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 18 09:48:34.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-6173" for this suite. 04/18/23 09:48:34.574
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:48:34.579
Apr 18 09:48:34.579: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 09:48:34.579
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:48:34.587
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:48:34.59
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-8f96d66f-0ff4-4393-a3f9-1845a155e3b4 04/18/23 09:48:34.593
STEP: Creating a pod to test consume secrets 04/18/23 09:48:34.597
Apr 18 09:48:34.603: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8" in namespace "projected-2491" to be "Succeeded or Failed"
Apr 18 09:48:34.605: INFO: Pod "pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.185313ms
Apr 18 09:48:36.608: INFO: Pod "pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005171685s
Apr 18 09:48:38.610: INFO: Pod "pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006564858s
STEP: Saw pod success 04/18/23 09:48:38.61
Apr 18 09:48:38.610: INFO: Pod "pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8" satisfied condition "Succeeded or Failed"
Apr 18 09:48:38.613: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8 container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 09:48:38.629
Apr 18 09:48:38.638: INFO: Waiting for pod pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8 to disappear
Apr 18 09:48:38.640: INFO: Pod pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 18 09:48:38.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2491" for this suite. 04/18/23 09:48:38.646
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":334,"skipped":6206,"failed":0}
------------------------------
• [4.076 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:48:34.579
    Apr 18 09:48:34.579: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 09:48:34.579
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:48:34.587
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:48:34.59
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-8f96d66f-0ff4-4393-a3f9-1845a155e3b4 04/18/23 09:48:34.593
    STEP: Creating a pod to test consume secrets 04/18/23 09:48:34.597
    Apr 18 09:48:34.603: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8" in namespace "projected-2491" to be "Succeeded or Failed"
    Apr 18 09:48:34.605: INFO: Pod "pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.185313ms
    Apr 18 09:48:36.608: INFO: Pod "pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005171685s
    Apr 18 09:48:38.610: INFO: Pod "pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006564858s
    STEP: Saw pod success 04/18/23 09:48:38.61
    Apr 18 09:48:38.610: INFO: Pod "pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8" satisfied condition "Succeeded or Failed"
    Apr 18 09:48:38.613: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8 container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 09:48:38.629
    Apr 18 09:48:38.638: INFO: Waiting for pod pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8 to disappear
    Apr 18 09:48:38.640: INFO: Pod pod-projected-secrets-32117744-755d-45b5-a972-0707901c90d8 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 18 09:48:38.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2491" for this suite. 04/18/23 09:48:38.646
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:48:38.655
Apr 18 09:48:38.655: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 09:48:38.656
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:48:38.665
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:48:38.668
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 04/18/23 09:48:38.671
Apr 18 09:48:38.678: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba" in namespace "downward-api-6150" to be "Succeeded or Failed"
Apr 18 09:48:38.692: INFO: Pod "downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba": Phase="Pending", Reason="", readiness=false. Elapsed: 13.922195ms
Apr 18 09:48:40.695: INFO: Pod "downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba": Phase="Running", Reason="", readiness=false. Elapsed: 2.017481389s
Apr 18 09:48:42.697: INFO: Pod "downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018698089s
STEP: Saw pod success 04/18/23 09:48:42.697
Apr 18 09:48:42.697: INFO: Pod "downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba" satisfied condition "Succeeded or Failed"
Apr 18 09:48:42.701: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba container client-container: <nil>
STEP: delete the pod 04/18/23 09:48:42.708
Apr 18 09:48:42.717: INFO: Waiting for pod downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba to disappear
Apr 18 09:48:42.720: INFO: Pod downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 09:48:42.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6150" for this suite. 04/18/23 09:48:42.724
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":335,"skipped":6206,"failed":0}
------------------------------
• [4.072 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:48:38.655
    Apr 18 09:48:38.655: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 09:48:38.656
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:48:38.665
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:48:38.668
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 04/18/23 09:48:38.671
    Apr 18 09:48:38.678: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba" in namespace "downward-api-6150" to be "Succeeded or Failed"
    Apr 18 09:48:38.692: INFO: Pod "downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba": Phase="Pending", Reason="", readiness=false. Elapsed: 13.922195ms
    Apr 18 09:48:40.695: INFO: Pod "downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba": Phase="Running", Reason="", readiness=false. Elapsed: 2.017481389s
    Apr 18 09:48:42.697: INFO: Pod "downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018698089s
    STEP: Saw pod success 04/18/23 09:48:42.697
    Apr 18 09:48:42.697: INFO: Pod "downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba" satisfied condition "Succeeded or Failed"
    Apr 18 09:48:42.701: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba container client-container: <nil>
    STEP: delete the pod 04/18/23 09:48:42.708
    Apr 18 09:48:42.717: INFO: Waiting for pod downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba to disappear
    Apr 18 09:48:42.720: INFO: Pod downwardapi-volume-0ecb7f8d-30c4-461f-a7c7-ae4d0bb59fba no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 09:48:42.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6150" for this suite. 04/18/23 09:48:42.724
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:48:42.728
Apr 18 09:48:42.728: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 09:48:42.729
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:48:42.738
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:48:42.741
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-6951 04/18/23 09:48:42.744
STEP: creating service affinity-nodeport in namespace services-6951 04/18/23 09:48:42.744
STEP: creating replication controller affinity-nodeport in namespace services-6951 04/18/23 09:48:42.756
I0418 09:48:42.762478      18 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-6951, replica count: 3
I0418 09:48:45.813169      18 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 09:48:45.821: INFO: Creating new exec pod
Apr 18 09:48:45.826: INFO: Waiting up to 5m0s for pod "execpod-affinityvg2wl" in namespace "services-6951" to be "running"
Apr 18 09:48:45.828: INFO: Pod "execpod-affinityvg2wl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.146097ms
Apr 18 09:48:47.832: INFO: Pod "execpod-affinityvg2wl": Phase="Running", Reason="", readiness=true. Elapsed: 2.005563986s
Apr 18 09:48:47.832: INFO: Pod "execpod-affinityvg2wl" satisfied condition "running"
Apr 18 09:48:48.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-6951 exec execpod-affinityvg2wl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Apr 18 09:48:48.944: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Apr 18 09:48:48.944: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:48:48.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-6951 exec execpod-affinityvg2wl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.32.177 80'
Apr 18 09:48:49.047: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.32.177 80\nConnection to 10.247.32.177 80 port [tcp/http] succeeded!\n"
Apr 18 09:48:49.047: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:48:49.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-6951 exec execpod-affinityvg2wl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.29 30502'
Apr 18 09:48:49.148: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.29 30502\nConnection to 192.168.1.29 30502 port [tcp/*] succeeded!\n"
Apr 18 09:48:49.148: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:48:49.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-6951 exec execpod-affinityvg2wl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.84 30502'
Apr 18 09:48:49.251: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.84 30502\nConnection to 192.168.1.84 30502 port [tcp/*] succeeded!\n"
Apr 18 09:48:49.251: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:48:49.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-6951 exec execpod-affinityvg2wl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.152:30502/ ; done'
Apr 18 09:48:49.402: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n"
Apr 18 09:48:49.402: INFO: stdout: "\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh"
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
Apr 18 09:48:49.402: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-6951, will wait for the garbage collector to delete the pods 04/18/23 09:48:49.409
Apr 18 09:48:49.467: INFO: Deleting ReplicationController affinity-nodeport took: 4.529628ms
Apr 18 09:48:49.567: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.444586ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 09:48:51.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6951" for this suite. 04/18/23 09:48:51.394
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":336,"skipped":6207,"failed":0}
------------------------------
• [SLOW TEST] [8.670 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:48:42.728
    Apr 18 09:48:42.728: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 09:48:42.729
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:48:42.738
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:48:42.741
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-6951 04/18/23 09:48:42.744
    STEP: creating service affinity-nodeport in namespace services-6951 04/18/23 09:48:42.744
    STEP: creating replication controller affinity-nodeport in namespace services-6951 04/18/23 09:48:42.756
    I0418 09:48:42.762478      18 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-6951, replica count: 3
    I0418 09:48:45.813169      18 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 09:48:45.821: INFO: Creating new exec pod
    Apr 18 09:48:45.826: INFO: Waiting up to 5m0s for pod "execpod-affinityvg2wl" in namespace "services-6951" to be "running"
    Apr 18 09:48:45.828: INFO: Pod "execpod-affinityvg2wl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.146097ms
    Apr 18 09:48:47.832: INFO: Pod "execpod-affinityvg2wl": Phase="Running", Reason="", readiness=true. Elapsed: 2.005563986s
    Apr 18 09:48:47.832: INFO: Pod "execpod-affinityvg2wl" satisfied condition "running"
    Apr 18 09:48:48.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-6951 exec execpod-affinityvg2wl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Apr 18 09:48:48.944: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Apr 18 09:48:48.944: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:48:48.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-6951 exec execpod-affinityvg2wl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.32.177 80'
    Apr 18 09:48:49.047: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.32.177 80\nConnection to 10.247.32.177 80 port [tcp/http] succeeded!\n"
    Apr 18 09:48:49.047: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:48:49.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-6951 exec execpod-affinityvg2wl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.29 30502'
    Apr 18 09:48:49.148: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.29 30502\nConnection to 192.168.1.29 30502 port [tcp/*] succeeded!\n"
    Apr 18 09:48:49.148: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:48:49.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-6951 exec execpod-affinityvg2wl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.1.84 30502'
    Apr 18 09:48:49.251: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.1.84 30502\nConnection to 192.168.1.84 30502 port [tcp/*] succeeded!\n"
    Apr 18 09:48:49.251: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:48:49.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-6951 exec execpod-affinityvg2wl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.1.152:30502/ ; done'
    Apr 18 09:48:49.402: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.1.152:30502/\n"
    Apr 18 09:48:49.402: INFO: stdout: "\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh\naffinity-nodeport-mhflh"
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Received response from host: affinity-nodeport-mhflh
    Apr 18 09:48:49.402: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-6951, will wait for the garbage collector to delete the pods 04/18/23 09:48:49.409
    Apr 18 09:48:49.467: INFO: Deleting ReplicationController affinity-nodeport took: 4.529628ms
    Apr 18 09:48:49.567: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.444586ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 09:48:51.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6951" for this suite. 04/18/23 09:48:51.394
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:48:51.399
Apr 18 09:48:51.399: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename sched-preemption 04/18/23 09:48:51.4
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:48:51.408
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:48:51.412
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 18 09:48:51.426: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 18 09:49:51.450: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:49:51.452
Apr 18 09:49:51.453: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename sched-preemption-path 04/18/23 09:49:51.453
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:49:51.461
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:49:51.464
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 04/18/23 09:49:51.468
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/18/23 09:49:51.468
Apr 18 09:49:51.473: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-1599" to be "running"
Apr 18 09:49:51.476: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.166905ms
Apr 18 09:49:53.479: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.005697505s
Apr 18 09:49:53.479: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/18/23 09:49:53.482
Apr 18 09:49:53.491: INFO: found a healthy node: 192.168.1.152
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Apr 18 09:50:03.552: INFO: pods created so far: [1 1 1]
Apr 18 09:50:03.552: INFO: length of pods created so far: 3
Apr 18 09:50:05.560: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Apr 18 09:50:12.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-1599" for this suite. 04/18/23 09:50:12.568
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 18 09:50:12.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-5308" for this suite. 04/18/23 09:50:12.598
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":337,"skipped":6224,"failed":0}
------------------------------
• [SLOW TEST] [81.237 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:48:51.399
    Apr 18 09:48:51.399: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename sched-preemption 04/18/23 09:48:51.4
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:48:51.408
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:48:51.412
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 18 09:48:51.426: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 18 09:49:51.450: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:49:51.452
    Apr 18 09:49:51.453: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename sched-preemption-path 04/18/23 09:49:51.453
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:49:51.461
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:49:51.464
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 04/18/23 09:49:51.468
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/18/23 09:49:51.468
    Apr 18 09:49:51.473: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-1599" to be "running"
    Apr 18 09:49:51.476: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.166905ms
    Apr 18 09:49:53.479: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.005697505s
    Apr 18 09:49:53.479: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/18/23 09:49:53.482
    Apr 18 09:49:53.491: INFO: found a healthy node: 192.168.1.152
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Apr 18 09:50:03.552: INFO: pods created so far: [1 1 1]
    Apr 18 09:50:03.552: INFO: length of pods created so far: 3
    Apr 18 09:50:05.560: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Apr 18 09:50:12.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-1599" for this suite. 04/18/23 09:50:12.568
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 09:50:12.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-5308" for this suite. 04/18/23 09:50:12.598
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:50:12.638
Apr 18 09:50:12.638: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename dns 04/18/23 09:50:12.639
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:12.654
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:12.657
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 04/18/23 09:50:12.66
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2478.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2478.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2478.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2478.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 71.191.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.191.71_udp@PTR;check="$$(dig +tcp +noall +answer +search 71.191.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.191.71_tcp@PTR;sleep 1; done
 04/18/23 09:50:12.675
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2478.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2478.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2478.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2478.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 71.191.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.191.71_udp@PTR;check="$$(dig +tcp +noall +answer +search 71.191.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.191.71_tcp@PTR;sleep 1; done
 04/18/23 09:50:12.675
STEP: creating a pod to probe DNS 04/18/23 09:50:12.675
STEP: submitting the pod to kubernetes 04/18/23 09:50:12.676
Apr 18 09:50:12.684: INFO: Waiting up to 15m0s for pod "dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5" in namespace "dns-2478" to be "running"
Apr 18 09:50:12.688: INFO: Pod "dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.520561ms
Apr 18 09:50:14.693: INFO: Pod "dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5": Phase="Running", Reason="", readiness=true. Elapsed: 2.008912923s
Apr 18 09:50:14.693: INFO: Pod "dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5" satisfied condition "running"
STEP: retrieving the pod 04/18/23 09:50:14.693
STEP: looking for the results for each expected name from probers 04/18/23 09:50:14.695
Apr 18 09:50:14.708: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local from pod dns-2478/dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5: the server could not find the requested resource (get pods dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5)
Apr 18 09:50:14.713: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local from pod dns-2478/dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5: the server could not find the requested resource (get pods dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5)
Apr 18 09:50:14.737: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local from pod dns-2478/dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5: the server could not find the requested resource (get pods dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5)
Apr 18 09:50:14.741: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local from pod dns-2478/dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5: the server could not find the requested resource (get pods dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5)
Apr 18 09:50:14.756: INFO: Lookups using dns-2478/dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local]

Apr 18 09:50:19.811: INFO: DNS probes using dns-2478/dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5 succeeded

STEP: deleting the pod 04/18/23 09:50:19.811
STEP: deleting the test service 04/18/23 09:50:19.822
STEP: deleting the test headless service 04/18/23 09:50:19.858
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 09:50:19.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2478" for this suite. 04/18/23 09:50:19.87
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":338,"skipped":6233,"failed":0}
------------------------------
• [SLOW TEST] [7.237 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:50:12.638
    Apr 18 09:50:12.638: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename dns 04/18/23 09:50:12.639
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:12.654
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:12.657
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 04/18/23 09:50:12.66
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2478.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2478.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2478.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2478.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 71.191.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.191.71_udp@PTR;check="$$(dig +tcp +noall +answer +search 71.191.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.191.71_tcp@PTR;sleep 1; done
     04/18/23 09:50:12.675
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2478.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2478.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2478.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2478.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2478.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 71.191.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.191.71_udp@PTR;check="$$(dig +tcp +noall +answer +search 71.191.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.191.71_tcp@PTR;sleep 1; done
     04/18/23 09:50:12.675
    STEP: creating a pod to probe DNS 04/18/23 09:50:12.675
    STEP: submitting the pod to kubernetes 04/18/23 09:50:12.676
    Apr 18 09:50:12.684: INFO: Waiting up to 15m0s for pod "dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5" in namespace "dns-2478" to be "running"
    Apr 18 09:50:12.688: INFO: Pod "dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.520561ms
    Apr 18 09:50:14.693: INFO: Pod "dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5": Phase="Running", Reason="", readiness=true. Elapsed: 2.008912923s
    Apr 18 09:50:14.693: INFO: Pod "dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 09:50:14.693
    STEP: looking for the results for each expected name from probers 04/18/23 09:50:14.695
    Apr 18 09:50:14.708: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local from pod dns-2478/dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5: the server could not find the requested resource (get pods dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5)
    Apr 18 09:50:14.713: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local from pod dns-2478/dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5: the server could not find the requested resource (get pods dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5)
    Apr 18 09:50:14.737: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local from pod dns-2478/dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5: the server could not find the requested resource (get pods dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5)
    Apr 18 09:50:14.741: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local from pod dns-2478/dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5: the server could not find the requested resource (get pods dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5)
    Apr 18 09:50:14.756: INFO: Lookups using dns-2478/dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2478.svc.cluster.local]

    Apr 18 09:50:19.811: INFO: DNS probes using dns-2478/dns-test-4b331d32-4aee-44bc-9efb-0957a9aa01f5 succeeded

    STEP: deleting the pod 04/18/23 09:50:19.811
    STEP: deleting the test service 04/18/23 09:50:19.822
    STEP: deleting the test headless service 04/18/23 09:50:19.858
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 09:50:19.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2478" for this suite. 04/18/23 09:50:19.87
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:50:19.878
Apr 18 09:50:19.878: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 09:50:19.878
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:19.888
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:19.891
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 04/18/23 09:50:19.894
Apr 18 09:50:19.899: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a" in namespace "downward-api-9554" to be "Succeeded or Failed"
Apr 18 09:50:19.902: INFO: Pod "downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.350727ms
Apr 18 09:50:21.905: INFO: Pod "downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00602298s
Apr 18 09:50:23.906: INFO: Pod "downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006171879s
STEP: Saw pod success 04/18/23 09:50:23.906
Apr 18 09:50:23.906: INFO: Pod "downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a" satisfied condition "Succeeded or Failed"
Apr 18 09:50:23.908: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a container client-container: <nil>
STEP: delete the pod 04/18/23 09:50:23.918
Apr 18 09:50:23.932: INFO: Waiting for pod downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a to disappear
Apr 18 09:50:23.934: INFO: Pod downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 09:50:23.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9554" for this suite. 04/18/23 09:50:23.938
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":339,"skipped":6273,"failed":0}
------------------------------
• [4.065 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:50:19.878
    Apr 18 09:50:19.878: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 09:50:19.878
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:19.888
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:19.891
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 04/18/23 09:50:19.894
    Apr 18 09:50:19.899: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a" in namespace "downward-api-9554" to be "Succeeded or Failed"
    Apr 18 09:50:19.902: INFO: Pod "downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.350727ms
    Apr 18 09:50:21.905: INFO: Pod "downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00602298s
    Apr 18 09:50:23.906: INFO: Pod "downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006171879s
    STEP: Saw pod success 04/18/23 09:50:23.906
    Apr 18 09:50:23.906: INFO: Pod "downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a" satisfied condition "Succeeded or Failed"
    Apr 18 09:50:23.908: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a container client-container: <nil>
    STEP: delete the pod 04/18/23 09:50:23.918
    Apr 18 09:50:23.932: INFO: Waiting for pod downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a to disappear
    Apr 18 09:50:23.934: INFO: Pod downwardapi-volume-dc453827-d2ae-4ebb-9d2b-23abb610d65a no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 09:50:23.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9554" for this suite. 04/18/23 09:50:23.938
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:50:23.944
Apr 18 09:50:23.944: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename watch 04/18/23 09:50:23.944
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:23.959
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:23.962
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 04/18/23 09:50:23.965
STEP: starting a background goroutine to produce watch events 04/18/23 09:50:23.968
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 04/18/23 09:50:23.968
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 18 09:50:26.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7514" for this suite. 04/18/23 09:50:26.798
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":340,"skipped":6275,"failed":0}
------------------------------
• [2.907 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:50:23.944
    Apr 18 09:50:23.944: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename watch 04/18/23 09:50:23.944
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:23.959
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:23.962
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 04/18/23 09:50:23.965
    STEP: starting a background goroutine to produce watch events 04/18/23 09:50:23.968
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 04/18/23 09:50:23.968
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 18 09:50:26.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-7514" for this suite. 04/18/23 09:50:26.798
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:50:26.851
Apr 18 09:50:26.851: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 09:50:26.852
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:26.86
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:26.864
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 04/18/23 09:50:26.867
Apr 18 09:50:26.873: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419" in namespace "projected-3879" to be "Succeeded or Failed"
Apr 18 09:50:26.876: INFO: Pod "downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419": Phase="Pending", Reason="", readiness=false. Elapsed: 2.298401ms
Apr 18 09:50:28.879: INFO: Pod "downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00538281s
Apr 18 09:50:30.880: INFO: Pod "downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006184308s
STEP: Saw pod success 04/18/23 09:50:30.88
Apr 18 09:50:30.880: INFO: Pod "downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419" satisfied condition "Succeeded or Failed"
Apr 18 09:50:30.887: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419 container client-container: <nil>
STEP: delete the pod 04/18/23 09:50:30.892
Apr 18 09:50:30.907: INFO: Waiting for pod downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419 to disappear
Apr 18 09:50:30.911: INFO: Pod downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 09:50:30.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3879" for this suite. 04/18/23 09:50:30.914
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":341,"skipped":6296,"failed":0}
------------------------------
• [4.067 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:50:26.851
    Apr 18 09:50:26.851: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 09:50:26.852
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:26.86
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:26.864
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 04/18/23 09:50:26.867
    Apr 18 09:50:26.873: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419" in namespace "projected-3879" to be "Succeeded or Failed"
    Apr 18 09:50:26.876: INFO: Pod "downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419": Phase="Pending", Reason="", readiness=false. Elapsed: 2.298401ms
    Apr 18 09:50:28.879: INFO: Pod "downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00538281s
    Apr 18 09:50:30.880: INFO: Pod "downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006184308s
    STEP: Saw pod success 04/18/23 09:50:30.88
    Apr 18 09:50:30.880: INFO: Pod "downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419" satisfied condition "Succeeded or Failed"
    Apr 18 09:50:30.887: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419 container client-container: <nil>
    STEP: delete the pod 04/18/23 09:50:30.892
    Apr 18 09:50:30.907: INFO: Waiting for pod downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419 to disappear
    Apr 18 09:50:30.911: INFO: Pod downwardapi-volume-dd45293a-1977-46c4-8ef3-a0d1d6f44419 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 09:50:30.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3879" for this suite. 04/18/23 09:50:30.914
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:50:30.919
Apr 18 09:50:30.920: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename configmap 04/18/23 09:50:30.92
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:30.929
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:30.932
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 04/18/23 09:50:30.935
STEP: fetching the ConfigMap 04/18/23 09:50:30.938
STEP: patching the ConfigMap 04/18/23 09:50:30.941
STEP: listing all ConfigMaps in all namespaces with a label selector 04/18/23 09:50:30.944
STEP: deleting the ConfigMap by collection with a label selector 04/18/23 09:50:30.947
STEP: listing all ConfigMaps in test namespace 04/18/23 09:50:30.952
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 09:50:30.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6289" for this suite. 04/18/23 09:50:30.957
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":342,"skipped":6304,"failed":0}
------------------------------
• [0.044 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:50:30.919
    Apr 18 09:50:30.920: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename configmap 04/18/23 09:50:30.92
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:30.929
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:30.932
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 04/18/23 09:50:30.935
    STEP: fetching the ConfigMap 04/18/23 09:50:30.938
    STEP: patching the ConfigMap 04/18/23 09:50:30.941
    STEP: listing all ConfigMaps in all namespaces with a label selector 04/18/23 09:50:30.944
    STEP: deleting the ConfigMap by collection with a label selector 04/18/23 09:50:30.947
    STEP: listing all ConfigMaps in test namespace 04/18/23 09:50:30.952
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 09:50:30.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6289" for this suite. 04/18/23 09:50:30.957
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:50:30.965
Apr 18 09:50:30.965: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 09:50:30.965
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:30.974
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:30.977
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 04/18/23 09:50:30.98
Apr 18 09:50:30.988: INFO: Waiting up to 5m0s for pod "labelsupdate514ee6b5-d8a8-40b4-881f-7693a03c1e38" in namespace "downward-api-8393" to be "running and ready"
Apr 18 09:50:30.990: INFO: Pod "labelsupdate514ee6b5-d8a8-40b4-881f-7693a03c1e38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.741003ms
Apr 18 09:50:30.990: INFO: The phase of Pod labelsupdate514ee6b5-d8a8-40b4-881f-7693a03c1e38 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:50:32.994: INFO: Pod "labelsupdate514ee6b5-d8a8-40b4-881f-7693a03c1e38": Phase="Running", Reason="", readiness=true. Elapsed: 2.006043065s
Apr 18 09:50:32.994: INFO: The phase of Pod labelsupdate514ee6b5-d8a8-40b4-881f-7693a03c1e38 is Running (Ready = true)
Apr 18 09:50:32.994: INFO: Pod "labelsupdate514ee6b5-d8a8-40b4-881f-7693a03c1e38" satisfied condition "running and ready"
Apr 18 09:50:33.512: INFO: Successfully updated pod "labelsupdate514ee6b5-d8a8-40b4-881f-7693a03c1e38"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 09:50:37.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8393" for this suite. 04/18/23 09:50:37.532
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":343,"skipped":6309,"failed":0}
------------------------------
• [SLOW TEST] [6.572 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:50:30.965
    Apr 18 09:50:30.965: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 09:50:30.965
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:30.974
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:30.977
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 04/18/23 09:50:30.98
    Apr 18 09:50:30.988: INFO: Waiting up to 5m0s for pod "labelsupdate514ee6b5-d8a8-40b4-881f-7693a03c1e38" in namespace "downward-api-8393" to be "running and ready"
    Apr 18 09:50:30.990: INFO: Pod "labelsupdate514ee6b5-d8a8-40b4-881f-7693a03c1e38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.741003ms
    Apr 18 09:50:30.990: INFO: The phase of Pod labelsupdate514ee6b5-d8a8-40b4-881f-7693a03c1e38 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:50:32.994: INFO: Pod "labelsupdate514ee6b5-d8a8-40b4-881f-7693a03c1e38": Phase="Running", Reason="", readiness=true. Elapsed: 2.006043065s
    Apr 18 09:50:32.994: INFO: The phase of Pod labelsupdate514ee6b5-d8a8-40b4-881f-7693a03c1e38 is Running (Ready = true)
    Apr 18 09:50:32.994: INFO: Pod "labelsupdate514ee6b5-d8a8-40b4-881f-7693a03c1e38" satisfied condition "running and ready"
    Apr 18 09:50:33.512: INFO: Successfully updated pod "labelsupdate514ee6b5-d8a8-40b4-881f-7693a03c1e38"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 09:50:37.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8393" for this suite. 04/18/23 09:50:37.532
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:50:37.538
Apr 18 09:50:37.538: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename downward-api 04/18/23 09:50:37.538
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:37.551
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:37.554
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 04/18/23 09:50:37.557
Apr 18 09:50:37.565: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be" in namespace "downward-api-8063" to be "Succeeded or Failed"
Apr 18 09:50:37.567: INFO: Pod "downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.34586ms
Apr 18 09:50:39.572: INFO: Pod "downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006592258s
Apr 18 09:50:41.571: INFO: Pod "downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006346996s
STEP: Saw pod success 04/18/23 09:50:41.571
Apr 18 09:50:41.571: INFO: Pod "downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be" satisfied condition "Succeeded or Failed"
Apr 18 09:50:41.575: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be container client-container: <nil>
STEP: delete the pod 04/18/23 09:50:41.58
Apr 18 09:50:41.596: INFO: Waiting for pod downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be to disappear
Apr 18 09:50:41.599: INFO: Pod downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 09:50:41.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8063" for this suite. 04/18/23 09:50:41.602
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":344,"skipped":6313,"failed":0}
------------------------------
• [4.069 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:50:37.538
    Apr 18 09:50:37.538: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename downward-api 04/18/23 09:50:37.538
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:37.551
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:37.554
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 04/18/23 09:50:37.557
    Apr 18 09:50:37.565: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be" in namespace "downward-api-8063" to be "Succeeded or Failed"
    Apr 18 09:50:37.567: INFO: Pod "downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.34586ms
    Apr 18 09:50:39.572: INFO: Pod "downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006592258s
    Apr 18 09:50:41.571: INFO: Pod "downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006346996s
    STEP: Saw pod success 04/18/23 09:50:41.571
    Apr 18 09:50:41.571: INFO: Pod "downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be" satisfied condition "Succeeded or Failed"
    Apr 18 09:50:41.575: INFO: Trying to get logs from node 192.168.1.152 pod downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be container client-container: <nil>
    STEP: delete the pod 04/18/23 09:50:41.58
    Apr 18 09:50:41.596: INFO: Waiting for pod downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be to disappear
    Apr 18 09:50:41.599: INFO: Pod downwardapi-volume-d6342404-7320-447c-a6d6-cbb79049d9be no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 09:50:41.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8063" for this suite. 04/18/23 09:50:41.602
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:50:41.61
Apr 18 09:50:41.610: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename configmap 04/18/23 09:50:41.61
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:41.62
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:41.623
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-11b9ce63-9397-49e5-bfd8-9cae3bed73fe 04/18/23 09:50:41.626
STEP: Creating a pod to test consume configMaps 04/18/23 09:50:41.63
Apr 18 09:50:41.637: INFO: Waiting up to 5m0s for pod "pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc" in namespace "configmap-9464" to be "Succeeded or Failed"
Apr 18 09:50:41.639: INFO: Pod "pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.220528ms
Apr 18 09:50:43.643: INFO: Pod "pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc": Phase="Running", Reason="", readiness=false. Elapsed: 2.005822761s
Apr 18 09:50:45.643: INFO: Pod "pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005592358s
STEP: Saw pod success 04/18/23 09:50:45.643
Apr 18 09:50:45.643: INFO: Pod "pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc" satisfied condition "Succeeded or Failed"
Apr 18 09:50:45.645: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc container agnhost-container: <nil>
STEP: delete the pod 04/18/23 09:50:45.65
Apr 18 09:50:45.659: INFO: Waiting for pod pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc to disappear
Apr 18 09:50:45.661: INFO: Pod pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 09:50:45.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9464" for this suite. 04/18/23 09:50:45.665
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":345,"skipped":6348,"failed":0}
------------------------------
• [4.059 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:50:41.61
    Apr 18 09:50:41.610: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename configmap 04/18/23 09:50:41.61
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:41.62
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:41.623
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-11b9ce63-9397-49e5-bfd8-9cae3bed73fe 04/18/23 09:50:41.626
    STEP: Creating a pod to test consume configMaps 04/18/23 09:50:41.63
    Apr 18 09:50:41.637: INFO: Waiting up to 5m0s for pod "pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc" in namespace "configmap-9464" to be "Succeeded or Failed"
    Apr 18 09:50:41.639: INFO: Pod "pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.220528ms
    Apr 18 09:50:43.643: INFO: Pod "pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc": Phase="Running", Reason="", readiness=false. Elapsed: 2.005822761s
    Apr 18 09:50:45.643: INFO: Pod "pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005592358s
    STEP: Saw pod success 04/18/23 09:50:45.643
    Apr 18 09:50:45.643: INFO: Pod "pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc" satisfied condition "Succeeded or Failed"
    Apr 18 09:50:45.645: INFO: Trying to get logs from node 192.168.1.152 pod pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 09:50:45.65
    Apr 18 09:50:45.659: INFO: Waiting for pod pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc to disappear
    Apr 18 09:50:45.661: INFO: Pod pod-configmaps-de183c36-fc62-40b8-9471-19c2323d25cc no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 09:50:45.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9464" for this suite. 04/18/23 09:50:45.665
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:50:45.67
Apr 18 09:50:45.670: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename pod-network-test 04/18/23 09:50:45.67
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:45.68
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:45.683
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-7517 04/18/23 09:50:45.686
STEP: creating a selector 04/18/23 09:50:45.686
STEP: Creating the service pods in kubernetes 04/18/23 09:50:45.686
Apr 18 09:50:45.686: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 18 09:50:45.710: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7517" to be "running and ready"
Apr 18 09:50:45.716: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.653573ms
Apr 18 09:50:45.716: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:50:47.720: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.009265272s
Apr 18 09:50:47.720: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:50:49.719: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.009127303s
Apr 18 09:50:49.720: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:50:51.720: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.009433572s
Apr 18 09:50:51.720: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:50:53.719: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.00849625s
Apr 18 09:50:53.719: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:50:55.720: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.009768838s
Apr 18 09:50:55.720: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 09:50:57.719: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.008761756s
Apr 18 09:50:57.719: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 18 09:50:57.719: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 18 09:50:57.722: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7517" to be "running and ready"
Apr 18 09:50:57.724: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.310996ms
Apr 18 09:50:57.724: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 18 09:50:57.724: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 18 09:50:57.726: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-7517" to be "running and ready"
Apr 18 09:50:57.728: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.107489ms
Apr 18 09:50:57.728: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 18 09:50:57.728: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/18/23 09:50:57.73
Apr 18 09:50:57.734: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7517" to be "running"
Apr 18 09:50:57.737: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.445305ms
Apr 18 09:50:59.740: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.006024634s
Apr 18 09:50:59.740: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 18 09:50:59.743: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 18 09:50:59.743: INFO: Breadth first check of 172.16.1.119 on host 192.168.1.152...
Apr 18 09:50:59.746: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.1.120:9080/dial?request=hostname&protocol=http&host=172.16.1.119&port=8083&tries=1'] Namespace:pod-network-test-7517 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 09:50:59.746: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 09:50:59.746: INFO: ExecWithOptions: Clientset creation
Apr 18 09:50:59.746: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-7517/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.1.120%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.1.119%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 18 09:50:59.797: INFO: Waiting for responses: map[]
Apr 18 09:50:59.797: INFO: reached 172.16.1.119 after 0/1 tries
Apr 18 09:50:59.797: INFO: Breadth first check of 172.16.0.104 on host 192.168.1.29...
Apr 18 09:50:59.800: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.1.120:9080/dial?request=hostname&protocol=http&host=172.16.0.104&port=8083&tries=1'] Namespace:pod-network-test-7517 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 09:50:59.800: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 09:50:59.800: INFO: ExecWithOptions: Clientset creation
Apr 18 09:50:59.800: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-7517/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.1.120%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.0.104%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 18 09:50:59.851: INFO: Waiting for responses: map[]
Apr 18 09:50:59.851: INFO: reached 172.16.0.104 after 0/1 tries
Apr 18 09:50:59.851: INFO: Breadth first check of 172.16.0.252 on host 192.168.1.84...
Apr 18 09:50:59.854: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.1.120:9080/dial?request=hostname&protocol=http&host=172.16.0.252&port=8083&tries=1'] Namespace:pod-network-test-7517 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 09:50:59.854: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
Apr 18 09:50:59.854: INFO: ExecWithOptions: Clientset creation
Apr 18 09:50:59.854: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-7517/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.1.120%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.0.252%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 18 09:50:59.910: INFO: Waiting for responses: map[]
Apr 18 09:50:59.910: INFO: reached 172.16.0.252 after 0/1 tries
Apr 18 09:50:59.910: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 18 09:50:59.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7517" for this suite. 04/18/23 09:50:59.914
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":346,"skipped":6360,"failed":0}
------------------------------
• [SLOW TEST] [14.249 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:50:45.67
    Apr 18 09:50:45.670: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename pod-network-test 04/18/23 09:50:45.67
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:45.68
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:45.683
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-7517 04/18/23 09:50:45.686
    STEP: creating a selector 04/18/23 09:50:45.686
    STEP: Creating the service pods in kubernetes 04/18/23 09:50:45.686
    Apr 18 09:50:45.686: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 18 09:50:45.710: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7517" to be "running and ready"
    Apr 18 09:50:45.716: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.653573ms
    Apr 18 09:50:45.716: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:50:47.720: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.009265272s
    Apr 18 09:50:47.720: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:50:49.719: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.009127303s
    Apr 18 09:50:49.720: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:50:51.720: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.009433572s
    Apr 18 09:50:51.720: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:50:53.719: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.00849625s
    Apr 18 09:50:53.719: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:50:55.720: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.009768838s
    Apr 18 09:50:55.720: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 09:50:57.719: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.008761756s
    Apr 18 09:50:57.719: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 18 09:50:57.719: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 18 09:50:57.722: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7517" to be "running and ready"
    Apr 18 09:50:57.724: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.310996ms
    Apr 18 09:50:57.724: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 18 09:50:57.724: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 18 09:50:57.726: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-7517" to be "running and ready"
    Apr 18 09:50:57.728: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.107489ms
    Apr 18 09:50:57.728: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 18 09:50:57.728: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/18/23 09:50:57.73
    Apr 18 09:50:57.734: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7517" to be "running"
    Apr 18 09:50:57.737: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.445305ms
    Apr 18 09:50:59.740: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.006024634s
    Apr 18 09:50:59.740: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 18 09:50:59.743: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 18 09:50:59.743: INFO: Breadth first check of 172.16.1.119 on host 192.168.1.152...
    Apr 18 09:50:59.746: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.1.120:9080/dial?request=hostname&protocol=http&host=172.16.1.119&port=8083&tries=1'] Namespace:pod-network-test-7517 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 09:50:59.746: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 09:50:59.746: INFO: ExecWithOptions: Clientset creation
    Apr 18 09:50:59.746: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-7517/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.1.120%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.1.119%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 18 09:50:59.797: INFO: Waiting for responses: map[]
    Apr 18 09:50:59.797: INFO: reached 172.16.1.119 after 0/1 tries
    Apr 18 09:50:59.797: INFO: Breadth first check of 172.16.0.104 on host 192.168.1.29...
    Apr 18 09:50:59.800: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.1.120:9080/dial?request=hostname&protocol=http&host=172.16.0.104&port=8083&tries=1'] Namespace:pod-network-test-7517 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 09:50:59.800: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 09:50:59.800: INFO: ExecWithOptions: Clientset creation
    Apr 18 09:50:59.800: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-7517/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.1.120%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.0.104%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 18 09:50:59.851: INFO: Waiting for responses: map[]
    Apr 18 09:50:59.851: INFO: reached 172.16.0.104 after 0/1 tries
    Apr 18 09:50:59.851: INFO: Breadth first check of 172.16.0.252 on host 192.168.1.84...
    Apr 18 09:50:59.854: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.1.120:9080/dial?request=hostname&protocol=http&host=172.16.0.252&port=8083&tries=1'] Namespace:pod-network-test-7517 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 09:50:59.854: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    Apr 18 09:50:59.854: INFO: ExecWithOptions: Clientset creation
    Apr 18 09:50:59.854: INFO: ExecWithOptions: execute(POST https://10.247.0.1:443/api/v1/namespaces/pod-network-test-7517/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.1.120%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.0.252%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 18 09:50:59.910: INFO: Waiting for responses: map[]
    Apr 18 09:50:59.910: INFO: reached 172.16.0.252 after 0/1 tries
    Apr 18 09:50:59.910: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 18 09:50:59.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-7517" for this suite. 04/18/23 09:50:59.914
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:50:59.92
Apr 18 09:50:59.920: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename resourcequota 04/18/23 09:50:59.921
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:59.929
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:59.932
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 04/18/23 09:50:59.936
STEP: Creating a ResourceQuota 04/18/23 09:51:04.938
STEP: Ensuring resource quota status is calculated 04/18/23 09:51:04.945
STEP: Creating a Pod that fits quota 04/18/23 09:51:06.95
STEP: Ensuring ResourceQuota status captures the pod usage 04/18/23 09:51:06.963
STEP: Not allowing a pod to be created that exceeds remaining quota 04/18/23 09:51:08.968
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 04/18/23 09:51:08.971
STEP: Ensuring a pod cannot update its resource requirements 04/18/23 09:51:08.974
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 04/18/23 09:51:08.979
STEP: Deleting the pod 04/18/23 09:51:10.982
STEP: Ensuring resource quota status released the pod usage 04/18/23 09:51:10.994
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 09:51:12.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6935" for this suite. 04/18/23 09:51:13
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":347,"skipped":6388,"failed":0}
------------------------------
• [SLOW TEST] [13.085 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:50:59.92
    Apr 18 09:50:59.920: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename resourcequota 04/18/23 09:50:59.921
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:50:59.929
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:50:59.932
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 04/18/23 09:50:59.936
    STEP: Creating a ResourceQuota 04/18/23 09:51:04.938
    STEP: Ensuring resource quota status is calculated 04/18/23 09:51:04.945
    STEP: Creating a Pod that fits quota 04/18/23 09:51:06.95
    STEP: Ensuring ResourceQuota status captures the pod usage 04/18/23 09:51:06.963
    STEP: Not allowing a pod to be created that exceeds remaining quota 04/18/23 09:51:08.968
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 04/18/23 09:51:08.971
    STEP: Ensuring a pod cannot update its resource requirements 04/18/23 09:51:08.974
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 04/18/23 09:51:08.979
    STEP: Deleting the pod 04/18/23 09:51:10.982
    STEP: Ensuring resource quota status released the pod usage 04/18/23 09:51:10.994
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 09:51:12.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6935" for this suite. 04/18/23 09:51:13
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:51:13.006
Apr 18 09:51:13.006: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename replication-controller 04/18/23 09:51:13.007
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:51:13.018
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:51:13.021
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 04/18/23 09:51:13.024
Apr 18 09:51:13.030: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-7414" to be "running and ready"
Apr 18 09:51:13.032: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 2.48638ms
Apr 18 09:51:13.032: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:51:15.036: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.005844371s
Apr 18 09:51:15.036: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Apr 18 09:51:15.036: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 04/18/23 09:51:15.038
STEP: Then the orphan pod is adopted 04/18/23 09:51:15.042
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 18 09:51:16.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7414" for this suite. 04/18/23 09:51:16.052
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":348,"skipped":6402,"failed":0}
------------------------------
• [3.051 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:51:13.006
    Apr 18 09:51:13.006: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename replication-controller 04/18/23 09:51:13.007
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:51:13.018
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:51:13.021
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 04/18/23 09:51:13.024
    Apr 18 09:51:13.030: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-7414" to be "running and ready"
    Apr 18 09:51:13.032: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 2.48638ms
    Apr 18 09:51:13.032: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:51:15.036: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.005844371s
    Apr 18 09:51:15.036: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Apr 18 09:51:15.036: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 04/18/23 09:51:15.038
    STEP: Then the orphan pod is adopted 04/18/23 09:51:15.042
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 18 09:51:16.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-7414" for this suite. 04/18/23 09:51:16.052
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:51:16.058
Apr 18 09:51:16.058: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename projected 04/18/23 09:51:16.059
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:51:16.07
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:51:16.073
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-6bb7b807-3c19-4160-8915-de962161aba5 04/18/23 09:51:16.076
STEP: Creating a pod to test consume configMaps 04/18/23 09:51:16.08
Apr 18 09:51:16.087: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91" in namespace "projected-6803" to be "Succeeded or Failed"
Apr 18 09:51:16.089: INFO: Pod "pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.838004ms
Apr 18 09:51:18.093: INFO: Pod "pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00620756s
Apr 18 09:51:20.094: INFO: Pod "pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007015513s
STEP: Saw pod success 04/18/23 09:51:20.094
Apr 18 09:51:20.094: INFO: Pod "pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91" satisfied condition "Succeeded or Failed"
Apr 18 09:51:20.097: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 09:51:20.102
Apr 18 09:51:20.111: INFO: Waiting for pod pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91 to disappear
Apr 18 09:51:20.114: INFO: Pod pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 09:51:20.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6803" for this suite. 04/18/23 09:51:20.118
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":349,"skipped":6459,"failed":0}
------------------------------
• [4.064 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:51:16.058
    Apr 18 09:51:16.058: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename projected 04/18/23 09:51:16.059
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:51:16.07
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:51:16.073
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-6bb7b807-3c19-4160-8915-de962161aba5 04/18/23 09:51:16.076
    STEP: Creating a pod to test consume configMaps 04/18/23 09:51:16.08
    Apr 18 09:51:16.087: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91" in namespace "projected-6803" to be "Succeeded or Failed"
    Apr 18 09:51:16.089: INFO: Pod "pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.838004ms
    Apr 18 09:51:18.093: INFO: Pod "pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00620756s
    Apr 18 09:51:20.094: INFO: Pod "pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007015513s
    STEP: Saw pod success 04/18/23 09:51:20.094
    Apr 18 09:51:20.094: INFO: Pod "pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91" satisfied condition "Succeeded or Failed"
    Apr 18 09:51:20.097: INFO: Trying to get logs from node 192.168.1.152 pod pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 09:51:20.102
    Apr 18 09:51:20.111: INFO: Waiting for pod pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91 to disappear
    Apr 18 09:51:20.114: INFO: Pod pod-projected-configmaps-ccc7cc98-7310-4d6b-8be4-87b4094beb91 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 09:51:20.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6803" for this suite. 04/18/23 09:51:20.118
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:51:20.122
Apr 18 09:51:20.122: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 09:51:20.123
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:51:20.133
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:51:20.136
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/18/23 09:51:20.142
Apr 18 09:51:20.148: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4857" to be "running and ready"
Apr 18 09:51:20.150: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.177484ms
Apr 18 09:51:20.150: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:51:22.153: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.005196695s
Apr 18 09:51:22.153: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 18 09:51:22.153: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 04/18/23 09:51:22.155
Apr 18 09:51:22.160: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-4857" to be "running and ready"
Apr 18 09:51:22.162: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.530173ms
Apr 18 09:51:22.162: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:51:24.166: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.005614813s
Apr 18 09:51:24.166: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Apr 18 09:51:24.166: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 04/18/23 09:51:24.168
Apr 18 09:51:24.181: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 18 09:51:24.183: INFO: Pod pod-with-prestop-http-hook still exists
Apr 18 09:51:26.184: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 18 09:51:26.187: INFO: Pod pod-with-prestop-http-hook still exists
Apr 18 09:51:28.184: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 18 09:51:28.187: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 04/18/23 09:51:28.187
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 18 09:51:28.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4857" for this suite. 04/18/23 09:51:28.201
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":350,"skipped":6461,"failed":0}
------------------------------
• [SLOW TEST] [8.084 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:51:20.122
    Apr 18 09:51:20.122: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 09:51:20.123
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:51:20.133
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:51:20.136
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/18/23 09:51:20.142
    Apr 18 09:51:20.148: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4857" to be "running and ready"
    Apr 18 09:51:20.150: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.177484ms
    Apr 18 09:51:20.150: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:51:22.153: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.005196695s
    Apr 18 09:51:22.153: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 18 09:51:22.153: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 04/18/23 09:51:22.155
    Apr 18 09:51:22.160: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-4857" to be "running and ready"
    Apr 18 09:51:22.162: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.530173ms
    Apr 18 09:51:22.162: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:51:24.166: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.005614813s
    Apr 18 09:51:24.166: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Apr 18 09:51:24.166: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 04/18/23 09:51:24.168
    Apr 18 09:51:24.181: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 18 09:51:24.183: INFO: Pod pod-with-prestop-http-hook still exists
    Apr 18 09:51:26.184: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 18 09:51:26.187: INFO: Pod pod-with-prestop-http-hook still exists
    Apr 18 09:51:28.184: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 18 09:51:28.187: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 04/18/23 09:51:28.187
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 18 09:51:28.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-4857" for this suite. 04/18/23 09:51:28.201
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:51:28.209
Apr 18 09:51:28.209: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename subpath 04/18/23 09:51:28.209
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:51:28.218
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:51:28.221
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/18/23 09:51:28.224
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-rnwx 04/18/23 09:51:28.231
STEP: Creating a pod to test atomic-volume-subpath 04/18/23 09:51:28.231
Apr 18 09:51:28.238: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-rnwx" in namespace "subpath-1614" to be "Succeeded or Failed"
Apr 18 09:51:28.240: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.783555ms
Apr 18 09:51:30.244: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 2.006289366s
Apr 18 09:51:32.244: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 4.006183003s
Apr 18 09:51:34.248: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 6.010154849s
Apr 18 09:51:36.245: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 8.007657398s
Apr 18 09:51:38.244: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 10.006701995s
Apr 18 09:51:40.245: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 12.006977577s
Apr 18 09:51:42.244: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 14.006647573s
Apr 18 09:51:44.245: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 16.007138879s
Apr 18 09:51:46.244: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 18.005909087s
Apr 18 09:51:48.246: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 20.00798146s
Apr 18 09:51:50.244: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=false. Elapsed: 22.006146219s
Apr 18 09:51:52.244: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.006415597s
STEP: Saw pod success 04/18/23 09:51:52.244
Apr 18 09:51:52.244: INFO: Pod "pod-subpath-test-projected-rnwx" satisfied condition "Succeeded or Failed"
Apr 18 09:51:52.247: INFO: Trying to get logs from node 192.168.1.152 pod pod-subpath-test-projected-rnwx container test-container-subpath-projected-rnwx: <nil>
STEP: delete the pod 04/18/23 09:51:52.253
Apr 18 09:51:52.262: INFO: Waiting for pod pod-subpath-test-projected-rnwx to disappear
Apr 18 09:51:52.265: INFO: Pod pod-subpath-test-projected-rnwx no longer exists
STEP: Deleting pod pod-subpath-test-projected-rnwx 04/18/23 09:51:52.265
Apr 18 09:51:52.265: INFO: Deleting pod "pod-subpath-test-projected-rnwx" in namespace "subpath-1614"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 18 09:51:52.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1614" for this suite. 04/18/23 09:51:52.271
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":351,"skipped":6494,"failed":0}
------------------------------
• [SLOW TEST] [24.067 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:51:28.209
    Apr 18 09:51:28.209: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename subpath 04/18/23 09:51:28.209
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:51:28.218
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:51:28.221
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/18/23 09:51:28.224
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-rnwx 04/18/23 09:51:28.231
    STEP: Creating a pod to test atomic-volume-subpath 04/18/23 09:51:28.231
    Apr 18 09:51:28.238: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-rnwx" in namespace "subpath-1614" to be "Succeeded or Failed"
    Apr 18 09:51:28.240: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.783555ms
    Apr 18 09:51:30.244: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 2.006289366s
    Apr 18 09:51:32.244: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 4.006183003s
    Apr 18 09:51:34.248: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 6.010154849s
    Apr 18 09:51:36.245: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 8.007657398s
    Apr 18 09:51:38.244: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 10.006701995s
    Apr 18 09:51:40.245: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 12.006977577s
    Apr 18 09:51:42.244: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 14.006647573s
    Apr 18 09:51:44.245: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 16.007138879s
    Apr 18 09:51:46.244: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 18.005909087s
    Apr 18 09:51:48.246: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=true. Elapsed: 20.00798146s
    Apr 18 09:51:50.244: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Running", Reason="", readiness=false. Elapsed: 22.006146219s
    Apr 18 09:51:52.244: INFO: Pod "pod-subpath-test-projected-rnwx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.006415597s
    STEP: Saw pod success 04/18/23 09:51:52.244
    Apr 18 09:51:52.244: INFO: Pod "pod-subpath-test-projected-rnwx" satisfied condition "Succeeded or Failed"
    Apr 18 09:51:52.247: INFO: Trying to get logs from node 192.168.1.152 pod pod-subpath-test-projected-rnwx container test-container-subpath-projected-rnwx: <nil>
    STEP: delete the pod 04/18/23 09:51:52.253
    Apr 18 09:51:52.262: INFO: Waiting for pod pod-subpath-test-projected-rnwx to disappear
    Apr 18 09:51:52.265: INFO: Pod pod-subpath-test-projected-rnwx no longer exists
    STEP: Deleting pod pod-subpath-test-projected-rnwx 04/18/23 09:51:52.265
    Apr 18 09:51:52.265: INFO: Deleting pod "pod-subpath-test-projected-rnwx" in namespace "subpath-1614"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 18 09:51:52.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-1614" for this suite. 04/18/23 09:51:52.271
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:51:52.276
Apr 18 09:51:52.276: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename statefulset 04/18/23 09:51:52.277
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:51:52.284
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:51:52.287
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2870 04/18/23 09:51:52.291
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-2870 04/18/23 09:51:52.297
Apr 18 09:51:52.304: INFO: Found 0 stateful pods, waiting for 1
Apr 18 09:52:02.308: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 04/18/23 09:52:02.313
STEP: Getting /status 04/18/23 09:52:02.318
Apr 18 09:52:02.321: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 04/18/23 09:52:02.321
Apr 18 09:52:02.330: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 04/18/23 09:52:02.33
Apr 18 09:52:02.332: INFO: Observed &StatefulSet event: ADDED
Apr 18 09:52:02.332: INFO: Found Statefulset ss in namespace statefulset-2870 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 18 09:52:02.332: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 04/18/23 09:52:02.332
Apr 18 09:52:02.332: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 18 09:52:02.337: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 04/18/23 09:52:02.337
Apr 18 09:52:02.339: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 09:52:02.340: INFO: Deleting all statefulset in ns statefulset-2870
Apr 18 09:52:02.345: INFO: Scaling statefulset ss to 0
Apr 18 09:52:12.367: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 09:52:12.369: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 09:52:12.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2870" for this suite. 04/18/23 09:52:12.385
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":352,"skipped":6498,"failed":0}
------------------------------
• [SLOW TEST] [20.114 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:51:52.276
    Apr 18 09:51:52.276: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename statefulset 04/18/23 09:51:52.277
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:51:52.284
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:51:52.287
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2870 04/18/23 09:51:52.291
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-2870 04/18/23 09:51:52.297
    Apr 18 09:51:52.304: INFO: Found 0 stateful pods, waiting for 1
    Apr 18 09:52:02.308: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 04/18/23 09:52:02.313
    STEP: Getting /status 04/18/23 09:52:02.318
    Apr 18 09:52:02.321: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 04/18/23 09:52:02.321
    Apr 18 09:52:02.330: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 04/18/23 09:52:02.33
    Apr 18 09:52:02.332: INFO: Observed &StatefulSet event: ADDED
    Apr 18 09:52:02.332: INFO: Found Statefulset ss in namespace statefulset-2870 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 18 09:52:02.332: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 04/18/23 09:52:02.332
    Apr 18 09:52:02.332: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 18 09:52:02.337: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 04/18/23 09:52:02.337
    Apr 18 09:52:02.339: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 09:52:02.340: INFO: Deleting all statefulset in ns statefulset-2870
    Apr 18 09:52:02.345: INFO: Scaling statefulset ss to 0
    Apr 18 09:52:12.367: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 09:52:12.369: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 09:52:12.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2870" for this suite. 04/18/23 09:52:12.385
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:52:12.39
Apr 18 09:52:12.391: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 09:52:12.391
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:52:12.4
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:52:12.403
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Apr 18 09:52:12.406: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/18/23 09:52:14.621
Apr 18 09:52:14.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-6954 --namespace=crd-publish-openapi-6954 create -f -'
Apr 18 09:52:15.307: INFO: stderr: ""
Apr 18 09:52:15.307: INFO: stdout: "e2e-test-crd-publish-openapi-7003-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 18 09:52:15.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-6954 --namespace=crd-publish-openapi-6954 delete e2e-test-crd-publish-openapi-7003-crds test-cr'
Apr 18 09:52:15.366: INFO: stderr: ""
Apr 18 09:52:15.366: INFO: stdout: "e2e-test-crd-publish-openapi-7003-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Apr 18 09:52:15.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-6954 --namespace=crd-publish-openapi-6954 apply -f -'
Apr 18 09:52:15.526: INFO: stderr: ""
Apr 18 09:52:15.526: INFO: stdout: "e2e-test-crd-publish-openapi-7003-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 18 09:52:15.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-6954 --namespace=crd-publish-openapi-6954 delete e2e-test-crd-publish-openapi-7003-crds test-cr'
Apr 18 09:52:15.586: INFO: stderr: ""
Apr 18 09:52:15.586: INFO: stdout: "e2e-test-crd-publish-openapi-7003-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 04/18/23 09:52:15.586
Apr 18 09:52:15.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-6954 explain e2e-test-crd-publish-openapi-7003-crds'
Apr 18 09:52:15.737: INFO: stderr: ""
Apr 18 09:52:15.737: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7003-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:52:17.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6954" for this suite. 04/18/23 09:52:17.895
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":353,"skipped":6502,"failed":0}
------------------------------
• [SLOW TEST] [5.509 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:52:12.39
    Apr 18 09:52:12.391: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 09:52:12.391
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:52:12.4
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:52:12.403
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Apr 18 09:52:12.406: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/18/23 09:52:14.621
    Apr 18 09:52:14.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-6954 --namespace=crd-publish-openapi-6954 create -f -'
    Apr 18 09:52:15.307: INFO: stderr: ""
    Apr 18 09:52:15.307: INFO: stdout: "e2e-test-crd-publish-openapi-7003-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Apr 18 09:52:15.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-6954 --namespace=crd-publish-openapi-6954 delete e2e-test-crd-publish-openapi-7003-crds test-cr'
    Apr 18 09:52:15.366: INFO: stderr: ""
    Apr 18 09:52:15.366: INFO: stdout: "e2e-test-crd-publish-openapi-7003-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Apr 18 09:52:15.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-6954 --namespace=crd-publish-openapi-6954 apply -f -'
    Apr 18 09:52:15.526: INFO: stderr: ""
    Apr 18 09:52:15.526: INFO: stdout: "e2e-test-crd-publish-openapi-7003-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Apr 18 09:52:15.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-6954 --namespace=crd-publish-openapi-6954 delete e2e-test-crd-publish-openapi-7003-crds test-cr'
    Apr 18 09:52:15.586: INFO: stderr: ""
    Apr 18 09:52:15.586: INFO: stdout: "e2e-test-crd-publish-openapi-7003-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 04/18/23 09:52:15.586
    Apr 18 09:52:15.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=crd-publish-openapi-6954 explain e2e-test-crd-publish-openapi-7003-crds'
    Apr 18 09:52:15.737: INFO: stderr: ""
    Apr 18 09:52:15.737: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7003-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:52:17.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6954" for this suite. 04/18/23 09:52:17.895
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:52:17.901
Apr 18 09:52:17.901: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename services 04/18/23 09:52:17.901
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:52:17.911
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:52:17.915
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-7461 04/18/23 09:52:17.919
Apr 18 09:52:17.926: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-7461" to be "running and ready"
Apr 18 09:52:17.929: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 3.047562ms
Apr 18 09:52:17.930: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Apr 18 09:52:19.934: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.007149295s
Apr 18 09:52:19.934: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Apr 18 09:52:19.934: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Apr 18 09:52:19.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7461 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Apr 18 09:52:20.045: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Apr 18 09:52:20.045: INFO: stdout: "iptables"
Apr 18 09:52:20.045: INFO: proxyMode: iptables
Apr 18 09:52:20.057: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Apr 18 09:52:20.060: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-7461 04/18/23 09:52:20.06
STEP: creating replication controller affinity-clusterip-timeout in namespace services-7461 04/18/23 09:52:20.069
I0418 09:52:20.073384      18 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-7461, replica count: 3
I0418 09:52:23.124668      18 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 09:52:23.130: INFO: Creating new exec pod
Apr 18 09:52:23.135: INFO: Waiting up to 5m0s for pod "execpod-affinityn5ccj" in namespace "services-7461" to be "running"
Apr 18 09:52:23.137: INFO: Pod "execpod-affinityn5ccj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.75046ms
Apr 18 09:52:25.142: INFO: Pod "execpod-affinityn5ccj": Phase="Running", Reason="", readiness=true. Elapsed: 2.007091562s
Apr 18 09:52:25.142: INFO: Pod "execpod-affinityn5ccj" satisfied condition "running"
Apr 18 09:52:26.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7461 exec execpod-affinityn5ccj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Apr 18 09:52:26.268: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Apr 18 09:52:26.268: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:52:26.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7461 exec execpod-affinityn5ccj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.34.162 80'
Apr 18 09:52:26.368: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.34.162 80\nConnection to 10.247.34.162 80 port [tcp/http] succeeded!\n"
Apr 18 09:52:26.368: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 09:52:26.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7461 exec execpod-affinityn5ccj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.247.34.162:80/ ; done'
Apr 18 09:52:26.522: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n"
Apr 18 09:52:26.522: INFO: stdout: "\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg"
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
Apr 18 09:52:26.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7461 exec execpod-affinityn5ccj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.247.34.162:80/'
Apr 18 09:52:26.633: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n"
Apr 18 09:52:26.633: INFO: stdout: "affinity-clusterip-timeout-kfbqg"
Apr 18 09:52:46.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7461 exec execpod-affinityn5ccj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.247.34.162:80/'
Apr 18 09:52:46.737: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n"
Apr 18 09:52:46.737: INFO: stdout: "affinity-clusterip-timeout-5qbs4"
Apr 18 09:52:46.737: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-7461, will wait for the garbage collector to delete the pods 04/18/23 09:52:46.749
Apr 18 09:52:46.807: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 4.629077ms
Apr 18 09:52:46.907: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.372646ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 09:52:48.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7461" for this suite. 04/18/23 09:52:48.826
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":354,"skipped":6511,"failed":0}
------------------------------
• [SLOW TEST] [30.931 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:52:17.901
    Apr 18 09:52:17.901: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename services 04/18/23 09:52:17.901
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:52:17.911
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:52:17.915
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-7461 04/18/23 09:52:17.919
    Apr 18 09:52:17.926: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-7461" to be "running and ready"
    Apr 18 09:52:17.929: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 3.047562ms
    Apr 18 09:52:17.930: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 09:52:19.934: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.007149295s
    Apr 18 09:52:19.934: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Apr 18 09:52:19.934: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Apr 18 09:52:19.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7461 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Apr 18 09:52:20.045: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Apr 18 09:52:20.045: INFO: stdout: "iptables"
    Apr 18 09:52:20.045: INFO: proxyMode: iptables
    Apr 18 09:52:20.057: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Apr 18 09:52:20.060: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-7461 04/18/23 09:52:20.06
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-7461 04/18/23 09:52:20.069
    I0418 09:52:20.073384      18 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-7461, replica count: 3
    I0418 09:52:23.124668      18 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 09:52:23.130: INFO: Creating new exec pod
    Apr 18 09:52:23.135: INFO: Waiting up to 5m0s for pod "execpod-affinityn5ccj" in namespace "services-7461" to be "running"
    Apr 18 09:52:23.137: INFO: Pod "execpod-affinityn5ccj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.75046ms
    Apr 18 09:52:25.142: INFO: Pod "execpod-affinityn5ccj": Phase="Running", Reason="", readiness=true. Elapsed: 2.007091562s
    Apr 18 09:52:25.142: INFO: Pod "execpod-affinityn5ccj" satisfied condition "running"
    Apr 18 09:52:26.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7461 exec execpod-affinityn5ccj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Apr 18 09:52:26.268: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Apr 18 09:52:26.268: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:52:26.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7461 exec execpod-affinityn5ccj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.247.34.162 80'
    Apr 18 09:52:26.368: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.247.34.162 80\nConnection to 10.247.34.162 80 port [tcp/http] succeeded!\n"
    Apr 18 09:52:26.368: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 09:52:26.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7461 exec execpod-affinityn5ccj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.247.34.162:80/ ; done'
    Apr 18 09:52:26.522: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n"
    Apr 18 09:52:26.522: INFO: stdout: "\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg\naffinity-clusterip-timeout-kfbqg"
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Received response from host: affinity-clusterip-timeout-kfbqg
    Apr 18 09:52:26.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7461 exec execpod-affinityn5ccj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.247.34.162:80/'
    Apr 18 09:52:26.633: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n"
    Apr 18 09:52:26.633: INFO: stdout: "affinity-clusterip-timeout-kfbqg"
    Apr 18 09:52:46.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=services-7461 exec execpod-affinityn5ccj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.247.34.162:80/'
    Apr 18 09:52:46.737: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.247.34.162:80/\n"
    Apr 18 09:52:46.737: INFO: stdout: "affinity-clusterip-timeout-5qbs4"
    Apr 18 09:52:46.737: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-7461, will wait for the garbage collector to delete the pods 04/18/23 09:52:46.749
    Apr 18 09:52:46.807: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 4.629077ms
    Apr 18 09:52:46.907: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.372646ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 09:52:48.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7461" for this suite. 04/18/23 09:52:48.826
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:52:48.832
Apr 18 09:52:48.832: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename resourcequota 04/18/23 09:52:48.832
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:52:48.841
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:52:48.847
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 04/18/23 09:52:48.851
STEP: Getting a ResourceQuota 04/18/23 09:52:48.855
STEP: Updating a ResourceQuota 04/18/23 09:52:48.86
STEP: Verifying a ResourceQuota was modified 04/18/23 09:52:48.864
STEP: Deleting a ResourceQuota 04/18/23 09:52:48.867
STEP: Verifying the deleted ResourceQuota 04/18/23 09:52:48.871
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 09:52:48.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3124" for this suite. 04/18/23 09:52:48.878
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":355,"skipped":6521,"failed":0}
------------------------------
• [0.051 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:52:48.832
    Apr 18 09:52:48.832: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename resourcequota 04/18/23 09:52:48.832
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:52:48.841
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:52:48.847
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 04/18/23 09:52:48.851
    STEP: Getting a ResourceQuota 04/18/23 09:52:48.855
    STEP: Updating a ResourceQuota 04/18/23 09:52:48.86
    STEP: Verifying a ResourceQuota was modified 04/18/23 09:52:48.864
    STEP: Deleting a ResourceQuota 04/18/23 09:52:48.867
    STEP: Verifying the deleted ResourceQuota 04/18/23 09:52:48.871
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 09:52:48.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3124" for this suite. 04/18/23 09:52:48.878
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:52:48.883
Apr 18 09:52:48.883: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename endpointslicemirroring 04/18/23 09:52:48.884
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:52:48.897
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:52:48.901
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 04/18/23 09:52:48.913
Apr 18 09:52:48.920: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 04/18/23 09:52:50.924
STEP: mirroring deletion of a custom Endpoint 04/18/23 09:52:50.933
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Apr 18 09:52:50.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-1138" for this suite. 04/18/23 09:52:50.952
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":356,"skipped":6526,"failed":0}
------------------------------
• [2.093 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:52:48.883
    Apr 18 09:52:48.883: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename endpointslicemirroring 04/18/23 09:52:48.884
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:52:48.897
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:52:48.901
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 04/18/23 09:52:48.913
    Apr 18 09:52:48.920: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 04/18/23 09:52:50.924
    STEP: mirroring deletion of a custom Endpoint 04/18/23 09:52:50.933
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Apr 18 09:52:50.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-1138" for this suite. 04/18/23 09:52:50.952
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:52:50.977
Apr 18 09:52:50.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 09:52:50.977
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:52:50.999
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:52:51.003
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Apr 18 09:52:51.007: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:52:57.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5110" for this suite. 04/18/23 09:52:57.225
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":357,"skipped":6538,"failed":0}
------------------------------
• [SLOW TEST] [6.254 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:52:50.977
    Apr 18 09:52:50.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 09:52:50.977
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:52:50.999
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:52:51.003
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Apr 18 09:52:51.007: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:52:57.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-5110" for this suite. 04/18/23 09:52:57.225
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:52:57.234
Apr 18 09:52:57.234: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename container-probe 04/18/23 09:52:57.234
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:52:57.246
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:52:57.25
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-01caa1a2-ffa2-494e-841a-1c5a3d690377 in namespace container-probe-4171 04/18/23 09:52:57.255
Apr 18 09:52:57.261: INFO: Waiting up to 5m0s for pod "busybox-01caa1a2-ffa2-494e-841a-1c5a3d690377" in namespace "container-probe-4171" to be "not pending"
Apr 18 09:52:57.264: INFO: Pod "busybox-01caa1a2-ffa2-494e-841a-1c5a3d690377": Phase="Pending", Reason="", readiness=false. Elapsed: 2.927044ms
Apr 18 09:52:59.269: INFO: Pod "busybox-01caa1a2-ffa2-494e-841a-1c5a3d690377": Phase="Running", Reason="", readiness=true. Elapsed: 2.008167975s
Apr 18 09:52:59.269: INFO: Pod "busybox-01caa1a2-ffa2-494e-841a-1c5a3d690377" satisfied condition "not pending"
Apr 18 09:52:59.269: INFO: Started pod busybox-01caa1a2-ffa2-494e-841a-1c5a3d690377 in namespace container-probe-4171
STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 09:52:59.269
Apr 18 09:52:59.272: INFO: Initial restart count of pod busybox-01caa1a2-ffa2-494e-841a-1c5a3d690377 is 0
STEP: deleting the pod 04/18/23 09:56:59.758
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 09:56:59.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4171" for this suite. 04/18/23 09:56:59.782
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":358,"skipped":6565,"failed":0}
------------------------------
• [SLOW TEST] [242.553 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:52:57.234
    Apr 18 09:52:57.234: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename container-probe 04/18/23 09:52:57.234
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:52:57.246
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:52:57.25
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-01caa1a2-ffa2-494e-841a-1c5a3d690377 in namespace container-probe-4171 04/18/23 09:52:57.255
    Apr 18 09:52:57.261: INFO: Waiting up to 5m0s for pod "busybox-01caa1a2-ffa2-494e-841a-1c5a3d690377" in namespace "container-probe-4171" to be "not pending"
    Apr 18 09:52:57.264: INFO: Pod "busybox-01caa1a2-ffa2-494e-841a-1c5a3d690377": Phase="Pending", Reason="", readiness=false. Elapsed: 2.927044ms
    Apr 18 09:52:59.269: INFO: Pod "busybox-01caa1a2-ffa2-494e-841a-1c5a3d690377": Phase="Running", Reason="", readiness=true. Elapsed: 2.008167975s
    Apr 18 09:52:59.269: INFO: Pod "busybox-01caa1a2-ffa2-494e-841a-1c5a3d690377" satisfied condition "not pending"
    Apr 18 09:52:59.269: INFO: Started pod busybox-01caa1a2-ffa2-494e-841a-1c5a3d690377 in namespace container-probe-4171
    STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 09:52:59.269
    Apr 18 09:52:59.272: INFO: Initial restart count of pod busybox-01caa1a2-ffa2-494e-841a-1c5a3d690377 is 0
    STEP: deleting the pod 04/18/23 09:56:59.758
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 09:56:59.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4171" for this suite. 04/18/23 09:56:59.782
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:56:59.788
Apr 18 09:56:59.788: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename init-container 04/18/23 09:56:59.789
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:56:59.802
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:56:59.812
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 04/18/23 09:56:59.816
Apr 18 09:56:59.816: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 18 09:57:03.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5522" for this suite. 04/18/23 09:57:03.167
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":359,"skipped":6595,"failed":0}
------------------------------
• [3.383 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:56:59.788
    Apr 18 09:56:59.788: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename init-container 04/18/23 09:56:59.789
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:56:59.802
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:56:59.812
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 04/18/23 09:56:59.816
    Apr 18 09:56:59.816: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 18 09:57:03.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-5522" for this suite. 04/18/23 09:57:03.167
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:57:03.173
Apr 18 09:57:03.173: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename webhook 04/18/23 09:57:03.176
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:57:03.186
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:57:03.19
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 09:57:03.203
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:57:03.527
STEP: Deploying the webhook pod 04/18/23 09:57:03.534
STEP: Wait for the deployment to be ready 04/18/23 09:57:03.547
Apr 18 09:57:03.552: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 04/18/23 09:57:05.563
STEP: Verifying the service has paired with the endpoint 04/18/23 09:57:05.574
Apr 18 09:57:06.575: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 04/18/23 09:57:06.578
STEP: create a pod that should be updated by the webhook 04/18/23 09:57:06.593
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 09:57:06.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8382" for this suite. 04/18/23 09:57:06.616
STEP: Destroying namespace "webhook-8382-markers" for this suite. 04/18/23 09:57:06.624
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":360,"skipped":6624,"failed":0}
------------------------------
• [3.494 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:57:03.173
    Apr 18 09:57:03.173: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename webhook 04/18/23 09:57:03.176
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:57:03.186
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:57:03.19
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 09:57:03.203
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 09:57:03.527
    STEP: Deploying the webhook pod 04/18/23 09:57:03.534
    STEP: Wait for the deployment to be ready 04/18/23 09:57:03.547
    Apr 18 09:57:03.552: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 04/18/23 09:57:05.563
    STEP: Verifying the service has paired with the endpoint 04/18/23 09:57:05.574
    Apr 18 09:57:06.575: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 04/18/23 09:57:06.578
    STEP: create a pod that should be updated by the webhook 04/18/23 09:57:06.593
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 09:57:06.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8382" for this suite. 04/18/23 09:57:06.616
    STEP: Destroying namespace "webhook-8382-markers" for this suite. 04/18/23 09:57:06.624
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:57:06.667
Apr 18 09:57:06.667: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename kubectl 04/18/23 09:57:06.668
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:57:06.682
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:57:06.685
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 04/18/23 09:57:06.689
Apr 18 09:57:06.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 create -f -'
Apr 18 09:57:07.647: INFO: stderr: ""
Apr 18 09:57:07.647: INFO: stdout: "pod/pause created\n"
Apr 18 09:57:07.647: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 18 09:57:07.647: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3450" to be "running and ready"
Apr 18 09:57:07.653: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.977219ms
Apr 18 09:57:07.653: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '192.168.1.152' to be 'Running' but was 'Pending'
Apr 18 09:57:09.657: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009727312s
Apr 18 09:57:09.657: INFO: Pod "pause" satisfied condition "running and ready"
Apr 18 09:57:09.657: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 04/18/23 09:57:09.657
Apr 18 09:57:09.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 label pods pause testing-label=testing-label-value'
Apr 18 09:57:09.721: INFO: stderr: ""
Apr 18 09:57:09.721: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 04/18/23 09:57:09.721
Apr 18 09:57:09.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 get pod pause -L testing-label'
Apr 18 09:57:09.777: INFO: stderr: ""
Apr 18 09:57:09.777: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod 04/18/23 09:57:09.777
Apr 18 09:57:09.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 label pods pause testing-label-'
Apr 18 09:57:09.839: INFO: stderr: ""
Apr 18 09:57:09.839: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 04/18/23 09:57:09.839
Apr 18 09:57:09.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 get pod pause -L testing-label'
Apr 18 09:57:09.893: INFO: stderr: ""
Apr 18 09:57:09.893: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 04/18/23 09:57:09.893
Apr 18 09:57:09.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 delete --grace-period=0 --force -f -'
Apr 18 09:57:09.950: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 09:57:09.950: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 18 09:57:09.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 get rc,svc -l name=pause --no-headers'
Apr 18 09:57:10.012: INFO: stderr: "No resources found in kubectl-3450 namespace.\n"
Apr 18 09:57:10.012: INFO: stdout: ""
Apr 18 09:57:10.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 18 09:57:10.066: INFO: stderr: ""
Apr 18 09:57:10.066: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 09:57:10.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3450" for this suite. 04/18/23 09:57:10.071
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":361,"skipped":6632,"failed":0}
------------------------------
• [3.411 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:57:06.667
    Apr 18 09:57:06.667: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename kubectl 04/18/23 09:57:06.668
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:57:06.682
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:57:06.685
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 04/18/23 09:57:06.689
    Apr 18 09:57:06.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 create -f -'
    Apr 18 09:57:07.647: INFO: stderr: ""
    Apr 18 09:57:07.647: INFO: stdout: "pod/pause created\n"
    Apr 18 09:57:07.647: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Apr 18 09:57:07.647: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3450" to be "running and ready"
    Apr 18 09:57:07.653: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.977219ms
    Apr 18 09:57:07.653: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '192.168.1.152' to be 'Running' but was 'Pending'
    Apr 18 09:57:09.657: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009727312s
    Apr 18 09:57:09.657: INFO: Pod "pause" satisfied condition "running and ready"
    Apr 18 09:57:09.657: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 04/18/23 09:57:09.657
    Apr 18 09:57:09.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 label pods pause testing-label=testing-label-value'
    Apr 18 09:57:09.721: INFO: stderr: ""
    Apr 18 09:57:09.721: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 04/18/23 09:57:09.721
    Apr 18 09:57:09.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 get pod pause -L testing-label'
    Apr 18 09:57:09.777: INFO: stderr: ""
    Apr 18 09:57:09.777: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 04/18/23 09:57:09.777
    Apr 18 09:57:09.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 label pods pause testing-label-'
    Apr 18 09:57:09.839: INFO: stderr: ""
    Apr 18 09:57:09.839: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 04/18/23 09:57:09.839
    Apr 18 09:57:09.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 get pod pause -L testing-label'
    Apr 18 09:57:09.893: INFO: stderr: ""
    Apr 18 09:57:09.893: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 04/18/23 09:57:09.893
    Apr 18 09:57:09.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 delete --grace-period=0 --force -f -'
    Apr 18 09:57:09.950: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 09:57:09.950: INFO: stdout: "pod \"pause\" force deleted\n"
    Apr 18 09:57:09.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 get rc,svc -l name=pause --no-headers'
    Apr 18 09:57:10.012: INFO: stderr: "No resources found in kubectl-3450 namespace.\n"
    Apr 18 09:57:10.012: INFO: stdout: ""
    Apr 18 09:57:10.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1343477019 --namespace=kubectl-3450 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 18 09:57:10.066: INFO: stderr: ""
    Apr 18 09:57:10.066: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 09:57:10.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3450" for this suite. 04/18/23 09:57:10.071
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 09:57:10.079
Apr 18 09:57:10.079: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
STEP: Building a namespace api object, basename deployment 04/18/23 09:57:10.08
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:57:10.09
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:57:10.093
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Apr 18 09:57:10.097: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 18 09:57:10.106: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 18 09:57:15.110: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/18/23 09:57:15.11
Apr 18 09:57:15.110: INFO: Creating deployment "test-rolling-update-deployment"
Apr 18 09:57:15.115: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 18 09:57:15.119: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 18 09:57:17.127: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 18 09:57:17.129: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 09:57:17.137: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-4177  d164fa6c-5365-4736-b027-62a3226a9d01 4206029 1 2023-04-18 09:57:15 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-04-18 09:57:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 09:57:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0051fc9d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-18 09:57:15 +0000 UTC,LastTransitionTime:2023-04-18 09:57:15 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-04-18 09:57:16 +0000 UTC,LastTransitionTime:2023-04-18 09:57:15 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 18 09:57:17.140: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-4177  748e0ced-5b0e-4fcf-992d-2bfcbbff8226 4206022 1 2023-04-18 09:57:15 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment d164fa6c-5365-4736-b027-62a3226a9d01 0xc005bc1b47 0xc005bc1b48}] [] [{kube-controller-manager Update apps/v1 2023-04-18 09:57:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d164fa6c-5365-4736-b027-62a3226a9d01\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 09:57:16 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005bc1bf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 18 09:57:17.140: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 18 09:57:17.140: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-4177  1843e270-613f-4ee7-ad34-38b4b83063bc 4206028 2 2023-04-18 09:57:10 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment d164fa6c-5365-4736-b027-62a3226a9d01 0xc005bc1a17 0xc005bc1a18}] [] [{e2e.test Update apps/v1 2023-04-18 09:57:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 09:57:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d164fa6c-5365-4736-b027-62a3226a9d01\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-18 09:57:16 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005bc1ad8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 18 09:57:17.143: INFO: Pod "test-rolling-update-deployment-78f575d8ff-flpbc" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-flpbc test-rolling-update-deployment-78f575d8ff- deployment-4177  211e30a3-505e-4009-9f4d-3c4beaf5ee66 4206021 0 2023-04-18 09:57:15 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 748e0ced-5b0e-4fcf-992d-2bfcbbff8226 0xc0051fd097 0xc0051fd098}] [] [{kube-controller-manager Update v1 2023-04-18 09:57:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"748e0ced-5b0e-4fcf-992d-2bfcbbff8226\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:57:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sqvz2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sqvz2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:57:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:57:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:57:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:57:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.7,StartTime:2023-04-18 09:57:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:57:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://914002e34d5391a1dab2c08ccec2f9f36e6aeff0bf794cc9c75b7a8b3e414107,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 09:57:17.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4177" for this suite. 04/18/23 09:57:17.149
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":362,"skipped":6692,"failed":0}
------------------------------
• [SLOW TEST] [7.075 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 09:57:10.079
    Apr 18 09:57:10.079: INFO: >>> kubeConfig: /tmp/kubeconfig-1343477019
    STEP: Building a namespace api object, basename deployment 04/18/23 09:57:10.08
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 09:57:10.09
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 09:57:10.093
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Apr 18 09:57:10.097: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Apr 18 09:57:10.106: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 18 09:57:15.110: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/18/23 09:57:15.11
    Apr 18 09:57:15.110: INFO: Creating deployment "test-rolling-update-deployment"
    Apr 18 09:57:15.115: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Apr 18 09:57:15.119: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Apr 18 09:57:17.127: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Apr 18 09:57:17.129: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 09:57:17.137: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-4177  d164fa6c-5365-4736-b027-62a3226a9d01 4206029 1 2023-04-18 09:57:15 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-04-18 09:57:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 09:57:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0051fc9d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-18 09:57:15 +0000 UTC,LastTransitionTime:2023-04-18 09:57:15 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-04-18 09:57:16 +0000 UTC,LastTransitionTime:2023-04-18 09:57:15 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 18 09:57:17.140: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-4177  748e0ced-5b0e-4fcf-992d-2bfcbbff8226 4206022 1 2023-04-18 09:57:15 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment d164fa6c-5365-4736-b027-62a3226a9d01 0xc005bc1b47 0xc005bc1b48}] [] [{kube-controller-manager Update apps/v1 2023-04-18 09:57:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d164fa6c-5365-4736-b027-62a3226a9d01\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 09:57:16 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005bc1bf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 09:57:17.140: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Apr 18 09:57:17.140: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-4177  1843e270-613f-4ee7-ad34-38b4b83063bc 4206028 2 2023-04-18 09:57:10 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment d164fa6c-5365-4736-b027-62a3226a9d01 0xc005bc1a17 0xc005bc1a18}] [] [{e2e.test Update apps/v1 2023-04-18 09:57:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 09:57:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d164fa6c-5365-4736-b027-62a3226a9d01\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-18 09:57:16 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005bc1ad8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 09:57:17.143: INFO: Pod "test-rolling-update-deployment-78f575d8ff-flpbc" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-flpbc test-rolling-update-deployment-78f575d8ff- deployment-4177  211e30a3-505e-4009-9f4d-3c4beaf5ee66 4206021 0 2023-04-18 09:57:15 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 748e0ced-5b0e-4fcf-992d-2bfcbbff8226 0xc0051fd097 0xc0051fd098}] [] [{kube-controller-manager Update v1 2023-04-18 09:57:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"748e0ced-5b0e-4fcf-992d-2bfcbbff8226\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 09:57:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sqvz2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sqvz2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.1.152,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[]PodDNSConfigOption{PodDNSConfigOption{Name:single-request-reopen,Value:*,},PodDNSConfigOption{Name:timeout,Value:*2,},},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:57:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:57:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:57:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 09:57:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.152,PodIP:172.16.1.7,StartTime:2023-04-18 09:57:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 09:57:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://914002e34d5391a1dab2c08ccec2f9f36e6aeff0bf794cc9c75b7a8b3e414107,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 09:57:17.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-4177" for this suite. 04/18/23 09:57:17.149
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6705,"failed":0}
Apr 18 09:57:17.156: INFO: Running AfterSuite actions on all nodes
Apr 18 09:57:17.156: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Apr 18 09:57:17.157: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Apr 18 09:57:17.157: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Apr 18 09:57:17.157: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Apr 18 09:57:17.157: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Apr 18 09:57:17.157: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Apr 18 09:57:17.157: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Apr 18 09:57:17.157: INFO: Running AfterSuite actions on node 1
Apr 18 09:57:17.157: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.001 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Apr 18 09:57:17.156: INFO: Running AfterSuite actions on all nodes
    Apr 18 09:57:17.156: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Apr 18 09:57:17.157: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Apr 18 09:57:17.157: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Apr 18 09:57:17.157: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Apr 18 09:57:17.157: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Apr 18 09:57:17.157: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Apr 18 09:57:17.157: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Apr 18 09:57:17.157: INFO: Running AfterSuite actions on node 1
    Apr 18 09:57:17.157: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.065 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7067 Specs in 5484.304 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6705 Skipped
PASS

Ginkgo ran 1 suite in 1h31m24.554474858s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.4[0m

